{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da3874d",
   "metadata": {},
   "source": [
    "In the field of machine learning, categorical features play a crucial role in determining the predictive ability of a model. Categorical features are features that can take a limited number of values, such as color, gender or location. While these features can provide useful insights into patterns and relationships within data, they also pose unique challenges for machine learning models.\n",
    "\n",
    "One of these challenges is the need to transform categorical features before they can be used by most models. This transformation involves converting categorical values into numerical values that can be processed by the machine learning algorithm.\n",
    "\n",
    "Another challenge is dealing with infrequent categories, which can lead to biased models. If a categorical feature has a large number of categories, but some of them are rare or appear infrequently in the data, the model may not be able to learn accurately from these categories, resulting in biased predictions and inaccurate results.\n",
    "\n",
    "Despite these difficulties, categorical features are still an essential component in many use cases. When properly encoded and handled, machine learning models can effectively learn from patterns and relationships in categorical data, leading to better predictions.\n",
    "\n",
    "There are various transformations described in the literature, each with its own benefits and drawbacks. Choosing the right one can significantly impact model performance. This document describes three of the most commonly used transformations: One-hot encoding, Ordinal encoding, and Target encoding, and explains how to apply them in skforecast using scikit-learn encoders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dea38b7",
   "metadata": {},
   "source": [
    "## Ordinal encoding\n",
    "\n",
    "Ordinal encoding is a technique used to convert categorical variables into numerical variables. Each category is assigned a unique numerical value based on its order or rank, as determined by a chosen criterion such as frequency or importance. This encoding method is particularly useful when categories have a natural order or ranking, such as with educational levels. However, it is important to note that the numerical values assigned to each category do not represent any inherent numerical difference between them, but simply provide a numerical representation.\n",
    "\n",
    "The `OrdinalEncoder` class in Scikit-learn can be used to transform each categorical feature into a new feature of integers, with values ranging from 0 to n_categories-1. This class also offers the `encoded_missing_value` parameter to encode missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b55fbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [nan],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "X = [['male'], ['female'], [np.nan], ['female']]\n",
    "encoder.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c879c7a7",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "In One hot encoding, also known as dummy encoding or one-of-K encoding, each categorical value is converted into a binary vector of 0s and 1s, where the index of the 1 represents the category. For example, suppose we have a dataset that includes a categorical variable called \"color\" with possible values \"red,\" \"blue,\" and \"green.\" To use this variable in a machine learning algorithm, we would convert it into a set of binary variables, such as \"color_red,\" \"color_blue,\" and \"color_green,\" where each variable has a value of either 0 or 1 depending on the category.\n",
    "\n",
    "The `OneHotEncoder` class in Scikit-learn can be used to transforms each categorical feature with n_categories possible values into n_categories binary features, with one of them 1, and all others 0.  One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the `parameter drop='if_binary'`. When `handle_unknown='ignore'` and `drop` is not None, unknown categories will be encoded as all zeros.\n",
    "\n",
    "OneHotEncoder also supports categorical features with missing values by considering the missing values as an additional category. If a feature contains both `np.nan` and `None`, they will be considered separate categories.\n",
    "\n",
    "Furthermore, OneHotEncoder supports aggregating infrequent categories into a single output for each feature. The parameters to enable the gathering of infrequent categories are `min_frequency` and `max_categories`. By setting `handle_unknown` to 'infrequent_if_exist', unknown categories will be considered infrequent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a9aad4d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0827a570",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "Coming Soon. This section is currently being created :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac014ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
