{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da3874d",
   "metadata": {},
   "source": [
    "In the field of machine learning, categorical features play a crucial role in determining the predictive ability of a model. Categorical features are features that can take a limited number of values, such as color, gender or location. While these features can provide useful insights into patterns and relationships within data, they also pose unique challenges for machine learning models.\n",
    "\n",
    "One of these challenges is the need to transform categorical features before they can be used by most models. This transformation involves converting categorical values into numerical values that can be processed by machine learning algorithm.\n",
    "\n",
    "Another challenge is dealing with infrequent categories, which can lead to biased models. If a categorical feature has a large number of categories, but some of them are rare or appear infrequently in the data, the model may not be able to learn accurately from these categories, resulting in biased predictions and inaccurate results.\n",
    "\n",
    "Despite these difficulties, categorical features are still an essential component in many use cases. When properly encoded and handled, machine learning models can effectively learn from patterns and relationships in categorical data, leading to better predictions.\n",
    "\n",
    "This document provides an overview of three of the most commonly used transformations: one-hot encoding, ordinal encoding, and target encoding. It explains how to apply them in the skforecast package using scikit-learn encoders, which provide a convenient and flexible way to preprocess data. Additionally, it demonstrates how to use the native implementation of four popular gradient boosting frameworks – **LightGBM**, **scikit-learn's HistogramGradientBoosting**, **XGBoost**, and **CatBoost** – to handle categorical features directly in the model.\n",
    "\n",
    "For a comprehensive demonstration of the use of categorical features in time series forecasting, check out the article [Forecasting time series with gradient boosting: Skforecast, XGBoost, LightGBM y CatBoost](https://www.cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bd0a8e9",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "All transformations described in this document can be applied to the entire dataset independently of the forecaster. However, it is crucial to ensure that the transformations are learned exclusively from the training data to prevent information leakage. Furthermore, the same transformation should be applied to the input data during predictions. To reduce the likelihood of errors and ensure consistent application of transformations, it is advisable to include the transformation within the forecaster object, so that it is handled internally.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15dfe9dc",
   "metadata": {},
   "source": [
    "## Libraries and data\n",
    "\n",
    "The dataset utilized in this user guide consists of information on the user count of a bicycle rental service, in addition to weather variables and holiday data. Two of the variables in the dataset, namely \"holiday\" and \"weather\", are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69472e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Joaquín Amat\\\\Documents\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent.parent))\n",
    "str(Path.cwd().parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "563e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc5647b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday     object\n",
      "weather     object\n",
      "temp       float64\n",
      "hum        float64\n",
      "users      float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    holiday weather  temp   hum  users\n",
       "date_time                                             \n",
       "2011-01-01 00:00:00       0   clear  9.84  81.0   16.0\n",
       "2011-01-01 01:00:00       0   clear  9.02  80.0   40.0\n",
       "2011-01-01 02:00:00       0   clear  9.02  80.0   32.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/Estadistica-machine-'\n",
    "       'learning-python/master/data/bike_sharing_dataset_clean.csv')\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Preprocess data\n",
    "# ==============================================================================\n",
    "data['date_time'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('date_time')\n",
    "data = data.asfreq('H')\n",
    "data = data.sort_index()\n",
    "data['holiday'] = data['holiday'].astype(int)\n",
    "data = data[['holiday', 'weather', 'temp', 'hum', 'users']]\n",
    "data[['holiday', 'weather']] = data[['holiday', 'weather']].astype(str)\n",
    "print(data.dtypes)\n",
    "data.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42b58b7c",
   "metadata": {},
   "source": [
    "To simplify the example, only a portion of the data is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fb9a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates train : 2012-06-01 00:00:00 --- 2012-07-31 23:00:00  (n=1464)\n",
      "Dates test  : 2012-08-01 00:00:00 --- 2012-08-15 23:00:00  (n=360)\n"
     ]
    }
   ],
   "source": [
    "# Split train-test\n",
    "# ==============================================================================\n",
    "start_train = '2012-06-01 00:00:00'\n",
    "end_train = '2012-07-31 23:59:00'\n",
    "end_test = '2012-08-15 23:59:00'\n",
    "data_train = data.loc[start_train:end_train, :]\n",
    "data_test  = data.loc[end_train:end_test, :]\n",
    "\n",
    "print(f\"Dates train : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Dates test  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c879c7a7",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "One hot encoding, also known as dummy encoding or one-of-K encoding, consists in replacing the categorical variable by a group of binary variables which take value 0 or 1, to indicate if a certain category is present in an observation. For example, suppose a dataset that includes a categorical variable called \"color\" with possible values of \"red,\" \"blue,\" and \"green.\" Using one hot encoding, this variable is converted into three binary variables such as \"color_red,\" \"color_blue,\" and \"color_green,\" where each variable takes a value of 0 or 1 depending on the category.\n",
    "\n",
    "The [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) class in scikit-learn can be used to transform each categorical feature with *n* possible values into *n* new binary features, with one of them taking the value 1, and all others 0. The `OneHotEncoder` can be configured to handle certain corner cases, including unknown categories, missing values, and infrequent categories.\n",
    "\n",
    "+ When `handle_unknown='ignore'` and `drop` is not `None`, unknown categories are encoded as zeros. Additionally, if a feature contains both `np.nan` and `None`, they will be considered separate categories.\n",
    "\n",
    "+ It supports aggregating infrequent categories into a single output for each feature. The parameters to enable the gathering of infrequent categories are `min_frequency` and `max_categories`. By setting `handle_unknown` to 'infrequent_if_exist', unknown categories will be considered infrequent.\n",
    "\n",
    "+ To avoid collinearity between features, it is possible to drop one of the categories per feature using the `drop` argument. This is particularly important when using linear models.\n",
    "\n",
    "\n",
    "[ColumnTransformers](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) in scikit-learn provide a powerful way to define transformations and apply them to specific features. By encapsulating the `OneHotEncoder` within a `ColumnTransformer` object, it can be passed to a forecaster using the `transformer_exog` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a90de56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer with one-hot encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using one-hot encoding. Numerical features are left untouched. For binary\n",
    "# features, only one column is created.\n",
    "one_hot_encoder = make_column_transformer(\n",
    "                    (\n",
    "                        OneHotEncoder(sparse_output=False, drop='if_binary'),\n",
    "                        make_column_selector(dtype_exclude=np.number)\n",
    "                    ),\n",
    "                    remainder=\"passthrough\",\n",
    "                    verbose_feature_names_out=False,\n",
    "                ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad53b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(random_state=123) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for y: None \n",
       "Transformer for exog: ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(drop='if_binary',\n",
       "                                               sparse_output=False),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC2FE0>)],\n",
       "                  verbose_feature_names_out=False) \n",
       "Window size: 5 \n",
       "Weight function included: False \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['holiday', 'weather', 'temp', 'hum'] \n",
       "Training range: [Timestamp('2011-01-01 00:00:00'), Timestamp('2012-07-31 23:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: H \n",
       "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-04-30 23:22:19 \n",
       "Last fit date: 2023-04-30 23:22:19 \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.10.0 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster with a transformer for exogenous features\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123),\n",
    "                lags = 5,\n",
    "                transformer_exog = one_hot_encoder\n",
    "             )\n",
    "\n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2d4e38c",
   "metadata": {},
   "source": [
    "Once the forecaster has been trained, the transformer can be inspected (feature_names_in, feature_names_out, ...) by accessing the `transformer_exog` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "705f4d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holiday_1' 'weather_clear' 'weather_mist' 'weather_rain' 'temp' 'hum']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC2FE0&gt;)],\n",
       "                  verbose_feature_names_out=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC2FE0&gt;)],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC2FE0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;temp&#x27;, &#x27;hum&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('onehotencoder',\n",
       "                                 OneHotEncoder(drop='if_binary',\n",
       "                                               sparse_output=False),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC2FE0>)],\n",
       "                  verbose_feature_names_out=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access to the transformer used for exogenous features\n",
    "# ==============================================================================\n",
    "print(forecaster.transformer_exog.get_feature_names_out())\n",
    "forecaster.transformer_exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1b232a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    88.946940\n",
       "2012-08-01 01:00:00    59.848451\n",
       "2012-08-01 02:00:00    28.870817\n",
       "Freq: H, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f865c551",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "Applying a transformation to the entire dataset independent of the forecaster is feasible. However, it is crucial to ensure that the transformations are learned exclusively from the training data to prevent information leakage. Additionally, the same transformation should be applied to the input data during predictions. Therefore, it is advisable to include the transformation within the forecaster, so that it is handled internally. This approach ensures consistency in the application of transformations and reduces the likelihood of errors.\n",
    "\n",
    "To examine how data is being transformed, it is possible to use the method <code>create_train_X_y</code> to generate the matrices the forecaster is using to train the model. This approach enables gaining insight into the specific data manipulations that occur during the training process.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69b6faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_1            float64\n",
      "lag_2            float64\n",
      "lag_3            float64\n",
      "lag_4            float64\n",
      "lag_5            float64\n",
      "holiday_1        float64\n",
      "weather_clear    float64\n",
      "weather_mist     float64\n",
      "weather_rain     float64\n",
      "temp             float64\n",
      "hum              float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>weather_clear</th>\n",
       "      <th>weather_mist</th>\n",
       "      <th>weather_rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5  holiday_1  \\\n",
       "date_time                                                           \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0        0.0   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0        0.0   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0        0.0   \n",
       "2011-01-01 08:00:00    3.0    2.0    1.0    1.0   13.0        0.0   \n",
       "2011-01-01 09:00:00    8.0    3.0    2.0    1.0    1.0        0.0   \n",
       "\n",
       "                     weather_clear  weather_mist  weather_rain   temp   hum  \n",
       "date_time                                                                    \n",
       "2011-01-01 05:00:00            0.0           1.0           0.0   9.84  75.0  \n",
       "2011-01-01 06:00:00            1.0           0.0           0.0   9.02  80.0  \n",
       "2011-01-01 07:00:00            1.0           0.0           0.0   8.20  86.0  \n",
       "2011-01-01 08:00:00            1.0           0.0           0.0   9.84  75.0  \n",
       "2011-01-01 09:00:00            1.0           0.0           0.0  13.12  76.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'],\n",
    "                        exog = data.loc[:end_train, exog_features]\n",
    "                   )\n",
    "print(X_train.dtypes)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e33abd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>weather_clear</th>\n",
       "      <th>weather_mist</th>\n",
       "      <th>weather_rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     holiday_1  weather_clear  weather_mist  weather_rain  \\\n",
       "date_time                                                                   \n",
       "2011-01-01 00:00:00        0.0            1.0           0.0           0.0   \n",
       "2011-01-01 01:00:00        0.0            1.0           0.0           0.0   \n",
       "2011-01-01 02:00:00        0.0            1.0           0.0           0.0   \n",
       "2011-01-01 03:00:00        0.0            1.0           0.0           0.0   \n",
       "2011-01-01 04:00:00        0.0            1.0           0.0           0.0   \n",
       "\n",
       "                     temp   hum  \n",
       "date_time                        \n",
       "2011-01-01 00:00:00  9.84  81.0  \n",
       "2011-01-01 01:00:00  9.02  80.0  \n",
       "2011-01-01 02:00:00  9.02  80.0  \n",
       "2011-01-01 03:00:00  9.84  75.0  \n",
       "2011-01-01 04:00:00  9.84  75.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform exogenous features using the transformer outside the forecaster\n",
    "# ==============================================================================\n",
    "exog_transformed = one_hot_encoder.fit_transform(data.loc[:end_train, exog_features])\n",
    "exog_transformed.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dea38b7",
   "metadata": {},
   "source": [
    "## Ordinal encoding\n",
    "\n",
    "Ordinal encoding is a technique used to convert categorical variables into numerical variables. Each category is assigned a unique numerical value based on its order or rank, as determined by a chosen criterion such as frequency or importance. This encoding method is particularly useful when categories have a natural order or ranking, such as with educational levels. However, it is important to note that the numerical values assigned to each category do not represent any inherent numerical difference between them, but simply provide a numerical representation.\n",
    "\n",
    "The Scikit-learn library provides the [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) class, which enables users to replace categorical variables with ordinal numbers, ranging from 0 to n_categories-1. Additionally, this class includes the `encoded_missing_value` parameter that allows encoding of missing values. It is important to note that this implementation assigns numbers to categories arbitrarily, based on a first-seen, first-served basis. Therefore, users should exercise caution when interpreting the numerical values assigned to the categories. Other implementations such as the one in [Feature-engine](https://feature-engine.trainindata.com/en/1.0.x/encoding/OrdinalEncoder.html) numbers can be ordered based on the mean of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d4e30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer with ordinal encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1.\n",
    "ordinal_encoder = make_column_transformer(\n",
    "                    (\n",
    "                        OrdinalEncoder(\n",
    "                            handle_unknown='use_encoded_value',\n",
    "                            unknown_value=-1,\n",
    "                            encoded_missing_value=-1\n",
    "                        ),\n",
    "                        make_column_selector(dtype_exclude=np.number)\n",
    "                    ),\n",
    "                    remainder=\"passthrough\",\n",
    "                    verbose_feature_names_out=False,\n",
    "                ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62742fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(random_state=123) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for y: None \n",
       "Transformer for exog: ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('ordinalencoder',\n",
       "                                 OrdinalEncoder(encoded_missing_value=-1,\n",
       "                                                handle_unknown='use_encoded_value',\n",
       "                                                unknown_value=-1),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000011DEBBC3CD0>)],\n",
       "                  verbose_feature_names_out=False) \n",
       "Window size: 5 \n",
       "Weight function included: False \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['holiday', 'weather', 'temp', 'hum'] \n",
       "Training range: [Timestamp('2011-01-01 00:00:00'), Timestamp('2012-07-31 23:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: H \n",
       "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-04-30 23:22:21 \n",
       "Last fit date: 2023-04-30 23:22:21 \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.10.0 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster with a transformer for exogenous features\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123),\n",
    "                lags = 5,\n",
    "                transformer_exog = ordinal_encoder\n",
    "             )\n",
    "\n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77fce7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag_1      float64\n",
      "lag_2      float64\n",
      "lag_3      float64\n",
      "lag_4      float64\n",
      "lag_5      float64\n",
      "holiday    float64\n",
      "weather    float64\n",
      "temp       float64\n",
      "hum        float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5  holiday  weather  \\\n",
       "date_time                                                                  \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0      0.0      1.0   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0      0.0      0.0   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0      0.0      0.0   \n",
       "2011-01-01 08:00:00    3.0    2.0    1.0    1.0   13.0      0.0      0.0   \n",
       "2011-01-01 09:00:00    8.0    3.0    2.0    1.0    1.0      0.0      0.0   \n",
       "\n",
       "                      temp   hum  \n",
       "date_time                         \n",
       "2011-01-01 05:00:00   9.84  75.0  \n",
       "2011-01-01 06:00:00   9.02  80.0  \n",
       "2011-01-01 07:00:00   8.20  86.0  \n",
       "2011-01-01 08:00:00   9.84  75.0  \n",
       "2011-01-01 09:00:00  13.12  76.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'],\n",
    "                        exog = data.loc[:end_train, exog_features]\n",
    "                   )\n",
    "print(X_train.dtypes)\n",
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddca9a92",
   "metadata": {},
   "source": [
    "Once the forecaster has been trained, the transformer can be inspected by accessing the `transformer_exog` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "503e22e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    89.096098\n",
       "2012-08-01 01:00:00    57.749964\n",
       "2012-08-01 02:00:00    29.263922\n",
       "Freq: H, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c5af312",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "\n",
    "Target encoding is a technic that encodes categorical variables based on the relationship between the categories and the target variable. Each category is encoded based on a shrinked estimate of the average target values for observations belonging to the category. The encoding scheme mixes the global target mean with the target mean conditioned on the value of the category.\n",
    "\n",
    "For example, suppose a categorical variable \"City\" with categories \"New York,\" \"Los Angeles,\" and \"Chicago,\" and a target variable \"Salary.\" One can calculate the mean salary for each city category based on the training data, and use these mean values to encode the categories.\n",
    "\n",
    "This encoding scheme is useful with categorical features with high cardinality, where one-hot encoding would inflate the feature space making it more expensive for a downstream model to process. A classical example of high cardinality categories are location based such as zip code or region.\n",
    "\n",
    "The [TargetEncoder](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.TargetEncoder.html) class is available in Scikit-learn (since version 1.3). `TargetEncoder` considers missing values, such as `np.nan` or `None`, as another category and encodes them like any other category. Categories that are not seen during fit are encoded with the target mean, i.e. `target_mean_`. A more detailed description of target encoding can be found in the [scikit-learn user guide](https://scikit-learn.org/dev/modules/preprocessing.html#target-encoder)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45b401ba",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "We are currently working to allow this type of transformation within skforecast.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b388bf",
   "metadata": {},
   "source": [
    "## Native implementation for categorical features\n",
    "\n",
    "Some machine learning models, including **XGBoost**, **LightGBM**, **CatBoost**, and **HistGradientBoostingRegressor**, offer built-in methods to handle categorical features, however, they assume that the input categories are integers starting from 0 up to the number of categories [0, 1, ..., n_categories-1]. In practice, categorical variables are not encoded with numbers but with strings, so an intermediate transformation step is necessary. Two options are:\n",
    "\n",
    "+ Set columns with categorical variables to `category` type. Internally, this data structure consists of an array of categories and an array of integer values (codes) that point to the actual value of the array of categories. That is, internally they are a numeric array with a mapping that relates each value to a category. Models are able to automatically identify the columns of type `category` and access their internal codes. This approach is applicable with **XGBoost**, **LightGBM** and **CatBoost**.\n",
    "\n",
    "+ Preprocess the categorical columns with an `OrdinalEncoder` to transform their values into integers and explicitly indicate that the columns should be treated as categorical. Skforecast allows it by using the `fit_kwargs` argument."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935caed0",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "When deploying models in production, it is strongly advised to avoid using automatic detection based on pandas `category` type columns. While pandas does provide internal coding for these columns, it is not consistent across different data sets and may vary depending on the categories present in each data set. Therefore, it is crucial to be mindful of this issue and to implement appropriate measures to ensure consistency in the coding of categorical features when deploying models in production.\n",
    "\n",
    "As of the writing of this documentation, the authors have only observed that LightGBM internally manages changes in the coding of categories. More details on this issue can be found in  <a href=https://github.com/microsoft/LightGBM/issues/2826)>github issue</a> and  <a href=https://stackoverflow.com/questions/60191643/are-lightgbm-treating-pandas-categoricals-based-on-name-or-cat-code-value>stackoverflow</a>.\n",
    "\n",
    "If the user still wishes to rely on automatic detection of categorical features based on pandas data types, categorical variables must be encoded first as integers (ordinal encoding) and then stored as category type. This is needed because skforecast makes internal use of numerical numpy array to speed the computation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5c109b9",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "412e83ff",
   "metadata": {},
   "source": [
    "**Encoding categories as integers and explicity indicating the name of the categorical features (recommended)**\n",
    "\n",
    "When creating a forecaster using `LGBMRegressor`, it is necessary to specify the names of the categorical columns using the `fit_kwargs` argument. This is because the `categorical_feature` argument is only specified in the `fit` method of `LGBMRegressor`, and not during its initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "767c0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1.\n",
    "categorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            categorical_features\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eb9ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "c:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "c:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "# Create and fit forecaster indicating the categorical features\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=963),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog,\n",
    "                fit_kwargs={'categorical_feature': categorical_features}\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2204eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    89.451199\n",
       "2012-08-01 01:00:00    49.589097\n",
       "2012-08-01 02:00:00    22.181453\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60310d05",
   "metadata": {},
   "source": [
    "**Allow the model to automatically detect categorical features (not recommended)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85edcb25",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "Handle categorical variables by relying on the automatic detection of `category` data types can be achieved by setting `categorical_features='auto'` during model initialization. However, this approach may lead to significant issues if the model is exposed to new datasets that have different pandas encoding for categorical columns than the one used during training. Therefore, it's crucial to ensure that the encoding is consistent between the training and the testing datasets to avoid any potential errors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f971a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding and cast to category type\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1. After the encoding, the features are cast again to category type so they\n",
    "# can beidentified as categorical features by the regressor.\n",
    "\n",
    "pipeline_categorical = make_pipeline(\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            FunctionTransformer(\n",
    "                                func=lambda x: x.astype('category'),\n",
    "                                feature_names_out= 'one-to-one'\n",
    "                            )\n",
    "                       )\n",
    "\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            pipeline_categorical,\n",
    "                            make_column_selector(dtype_exclude=np.number)\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d8f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_features in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(categorical_features='auto', random_state=963),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "869e0946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    88.946940\n",
       "2012-08-01 01:00:00    59.848451\n",
       "2012-08-01 02:00:00    28.870817\n",
       "Freq: H, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bad7ac00",
   "metadata": {},
   "source": [
    "As with any other forecaster, the matrices used during model training can created with `create_train_X_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9358a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5 holiday weather   temp  \\\n",
       "date_time                                                                       \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0       0       1   9.84   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0       0       0   9.02   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0       0       0   8.20   \n",
       "2011-01-01 08:00:00    3.0    2.0    1.0    1.0   13.0       0       0   9.84   \n",
       "2011-01-01 09:00:00    8.0    3.0    2.0    1.0    1.0       0       0  13.12   \n",
       "\n",
       "                      hum  \n",
       "date_time                  \n",
       "2011-01-01 05:00:00  75.0  \n",
       "2011-01-01 06:00:00  80.0  \n",
       "2011-01-01 07:00:00  86.0  \n",
       "2011-01-01 08:00:00  75.0  \n",
       "2011-01-01 09:00:00  76.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'],\n",
    "                        exog = data.loc[:end_train, exog_features]\n",
    "                   )\n",
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a9aad4d",
   "metadata": {},
   "source": [
    "### Scikit-learn HistogramGradientBoosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e938a41",
   "metadata": {},
   "source": [
    "When creating a forecaster using `HistogramGradientBoosting`, the names of categorical columns should be specified during the instantiation of the regressor by passing them as a list to the `categorical_feature` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e455aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1.\n",
    "categorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            categorical_features\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6ff94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit forecaster indicating the categorical features\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = HistGradientBoostingRegressor(\n",
    "                                categorical_features=categorical_features,\n",
    "                                random_state=963\n",
    "                            ),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f5c4ebd",
   "metadata": {},
   "source": [
    "`HistGradientBoostingRegressor` stores boolean mask that indicates what features have been considered as categorical. `None` if there are no categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ea8937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True, False, False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.regressor.is_categorical_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d04c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    99.185547\n",
       "2012-08-01 01:00:00    71.914255\n",
       "2012-08-01 02:00:00    43.342723\n",
       "Freq: H, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b9a0b27",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e0a2419",
   "metadata": {},
   "source": [
    "**Encoding categories as integers and explicity indicating the categorical features (recommended)**\n",
    "\n",
    "As of the time of writing, the `XGBRegressor` module does not offer an explicit option for specifying the names of categorical features. Instead, the feature types are indicated by passing a list of strings to the `feature_types` argument, where 'c' denotes categorical and 'q' denotes numeric features. Moreover, the `enable_categorical` argument must be set to True.\n",
    "\n",
    "Determining the position of each feature to create the list of feature types can be challenging, as the shape of the data matrix depends on the number of lags used and the transformations applied to the exogenous variables. A workaround involves creating a dummy forecaster and using the `create_train_X_y` method with a small sample of data to determine the final position of each feature. This approach can help to accurately specify the feature types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35230362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1.\n",
    "categorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            categorical_features\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1fdd54d",
   "metadata": {},
   "source": [
    "A first forecaster is created without indicating the argument `feature_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e19b4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = XGBRegressor(\n",
    "                              tree_method='hist',\n",
    "                              random_state=12345,\n",
    "                              enable_categorical=True,\n",
    "                            ),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "642c3dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5  holiday  weather  \\\n",
       "date_time                                                                  \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0        0        1   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0        0        0   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0        0        0   \n",
       "\n",
       "                     temp   hum  \n",
       "date_time                        \n",
       "2011-01-01 05:00:00  9.84  75.0  \n",
       "2011-01-01 06:00:00  9.02  80.0  \n",
       "2011-01-01 07:00:00  8.20  86.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices with a sample of the data\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'][:10],\n",
    "                        exog = data.loc[:end_train, exog_features][:10]\n",
    "                   )\n",
    "X_train.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b81f8a",
   "metadata": {},
   "source": [
    "Create a list to identify what columns in the training matrix is numeric and categoric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acc6b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q', 'q', 'q', 'q', 'q', 'c', 'c', 'q', 'q']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_types = ['c' if col in categorical_features else 'q' for col in X_train.columns]\n",
    "feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d9a5664",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2387882118.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[66], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Update the regressor parameters using the forecaster's method `set_params`.\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "Update the regressor parameters using the forecaster's method `set_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02302bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None,\n",
       "             feature_types=['q', 'q', 'q', 'q', 'q', 'c', 'c', 'q', 'q'],\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=55, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=12345, ...) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for y: None \n",
       "Transformer for exog: ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('ordinalencoder',\n",
       "                                 OrdinalEncoder(dtype=<class 'int'>,\n",
       "                                                encoded_missing_value=-1,\n",
       "                                                handle_unknown='use_encoded_value',\n",
       "                                                unknown_value=-1),\n",
       "                                 ['holiday', 'weather'])],\n",
       "                  verbose_feature_names_out=False) \n",
       "Window size: 5 \n",
       "Weight function included: False \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['holiday', 'weather', 'temp', 'hum'] \n",
       "Training range: [Timestamp('2011-01-01 00:00:00'), Timestamp('2012-07-31 23:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: H \n",
       "Regressor parameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': True, 'eval_metric': None, 'feature_types': ['q', 'q', 'q', 'q', 'q', 'c', 'c', 'q', 'q'], 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 55, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': 12345, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'hist', 'validate_parameters': None, 'verbosity': None} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-05-01 00:22:31 \n",
       "Last fit date: 2023-05-01 00:22:31 \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.10.0 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.set_params({'feature_types': feature_types})\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde5676",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65824211",
   "metadata": {},
   "source": [
    "**Allow the model to automatically detect categorical features (not recommended)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98579cf9",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "Handle categorical variables by relying on the automatic detection of `category` data types can be achieved by setting `enable_categorical=True` during model initialization. However, this approach may lead to significant issues if the model is exposed to new datasets that have different pandas encoding for categorical columns than the one used during training. Therefore, it's crucial to ensure that the encoding is consistent between the training and the testing datasets to avoid any potential errors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0be2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding and cast to category type\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1. After the encoding, the features are cast again to category type so they\n",
    "# can beidentified as categorical features by the regressor.\n",
    "\n",
    "pipeline_categorical = make_pipeline(\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            FunctionTransformer(\n",
    "                                func=lambda x: x.astype('category'),\n",
    "                                feature_names_out= 'one-to-one'\n",
    "                            )\n",
    "                       )\n",
    "\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            pipeline_categorical,\n",
    "                            make_column_selector(dtype_exclude=np.number)\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d1051d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = XGBRegressor(\n",
    "                                enable_categorical=True,\n",
    "                                tree_method='hist',\n",
    "                                random_state=963\n",
    "                            ),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d915fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01 00:00:00    77.470787\n",
       "2012-08-01 01:00:00    40.735706\n",
       "2012-08-01 02:00:00    13.448755\n",
       "Freq: H, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2e48ce0",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "Unfortunately, the current versions of `ForecasterAutoreg`, `ForecasterAutoregCustom`, and the multiseries equivalent are not compatible with CatBoost's native handling of categorical features. The issue arises because CatBoost only accepts categorical features as integers, while skforecast converts input data to floats for faster computation using numpy arrays in the internal recursive prediction process. As a result, there is a mismatch in data types between the two frameworks, leading to incompatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c67607e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: ordinal encoding\n",
    "# ==============================================================================\n",
    "# A ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# using ordinal encoding. Numerical features are left untouched. Missing values\n",
    "# are encoded as -1. If a new category is found in the test set, it is encoded\n",
    "# as -1.\n",
    "categorical_features = data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            categorical_features\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a884769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                regressor = CatBoostRegressor(\n",
    "                                cat_features=categorical_features,\n",
    "                                n_estimators=5,\n",
    "                                random_state=963,\n",
    "                                silent=True,\n",
    "                                allow_writing_files=False\n",
    "                            ),\n",
    "                lags = 5,\n",
    "                steps = 3,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad4dc65",
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "'data' is numpy array of floating point numerical type, it means no categorical features, but 'cat_features' parameter specifies nonzero number of categorical features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m forecaster\u001b[39m.\u001b[39;49mpredict(steps\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, exog\u001b[39m=\u001b[39;49mdata_test[exog_features])\n",
      "File \u001b[1;32mc:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\\skforecast\\ForecasterAutoregDirect\\ForecasterAutoregDirect.py:806\u001b[0m, in \u001b[0;36mForecasterAutoregDirect.predict\u001b[1;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[0;32m    803\u001b[0m         \u001b[39m# Suppress scikit-learn warning: \"X does not have valid feature names,\u001b[39;00m\n\u001b[0;32m    804\u001b[0m         \u001b[39m# but NoOpTransformer was fitted with feature names\".\u001b[39;00m\n\u001b[0;32m    805\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 806\u001b[0m         predictions[i] \u001b[39m=\u001b[39m regressor\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    808\u001b[0m idx \u001b[39m=\u001b[39m expand_index(index\u001b[39m=\u001b[39mlast_window_index, steps\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(steps))\n\u001b[0;32m    810\u001b[0m predictions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\n\u001b[0;32m    811\u001b[0m                   data  \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    812\u001b[0m                   index \u001b[39m=\u001b[39m idx[np\u001b[39m.\u001b[39marray(steps)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m    813\u001b[0m                   name  \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    814\u001b[0m               )\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\catboost\\core.py:5775\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   5773\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5774\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[1;32m-> 5775\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\catboost\\core.py:2541\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2540\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 2541\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[0;32m   2542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[0;32m   2544\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\catboost\\core.py:2521\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[1;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[0;32m   2519\u001b[0m is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[0;32m   2520\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n\u001b[1;32m-> 2521\u001b[0m     data \u001b[39m=\u001b[39m Pool(\n\u001b[0;32m   2522\u001b[0m         data\u001b[39m=\u001b[39;49m[data] \u001b[39mif\u001b[39;49;00m is_single_object \u001b[39melse\u001b[39;49;00m data,\n\u001b[0;32m   2523\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m   2524\u001b[0m         cat_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cat_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2525\u001b[0m         text_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2526\u001b[0m         embedding_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_embedding_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2527\u001b[0m         thread_count\u001b[39m=\u001b[39;49mthread_count\n\u001b[0;32m   2528\u001b[0m     )\n\u001b[0;32m   2529\u001b[0m \u001b[39mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\catboost\\core.py:734\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    733\u001b[0m     \u001b[39mif\u001b[39;00m (data\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (cat_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(cat_features) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    735\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is numpy array of floating point numerical type, it means no categorical features,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m but \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcat_features\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter specifies nonzero number of categorical features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         )\n\u001b[0;32m    738\u001b[0m     \u001b[39mif\u001b[39;00m (data\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (text_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(text_features) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    739\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    740\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is numpy array of floating point numerical type, it means no text features,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    741\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m but \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtext_features\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter specifies nonzero number of text features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    742\u001b[0m         )\n",
      "\u001b[1;31mCatBoostError\u001b[0m: 'data' is numpy array of floating point numerical type, it means no categorical features, but 'cat_features' parameter specifies nonzero number of categorical features"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "forecaster.predict(steps=3, exog=data_test[exog_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac014ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
