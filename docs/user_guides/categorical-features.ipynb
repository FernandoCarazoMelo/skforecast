{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da3874d",
   "metadata": {},
   "source": [
    "In the field of machine learning, categorical features play a crucial role in determining the predictive ability of a model. Categorical features are features that can take a limited number of values, such as color, gender or location. While these features can provide useful insights into patterns and relationships within data, they also pose unique challenges for machine learning models.\n",
    "\n",
    "One of these challenges is the need to transform categorical features before they can be used by most models. This transformation involves converting categorical values into numerical values that can be processed by the machine learning algorithm.\n",
    "\n",
    "Another challenge is dealing with infrequent categories, which can lead to biased models. If a categorical feature has a large number of categories, but some of them are rare or appear infrequently in the data, the model may not be able to learn accurately from these categories, resulting in biased predictions and inaccurate results.\n",
    "\n",
    "Despite these difficulties, categorical features are still an essential component in many use cases. When properly encoded and handled, machine learning models can effectively learn from patterns and relationships in categorical data, leading to better predictions.\n",
    "\n",
    "There are various transformations described in the literature, each with its own benefits and drawbacks. Choosing the right one can significantly impact model performance. This document describes three of the most commonly used transformations: One-hot encoding, Ordinal encoding, and Target encoding, and explains how to apply them in skforecast using scikit-learn encoders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15dfe9dc",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "563e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc5647b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.84</td>\n",
       "      <td>81.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    holiday weather  temp   hum  users\n",
       "date_time                                             \n",
       "2011-01-01 00:00:00     0.0   clear  9.84  81.0   16.0\n",
       "2011-01-01 01:00:00     0.0   clear  9.02  80.0   40.0\n",
       "2011-01-01 02:00:00     0.0   clear  9.02  80.0   32.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/Estadistica-machine-'\n",
    "       'learning-python/master/data/bike_sharing_dataset_clean.csv')\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Preprocess data\n",
    "# ==============================================================================\n",
    "data['date_time'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('date_time')\n",
    "data = data.asfreq('H')\n",
    "data = data.sort_index()\n",
    "data = data[['holiday', 'weather', 'temp', 'hum', 'users']]\n",
    "data[['holiday', 'weather']] = data[['holiday', 'weather']].astype(str)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb9a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates train : 2012-06-01 00:00:00 --- 2012-07-31 23:00:00  (n=1464)\n",
      "Dates test  : 2012-08-01 00:00:00 --- 2012-08-15 23:00:00  (n=360)\n"
     ]
    }
   ],
   "source": [
    "# Split train-val-test\n",
    "# ==============================================================================\n",
    "start_train = '2012-06-01 00:00:00'\n",
    "end_train = '2012-07-31 23:59:00'\n",
    "end_test = '2012-08-15 23:59:00'\n",
    "data_train = data.loc[start_train:end_train, :]\n",
    "data_test  = data.loc[end_train:end_test, :]\n",
    "\n",
    "print(f\"Dates train : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Dates test  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c879c7a7",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "One hot encoding, also known as dummy encoding or one-of-K encoding, consists in replacing the categorical variable by a group of binary variables which take value 0 or 1, to indicate if a certain category is present in an observation. For example, suppose a dataset that includes a categorical variable called \"color\" with possible values of \"red,\" \"blue,\" and \"green.\" Using one hot encoding, this variable is converted into a set of binary variables such as \"color_red,\" \"color_blue,\" and \"color_green,\" where each variable takes a value of 0 or 1 depending on the category.\n",
    "\n",
    "The `OneHotEncoder` class in Scikit-learn can be used to transform each categorical feature with *n* possible values into *n* new binary features, with one of them taking the value 1, and all others 0. The `OneHotEncoder` can be configured to handle certain corner cases, including unknown categories, missing values, and infrequent categories.\n",
    "\n",
    "+ When `handle_unknown='ignore'` and `drop` is not `None`, unknown categories are encoded as all zeros. Additionally, if a feature contains both `np.nan` and `None`, they will be considered separate categories\n",
    "\n",
    "+ `OneHotEncoder` supports aggregating infrequent categories into a single output for each feature. The parameters to enable the gathering of infrequent categories are `min_frequency` and `max_categories`. By setting `handle_unknown` to 'infrequent_if_exist', unknown categories will be considered infrequent.\n",
    "\n",
    "+ To avoid collinearity between features, it is possible to drop one of the categories per feature. This is particularly important when using linear models. This behavior can be set using the drop argument.\n",
    "\n",
    "\n",
    "[ColumnTransformers in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) provide a powerful way to define transformations and apply them to specific features. By encapsulating the `OneHotEncoder` within a `ColumnTransformer` object, it can be passed to a forecaster using the `transformer_exog` argument. For more details on how to use `OneHotEncoder`, please refer to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a90de56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer with a one hot encoding transformer\n",
    "# ==============================================================================\n",
    "# The ColumnTransformer is used to transform categorical features (no numerical)\n",
    "# into one-hot encoded features. Numerical features are left untouched. For binary\n",
    "# features, only one column is created.\n",
    "one_hot_encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('oh', OneHotEncoder(sparse_output=False, drop='if_binary'), make_column_selector(dtype_exclude=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad53b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(random_state=123) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for y: None \n",
       "Transformer for exog: ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('oh',\n",
       "                                 OneHotEncoder(drop='if_binary',\n",
       "                                               sparse_output=False),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7fb94aff0820>)],\n",
       "                  verbose_feature_names_out=False) \n",
       "Window size: 5 \n",
       "Weight function included: False \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['holiday', 'weather', 'temp', 'hum'] \n",
       "Training range: [Timestamp('2011-01-01 00:00:00'), Timestamp('2012-07-31 23:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: H \n",
       "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} \n",
       "Creation date: 2023-04-17 16:03:03 \n",
       "Last fit date: 2023-04-17 16:03:03 \n",
       "Skforecast version: 0.7.1 \n",
       "Python version: 3.10.9 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster with a transformer for exogenous features\n",
    "# ==============================================================================\n",
    "exog_features = ['holiday', 'weather', 'temp', 'hum']\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123),\n",
    "                lags = 5,\n",
    "                transformer_exog = one_hot_encoder\n",
    "             )\n",
    "\n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f865c551",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "Applying a transformation to the entire dataset independent of the forecaster is feasible. However, it is crucial to ensure that the transformations are learned exclusively from the training data to prevent information leakage. Additionally, the same transformation should be applied to the input data during predictions. Therefore, it is advisable to include the transformation inside the forecaster, so that it is handled internally. This approach ensures consistency in the application of transformations and reduces the likelihood of errors.\n",
    "\n",
    "To examine how data is being transformed, it is possible to use the <code>create_train_X_y</code> method to generate the matrices that the forecaster is using to train the model. This approach enables gaining insight into the specific data manipulations that occur during the training process.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b6faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday_1.0</th>\n",
       "      <th>weather_clear</th>\n",
       "      <th>weather_mist</th>\n",
       "      <th>weather_rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5  holiday_1.0  \\\n",
       "date_time                                                             \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0          0.0   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0          0.0   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0          0.0   \n",
       "2011-01-01 08:00:00    3.0    2.0    1.0    1.0   13.0          0.0   \n",
       "2011-01-01 09:00:00    8.0    3.0    2.0    1.0    1.0          0.0   \n",
       "\n",
       "                     weather_clear  weather_mist  weather_rain   temp   hum  \n",
       "date_time                                                                    \n",
       "2011-01-01 05:00:00            0.0           1.0           0.0   9.84  75.0  \n",
       "2011-01-01 06:00:00            1.0           0.0           0.0   9.02  80.0  \n",
       "2011-01-01 07:00:00            1.0           0.0           0.0   8.20  86.0  \n",
       "2011-01-01 08:00:00            1.0           0.0           0.0   9.84  75.0  \n",
       "2011-01-01 09:00:00            1.0           0.0           0.0  13.12  76.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'],\n",
    "                        exog = data.loc[:end_train, exog_features]\n",
    "                   )\n",
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dea38b7",
   "metadata": {},
   "source": [
    "## Ordinal encoding\n",
    "\n",
    "Ordinal encoding is a technique used to convert categorical variables into numerical variables. Each category is assigned a unique numerical value based on its order or rank, as determined by a chosen criterion such as frequency or importance. This encoding method is particularly useful when categories have a natural order or ranking, such as with educational levels. However, it is important to note that the numerical values assigned to each category do not represent any inherent numerical difference between them, but simply provide a numerical representation.\n",
    "\n",
    "The `OrdinalEncoder` class in Scikit-learn can be used to transform each categorical feature into a new feature of integers, with values ranging from 0 to n_categories-1. This class also offers the `encoded_missing_value` parameter to encode missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c5af312",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "\n",
    "Target encoding is a technic that encodes categorical variables based on the relationship between the categories and the target variable. Each category is encoded based on a shrinked estimate of the average target values for observations belonging to the category. The encoding scheme mixes the global target mean with the target mean conditioned on the value of the category.\n",
    "\n",
    "For example, suppose we have a categorical variable \"City\" with categories \"New York,\" \"Los Angeles,\" and \"Chicago,\" and a target variable \"Salary.\" One can calculate the mean salary for each city category based on the training data, and use these mean values to encode the categories.\n",
    "\n",
    "This encoding scheme is useful with categorical features with high cardinality, where one-hot encoding would inflate the feature space making it more expensive for a downstream model to process. A classical example of high cardinality categories are location based such as zip code or region.\n",
    "\n",
    "The `TargetEncoder` class in Scikit-learn (since version 1.3) considers missing values, such as `np.nan` or `None`, as another category and encodes them like any other category. Categories that are not seen during fit are encoded with the target mean, i.e. target_mean_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b388bf",
   "metadata": {},
   "source": [
    "## Native implementation for categorical features\n",
    "\n",
    "Gradient boosting libraries (XGBoost, LightGBM, CatBoost) assume that the input categories are integers starting from 0 up to the number of categories [0, 1, ..., n_categories-1]. In most real cases, categorical variables are not encoded with numbers but with strings, so an intermediate transformation step is necessary. Two options are:\n",
    "\n",
    "+ Set columns with categorical variables to `category` type. Internally, this data structure consists of an array of categories and an array of integer values (codes) that point to the actual value of the array of categories. That is, internally they are a numeric array with a mapping that relates each value to a category. Models are able to automatically identify the columns of type `category` and access their internal codes. This approach is applicable with XGBoost, LightGBM and CatBoost.\n",
    "\n",
    "+ Preprocess the categorical columns with an `OrdinalEncoder` to transform their values into integers and then store them again as `category` type. If this last step is not done, the models will treat the variable as if they were numeric.\n",
    "\n",
    "In order to use the XGBoost native implementation in skforecast, categorical variables must be encoded first as integers and then stored as `category` type. This is because skforecast makes internal use of numerical numpy array to speed the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "094ca690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer: Ordinal encoding + cast to category type\n",
    "# ==============================================================================\n",
    "pipeline_categorical = make_pipeline(\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            FunctionTransformer(\n",
    "                                func=lambda x: x.astype('category'),\n",
    "                                feature_names_out= 'one-to-one'\n",
    "                            )\n",
    "                       )\n",
    "\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            pipeline_categorical,\n",
    "                            make_column_selector(dtype_exclude=np.number)\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d8f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cienciadedatos_p10/lib/python3.10/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_features in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(categorical_features='auto') \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for y: None \n",
       "Transformer for exog: ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('pipeline',\n",
       "                                 Pipeline(steps=[('ordinalencoder',\n",
       "                                                  OrdinalEncoder(dtype=<class 'int'>,\n",
       "                                                                 encoded_missing_value=-1,\n",
       "                                                                 handle_unknown='use_encoded_value',\n",
       "                                                                 unknown_value=-1)),\n",
       "                                                 ('functiontransformer',\n",
       "                                                  FunctionTransformer(feature_names_out='one-to-one',\n",
       "                                                                      func=<function <lambda> at 0x7fb94ae53a30>))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7fb94b1445e0>)],\n",
       "                  verbose_feature_names_out=False) \n",
       "Window size: 5 \n",
       "Weight function included: False \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['holiday', 'weather', 'temp', 'hum'] \n",
       "Training range: [Timestamp('2011-01-01 00:00:00'), Timestamp('2012-07-31 23:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: H \n",
       "Regressor parameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'categorical_features': 'auto'} \n",
       "Creation date: 2023-04-17 16:04:22 \n",
       "Last fit date: 2023-04-17 16:04:22 \n",
       "Skforecast version: 0.7.1 \n",
       "Python version: 3.10.9 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(categorical_features='auto'),\n",
    "                lags = 5,\n",
    "                transformer_exog = transformer_exog\n",
    "             )\n",
    "            \n",
    "forecaster.fit(\n",
    "    y = data.loc[:end_train, 'users'],\n",
    "    exog = data.loc[:end_train, exog_features]\n",
    ")\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9358a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 05:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 06:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 07:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 08:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.12</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lag_1  lag_2  lag_3  lag_4  lag_5 holiday weather   temp  \\\n",
       "date_time                                                                       \n",
       "2011-01-01 05:00:00    1.0   13.0   32.0   40.0   16.0       0       1   9.84   \n",
       "2011-01-01 06:00:00    1.0    1.0   13.0   32.0   40.0       0       0   9.02   \n",
       "2011-01-01 07:00:00    2.0    1.0    1.0   13.0   32.0       0       0   8.20   \n",
       "2011-01-01 08:00:00    3.0    2.0    1.0    1.0   13.0       0       0   9.84   \n",
       "2011-01-01 09:00:00    8.0    3.0    2.0    1.0    1.0       0       0  13.12   \n",
       "\n",
       "                      hum  \n",
       "date_time                  \n",
       "2011-01-01 05:00:00  75.0  \n",
       "2011-01-01 06:00:00  80.0  \n",
       "2011-01-01 07:00:00  86.0  \n",
       "2011-01-01 08:00:00  75.0  \n",
       "2011-01-01 09:00:00  76.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training matrices\n",
    "# ==============================================================================\n",
    "X_train, y_train = forecaster.create_train_X_y(\n",
    "                        y = data.loc[:end_train, 'users'],\n",
    "                        exog = data.loc[:end_train, exog_features]\n",
    "                   )\n",
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a9aad4d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0827a570",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-circle-exclamation fa\" style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b> &nbsp Note</b>\n",
    "</p>\n",
    "\n",
    "Coming Soon. This section is currently being created :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac014ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
