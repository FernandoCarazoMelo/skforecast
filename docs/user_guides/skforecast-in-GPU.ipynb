{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Skforecast in GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2a3d8",
   "metadata": {},
   "source": [
    "Traditionally, machine learning algorithms are executed on CPUs (Central Processing Units), which are general-purpose processors that are designed to handle a wide range of tasks. However, CPUs are not optimized for the highly parallelized matrix operations that are required by many machine learning algorithms, which can result in slow training times and limited scalability. GPUs, on the other hand, are designed specifically for parallel processing and can perform thousands of mathematical operations simultaneously, making them ideal for training and deploying large-scale machine learning models.\n",
    "\n",
    "Two popular machine learning libraries that have implemented GPU acceleration are **XGBoost** and **LightGBM**. These libraries are used for building gradient boosting models, which are a type of machine learning algorithm that is highly effective for a wide range of tasks, including forecasting. With GPU acceleration, these libraries can significantly reduce the training time required to build these models and improve their scalability.\n",
    "\n",
    "Despite the significant advantages offered by GPUs (specifically Nvidia GPUs) in accelerating machine learning computations, access to them is often limited due to high costs or other practical constraints. Fortunatelly, **Google Colaboratory (Colab)**, a free Jupyter notebook environment, allows users to run Python code in the cloud, with access to powerful hardware resources such as GPUs. This makes it an excellent platform for experimenting with machine learning models, especially those that require intensive computations.\n",
    "\n",
    "The following sections demonstrate how to install and use **XGBoost** and **LightGBM** with GPU acceleration to create powerful forecasting models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b9fd63a",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/d20edc211b.js\" crossorigin=\"anonymous\"></script>\n",
    "\n",
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i class=\"fa-triangle-exclamation fa\" style=\"font-size: 18px; color:#ff9100;\"></i>\n",
    "    <b> &nbsp Warning</b>\n",
    "</p>\n",
    "\n",
    "The following code assumes that the user is executing it in Google Colab with an activated GPU runtime.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074ca42f",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "When creating the model, only two arguments are need to indicate XGBoost to GPU, if it available: `tree_method='gpu_hist'` and `gpu_id=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e11a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0be51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "CPU RAM Free: 6.81 GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# GPU info\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "# CPU info\n",
    "print(f\"CPU RAM Free: {psutil.virtual_memory().available / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8181b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = pd.Series(np.random.normal(size=1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9a6c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:30:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:339: No visible GPU is found, setting `gpu_id` to -1\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[00:30:58] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      4\u001b[0m forecaster \u001b[39m=\u001b[39m ForecasterAutoreg(\n\u001b[0;32m      5\u001b[0m                 regressor \u001b[39m=\u001b[39m XGBRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m, tree_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m'\u001b[39m, gpu_id\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[0;32m      6\u001b[0m                 lags \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m      7\u001b[0m              )\n\u001b[1;32m----> 9\u001b[0m forecaster\u001b[39m.\u001b[39;49mfit(y\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m     10\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime of execution: \u001b[39m\u001b[39m{\u001b[39;00mstop\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m second\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\skforecast\\ForecasterAutoreg\\ForecasterAutoreg.py:493\u001b[0m, in \u001b[0;36mForecasterAutoreg.fit\u001b[1;34m(self, y, exog)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregressor\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX_train, y\u001b[39m=\u001b[39my_train, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[0;32m    492\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregressor\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX_train, y\u001b[39m=\u001b[39;49my_train)\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mTimestamp\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[0;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [00:30:58] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/gbm/gbtree.cc:625: Check failed: common::AllVisibleGPUs() >= 1 (0 vs. 1) : No visible GPU is found for XGBoost."
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using GPU\n",
    "# ==============================================================================\n",
    "start = time.time()\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = XGBRegressor(n_estimators=5000, tree_method='gpu_hist', gpu_id=0),\n",
    "                lags = 20\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data)\n",
    "stop = time.time()\n",
    "print(f\"Time of execution: {stop - start} second\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a27b9011",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef624ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e23eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88704475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y -qq libboost-all-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd LightGBM\n",
    "rm -r build\n",
    "mkdir build\n",
    "cd build\n",
    "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
    "make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e97669",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd LightGBM/python-package/;python3 setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dea497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!rm -r LightGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f1bc7c7",
   "metadata": {},
   "source": [
    "Once all the above installation has been executed, it is necessary to **restart** the runtime (kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm  import LGBMRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da945f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with a LGBMRegressor using GPU\n",
    "# ==============================================================================\n",
    "start = time.time()\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(n_estimators=5000, device_type='gpu'),\n",
    "                lags = 20\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data)\n",
    "stop = time.time()\n",
    "print(f\"Time of execution: {stop - start} second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac014ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt {display: none;}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
