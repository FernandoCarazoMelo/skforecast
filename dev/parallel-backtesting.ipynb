{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding joblib multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[range(0, 5000), range(5000, 5024)],\n",
       " [range(0, 5024), range(5024, 5048)],\n",
       " [range(0, 5048), range(5048, 5072)],\n",
       " [range(0, 5072), range(5072, 5096)],\n",
       " [range(0, 5096), range(5096, 5120)],\n",
       " [range(0, 5120), range(5120, 5144)],\n",
       " [range(0, 5144), range(5144, 5168)],\n",
       " [range(0, 5168), range(5168, 5192)],\n",
       " [range(0, 5192), range(5192, 5216)],\n",
       " [range(0, 5216), range(5216, 5240)],\n",
       " [range(0, 5240), range(5240, 5264)],\n",
       " [range(0, 5264), range(5264, 5288)],\n",
       " [range(0, 5288), range(5288, 5312)],\n",
       " [range(0, 5312), range(5312, 5336)],\n",
       " [range(0, 5336), range(5336, 5360)],\n",
       " [range(0, 5360), range(5360, 5384)],\n",
       " [range(0, 5384), range(5384, 5408)],\n",
       " [range(0, 5408), range(5408, 5432)],\n",
       " [range(0, 5432), range(5432, 5456)],\n",
       " [range(0, 5456), range(5456, 5480)],\n",
       " [range(0, 5480), range(5480, 5504)],\n",
       " [range(0, 5504), range(5504, 5528)],\n",
       " [range(0, 5528), range(5528, 5552)],\n",
       " [range(0, 5552), range(5552, 5576)],\n",
       " [range(0, 5576), range(5576, 5600)],\n",
       " [range(0, 5600), range(5600, 5624)],\n",
       " [range(0, 5624), range(5624, 5648)],\n",
       " [range(0, 5648), range(5648, 5672)],\n",
       " [range(0, 5672), range(5672, 5696)],\n",
       " [range(0, 5696), range(5696, 5720)],\n",
       " [range(0, 5720), range(5720, 5744)],\n",
       " [range(0, 5744), range(5744, 5768)],\n",
       " [range(0, 5768), range(5768, 5792)],\n",
       " [range(0, 5792), range(5792, 5816)],\n",
       " [range(0, 5816), range(5816, 5840)],\n",
       " [range(0, 5840), range(5840, 5864)],\n",
       " [range(0, 5864), range(5864, 5888)],\n",
       " [range(0, 5888), range(5888, 5912)],\n",
       " [range(0, 5912), range(5912, 5936)],\n",
       " [range(0, 5936), range(5936, 5960)],\n",
       " [range(0, 5960), range(5960, 5984)],\n",
       " [range(0, 5984), range(5984, 6008)],\n",
       " [range(0, 6008), range(6008, 6032)],\n",
       " [range(0, 6032), range(6032, 6056)],\n",
       " [range(0, 6056), range(6056, 6080)],\n",
       " [range(0, 6080), range(6080, 6104)],\n",
       " [range(0, 6104), range(6104, 6128)],\n",
       " [range(0, 6128), range(6128, 6152)],\n",
       " [range(0, 6152), range(6152, 6176)],\n",
       " [range(0, 6176), range(6176, 6200)],\n",
       " [range(0, 6200), range(6200, 6224)],\n",
       " [range(0, 6224), range(6224, 6248)],\n",
       " [range(0, 6248), range(6248, 6272)],\n",
       " [range(0, 6272), range(6272, 6296)],\n",
       " [range(0, 6296), range(6296, 6320)],\n",
       " [range(0, 6320), range(6320, 6344)],\n",
       " [range(0, 6344), range(6344, 6368)],\n",
       " [range(0, 6368), range(6368, 6392)],\n",
       " [range(0, 6392), range(6392, 6416)],\n",
       " [range(0, 6416), range(6416, 6440)],\n",
       " [range(0, 6440), range(6440, 6464)],\n",
       " [range(0, 6464), range(6464, 6488)],\n",
       " [range(0, 6488), range(6488, 6512)],\n",
       " [range(0, 6512), range(6512, 6536)],\n",
       " [range(0, 6536), range(6536, 6560)],\n",
       " [range(0, 6560), range(6560, 6584)],\n",
       " [range(0, 6584), range(6584, 6608)],\n",
       " [range(0, 6608), range(6608, 6632)],\n",
       " [range(0, 6632), range(6632, 6656)],\n",
       " [range(0, 6656), range(6656, 6680)],\n",
       " [range(0, 6680), range(6680, 6704)],\n",
       " [range(0, 6704), range(6704, 6728)],\n",
       " [range(0, 6728), range(6728, 6752)],\n",
       " [range(0, 6752), range(6752, 6776)],\n",
       " [range(0, 6776), range(6776, 6800)],\n",
       " [range(0, 6800), range(6800, 6824)],\n",
       " [range(0, 6824), range(6824, 6848)],\n",
       " [range(0, 6848), range(6848, 6872)],\n",
       " [range(0, 6872), range(6872, 6896)],\n",
       " [range(0, 6896), range(6896, 6920)],\n",
       " [range(0, 6920), range(6920, 6944)],\n",
       " [range(0, 6944), range(6944, 6968)],\n",
       " [range(0, 6968), range(6968, 6992)],\n",
       " [range(0, 6992), range(6992, 7016)],\n",
       " [range(0, 7016), range(7016, 7040)],\n",
       " [range(0, 7040), range(7040, 7064)],\n",
       " [range(0, 7064), range(7064, 7088)],\n",
       " [range(0, 7088), range(7088, 7112)],\n",
       " [range(0, 7112), range(7112, 7136)],\n",
       " [range(0, 7136), range(7136, 7160)],\n",
       " [range(0, 7160), range(7160, 7184)],\n",
       " [range(0, 7184), range(7184, 7208)],\n",
       " [range(0, 7208), range(7208, 7232)],\n",
       " [range(0, 7232), range(7232, 7256)],\n",
       " [range(0, 7256), range(7256, 7280)],\n",
       " [range(0, 7280), range(7280, 7304)],\n",
       " [range(0, 7304), range(7304, 7328)],\n",
       " [range(0, 7328), range(7328, 7352)],\n",
       " [range(0, 7352), range(7352, 7376)],\n",
       " [range(0, 7376), range(7376, 7400)],\n",
       " [range(0, 7400), range(7400, 7424)],\n",
       " [range(0, 7424), range(7424, 7448)],\n",
       " [range(0, 7448), range(7448, 7472)],\n",
       " [range(0, 7472), range(7472, 7496)],\n",
       " [range(0, 7496), range(7496, 7520)],\n",
       " [range(0, 7520), range(7520, 7544)],\n",
       " [range(0, 7544), range(7544, 7568)],\n",
       " [range(0, 7568), range(7568, 7592)],\n",
       " [range(0, 7592), range(7592, 7616)],\n",
       " [range(0, 7616), range(7616, 7640)],\n",
       " [range(0, 7640), range(7640, 7664)],\n",
       " [range(0, 7664), range(7664, 7688)],\n",
       " [range(0, 7688), range(7688, 7712)],\n",
       " [range(0, 7712), range(7712, 7736)],\n",
       " [range(0, 7736), range(7736, 7760)],\n",
       " [range(0, 7760), range(7760, 7784)],\n",
       " [range(0, 7784), range(7784, 7808)],\n",
       " [range(0, 7808), range(7808, 7832)],\n",
       " [range(0, 7832), range(7832, 7856)],\n",
       " [range(0, 7856), range(7856, 7880)],\n",
       " [range(0, 7880), range(7880, 7904)],\n",
       " [range(0, 7904), range(7904, 7928)],\n",
       " [range(0, 7928), range(7928, 7952)],\n",
       " [range(0, 7952), range(7952, 7976)],\n",
       " [range(0, 7976), range(7976, 8000)],\n",
       " [range(0, 8000), range(8000, 8024)],\n",
       " [range(0, 8024), range(8024, 8048)],\n",
       " [range(0, 8048), range(8048, 8072)],\n",
       " [range(0, 8072), range(8072, 8096)],\n",
       " [range(0, 8096), range(8096, 8120)],\n",
       " [range(0, 8120), range(8120, 8144)],\n",
       " [range(0, 8144), range(8144, 8168)],\n",
       " [range(0, 8168), range(8168, 8192)],\n",
       " [range(0, 8192), range(8192, 8216)],\n",
       " [range(0, 8216), range(8216, 8240)],\n",
       " [range(0, 8240), range(8240, 8264)],\n",
       " [range(0, 8264), range(8264, 8288)],\n",
       " [range(0, 8288), range(8288, 8312)],\n",
       " [range(0, 8312), range(8312, 8336)],\n",
       " [range(0, 8336), range(8336, 8360)],\n",
       " [range(0, 8360), range(8360, 8384)],\n",
       " [range(0, 8384), range(8384, 8408)],\n",
       " [range(0, 8408), range(8408, 8432)],\n",
       " [range(0, 8432), range(8432, 8456)],\n",
       " [range(0, 8456), range(8456, 8480)],\n",
       " [range(0, 8480), range(8480, 8504)],\n",
       " [range(0, 8504), range(8504, 8528)],\n",
       " [range(0, 8528), range(8528, 8552)],\n",
       " [range(0, 8552), range(8552, 8576)],\n",
       " [range(0, 8576), range(8576, 8600)],\n",
       " [range(0, 8600), range(8600, 8624)],\n",
       " [range(0, 8624), range(8624, 8648)],\n",
       " [range(0, 8648), range(8648, 8672)],\n",
       " [range(0, 8672), range(8672, 8696)],\n",
       " [range(0, 8696), range(8696, 8720)],\n",
       " [range(0, 8720), range(8720, 8744)],\n",
       " [range(0, 8744), range(8744, 8768)],\n",
       " [range(0, 8768), range(8768, 8792)],\n",
       " [range(0, 8792), range(8792, 8816)],\n",
       " [range(0, 8816), range(8816, 8840)],\n",
       " [range(0, 8840), range(8840, 8864)],\n",
       " [range(0, 8864), range(8864, 8888)],\n",
       " [range(0, 8888), range(8888, 8912)],\n",
       " [range(0, 8912), range(8912, 8936)],\n",
       " [range(0, 8936), range(8936, 8960)],\n",
       " [range(0, 8960), range(8960, 8984)],\n",
       " [range(0, 8984), range(8984, 9008)],\n",
       " [range(0, 9008), range(9008, 9032)],\n",
       " [range(0, 9032), range(9032, 9056)],\n",
       " [range(0, 9056), range(9056, 9080)],\n",
       " [range(0, 9080), range(9080, 9104)],\n",
       " [range(0, 9104), range(9104, 9128)],\n",
       " [range(0, 9128), range(9128, 9152)],\n",
       " [range(0, 9152), range(9152, 9176)],\n",
       " [range(0, 9176), range(9176, 9200)],\n",
       " [range(0, 9200), range(9200, 9224)],\n",
       " [range(0, 9224), range(9224, 9248)],\n",
       " [range(0, 9248), range(9248, 9272)],\n",
       " [range(0, 9272), range(9272, 9296)],\n",
       " [range(0, 9296), range(9296, 9320)],\n",
       " [range(0, 9320), range(9320, 9344)],\n",
       " [range(0, 9344), range(9344, 9368)],\n",
       " [range(0, 9368), range(9368, 9392)],\n",
       " [range(0, 9392), range(9392, 9416)],\n",
       " [range(0, 9416), range(9416, 9440)],\n",
       " [range(0, 9440), range(9440, 9464)],\n",
       " [range(0, 9464), range(9464, 9488)],\n",
       " [range(0, 9488), range(9488, 9512)],\n",
       " [range(0, 9512), range(9512, 9536)],\n",
       " [range(0, 9536), range(9536, 9560)],\n",
       " [range(0, 9560), range(9560, 9584)],\n",
       " [range(0, 9584), range(9584, 9608)],\n",
       " [range(0, 9608), range(9608, 9632)],\n",
       " [range(0, 9632), range(9632, 9656)],\n",
       " [range(0, 9656), range(9656, 9680)],\n",
       " [range(0, 9680), range(9680, 9704)],\n",
       " [range(0, 9704), range(9704, 9728)],\n",
       " [range(0, 9728), range(9728, 9752)],\n",
       " [range(0, 9752), range(9752, 9776)],\n",
       " [range(0, 9776), range(9776, 9800)],\n",
       " [range(0, 9800), range(9800, 9824)],\n",
       " [range(0, 9824), range(9824, 9848)],\n",
       " [range(0, 9848), range(9848, 9872)],\n",
       " [range(0, 9872), range(9872, 9896)],\n",
       " [range(0, 9896), range(9896, 9920)],\n",
       " [range(0, 9920), range(9920, 9944)],\n",
       " [range(0, 9944), range(9944, 9968)],\n",
       " [range(0, 9968), range(9968, 9992)],\n",
       " [range(0, 9992), range(9992, 10000)]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.model_selection import _create_backtesting_folds\n",
    "\n",
    "# Create a dataframe with random values and 3 columns\n",
    "n=10_000\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(n, 30)))\n",
    "\n",
    "backtesting_folds = _create_backtesting_folds(\n",
    "    data = df,\n",
    "    initial_train_size=int(n/2),\n",
    "    test_size=24,\n",
    "    refit=True,\n",
    "    return_all_indexes=True,\n",
    "    fixed_train_size=False,\n",
    "    verbose=False\n",
    ")\n",
    "backtesting_folds = [fold[:2] for fold in backtesting_folds]\n",
    "print(len(backtesting_folds))\n",
    "backtesting_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_predict_1(df, folds, regressor=LinearRegression()):\n",
    "    \"\"\"\n",
    "    Fit forecaster and predict `steps` ahead. This function is used to test\n",
    "    the parallelization of the backtesting_forecaster function. The whole\n",
    "    dataframe is passed to the function, but only the train and test sets\n",
    "    corresponding to the fold are used.\n",
    "    \"\"\"\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X=df.iloc[folds[0], 1:], y=df.iloc[folds[0], 0])\n",
    "    pred = regressor.predict(df.iloc[folds[1], 1:])\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def _fit_predict_2(data_train, data_test, regressor=LinearRegression()):\n",
    "    \"\"\"\n",
    "    Fit forecaster and predict `steps` ahead. This function is used to test\n",
    "    the parallelization of the backtesting_forecaster function. Only the data\n",
    "    corresponding to the fold are passed to the function.\n",
    "    \"\"\"\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X=data_train.iloc[:, 1:], y=data_train.iloc[:, 0])\n",
    "    pred = regressor.predict(X=data_test.iloc[:, 1:])\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "n_jobs  = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_1\n",
    "results = [_fit_predict_1(df, folds, regressor) for folds in backtesting_folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 ms ± 5.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_1\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_1)(df, folds, regressor) for folds in backtesting_folds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.36 s ± 4.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_2\n",
    "results = [\n",
    "    _fit_predict_2(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in backtesting_folds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35 s ± 12.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_2\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in backtesting_folds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_backtesting = [[df.iloc[folds[0],:], df.iloc[folds[1],:]] for folds in backtesting_folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 s ± 6.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_2\n",
    "results = [\n",
    "    _fit_predict_2(partition[0], partition[1], regressor)\n",
    "    for partition in partitions_backtesting\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925 ms ± 7.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_2\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(partition[0], partition[1], regressor)\n",
    "    for partition in partitions_backtesting)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (50000, 30)\n",
      "Number of folds: 1042\n",
      "Number of CPUs: 8\n",
      "\n",
      "_fit_predict_1\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5b742672f1401882834de000fee394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_1 sequential: 64.37 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffb303e90dd4429b2905ffee3cd20d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_1 parallel: 34.65 seconds\n",
      "\n",
      "_fit_predict_2\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc31c10362ad49afbb90bb420a424e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 sequential: 51.10 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29993c6a534424e99eab0a49e86ae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 parallel: 33.09 seconds\n",
      "\n",
      "_fit_predict_2: list of partitions\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88cfe59265847f4a78bdc762e9bd771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 sequential: 40.99 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0c2dc3c9b740b688cd4b96fd07a2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 parallel: 32.74 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=5_000\n",
    "df = pd.DataFrame(np.random.randint(0, 100, size=(n, 30)))\n",
    "print(f\"Shape of dataframe: {df.shape}\")\n",
    "backtesting_folds = _create_backtesting_folds(\n",
    "    data = df,\n",
    "    initial_train_size=int(n/2),\n",
    "    test_size=24,\n",
    "    refit=True,\n",
    "    return_all_indexes=True,\n",
    "    fixed_train_size=False,\n",
    "    verbose=False\n",
    ")\n",
    "backtesting_folds = [fold[:2] for fold in backtesting_folds]\n",
    "print(f\"Number of folds: {len(backtesting_folds)}\")\n",
    "\n",
    "n_jobs  = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPUs: {n_jobs}\")\n",
    "partitions_backtesting = [[df.iloc[folds[0],:], df.iloc[folds[1],:]] for folds in backtesting_folds]\n",
    "regressor = HistGradientBoostingRegressor()\n",
    "\n",
    "# Benchmarking\n",
    "# ==============================================================================\n",
    "print(\"\")\n",
    "print(\"_fit_predict_1\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_1\n",
    "start = time.time()\n",
    "results = [_fit_predict_1(df, folds, regressor) for folds in tqdm(backtesting_folds)]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_1 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_1\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_1)(df, folds, regressor) for folds in tqdm(backtesting_folds))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_1 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"_fit_predict_2\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = [\n",
    "    _fit_predict_2(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in tqdm(backtesting_folds)\n",
    "]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in tqdm(backtesting_folds))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"_fit_predict_2: list of partitions\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = [\n",
    "    _fit_predict_2(partition[0], partition[1], regressor)\n",
    "    for partition in tqdm(partitions_backtesting)\n",
    "]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(partition[0], partition[1], regressor)\n",
    "    for partition in tqdm(partitions_backtesting))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel barcktesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "\n",
    "from skforecast.model_selection import _backtesting_forecaster_refit\n",
    "from skforecast.model_selection import _backtesting_forecaster_verbose\n",
    "from skforecast.model_selection import _get_metric\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _backtesting_forecaster_refit_parallel(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    n_jobs: int=1,\n",
    "    show_progress: bool=True\n",
    ") -> Tuple[Union[float, list], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with refit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect\n",
    "        Forecaster model.\n",
    "    y : pandas Series\n",
    "        Training time series.\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "            - If string: {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "            - If Callable: Function with arguments y_true, y_pred that returns a float.\n",
    "            - If list: List containing multiple strings and/or Callables.\n",
    "    initial_train_size : int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "    interval : list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. For example, \n",
    "        interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no\n",
    "        intervals are estimated.\n",
    "    n_boot : int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "    in_sample_residuals : bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of prediction\n",
    "        error to create prediction intervals. If `False`, out_sample_residuals \n",
    "        are used if they are already stored inside the forecaster.\n",
    "    n_jobs : int, default 1\n",
    "        Number of jobs to run in parallel. If -1, then the number of jobs is set\n",
    "        to the number of cores.\n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used \n",
    "        for backtesting.\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_value : float, list\n",
    "        Value(s) of the metric(s).\n",
    "    backtest_predictions : pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "\n",
    "            - column pred: predictions.\n",
    "            - column lower_bound: lower bound of the interval.\n",
    "            - column upper_bound: upper bound of the interval.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_jobs = n_jobs if n_jobs > 0 else cpu_count()\n",
    "    forecaster = deepcopy(forecaster)\n",
    "\n",
    "    if not isinstance(metric, list):\n",
    "        metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]\n",
    "    else:\n",
    "        metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]\n",
    "\n",
    "    folds = _create_backtesting_folds(\n",
    "                data                  = y,\n",
    "                test_size             = steps,\n",
    "                initial_train_size    = initial_train_size,\n",
    "                gap                   = gap,\n",
    "                refit                 = True,\n",
    "                fixed_train_size      = fixed_train_size,\n",
    "                allow_incomplete_fold = allow_incomplete_fold,\n",
    "                return_all_indexes    = False,\n",
    "                verbose               = verbose  \n",
    "            )\n",
    "        \n",
    "    if type(forecaster).__name__ != 'ForecasterAutoregDirect' and len(folds) > 50:\n",
    "        warnings.warn(\n",
    "            (f\"The forecaster will be fit {len(folds)} times. This can take substantial\"\n",
    "             f\" amounts of time. If not feasible, try with `refit = False`.\\n\"),\n",
    "            LongTrainingWarning\n",
    "        )\n",
    "    elif type(forecaster).__name__ == 'ForecasterAutoregDirect' and len(folds)*forecaster.steps > 50:\n",
    "        warnings.warn(\n",
    "            (f\"The forecaster will be fit {len(folds)*forecaster.steps} times \"\n",
    "             f\"({len(folds)} folds * {forecaster.steps} regressors). This can take \"\n",
    "             f\"substantial amounts of time. If not feasible, try with `refit = False`.\\n\"),\n",
    "             LongTrainingWarning\n",
    "        )\n",
    "\n",
    "    store_in_sample_residuals = False if interval is None else True\n",
    "\n",
    "    def _fit_predict_forecaster(y, exog, forecaster, interval, fold):\n",
    "        '''\n",
    "        Fit forecaster and predict `steps` ahead.\n",
    "        '''\n",
    "        train_idx_start = fold[0][0]\n",
    "        train_idx_end   = fold[0][1]\n",
    "        test_idx_start  = fold[1][0]\n",
    "        test_idx_end    = fold[1][1]\n",
    "        \n",
    "        y_train = y.iloc[train_idx_start:train_idx_end, ]\n",
    "        exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None\n",
    "        next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None\n",
    "\n",
    "        forecaster.fit(\n",
    "            y                         = y_train, \n",
    "            exog                      = exog_train, \n",
    "            store_in_sample_residuals = store_in_sample_residuals\n",
    "        )\n",
    "        steps = len(range(test_idx_start, test_idx_end))\n",
    "        if interval is None:\n",
    "            pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "            pred = forecaster.predict_interval(\n",
    "                       steps               = steps,\n",
    "                       exog                = next_window_exog,\n",
    "                       interval            = interval,\n",
    "                       n_boot              = n_boot,\n",
    "                       random_state        = random_state,\n",
    "                       in_sample_residuals = in_sample_residuals\n",
    "                   )\n",
    "\n",
    "        pred = pred.iloc[gap:, ]\n",
    "\n",
    "        return pred\n",
    "\n",
    "    backtest_predictions = (\n",
    "        Parallel(n_jobs=n_jobs)\n",
    "        (delayed(_fit_predict_forecaster)\n",
    "        (y=y, exog=exog, forecaster=forecaster, interval=interval, fold=fold)\n",
    "        for fold in tqdm(folds))\n",
    "    )        \n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "        backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    metrics_values = [m(\n",
    "                        y_true = y.loc[backtest_predictions.index],\n",
    "                        y_pred = backtest_predictions['pred']\n",
    "                      ) for m in metrics\n",
    "                     ]\n",
    "    \n",
    "    if not isinstance(metric, list):\n",
    "        metrics_values = metrics_values[0]\n",
    "\n",
    "    return metrics_values, backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(regressor=HistGradientBoostingRegressor(random_state=666), lags=50)\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=50)\n",
    "n=5_000\n",
    "y = pd.Series(np.random.randint(0,100,size=(n)))\n",
    "y_train = y[:-int(n/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:419: LongTrainingWarning: The forecaster will be fit 105 times. This can take substantial amounts of time. If not feasible, try with `refit = False`.\n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f648440c4004004a07e0f578e507cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    fixed_train_size    = False,\n",
    "                                    steps               = 24,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    verbose             = False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27042/2675875714.py:121: LongTrainingWarning: The forecaster will be fit 105 times. This can take substantial amounts of time. If not feasible, try with `refit = False`.\n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e256a710b934417a8bad11deaa2a5dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_parallel, backtest_predictions_parallel = _backtesting_forecaster_refit_parallel(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    fixed_train_size    = False,\n",
    "                                    steps               = 24,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    n_jobs              = -1,\n",
    "                                    verbose             = False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_parallel == metric\n",
    "pd.testing.assert_frame_equal(backtest_predictions_parallel, backtest_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
