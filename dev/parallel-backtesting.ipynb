{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding joblib multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.model_selection import _create_backtesting_folds\n",
    "\n",
    "# Create a dataframe with random values and 3 columns\n",
    "n=5_000\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(n, 30)))\n",
    "\n",
    "backtesting_folds = _create_backtesting_folds(\n",
    "    data = df,\n",
    "    initial_train_size=int(n/2),\n",
    "    test_size=24,\n",
    "    refit=True,\n",
    "    return_all_indexes=True,\n",
    "    fixed_train_size=False,\n",
    "    verbose=False\n",
    ")\n",
    "backtesting_folds = [fold[:2] for fold in backtesting_folds]\n",
    "print(len(backtesting_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_predict_1(df, folds, regressor=LinearRegression()):\n",
    "    \"\"\"\n",
    "    Fit forecaster and predict `steps` ahead. This function is used to test\n",
    "    the parallelization of the backtesting_forecaster function. The whole\n",
    "    dataframe is passed to the function, but only the train and test sets\n",
    "    corresponding to the fold are used.\n",
    "    \"\"\"\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X=df.iloc[folds[0], 1:], y=df.iloc[folds[0], 0])\n",
    "    pred = regressor.predict(df.iloc[folds[1], 1:])\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def _fit_predict_2(data_train, data_test, regressor=LinearRegression()):\n",
    "    \"\"\"\n",
    "    Fit forecaster and predict `steps` ahead. This function is used to test\n",
    "    the parallelization of the backtesting_forecaster function. Only the data\n",
    "    corresponding to the fold are passed to the function.\n",
    "    \"\"\"\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X=data_train.iloc[:, 1:], y=data_train.iloc[:, 0])\n",
    "    pred = regressor.predict(X=data_test.iloc[:, 1:])\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "n_jobs  = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 s ± 6.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_1\n",
    "results = [_fit_predict_1(df, folds, regressor) for folds in backtesting_folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_1\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_1)(df, folds, regressor) for folds in backtesting_folds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01 s ± 3.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_2\n",
    "results = [\n",
    "    _fit_predict_2(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in backtesting_folds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503 ms ± 5.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_2\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in backtesting_folds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_backtesting = [[df.iloc[folds[0],:], df.iloc[folds[1],:]] for folds in backtesting_folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843 ms ± 2.49 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Sequential execution _fit_predict_2\n",
    "results = [\n",
    "    _fit_predict_2(partition[0], partition[1], regressor)\n",
    "    for partition in partitions_backtesting\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 ms ± 4.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Parallel execution _fit_predict_2\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(partition[0], partition[1], regressor)\n",
    "    for partition in partitions_backtesting)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (10000, 50)\n",
      "Number of folds: 209\n",
      "Number of CPUs: 8\n",
      "\n",
      "_fit_predict_1\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7817bd4f536a445f80a30958ea9119bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_1 sequential: 4.66 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627446fb540a476fb4909f624c13af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_1 parallel: 1.82 seconds\n",
      "\n",
      "_fit_predict_2\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d464a892ea49f7b75ad4c741678725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 sequential: 4.24 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b678d8d59f047e388c22ef8f41520f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 parallel: 2.32 seconds\n",
      "\n",
      "_fit_predict_2: list of partitions\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba1e6376f864d1883f1e7070b1bab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 sequential: 3.62 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71753ebdca84c45877986af44c42bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time _fit_predict_2 parallel: 1.69 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=10_000\n",
    "df = pd.DataFrame(np.random.randint(0, 100, size=(n, 50)))\n",
    "print(f\"Shape of dataframe: {df.shape}\")\n",
    "backtesting_folds = _create_backtesting_folds(\n",
    "    data = df,\n",
    "    initial_train_size=int(n/2),\n",
    "    test_size=24,\n",
    "    refit=True,\n",
    "    return_all_indexes=True,\n",
    "    fixed_train_size=False,\n",
    "    verbose=False\n",
    ")\n",
    "backtesting_folds = [fold[:2] for fold in backtesting_folds]\n",
    "print(f\"Number of folds: {len(backtesting_folds)}\")\n",
    "\n",
    "n_jobs  = multiprocessing.cpu_count()\n",
    "print(f\"Number of CPUs: {n_jobs}\")\n",
    "partitions_backtesting = [[df.iloc[folds[0],:], df.iloc[folds[1],:]] for folds in backtesting_folds]\n",
    "regressor = HistGradientBoostingRegressor()\n",
    "\n",
    "# Benchmarking\n",
    "# ==============================================================================\n",
    "print(\"\")\n",
    "print(\"_fit_predict_1\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_1\n",
    "start = time.time()\n",
    "results = [_fit_predict_1(df, folds, regressor) for folds in tqdm(backtesting_folds)]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_1 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_1\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_1)(df, folds, regressor) for folds in tqdm(backtesting_folds))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_1 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"_fit_predict_2\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = [\n",
    "    _fit_predict_2(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in tqdm(backtesting_folds)\n",
    "]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(df.iloc[folds[0],:], df.iloc[folds[1],:], regressor)\n",
    "    for folds in tqdm(backtesting_folds))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"_fit_predict_2: list of partitions\")\n",
    "print(\"==============\")\n",
    "# Sequential execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = [\n",
    "    _fit_predict_2(partition[0], partition[1], regressor)\n",
    "    for partition in tqdm(partitions_backtesting)\n",
    "]\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 sequential: {elapsed:.2f} seconds\")\n",
    "\n",
    "# Parallel execution _fit_predict_2\n",
    "start = time.time()\n",
    "results = (\n",
    "    Parallel(n_jobs=n_jobs)\n",
    "    (delayed(_fit_predict_2)(partition[0], partition[1], regressor)\n",
    "    for partition in tqdm(partitions_backtesting))\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time _fit_predict_2 parallel: {elapsed:.2f} seconds\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel barcktesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "\n",
    "from skforecast.model_selection import _backtesting_forecaster_refit\n",
    "from skforecast.model_selection import _backtesting_forecaster_no_refit\n",
    "from skforecast.model_selection import _backtesting_forecaster_verbose\n",
    "from skforecast.model_selection import _get_metric\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _backtesting_forecaster_refit_parallel(\n",
    "#     forecaster,\n",
    "#     y: pd.Series,\n",
    "#     steps: int,\n",
    "#     metric: Union[str, Callable, list],\n",
    "#     initial_train_size: int,\n",
    "#     fixed_train_size: bool=True,\n",
    "#     gap: int=0,\n",
    "#     allow_incomplete_fold: bool=True,\n",
    "#     exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "#     interval: Optional[list]=None,\n",
    "#     n_boot: int=500,\n",
    "#     random_state: int=123,\n",
    "#     in_sample_residuals: bool=True,\n",
    "#     verbose: bool=False,\n",
    "#     n_jobs: int=-1,\n",
    "#     show_progress: bool=True\n",
    "# ) -> Tuple[Union[float, list], pd.DataFrame]:\n",
    "#     \"\"\"\n",
    "#     Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "#     original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "#     In each iteration:\n",
    "#         - Fit forecaster with the training set.\n",
    "#         - A number of `steps` ahead are predicted.\n",
    "#         - The training set increases with `steps` observations.\n",
    "#         - The model is re-fitted using the new training set.\n",
    "\n",
    "#     In order to apply backtesting with refit, an initial training set must be\n",
    "#     available, otherwise it would not be possible to increase the training set \n",
    "#     after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect\n",
    "#         Forecaster model.\n",
    "#     y : pandas Series\n",
    "#         Training time series.\n",
    "#     steps : int\n",
    "#         Number of steps to predict.\n",
    "#     metric : str, Callable, list\n",
    "#         Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "#             - If string: {'mean_squared_error', 'mean_absolute_error',\n",
    "#              'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "#             - If Callable: Function with arguments y_true, y_pred that returns a float.\n",
    "#             - If list: List containing multiple strings and/or Callables.\n",
    "#     initial_train_size : int\n",
    "#         Number of samples in the initial train split. The backtest forecaster is\n",
    "#         trained using the first `initial_train_size` observations.\n",
    "#     fixed_train_size : bool, default `True`\n",
    "#         If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "#     gap : int, default `0`\n",
    "#         Number of samples to be excluded after the end of each training set and \n",
    "#         before the test set.\n",
    "#     allow_incomplete_fold : bool, default `True`\n",
    "#         Last fold is allowed to have a smaller number of samples than the \n",
    "#         `test_size`. If `False`, the last fold is excluded.\n",
    "#     exog : pandas Series, pandas DataFrame, default `None`\n",
    "#         Exogenous variable/s included as predictor/s. Must have the same\n",
    "#         number of observations as `y` and should be aligned so that y[i] is\n",
    "#         regressed on exog[i].\n",
    "#     interval : list, default `None`\n",
    "#         Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "#         to compute, which must be between 0 and 100 inclusive. For example, \n",
    "#         interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no\n",
    "#         intervals are estimated.\n",
    "#     n_boot : int, default `500`\n",
    "#         Number of bootstrapping iterations used to estimate prediction\n",
    "#         intervals.\n",
    "#     random_state : int, default `123`\n",
    "#         Sets a seed to the random generator, so that boot intervals are always \n",
    "#         deterministic.\n",
    "#     in_sample_residuals : bool, default `True`\n",
    "#         If `True`, residuals from the training data are used as proxy of prediction\n",
    "#         error to create prediction intervals. If `False`, out_sample_residuals \n",
    "#         are used if they are already stored inside the forecaster.\n",
    "#     n_jobs : int, default -1\n",
    "#         The number of jobs to run in parallel. If -1, then the number of jobs is \n",
    "#         set to the number of cores.\n",
    "#     verbose : bool, default `False`\n",
    "#         Print number of folds and index of training and validation sets used \n",
    "#         for backtesting.\n",
    "#     show_progress: bool, default `True`\n",
    "#         Whether to show a progress bar. Defaults to True.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     metrics_value : float, list\n",
    "#         Value(s) of the metric(s).\n",
    "#     backtest_predictions : pandas Dataframe\n",
    "#         Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "\n",
    "#             - column pred: predictions.\n",
    "#             - column lower_bound: lower bound of the interval.\n",
    "#             - column upper_bound: upper bound of the interval.\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "#     forecaster = deepcopy(forecaster)\n",
    "#     n_jobs = n_jobs if n_jobs > 0 else cpu_count()\n",
    "\n",
    "#     if not isinstance(metric, list):\n",
    "#         metrics = [_get_metric(metric=metric) if isinstance(metric, str) else metric]\n",
    "#     else:\n",
    "#         metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]\n",
    "\n",
    "#     folds = _create_backtesting_folds(\n",
    "#                 data                  = y,\n",
    "#                 test_size             = steps,\n",
    "#                 initial_train_size    = initial_train_size,\n",
    "#                 gap                   = gap,\n",
    "#                 refit                 = True,\n",
    "#                 fixed_train_size      = fixed_train_size,\n",
    "#                 allow_incomplete_fold = allow_incomplete_fold,\n",
    "#                 return_all_indexes    = False,\n",
    "#                 verbose               = verbose  \n",
    "#             )\n",
    "    \n",
    "#     if show_progress:\n",
    "#         folds = tqdm(folds)\n",
    "\n",
    "#     if type(forecaster).__name__ != 'ForecasterAutoregDirect' and len(folds) > 50:\n",
    "#         warnings.warn(\n",
    "#             (f\"The forecaster will be fit {len(folds)} times. This can take substantial\"\n",
    "#              f\" amounts of time. If not feasible, try with `refit = False`.\\n\"),\n",
    "#             LongTrainingWarning\n",
    "#         )\n",
    "#     elif type(forecaster).__name__ == 'ForecasterAutoregDirect' and len(folds)*forecaster.steps > 50:\n",
    "#         warnings.warn(\n",
    "#             (f\"The forecaster will be fit {len(folds)*forecaster.steps} times \"\n",
    "#              f\"({len(folds)} folds * {forecaster.steps} regressors). This can take \"\n",
    "#              f\"substantial amounts of time. If not feasible, try with `refit = False`.\\n\"),\n",
    "#              LongTrainingWarning\n",
    "#         )\n",
    "\n",
    "#     store_in_sample_residuals = False if interval is None else True\n",
    "\n",
    "#     def _fit_predict_forecaster(y, exog, forecaster, interval, fold):\n",
    "#         \"\"\"\n",
    "#         Fit the forecaster and predict `steps` ahead. This is an auxiliary \n",
    "#         function used to parallelize the backtesting_forecaster function.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # In each iteration the model is fitted before making predictions. \n",
    "#         # if fixed_train_size the train size doesn't increase but moves by `steps` \n",
    "#         # in each iteration. if False the train size increases by `steps` in each \n",
    "#         # iteration.\n",
    "#         train_idx_start = fold[0][0]\n",
    "#         train_idx_end   = fold[0][1]\n",
    "#         test_idx_start  = fold[1][0]\n",
    "#         test_idx_end    = fold[1][1]\n",
    "\n",
    "#         y_train = y.iloc[train_idx_start:train_idx_end, ]\n",
    "#         exog_train = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None\n",
    "#         next_window_exog = exog.iloc[test_idx_start:test_idx_end, ] if exog is not None else None\n",
    "\n",
    "#         forecaster.fit(\n",
    "#             y                         = y_train, \n",
    "#             exog                      = exog_train, \n",
    "#             store_in_sample_residuals = store_in_sample_residuals\n",
    "#         )\n",
    "#         steps = len(range(test_idx_start, test_idx_end))\n",
    "#         if interval is None:\n",
    "#             pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "#         else:\n",
    "#             pred = forecaster.predict_interval(\n",
    "#                        steps               = steps,\n",
    "#                        exog                = next_window_exog,\n",
    "#                        interval            = interval,\n",
    "#                        n_boot              = n_boot,\n",
    "#                        random_state        = random_state,\n",
    "#                        in_sample_residuals = in_sample_residuals\n",
    "#                    )\n",
    "#         pred = pred.iloc[gap:, ]\n",
    "\n",
    "#         return pred\n",
    "\n",
    "#     backtest_predictions = (\n",
    "#         Parallel(n_jobs=n_jobs)\n",
    "#         (delayed(_fit_predict_forecaster)\n",
    "#         (y=y, exog=exog, forecaster=forecaster, interval=interval, fold=fold)\n",
    "#         for fold in folds)\n",
    "#     )\n",
    "    \n",
    "#     backtest_predictions = pd.concat(backtest_predictions)\n",
    "#     if isinstance(backtest_predictions, pd.Series):\n",
    "#         backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "#     metrics_values = [m(\n",
    "#                         y_true = y.loc[backtest_predictions.index],\n",
    "#                         y_pred = backtest_predictions['pred']\n",
    "#                       ) for m in metrics\n",
    "#                      ]\n",
    "    \n",
    "#     if not isinstance(metric, list):\n",
    "#         metrics_values = metrics_values[0]\n",
    "\n",
    "#     return metrics_values, backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(regressor=HistGradientBoostingRegressor(random_state=666), lags=50)\n",
    "#forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=50)\n",
    "n=10_000\n",
    "y = pd.Series(np.random.randint(0,100,size=(n)), name=\"y\")\n",
    "exog = pd.DataFrame(np.random.randint(0, 100, size=(n, 10)))\n",
    "exog.columns = [f\"col_{i}\" for i in range(exog.shape[1])]\n",
    "y_train = y[:-int(n/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93766f04f882476899aa7964edc1a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:427: LongTrainingWarning: The forecaster will be fit 209 times. This can take substantial amounts of time. If not feasible, try with `refit = False`.\n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = exog,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    fixed_train_size    = False,\n",
    "                                    steps               = 24,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    verbose             = False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874.9358045268056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>49.908513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>57.282173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>47.747914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>46.525623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>51.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>48.862105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>46.959207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>51.538055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>56.505729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>47.966177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred\n",
       "5000  49.908513\n",
       "5001  57.282173\n",
       "5002  47.747914\n",
       "5003  46.525623\n",
       "5004  51.098836\n",
       "...         ...\n",
       "9995  48.862105\n",
       "9996  46.959207\n",
       "9997  51.538055\n",
       "9998  56.505729\n",
       "9999  47.966177\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metric)\n",
    "backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baa98b8bfbc471baa6277f8db1af238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric, backtest_predictions = _backtesting_forecaster_no_refit(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = exog,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    steps               = 24,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    verbose             = False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877.8831850272799\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>49.908513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>57.282173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>47.747914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>46.525623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>51.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>46.123965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>52.104853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57.122831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>54.109774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>51.248282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred\n",
       "5000  49.908513\n",
       "5001  57.282173\n",
       "5002  47.747914\n",
       "5003  46.525623\n",
       "5004  51.098836\n",
       "...         ...\n",
       "9995  46.123965\n",
       "9996  52.104853\n",
       "9997  57.122831\n",
       "9998  54.109774\n",
       "9999  51.248282\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metric)\n",
    "backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 81.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8224321a87c548ee90d495cfd8acfc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04dd93b10f74908b215fab287accb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backtesting\n",
    "# ==============================================================================\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'max_iter': [200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_leaf': [5, 10, 20],\n",
    "    'l2_regularization': [0.0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                    forecaster          = forecaster,\n",
    "                    y                   = y,\n",
    "                    exog                = exog,\n",
    "                    initial_train_size  = len(y_train),\n",
    "                    steps               = 24,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    refit              = False,\n",
    "                    metric             = 'mean_squared_error',\n",
    "                    fixed_train_size   = False,\n",
    "                    return_best        = False,\n",
    "                    verbose            = False,\n",
    "                    show_progress      = True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 81.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca4a6ad80f94cdf9308809e67cbe4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c6dcd984cc40c3a1f02443977fdfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5aff09e84d74aeb96fae37cfaf3753c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_15902/888595618.py\", line 12, in <module>\n",
      "    results_grid = grid_search_forecaster(\n",
      "  File \"/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py\", line 954, in grid_search_forecaster\n",
      "  File \"/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py\", line 1191, in _evaluate_grid_hyperparameters\n",
      "  File \"/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py\", line 857, in backtesting_forecaster\n",
      "    n_jobs                = n_jobs,\n",
      "  File \"/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py\", line 683, in _backtesting_forecaster_no_refit\n",
      "    Parallel(n_jobs=n_jobs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/joblib/parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/joblib/parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/concurrent/futures/_base.py\", line 453, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ubuntu/anaconda3/envs/skforecast_py10/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'max_iter': [200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_leaf': [5, 10, 20],\n",
    "    'l2_regularization': [0.0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                    forecaster          = forecaster,\n",
    "                    y                   = y,\n",
    "                    exog                = exog,\n",
    "                    initial_train_size  = len(y_train),\n",
    "                    steps               = 24,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    refit              = False,\n",
    "                    metric             = 'mean_squared_error',\n",
    "                    fixed_train_size   = False,\n",
    "                    return_best        = False,\n",
    "                    verbose            = False,\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
