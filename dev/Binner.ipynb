{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "c:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from timeit import repeat\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.linear_model import LinearRegression   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QuantileBinner:\n",
    "    \"\"\"\n",
    "    QuantileBinner class to bin data into quantile-based bins.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_bins : int, optional\n",
    "        The number of quantile-based bins to create. Default is 4 (quartiles).\n",
    "    method : str, default='linear'\n",
    "        The method used to compute the quantiles. This parameter is passed to \n",
    "        `numpy.percentile`. Default is 'linear'. Valid values are 'linear',\n",
    "        'lower', 'higher', 'midpoint', 'nearest'.\n",
    "    subsample : int, default=200000\n",
    "        The number of samples to use for computing quantiles. If the dataset \n",
    "        has more samples than `subsample`, a random subset will be used. \n",
    "        Default is 200000.\n",
    "    dtype : data type, default=numpy.int32\n",
    "        The data type to use for the bin indices. Default is `numpy.int32`.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_bins : int, optional\n",
    "        The number of quantile-based bins to create. Default is 4 (quartiles).\n",
    "    method : str, default='linear'\n",
    "        The method used to compute the quantiles. This parameter is passed to \n",
    "        `numpy.percentile`. Default is 'linear'. Valid values are 'linear',\n",
    "        'lower', 'higher', 'midpoint', 'nearest'.\n",
    "    subsample : int, default=200000\n",
    "        The number of samples to use for computing quantiles. If the dataset \n",
    "        has more samples than `subsample`, a random subset will be used. \n",
    "        Default is 200000.\n",
    "    dtype : data type, default=numpy.int32\n",
    "        The data type to use for the bin indices. Default is `numpy.int32`.\n",
    "    bin_edges_ : ndarray\n",
    "        The edges of the bins learned during fitting.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_bins=4, method=\"linear\", subsample=200000, dtype=np.int32):\n",
    "        self.n_bins     = n_bins\n",
    "        self.method     = method\n",
    "        self.subsample  = subsample\n",
    "        self.dtype      = dtype\n",
    "        self.bin_edges_ = None\n",
    "    \n",
    "    def fit(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Learn the bin edges based on quantiles from the training data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray\n",
    "            The training data used to compute the quantiles.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : QuantileBinner\n",
    "            Fitted estimator.\n",
    "        \"\"\"\n",
    "\n",
    "        if X.size == 0:\n",
    "            raise ValueError(\"Input data `X` cannot be empty.\")\n",
    "        if len(X) > self.subsample:\n",
    "            rng = np.random.default_rng()\n",
    "            X = rng.choice(X, size=self.subsample, replace=False)\n",
    "        \n",
    "        if self.n_bins == 1:\n",
    "            self.bin_edges_ = [np.min(X), np.max(X)]\n",
    "        else:\n",
    "            self.bin_edges_ = np.percentile(X, np.linspace(0, 100, self.n_bins + 1), method=self.method)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_new):\n",
    "        \"\"\"\n",
    "        Assign new data to the learned bins.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_new : array-like of shape (n_samples,)\n",
    "            The data to assign to the bins.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        bin_indices : ndarray of shape (n_samples,)\n",
    "            The indices of the bins each value belongs to.\n",
    "            Values less than the smallest bin edge are assigned to the first bin,\n",
    "            and values greater than the largest bin edge are assigned to the last bin.\n",
    "        \"\"\"\n",
    "        if self.bin_edges_ is None:\n",
    "            raise ValueError(\"The model has not been fitted yet. Call 'fit' with training data first.\")\n",
    "        \n",
    "        bin_indices = np.digitize(X_new, bins=self.bin_edges_, right=True)\n",
    "        bin_indices = np.clip(bin_indices, 1, self.n_bins).astype(self.dtype)\n",
    "        \n",
    "        return bin_indices\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit the model to the data and return the bin indices for the same data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples,)\n",
    "            The data to fit and transform.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        bin_indices : ndarray of shape (n_samples,)\n",
    "            The indices of the bins each value in `X` belongs to.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def get_bin_edges(self):\n",
    "        \"\"\"\n",
    "        Get the learned bin edges after fitting.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        bin_edges_ : ndarray\n",
    "            The edges of the bins.\n",
    "        \"\"\"\n",
    "        return self.bin_edges_\n",
    "    \n",
    "    def get_bin_intervals(self):\n",
    "        \"\"\"\n",
    "        Get the bin intervals as a list of tuples (lower_bound, upper_bound).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        intervals : list of tuple\n",
    "            A list of bin intervals, where each interval is represented as a \n",
    "            tuple (lower_bound, upper_bound).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.bin_edges_ is None:\n",
    "            raise ValueError(\"The model has not been fitted yet. Call 'fit' with training data first.\")\n",
    "        \n",
    "        intervals = [(self.bin_edges_[i], self.bin_edges_[i + 1]) for i in range(self.n_bins)]\n",
    "        return intervals\n",
    "    \n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Get the parameters of the quantile binner.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        params : dict\n",
    "            A dictionary of the parameters of the quantile binner.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"n_bins\": self.n_bins,\n",
    "            \"method\": self.method,\n",
    "            \"subsample\": self.subsample,\n",
    "            \"dtype\": self.dtype\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(10, 10, 10000)\n",
    "X_reshaped = X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn KBinsDiscretizer {'dtype': <class 'numpy.float64'>, 'encode': 'ordinal', 'n_bins': 10, 'random_state': None, 'strategy': 'uniform', 'subsample': 200000}\n",
      "    Fit      : 0.308964 μs +- 0.000051\n",
      "    Transform: 0.170891 μs +- 0.000013\n",
      "\n",
      "Sklearn KBinsDiscretizer {'dtype': <class 'numpy.float64'>, 'encode': 'ordinal', 'n_bins': 10, 'random_state': None, 'strategy': 'quantile', 'subsample': 200000}\n",
      "    Fit      : 0.637658 μs +- 0.000056\n",
      "    Transform: 0.219849 μs +- 0.000022\n",
      "\n",
      "QuantileBinner {'n_bins': 10, 'method': 'linear', 'subsample': 200000, 'dtype': <class 'numpy.float64'>}\n",
      "    Fit      : 0.434101 μs +- 0.000031\n",
      "    Transform: 0.173879 μs +- 0.000012\n",
      "\n",
      "QuantileBinner {'n_bins': 10, 'method': 'closest_observation', 'subsample': 200000, 'dtype': <class 'numpy.float64'>}\n",
      "    Fit      : 0.416794 μs +- 0.000035\n",
      "    Transform: 0.171105 μs +- 0.000012\n"
     ]
    }
   ],
   "source": [
    "binner = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform', dtype=np.float64)\n",
    "times_fit = repeat(\"binner.fit_transform(X_reshaped)\", repeat=100, number=1, globals=globals())\n",
    "times_transform = repeat(\"binner.transform(X_reshaped)\", repeat=100, number=1, globals=globals())\n",
    "print(f\"Sklearn KBinsDiscretizer {binner.get_params()}\")\n",
    "print(f\"    Fit      : {1000 * np.mean(times_fit):.6f} μs +- {np.std(times_fit):.6f}\")\n",
    "print(f\"    Transform: {1000 * np.mean(times_transform):.6f} μs +- {np.std(times_transform):.6f}\")\n",
    "print(\"\")\n",
    "\n",
    "binner = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile', dtype=np.float64)\n",
    "times_fit = repeat(\"binner.fit_transform(X_reshaped)\", repeat=100, number=1, globals=globals())\n",
    "times_transform = repeat(\"binner.transform(X_reshaped)\", repeat=100, number=1, globals=globals())\n",
    "print(f\"Sklearn KBinsDiscretizer {binner.get_params()}\")\n",
    "print(f\"    Fit      : {1000 * np.mean(times_fit):.6f} μs +- {np.std(times_fit):.6f}\")\n",
    "print(f\"    Transform: {1000 * np.mean(times_transform):.6f} μs +- {np.std(times_transform):.6f}\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "binner = QuantileBinner(n_bins=10, method=\"linear\", dtype=np.float64)\n",
    "times_fit = repeat(\"binner.fit_transform(X)\", repeat=100, number=1, globals=globals())\n",
    "times_transform = repeat(\"binner.transform(X)\", repeat=100, number=1, globals=globals())\n",
    "print(f\"QuantileBinner {binner.get_params()}\")\n",
    "print(f\"    Fit      : {1000 * np.mean(times_fit):.6f} μs +- {np.std(times_fit):.6f}\")\n",
    "print(f\"    Transform: {1000 * np.mean(times_transform):.6f} μs +- {np.std(times_transform):.6f}\")\n",
    "print(\"\")\n",
    "\n",
    "binner = QuantileBinner(n_bins=10, method=\"closest_observation\", dtype=np.float64)\n",
    "times_fit = repeat(\"binner.fit_transform(X)\", repeat=100, number=1, globals=globals())\n",
    "times_transform = repeat(\"binner.transform(X)\", repeat=100, number=1, globals=globals())\n",
    "print(f\"QuantileBinner {binner.get_params()}\")\n",
    "print(f\"    Fit      : {1000 * np.mean(times_fit):.6f} μs +- {np.std(times_fit):.6f}\")\n",
    "print(f\"    Transform: {1000 * np.mean(times_transform):.6f} μs +- {np.std(times_transform):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert equivalence\n",
    "binner_1 = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "binner_2 = QuantileBinner(n_bins=10, method=\"linear\")\n",
    "\n",
    "binner_1.fit(X.reshape(-1, 1))\n",
    "binner_2.fit(X)\n",
    "\n",
    "transformed_1 = binner_1.transform(X.reshape(-1, 1)).flatten()\n",
    "transformed_2 = binner_2.transform(X) -1\n",
    "\n",
    "np.testing.assert_array_almost_equal(binner_1.bin_edges_[0], binner_2.get_bin_edges())\n",
    "np.testing.assert_array_almost_equal(transformed_1, transformed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.26292295,  3.89720011, 11.43095513, 10.74486889, 18.53360102,\n",
       "        5.19816378, 29.445935  ,  5.96495197,  5.89220585, 10.44343867])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(X)\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=10)\n",
    "forecaster.fit(y)\n",
    "steps = 24\n",
    "last_window_values, _, _  = forecaster._create_predict_inputs(\n",
    "            steps=steps, last_window=forecaster.last_window_\n",
    "        )\n",
    "last_window_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.2 ms ± 19.2 ms per loop (mean ± std. dev. of 100 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 100 -n 2\n",
    "\n",
    "forecaster._recursive_predict_13(\n",
    "    steps=500,\n",
    "    last_window_values=last_window_values,\n",
    "    residuals=forecaster.in_sample_residuals_by_bin_,\n",
    "    use_binned_residuals=True,\n",
    "    rng=np.random.default_rng(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.7 ms ± 6.24 ms per loop (mean ± std. dev. of 100 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 100 -n 2\n",
    "\n",
    "forecaster._recursive_predict(\n",
    "    steps=500,\n",
    "    last_window_values=last_window_values,\n",
    "    residuals=forecaster.in_sample_residuals_by_bin_,\n",
    "    use_binned_residuals=True,\n",
    "    rng=np.random.default_rng(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_14_p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
