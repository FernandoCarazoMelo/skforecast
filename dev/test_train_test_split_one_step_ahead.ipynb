{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "c:\\Users\\JoaquÃ­n Amat\\Documents\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error\n",
    "from skforecast.metrics import root_mean_squared_scaled_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection.model_selection import _evaluate_grid_hyperparameters\n",
    "\n",
    "\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y_feature_selection\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog_feature_selection\n",
    "\n",
    "\n",
    "metrics = ['mean_absolute_error', mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "#metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame.iloc[:, 3] (column name=\"mean_absolute_error\") are different\n\nDataFrame.iloc[:, 3] (column name=\"mean_absolute_error\") values are different (100.0 %)\n[index]: [0, 1, 2, 3, 4, 5]\n[left]:  [0.0005606372165538498, 0.0005711071213165906, 0.000598871299685834, 49.21313141756098, 49.55171923705793, 50.51903847355794]\n[right]: [0.0007645824801421455, 0.0007750281610598293, 0.0008082819061429347, 50.293556578595144, 50.60648358600952, 51.59721196976838]\nAt positional index 0, first diff: 0.0005606372165538498 != 0.0007645824801421455",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, forecaster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(forecasters):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mtest_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecaster\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[98], line 50\u001b[0m, in \u001b[0;36mtest_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead\u001b[1;34m(forecaster)\u001b[0m\n\u001b[0;32m     19\u001b[0m results_backtesting \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters(\n\u001b[0;32m     20\u001b[0m     forecaster         \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[0;32m     21\u001b[0m     y                  \u001b[38;5;241m=\u001b[39m y_feature_selection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m results_one_step_ahead \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters(\n\u001b[0;32m     37\u001b[0m     forecaster         \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[0;32m     38\u001b[0m     y                  \u001b[38;5;241m=\u001b[39m y_feature_selection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     48\u001b[0m )\n\u001b[1;32m---> 50\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_backtesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_one_step_ahead\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_13_p12\\Lib\\site-packages\\pandas\\_testing\\asserters.py:614\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[1;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: DataFrame.iloc[:, 3] (column name=\"mean_absolute_error\") are different\n\nDataFrame.iloc[:, 3] (column name=\"mean_absolute_error\") values are different (100.0 %)\n[index]: [0, 1, 2, 3, 4, 5]\n[left]:  [0.0005606372165538498, 0.0005711071213165906, 0.000598871299685834, 49.21313141756098, 49.55171923705793, 50.51903847355794]\n[right]: [0.0007645824801421455, 0.0007750281610598293, 0.0008082819061429347, 50.293556578595144, 50.60648358600952, 51.59721196976838]\nAt positional index 0, first diff: 0.0005606372165538498 != 0.0007645824801421455"
     ]
    }
   ],
   "source": [
    "def test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "    forecaster,\n",
    "):\n",
    "\n",
    "    metrics = [\n",
    "        \"mean_absolute_error\",\n",
    "        \"mean_squared_error\",\n",
    "        mean_absolute_percentage_error,\n",
    "        mean_absolute_scaled_error,\n",
    "        root_mean_squared_scaled_error,\n",
    "    ]\n",
    "    steps = 1\n",
    "    initial_train_size = 100\n",
    "    param_grid = {\n",
    "        \"alpha\": np.logspace(-3, 3, 2),\n",
    "    }\n",
    "    lags_grid = [3, 5, 7]\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    results_backtesting = _evaluate_grid_hyperparameters(\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y_feature_selection,\n",
    "        exog               = exog_feature_selection,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        steps              = steps,\n",
    "        refit              = False,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'backtesting',\n",
    "        fixed_train_size   = False,\n",
    "        return_best        = False,\n",
    "        n_jobs             = 'auto',\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    results_one_step_ahead = _evaluate_grid_hyperparameters(\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y_feature_selection,\n",
    "        exog               = exog_feature_selection,\n",
    "        param_grid         = param_grid,\n",
    "        lags_grid          = lags_grid,\n",
    "        metric             = metrics,\n",
    "        initial_train_size = initial_train_size,\n",
    "        method             = 'one_step_ahead',\n",
    "        return_best        = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "\n",
    "    pd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)\n",
    "\n",
    "\n",
    "forecasters = [\n",
    "    ForecasterAutoreg(regressor=Ridge(random_state=678), lags=3),\n",
    "    ForecasterAutoregDirect(regressor=Ridge(random_state=678), lags=3, steps=1),\n",
    "    ForecasterAutoreg(\n",
    "        regressor=Ridge(random_state=678),\n",
    "        lags=3,\n",
    "        #transformer_y=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "    ),\n",
    "]\n",
    "\n",
    "for i, forecaster in enumerate(forecasters):\n",
    "    print(i)\n",
    "    test_evaluate_grid_hyperparameters_equivalent_outputs_backtesting_one_step_ahead(\n",
    "        forecaster=forecaster\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>exog_0</th>\n",
       "      <th>exog_1</th>\n",
       "      <th>exog_2</th>\n",
       "      <th>exog_3</th>\n",
       "      <th>exog_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:00:00</th>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>36.352492</td>\n",
       "      <td>-0.158530</td>\n",
       "      <td>-1.121145</td>\n",
       "      <td>1.590948</td>\n",
       "      <td>0.279970</td>\n",
       "      <td>0.618352</td>\n",
       "      <td>0.595441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>36.352492</td>\n",
       "      <td>-0.217728</td>\n",
       "      <td>0.550228</td>\n",
       "      <td>-0.849106</td>\n",
       "      <td>2.073872</td>\n",
       "      <td>0.841560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 09:00:00</th>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>0.340883</td>\n",
       "      <td>-1.159585</td>\n",
       "      <td>-0.991874</td>\n",
       "      <td>-0.807768</td>\n",
       "      <td>0.833413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 10:00:00</th>\n",
       "      <td>-89.906870</td>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>0.236108</td>\n",
       "      <td>-0.275506</td>\n",
       "      <td>0.094968</td>\n",
       "      <td>1.410528</td>\n",
       "      <td>1.350831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 11:00:00</th>\n",
       "      <td>-0.531842</td>\n",
       "      <td>-89.906870</td>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-0.675685</td>\n",
       "      <td>-2.892512</td>\n",
       "      <td>-0.253320</td>\n",
       "      <td>-1.886690</td>\n",
       "      <td>1.007638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         lag_1      lag_2      lag_3      lag_4      lag_5  \\\n",
       "2020-01-01 07:00:00  24.995108  54.203926  37.674479 -20.809688  88.677077   \n",
       "2020-01-01 08:00:00  59.649762  24.995108  54.203926  37.674479 -20.809688   \n",
       "2020-01-01 09:00:00 -36.402938  59.649762  24.995108  54.203926  37.674479   \n",
       "2020-01-01 10:00:00 -89.906870 -36.402938  59.649762  24.995108  54.203926   \n",
       "2020-01-01 11:00:00  -0.531842 -89.906870 -36.402938  59.649762  24.995108   \n",
       "\n",
       "                         lag_6      lag_7    exog_0    exog_1    exog_2  \\\n",
       "2020-01-01 07:00:00  36.352492  -0.158530 -1.121145  1.590948  0.279970   \n",
       "2020-01-01 08:00:00  88.677077  36.352492 -0.217728  0.550228 -0.849106   \n",
       "2020-01-01 09:00:00 -20.809688  88.677077  0.340883 -1.159585 -0.991874   \n",
       "2020-01-01 10:00:00  37.674479 -20.809688  0.236108 -0.275506  0.094968   \n",
       "2020-01-01 11:00:00  54.203926  37.674479 -0.675685 -2.892512 -0.253320   \n",
       "\n",
       "                       exog_3    exog_4  \n",
       "2020-01-01 07:00:00  0.618352  0.595441  \n",
       "2020-01-01 08:00:00  2.073872  0.841560  \n",
       "2020-01-01 09:00:00 -0.807768  0.833413  \n",
       "2020-01-01 10:00:00  1.410528  1.350831  \n",
       "2020-01-01 11:00:00 -1.886690  1.007638  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>exog_0</th>\n",
       "      <th>exog_1</th>\n",
       "      <th>exog_2</th>\n",
       "      <th>exog_3</th>\n",
       "      <th>exog_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:00:00</th>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>36.352492</td>\n",
       "      <td>-0.158530</td>\n",
       "      <td>-1.121145</td>\n",
       "      <td>1.590948</td>\n",
       "      <td>0.279970</td>\n",
       "      <td>0.618352</td>\n",
       "      <td>0.595441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>36.352492</td>\n",
       "      <td>-0.217728</td>\n",
       "      <td>0.550228</td>\n",
       "      <td>-0.849106</td>\n",
       "      <td>2.073872</td>\n",
       "      <td>0.841560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 09:00:00</th>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>88.677077</td>\n",
       "      <td>0.340883</td>\n",
       "      <td>-1.159585</td>\n",
       "      <td>-0.991874</td>\n",
       "      <td>-0.807768</td>\n",
       "      <td>0.833413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 10:00:00</th>\n",
       "      <td>-89.906870</td>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-20.809688</td>\n",
       "      <td>0.236108</td>\n",
       "      <td>-0.275506</td>\n",
       "      <td>0.094968</td>\n",
       "      <td>1.410528</td>\n",
       "      <td>1.350831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 11:00:00</th>\n",
       "      <td>-0.531842</td>\n",
       "      <td>-89.906870</td>\n",
       "      <td>-36.402938</td>\n",
       "      <td>59.649762</td>\n",
       "      <td>24.995108</td>\n",
       "      <td>54.203926</td>\n",
       "      <td>37.674479</td>\n",
       "      <td>-0.675685</td>\n",
       "      <td>-2.892512</td>\n",
       "      <td>-0.253320</td>\n",
       "      <td>-1.886690</td>\n",
       "      <td>1.007638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         lag_1      lag_2      lag_3      lag_4      lag_5  \\\n",
       "2020-01-01 07:00:00  24.995108  54.203926  37.674479 -20.809688  88.677077   \n",
       "2020-01-01 08:00:00  59.649762  24.995108  54.203926  37.674479 -20.809688   \n",
       "2020-01-01 09:00:00 -36.402938  59.649762  24.995108  54.203926  37.674479   \n",
       "2020-01-01 10:00:00 -89.906870 -36.402938  59.649762  24.995108  54.203926   \n",
       "2020-01-01 11:00:00  -0.531842 -89.906870 -36.402938  59.649762  24.995108   \n",
       "\n",
       "                         lag_6      lag_7    exog_0    exog_1    exog_2  \\\n",
       "2020-01-01 07:00:00  36.352492  -0.158530 -1.121145  1.590948  0.279970   \n",
       "2020-01-01 08:00:00  88.677077  36.352492 -0.217728  0.550228 -0.849106   \n",
       "2020-01-01 09:00:00 -20.809688  88.677077  0.340883 -1.159585 -0.991874   \n",
       "2020-01-01 10:00:00  37.674479 -20.809688  0.236108 -0.275506  0.094968   \n",
       "2020-01-01 11:00:00  54.203926  37.674479 -0.675685 -2.892512 -0.253320   \n",
       "\n",
       "                       exog_3    exog_4  \n",
       "2020-01-01 07:00:00  0.618352  0.595441  \n",
       "2020-01-01 08:00:00  2.073872  0.841560  \n",
       "2020-01-01 09:00:00 -0.807768  0.833413  \n",
       "2020-01-01 10:00:00  1.410528  1.350831  \n",
       "2020-01-01 11:00:00 -1.886690  1.007638  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = forecaster.create_train_X_y(y=y_feature_selection, exog=exog_feature_selection)\n",
    "X_train, y_train, X_test, y_test = forecaster._train_test_split_one_step_ahead(y=y_feature_selection, exog=exog_feature_selection, initial_train_size=100)\n",
    "X_one_step_ahead = pd.concat([X_train, X_test])\n",
    "y_one_step_ahead = pd.concat([y_train, y_test])\n",
    "\n",
    "pd.testing.assert_frame_equal(X, X_one_step_ahead)\n",
    "pd.testing.assert_series_equal(y, y_one_step_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (100, 12)\n[right]: (93, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mcreate_train_X_y(y\u001b[38;5;241m=\u001b[39my_feature_selection, exog\u001b[38;5;241m=\u001b[39mexog_feature_selection)\n\u001b[0;32m      3\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39m_train_test_split_one_step_ahead(y\u001b[38;5;241m=\u001b[39my_feature_selection, exog\u001b[38;5;241m=\u001b[39mexog_feature_selection, initial_train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_series_equal(y\u001b[38;5;241m.\u001b[39miloc[:initial_train_size], y_train)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_13_p12\\Lib\\site-packages\\pandas\\_testing\\asserters.py:614\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[1;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (100, 12)\n[right]: (93, 12)"
     ]
    }
   ],
   "source": [
    "initial_train_size = 100\n",
    "X, y = forecaster.create_train_X_y(y=y_feature_selection, exog=exog_feature_selection)\n",
    "X_train, y_train, X_test, y_test = forecaster._train_test_split_one_step_ahead(y=y_feature_selection, exog=exog_feature_selection, initial_train_size=100)\n",
    "\n",
    "pd.testing.assert_frame_equal(X.iloc[:initial_train_size, :], X_train)\n",
    "pd.testing.assert_series_equal(y.iloc[:initial_train_size], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from copy import copy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import bayesian_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "# Warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore', category=IgnoredArgumentWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection.model_selection import _evaluate_grid_hyperparameters\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o_exog\",\n",
    "    verbose=False,\n",
    ")\n",
    "data = data.sort_index()\n",
    "end_train = \"2001-01-01 23:59:00\"\n",
    "end_validation = \"2006-01-01 23:59:00\"\n",
    "target = \"y\"\n",
    "exog_features = ['exog_1', 'exog_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86050004 0.62134986 0.92298243 0.76921168 0.80404391 0.85138085\n",
      " 0.8390067  0.8544545  0.86050004 0.86050004 0.86050004 0.86050004\n",
      " 0.86050004 0.67881567 0.83968142 0.86732965 0.81633951 0.86234101\n",
      " 0.92600178 0.8544545  0.86050004 0.86050004 0.86050004 0.86050004\n",
      " 0.86050004 0.67881567 0.83968142 0.78516049 0.82152907 0.86747834\n",
      " 0.92600178 0.8544545  0.86050004 0.86050004 0.86050004 0.86050004\n",
      " 0.86050004 0.77849741 0.92690999 0.92086445 0.8390067  0.92600178\n",
      " 0.8544545  0.86050004 0.86050004 0.86050004 0.86050004 0.86050004\n",
      " 0.86050004 0.73771259 0.83968142 0.78516049 0.82152907 0.87246699\n",
      " 0.8544545  0.86050004 0.86050004 0.86050004 0.86050004 0.86050004]\n",
      "[0.8727035  0.63886949 0.94836765 0.76479828 0.79310052 0.84657345\n",
      " 0.8337     0.84016863 0.8727035  0.8727035  0.8727035  0.8727035\n",
      " 0.8727035  0.6963353  0.87220827 0.87540656 0.81733456 0.8564396\n",
      " 0.94192984 0.84016863 0.8727035  0.8727035  0.8727035  0.8727035\n",
      " 0.8727035  0.6963353  0.87220827 0.7932374  0.81012869 0.86025409\n",
      " 0.94192984 0.84016863 0.8727035  0.8727035  0.8727035  0.8727035\n",
      " 0.8727035  0.79601704 0.96224811 0.93811535 0.8337     0.94192984\n",
      " 0.84016863 0.8727035  0.8727035  0.8727035  0.8727035  0.8727035\n",
      " 0.8727035  0.75523222 0.87220827 0.7932374  0.8134311  0.87872991\n",
      " 0.84016863 0.8727035  0.8727035  0.8727035  0.8727035  0.8727035 ]\n",
      "[0.86149414 0.63562685 0.91932865 0.78654694 0.77832513 0.84869959\n",
      " 0.83332665 0.85568663 0.86149414 0.86149414 0.86149414 0.86149414\n",
      " 0.86149414 0.68587365 0.84905887 0.86608738 0.81317754 0.8546604\n",
      " 0.93332658 0.85568663 0.86149414 0.86149414 0.86149414 0.86149414\n",
      " 0.86149414 0.68587365 0.84905887 0.79405081 0.80018146 0.87269905\n",
      " 0.93332658 0.85568663 0.86149414 0.86149414 0.86149414 0.86149414\n",
      " 0.86149414 0.79454024 0.92109543 0.91528793 0.83332665 0.93332658\n",
      " 0.85568663 0.86149414 0.86149414 0.86149414 0.86149414 0.86149414\n",
      " 0.86149414 0.75381015 0.84905887 0.79405081 0.80018146 0.87882467\n",
      " 0.85568663 0.86149414 0.86149414 0.86149414 0.86149414 0.86149414]\n",
      "[0.87618986 0.65032258 0.93511562 0.77600008 0.76278648 0.83073907\n",
      " 0.83525739 0.84706052 0.87618986 0.87618986 0.87618986 0.87618986\n",
      " 0.87618986 0.70056937 0.86484583 0.87422506 0.82710468 0.85790118\n",
      " 0.95767938 0.84706052 0.87618986 0.87618986 0.87618986 0.87618986\n",
      " 0.87618986 0.70056937 0.86484583 0.80218849 0.78464281 0.87815223\n",
      " 0.95767938 0.84706052 0.87618986 0.87618986 0.87618986 0.87618986\n",
      " 0.87618986 0.80923596 0.9368824  0.93742834 0.83525739 0.95767938\n",
      " 0.84706052 0.87618986 0.87618986 0.87618986 0.87618986 0.87618986\n",
      " 0.87618986 0.76850588 0.86484583 0.80218849 0.78464281 0.88427784\n",
      " 0.84706052 0.87618986 0.87618986 0.87618986 0.87618986 0.87618986]\n",
      "[0.86150813 0.63564084 0.9192482  0.79025533 0.78105249 0.85165679\n",
      " 0.83113781 0.85582218 0.86150813 0.86150813 0.86150813 0.86150813\n",
      " 0.86150813 0.68588763 0.84721163 0.86979577 0.81757295 0.8637432\n",
      " 0.93351736 0.85582218 0.86150813 0.86150813 0.86150813 0.86150813\n",
      " 0.86150813 0.68588763 0.84721163 0.7977592  0.80266041 0.87654321\n",
      " 0.93351736 0.85582218 0.86150813 0.86150813 0.86150813 0.86150813\n",
      " 0.86150813 0.79455423 0.9192482  0.92071736 0.83113781 0.93351736\n",
      " 0.85582218 0.86150813 0.86150813 0.86150813 0.86150813 0.86150813\n",
      " 0.86150813 0.75382414 0.84721163 0.7977592  0.80266041 0.87654321\n",
      " 0.85582218 0.86150813 0.86150813 0.86150813 0.86150813 0.86150813]\n",
      "[0.8759462  0.65007891 0.935774   0.77310916 0.76124786 0.82784329\n",
      " 0.84063479 0.85167295 0.8759462  0.8759462  0.8759462  0.8759462\n",
      " 0.8759462  0.70032571 0.86373743 0.86894625 0.82872942 0.85305489\n",
      " 0.96642583 0.85167295 0.8759462  0.8759462  0.8759462  0.8759462\n",
      " 0.8759462  0.70032571 0.86373743 0.79690969 0.78285578 0.88394169\n",
      " 0.96642583 0.85167295 0.8759462  0.8759462  0.8759462  0.8759462\n",
      " 0.8759462  0.8089923  0.935774   0.93553902 0.84063479 0.96642583\n",
      " 0.85167295 0.8759462  0.8759462  0.8759462  0.8759462  0.8759462\n",
      " 0.8759462  0.76826221 0.86373743 0.79690969 0.78285578 0.88958633\n",
      " 0.85167295 0.8759462  0.8759462  0.8759462  0.8759462  0.8759462 ]\n",
      "[0.85657666 0.66672447 0.78089996 0.76216357 0.75835343 0.81030954\n",
      " 0.83279972 0.8719938  0.90566561 0.87191315 0.84187923 0.86052923\n",
      " 0.85657666 0.6826527  0.86149018 0.79630952 0.77419613 0.81453746\n",
      " 0.96075251 0.90566561 0.86052923 0.8645278  0.83890857 0.85657666\n",
      " 0.85657666 0.70302786 0.86149018 0.77270029 0.77419613 0.81453746\n",
      " 0.96075251 0.90566561 0.89420104 0.8645278  0.83890857 0.85657666\n",
      " 0.85657666 0.80245071 0.91561613 0.91561613 0.78766333 0.9270807\n",
      " 0.85657666 0.86052923 0.85657666 0.86052923 0.85657666 0.85657666\n",
      " 0.85657666 0.72726107 0.86149018 0.77270029 0.79555612 0.81453746\n",
      " 0.90171304 0.90566561 0.8719938  0.8645278  0.84286114 0.85657666]\n",
      "[0.82753397 0.6515763  0.76920883 0.74756648 0.74953387 0.82228451\n",
      " 0.83249598 0.87291315 0.9381965  0.88541286 0.85178867 0.87471777\n",
      " 0.82753397 0.66750453 0.85273381 0.78208331 0.76270951 0.79940229\n",
      " 0.95452154 0.90341081 0.88146889 0.87871634 0.80558678 0.85433738\n",
      " 0.82753397 0.68787969 0.85273381 0.75847409 0.76270951 0.79940229\n",
      " 0.95452154 0.90341081 0.9151407  0.87871634 0.83239019 0.82753397\n",
      " 0.82753397 0.7761559  0.90643984 0.88752712 0.75304722 0.91572475\n",
      " 0.80904751 0.87471777 0.85433738 0.87471777 0.82753397 0.82753397\n",
      " 0.82753397 0.71211289 0.85273381 0.75847409 0.79475295 0.81619986\n",
      " 0.86063484 0.92824558 0.88469339 0.87871634 0.85277058 0.82753397]\n",
      "[0.84713575 0.65332675 0.74438107 0.78382648 0.77690401 0.82912627\n",
      " 0.83944932 0.87456376 0.90477735 0.88033442 0.85886818 0.86290369\n",
      " 0.84713575 0.68679861 0.86084735 0.79620963 0.77917528 0.82336591\n",
      " 0.93234214 0.90057397 0.85727507 0.86290369 0.84310024 0.86290369\n",
      " 0.84713575 0.72967548 0.86084735 0.79034489 0.77917528 0.82336591\n",
      " 0.93234214 0.90057397 0.88328529 0.86290369 0.85886818 0.84713575\n",
      " 0.84713575 0.81331125 0.89467185 0.88483986 0.77764756 0.90633192\n",
      " 0.83730376 0.86290369 0.86290369 0.86290369 0.84713575 0.84713575\n",
      " 0.84713575 0.75390868 0.86084735 0.79034489 0.79717945 0.83230397\n",
      " 0.88480603 0.91040596 0.87876713 0.86290369 0.85886818 0.84713575]\n",
      "[0.82020783 0.63423325 0.72442575 0.75942913 0.76728394 0.83911345\n",
      " 0.84417806 0.88174885 0.93072411 0.89297076 0.86756681 0.88496465\n",
      " 0.82020783 0.66770511 0.84437511 0.77181228 0.75536328 0.81931998\n",
      " 0.9282798  0.90775906 0.88322184 0.88737067 0.80280999 0.84964421\n",
      " 0.81831432 0.71058198 0.84437511 0.76594753 0.75536328 0.81931998\n",
      " 0.9282798  0.90775906 0.90923205 0.89340011 0.83224636 0.82020783\n",
      " 0.82020783 0.78554326 0.8736631  0.850598   0.74423233 0.90163419\n",
      " 0.79324569 0.88709706 0.85015671 0.87648634 0.82020783 0.82020783\n",
      " 0.81831432 0.73292167 0.84089204 0.76594753 0.77692883 0.83704913\n",
      " 0.8385532  0.93082417 0.89705449 0.89340011 0.86756681 0.82020783]\n",
      "[0.84713575 0.65332675 0.74438107 0.78382648 0.77690401 0.82912627\n",
      " 0.83944932 0.87456376 0.90477735 0.88033442 0.85886818 0.86290369\n",
      " 0.84713575 0.68679861 0.86084735 0.79620963 0.77917528 0.82336591\n",
      " 0.93234214 0.90057397 0.85727507 0.86290369 0.84310024 0.86290369\n",
      " 0.84713575 0.72967548 0.86084735 0.79034489 0.77917528 0.82336591\n",
      " 0.93234214 0.90057397 0.88328529 0.86290369 0.85886818 0.84713575\n",
      " 0.84713575 0.81331125 0.89467185 0.88483986 0.77764756 0.90633192\n",
      " 0.83730376 0.86290369 0.86290369 0.86290369 0.84713575 0.84713575\n",
      " 0.84713575 0.75390868 0.86084735 0.79034489 0.79717945 0.83230397\n",
      " 0.88480603 0.91040596 0.87876713 0.86290369 0.85886818 0.84713575]\n",
      "[0.82020783 0.63423325 0.72442575 0.75942913 0.76728394 0.83911345\n",
      " 0.84417806 0.88174885 0.93072411 0.89297076 0.86756681 0.88496465\n",
      " 0.82020783 0.66770511 0.84437511 0.77181228 0.75536328 0.81931998\n",
      " 0.9282798  0.90775906 0.88322184 0.88737067 0.80280999 0.84964421\n",
      " 0.81831432 0.71058198 0.84437511 0.76594753 0.75536328 0.81931998\n",
      " 0.9282798  0.90775906 0.90923205 0.89340011 0.83224636 0.82020783\n",
      " 0.82020783 0.78554326 0.8736631  0.850598   0.74423233 0.90163419\n",
      " 0.79324569 0.88709706 0.85015671 0.87648634 0.82020783 0.82020783\n",
      " 0.81831432 0.73292167 0.84089204 0.76594753 0.77692883 0.83704913\n",
      " 0.8385532  0.93082417 0.89705449 0.89340011 0.86756681 0.82020783]\n",
      "[0.86408888 0.73690611 0.77917269 0.75436043 0.83205402 0.84431152\n",
      " 0.82495168 0.86794478 0.88678921 0.85539624 0.85539624 0.86408888\n",
      " 0.86408888 0.74275476 0.81254587 0.82362192 0.83545002 0.86079036\n",
      " 0.92758635 0.86794478 0.89788496 0.86408888 0.86408888 0.86408888\n",
      " 0.86408888 0.74275476 0.81254587 0.75436043 0.83545002 0.86079036\n",
      " 0.92758635 0.86794478 0.88678921 0.86408888 0.86408888 0.86794478\n",
      " 0.86794478 0.79646005 0.92758635 0.92758635 0.82495168 0.92758635\n",
      " 0.86794478 0.86794478 0.85539624 0.86408888 0.86408888 0.86794478\n",
      " 0.86794478 0.75766804 0.81254587 0.75436043 0.83545002 0.86079036\n",
      " 0.86794478 0.86794478 0.86408888 0.86794478 0.86408888 0.86794478]\n",
      "[0.86444198 0.75151788 0.79151542 0.77130969 0.82323436 0.85854152\n",
      " 0.835772   0.87056948 0.89991622 0.83983137 0.83983137 0.86444198\n",
      " 0.86444198 0.75736653 0.83358343 0.84638532 0.8303249  0.88359774\n",
      " 0.94927271 0.87056948 0.91504679 0.86444198 0.86444198 0.86444198\n",
      " 0.86444198 0.75736653 0.83358343 0.77130969 0.8303249  0.87161068\n",
      " 0.94927271 0.87056948 0.89991622 0.86444198 0.86444198 0.87056948\n",
      " 0.87056948 0.81107182 0.96125977 0.96125977 0.84775907 0.94927271\n",
      " 0.87056948 0.87056948 0.83983137 0.86444198 0.86444198 0.87056948\n",
      " 0.87056948 0.77227981 0.83358343 0.77712383 0.8324961  0.87161068\n",
      " 0.87056948 0.87056948 0.86444198 0.87056948 0.86444198 0.87056948]\n",
      "[0.86530384 0.74465783 0.78902239 0.7371648  0.8170899  0.84137687\n",
      " 0.80915002 0.86530384 0.89031975 0.85577501 0.85577501 0.86530384\n",
      " 0.86530384 0.75139152 0.82285584 0.83772808 0.82051265 0.85785571\n",
      " 0.912732   0.86530384 0.90178382 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.75139152 0.82285584 0.76797955 0.82051265 0.85785571\n",
      " 0.912732   0.86530384 0.89031975 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.79180331 0.912732   0.912732   0.80915002 0.912732\n",
      " 0.86530384 0.86530384 0.85577501 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.7661612  0.82285584 0.76797955 0.82051265 0.85785571\n",
      " 0.86530384 0.86530384 0.86530384 0.86530384 0.86530384 0.86530384]\n",
      "[0.86532847 0.74829836 0.80177553 0.74475639 0.80445895 0.84742532\n",
      " 0.83764592 0.87461726 0.8948638  0.83638084 0.83638084 0.86532847\n",
      " 0.86532847 0.75503206 0.84391569 0.86123343 0.81538344 0.88787176\n",
      " 0.94953462 0.87461726 0.91787278 0.86532847 0.86532847 0.86532847\n",
      " 0.86532847 0.75503206 0.84391569 0.77557114 0.81538344 0.8863516\n",
      " 0.94953462 0.87461726 0.8948638  0.86532847 0.86532847 0.86742422\n",
      " 0.86742422 0.79544385 0.94386173 0.95105477 0.83916607 0.94953462\n",
      " 0.87461726 0.86742422 0.8385838  0.86532847 0.86532847 0.86742422\n",
      " 0.86742422 0.76980174 0.84391569 0.7914849  0.81538344 0.8863516\n",
      " 0.87461726 0.86742422 0.86532847 0.86742422 0.86532847 0.86742422]\n",
      "[0.86530384 0.74465783 0.78902239 0.7371648  0.8170899  0.84137687\n",
      " 0.80915002 0.86530384 0.89031975 0.85577501 0.85577501 0.86530384\n",
      " 0.86530384 0.75139152 0.82285584 0.83772808 0.82051265 0.85785571\n",
      " 0.912732   0.86530384 0.90178382 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.75139152 0.82285584 0.76797955 0.82051265 0.85785571\n",
      " 0.912732   0.86530384 0.89031975 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.79180331 0.912732   0.912732   0.80915002 0.912732\n",
      " 0.86530384 0.86530384 0.85577501 0.86530384 0.86530384 0.86530384\n",
      " 0.86530384 0.7661612  0.82285584 0.76797955 0.82051265 0.85785571\n",
      " 0.86530384 0.86530384 0.86530384 0.86530384 0.86530384 0.86530384]\n",
      "[0.86532847 0.74829836 0.80177553 0.74475639 0.80445895 0.84742532\n",
      " 0.83764592 0.87461726 0.8948638  0.83638084 0.83638084 0.86532847\n",
      " 0.86532847 0.75503206 0.84391569 0.86123343 0.81538344 0.88787176\n",
      " 0.94953462 0.87461726 0.91787278 0.86532847 0.86532847 0.86532847\n",
      " 0.86532847 0.75503206 0.84391569 0.77557114 0.81538344 0.8863516\n",
      " 0.94953462 0.87461726 0.8948638  0.86532847 0.86532847 0.86742422\n",
      " 0.86742422 0.79544385 0.94386173 0.95105477 0.83916607 0.94953462\n",
      " 0.87461726 0.86742422 0.8385838  0.86532847 0.86532847 0.86742422\n",
      " 0.86742422 0.76980174 0.84391569 0.7914849  0.81538344 0.8863516\n",
      " 0.87461726 0.86742422 0.86532847 0.86742422 0.86532847 0.86742422]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame.iloc[:, 0] (column name=\"lags\") are different\n\nDataFrame.iloc[:, 0] (column name=\"lags\") values are different (33.33333 %)\n[index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n[left]:  [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]\n[right]: [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3, 20]]\nAt positional index 9, first diff: [ 1  2  3 20] != [1 2 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 46\u001b[0m\n\u001b[0;32m     13\u001b[0m results_backtesting \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters(\n\u001b[0;32m     14\u001b[0m     forecaster         \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[0;32m     15\u001b[0m     y                  \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[:end_validation, target],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m results_one_step_ahead \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters(\n\u001b[0;32m     32\u001b[0m     forecaster         \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[0;32m     33\u001b[0m     y                  \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[:end_validation, target],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     show_progress      \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 46\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_backtesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_one_step_ahead\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_13_p12\\Lib\\site-packages\\pandas\\_testing\\asserters.py:614\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[1;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: DataFrame.iloc[:, 0] (column name=\"lags\") are different\n\nDataFrame.iloc[:, 0] (column name=\"lags\") values are different (33.33333 %)\n[index]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n[left]:  [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]\n[right]: [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3, 20], [1, 2, 3, 20], [1, 2, 3], [1, 2, 3, 20]]\nAt positional index 9, first diff: [ 1  2  3 20] != [1 2 3]"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags      = 10,\n",
    "                transformer_y=StandardScaler(),\n",
    "            )\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    steps              = 1,\n",
    "    method             = 'backtesting',\n",
    "    refit              = False,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    fixed_train_size   = False,\n",
    "    return_best        = False,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    method             = 'one_step_ahead',\n",
    "    return_best        = False,\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(results_backtesting, results_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _calculate_metrics_multiseries vs _calculate_metrics_multiseries_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = 'ordinal',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "X, y = forecaster.create_train_X_y(series=data)\n",
    "X_train = X.loc[X.index <= end_train, :]\n",
    "y_train = y.loc[y.index <= end_train]\n",
    "X_test = X.loc[X.index > end_train, :]\n",
    "y_test = y.loc[y.index > end_train]\n",
    "\n",
    "forecaster.regressor.fit(X_train, y_train)\n",
    "pred = forecaster.regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _calculate_metrics_multiseries_one_step_ahead and _calculate_metrics_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics should be equal when using step=1 in backtesting\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "if forecaster.encoding in ['ordinal', 'ordinal_category']:\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(X_train[['_level_skforecast']]).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(X_test[['_level_skforecast']]).ravel()\n",
    "elif forecaster.encoding == 'onehot':\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_train.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_test.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "X_train_encoding = pd.Series(X_train_encoding, index=X_train.index)\n",
    "X_test_encoding = pd.Series(X_test_encoding, index=X_test.index)\n",
    "\n",
    "metrics_one_step_ahead = _calculate_metrics_multiseries_one_step_ahead(\n",
    "    y_true = y_test,\n",
    "    y_pred = pred,\n",
    "    y_pred_encoding = X_test_encoding,\n",
    "    y_train = y_train,\n",
    "    y_train_encoding = X_train_encoding,\n",
    "    levels = ['item_1', 'item_2', 'item_3'],\n",
    "    metrics = metrics,\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_one_step_ahead)\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries\n",
    "folds = _create_backtesting_folds(\n",
    "    data = data,\n",
    "    window_size = 24,\n",
    "    initial_train_size = len(data_train),\n",
    "    test_size = 1,\n",
    "    externally_fitted = False,\n",
    "    refit = False,\n",
    "    fixed_train_size = True,\n",
    "    gap = 0,\n",
    "    skip_folds = None,\n",
    "    allow_incomplete_fold = True,\n",
    "    return_all_indexes = False,\n",
    "    differentiation = None,\n",
    "    verbose = False\n",
    ")\n",
    "_, predictions = backtesting_forecaster_multiseries(\n",
    "    series=data,\n",
    "    forecaster=forecaster,\n",
    "    steps=1,\n",
    "    metric=metrics,\n",
    "    initial_train_size = len(data_train),\n",
    "    refit=False,\n",
    "    add_aggregated_metric=True,\n",
    "    show_progress=False\n",
    ")\n",
    "metrics_backtesting = _calculate_metrics_multiseries(\n",
    "    series = data,\n",
    "    predictions= predictions,\n",
    "    folds= folds,\n",
    "    span_index= data.index,\n",
    "    window_size = 24,\n",
    "    metrics= metrics,\n",
    "    levels= ['item_1', 'item_2', 'item_3'],\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_backtesting)\n",
    "\n",
    "assert metrics_backtesting.equals(metrics_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters_multiseries: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "exog_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1710: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "    lags               = 24,\n",
    "    encoding           = 'ordinal',\n",
    "    transformer_series = None,\n",
    "    transformer_exog   = None,\n",
    "    weight_func        = None,\n",
    "    series_weights     = None,\n",
    "    differentiation    = None,\n",
    "    dropna_from_series = False,\n",
    "    fit_kwargs         = None,\n",
    "    forecaster_id      = None\n",
    ")\n",
    "lags_grid = [3, 10]\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            steps                 = 1,\n",
    "                            metric                = metrics,\n",
    "                            aggregate_metric      = ['weighted_average', 'average', 'pooling'],\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            method                = 'backtesting',\n",
    "                            fixed_train_size      = True,\n",
    "                            gap                   = 0,\n",
    "                            skip_folds            = None,\n",
    "                            allow_incomplete_fold = True,\n",
    "                            levels                = None,\n",
    "                            exog                  = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            refit                 = False,\n",
    "                            n_jobs                = 'auto',\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False,\n",
    "                            suppress_warnings     = False\n",
    "                        )\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            metric                = metrics,\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            method                = 'one_step_ahead',\n",
    "                            exog                  = data.loc[:data_train, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False\n",
    "                        )\n",
    "\n",
    "assert results_backtesting.equals(results_one_step_ahead)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
