{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "import re\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.datasets import fetch_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astral.sun import sun\n",
    "from astral import LocationInfo\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.model_selection import select_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike_sharing\n",
      "------------\n",
      "Hourly usage of the bike share system in the city of Washington D.C. during the\n",
      "years 2011 and 2012. In addition to the number of users per hour, information\n",
      "about weather conditions and holidays is available.\n",
      "Fanaee-T,Hadi. (2013). Bike Sharing Dataset. UCI Machine Learning Repository.\n",
      "https://doi.org/10.24432/C5W894.\n",
      "Shape of the dataset: (17544, 12)\n"
     ]
    }
   ],
   "source": [
    "# Downloading data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset('bike_sharing', raw=True)\n",
    "\n",
    "# Preprocessing data (setting index and frequency)\n",
    "# ==============================================================================\n",
    "data = data[['date_time', 'users', 'holiday', 'weather', 'temp', 'atemp', 'hum', 'windspeed']]\n",
    "data['date_time'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('date_time')\n",
    "data = data.asfreq('H')\n",
    "data = data.sort_index()\n",
    "data.head()\n",
    "\n",
    "# Calendar features\n",
    "# ==============================================================================\n",
    "calendar_features = pd.DataFrame(index=data.index)\n",
    "calendar_features['month'] = calendar_features.index.month\n",
    "calendar_features['week_of_year'] = calendar_features.index.isocalendar().week\n",
    "calendar_features['week_day'] = calendar_features.index.day_of_week + 1\n",
    "calendar_features['hour_day'] = calendar_features.index.hour + 1\n",
    "\n",
    "# Sunlight features\n",
    "# ==============================================================================\n",
    "location = LocationInfo(\n",
    "    name='Washington DC',\n",
    "    region='USA',\n",
    "    timezone='US/Eastern',\n",
    "    latitude=40.516666666666666,\n",
    "    longitude=-77.03333333333333\n",
    ")\n",
    "sunrise_hour = [\n",
    "    sun(location.observer, date=date, tzinfo=location.timezone)['sunrise'].hour\n",
    "    for date in data.index\n",
    "]\n",
    "sunset_hour = [\n",
    "    sun(location.observer, date=date, tzinfo=location.timezone)['sunset'].hour\n",
    "    for date in data.index\n",
    "]\n",
    "sun_light_features = pd.DataFrame({\n",
    "                         'sunrise_hour': sunrise_hour,\n",
    "                         'sunset_hour': sunset_hour}, \n",
    "                         index = data.index\n",
    "                     )\n",
    "sun_light_features['daylight_hours'] = (\n",
    "    sun_light_features['sunset_hour'] - sun_light_features['sunrise_hour']\n",
    ")\n",
    "sun_light_features['is_daylight'] = np.where(\n",
    "                                        (data.index.hour >= sun_light_features['sunrise_hour']) & \\\n",
    "                                        (data.index.hour < sun_light_features['sunset_hour']),\n",
    "                                        1,\n",
    "                                        0\n",
    "                                    )\n",
    "\n",
    "# Holiday features\n",
    "# ==============================================================================\n",
    "holiday_features = data[['holiday']].astype(int)\n",
    "holiday_features['holiday_previous_day'] = holiday_features['holiday'].shift(24)\n",
    "holiday_features['holiday_next_day'] = holiday_features['holiday'].shift(-24)\n",
    "\n",
    "# Temperature features\n",
    "# ==============================================================================\n",
    "temp_features = data[['temp']].copy()\n",
    "temp_features['temp_roll_mean_1_day'] = temp_features['temp'].rolling(24, closed='left').mean()\n",
    "temp_features['temp_roll_mean_7_day'] = temp_features['temp'].rolling(24*7, closed='left').mean()\n",
    "temp_features['temp_roll_max_1_day'] = temp_features['temp'].rolling(24, closed='left').max()\n",
    "temp_features['temp_roll_min_1_day'] = temp_features['temp'].rolling(24, closed='left').min()\n",
    "temp_features['temp_roll_max_7_day'] = temp_features['temp'].rolling(24*7, closed='left').max()\n",
    "temp_features['temp_roll_min_7_day'] = temp_features['temp'].rolling(24*7, closed='left').min()\n",
    "\n",
    "\n",
    "# Merge all exogenous variables\n",
    "# ==============================================================================\n",
    "df_exogenous_features = pd.concat([\n",
    "                            calendar_features,\n",
    "                            sun_light_features,\n",
    "                            temp_features,\n",
    "                            holiday_features\n",
    "                        ], axis=1)\n",
    "\n",
    "df_exogenous_features.head(4)\n",
    "\n",
    "# Cliclical encoding of calendar and sunlight features\n",
    "# ==============================================================================\n",
    "def cyclical_encoding(data: pd.Series, cycle_length: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode a cyclical feature with two new features sine and cosine.\n",
    "    The minimum value of the feature is assumed to be 0. The maximum value\n",
    "    of the feature is passed as an argument.\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.Series\n",
    "        Series with the feature to encode.\n",
    "    cycle_length : int\n",
    "        The length of the cycle. For example, 12 for months, 24 for hours, etc.\n",
    "        This value is used to calculate the angle of the sin and cos.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : pd.DataFrame\n",
    "        Dataframe with the two new features sin and cos.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sin = np.sin(2 * np.pi * data/cycle_length)\n",
    "    cos = np.cos(2 * np.pi * data/cycle_length)\n",
    "    result =  pd.DataFrame({\n",
    "                  f\"{data.name}_sin\": sin,\n",
    "                  f\"{data.name}_cos\": cos\n",
    "              })\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "month_encoded = cyclical_encoding(df_exogenous_features['month'], cycle_length=12)\n",
    "week_of_year_encoded = cyclical_encoding(df_exogenous_features['week_of_year'], cycle_length=52)\n",
    "week_day_encoded = cyclical_encoding(df_exogenous_features['week_day'], cycle_length=7)\n",
    "hour_day_encoded = cyclical_encoding(df_exogenous_features['hour_day'], cycle_length=24)\n",
    "sunrise_hour_encoded = cyclical_encoding(df_exogenous_features['sunrise_hour'], cycle_length=24)\n",
    "sunset_hour_encoded = cyclical_encoding(df_exogenous_features['sunset_hour'], cycle_length=24)\n",
    "\n",
    "cyclical_features = pd.concat([\n",
    "                        month_encoded,\n",
    "                        week_of_year_encoded,\n",
    "                        week_day_encoded,\n",
    "                        hour_day_encoded,\n",
    "                        sunrise_hour_encoded,\n",
    "                        sunset_hour_encoded\n",
    "                    ], axis=1)\n",
    "\n",
    "df_exogenous_features = pd.concat([df_exogenous_features, cyclical_features], axis=1)\n",
    "df_exogenous_features.head(3)\n",
    "\n",
    "# Interaction between exogenous variables\n",
    "# ==============================================================================\n",
    "transformer_poly = PolynomialFeatures(\n",
    "                       degree           = 2,\n",
    "                       interaction_only = True,\n",
    "                       include_bias     = False\n",
    "                   ).set_output(transform=\"pandas\")\n",
    "\n",
    "poly_cols = [\n",
    "    'month_sin', \n",
    "    'month_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos',\n",
    "    'week_day_sin',\n",
    "    'week_day_cos',\n",
    "    'hour_day_sin',\n",
    "    'hour_day_cos',\n",
    "    'sunrise_hour_sin',\n",
    "    'sunrise_hour_cos',\n",
    "    'sunset_hour_sin',\n",
    "    'sunset_hour_cos',\n",
    "    'daylight_hours',\n",
    "    'is_daylight',\n",
    "    'holiday_previous_day',\n",
    "    'holiday_next_day',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day',\n",
    "    'temp',\n",
    "    'holiday'\n",
    "]\n",
    "\n",
    "poly_features = transformer_poly.fit_transform(df_exogenous_features[poly_cols].dropna())\n",
    "poly_features = poly_features.drop(columns=poly_cols)\n",
    "poly_features.columns = [f\"poly_{col}\" for col in poly_features.columns]\n",
    "poly_features.columns = poly_features.columns.str.replace(\" \", \"__\")\n",
    "df_exogenous_features = pd.concat([df_exogenous_features, poly_features], axis=1)\n",
    "df_exogenous_features.head(4)\n",
    "\n",
    "# Select exogenous variables to be included in the model\n",
    "# ==============================================================================\n",
    "exog_features = []\n",
    "# Columns that ends with _sin or _cos are selected\n",
    "exog_features.extend(df_exogenous_features.filter(regex='_sin$|_cos$').columns.tolist())\n",
    "# columns that start with temp_ are selected\n",
    "exog_features.extend(df_exogenous_features.filter(regex='^temp_.*').columns.tolist())\n",
    "# Columns that start with holiday_ are selected\n",
    "exog_features.extend(df_exogenous_features.filter(regex='^holiday_.*').columns.tolist())\n",
    "exog_features.extend(['temp', 'holiday'])\n",
    "\n",
    "df_exogenous_features = df_exogenous_features.filter(exog_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exogenous_features = df_exogenous_features.dropna()\n",
    "data = data.loc[df_exogenous_features.index, :]\n",
    "df_exogenous_features['dummy_variable'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive feature elimination\n",
      "-----------------------------\n",
      "Total number of features available: 188\n",
      "Total number of records available: 17252\n",
      "Total number of records used for feature selection: 1725\n",
      "Number of features selected: 133\n",
      "Selected lags: [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19, 23, 24, 25, 31, 32, 35, 36, 38, 43, 46, 47, 49, 50, 51, 55, 57, 59, 60, 62, 70, 71, 72, 73, 74, 75, 82, 84, 85, 91, 96, 97]\n",
      "Selected exog : \n",
      " ['month_sin', 'month_cos', 'week_of_year_sin', 'week_of_year_cos', 'week_day_sin', 'week_day_cos', 'hour_day_sin', 'hour_day_cos', 'sunrise_hour_sin', 'sunrise_hour_cos', 'sunset_hour_sin', 'sunset_hour_cos', 'poly_month_sin__month_cos', 'poly_month_sin__week_of_year_sin', 'poly_month_sin__week_of_year_cos', 'poly_month_sin__week_day_sin', 'poly_month_sin__week_day_cos', 'poly_month_sin__hour_day_sin', 'poly_month_sin__hour_day_cos', 'poly_month_sin__sunrise_hour_sin', 'poly_month_sin__sunrise_hour_cos', 'poly_month_sin__sunset_hour_sin', 'poly_month_sin__sunset_hour_cos', 'poly_month_cos__week_of_year_sin', 'poly_month_cos__week_of_year_cos', 'poly_month_cos__week_day_sin', 'poly_month_cos__week_day_cos', 'poly_month_cos__hour_day_sin', 'poly_month_cos__hour_day_cos', 'poly_month_cos__sunrise_hour_sin', 'poly_month_cos__sunrise_hour_cos', 'poly_month_cos__sunset_hour_sin', 'poly_month_cos__sunset_hour_cos', 'poly_week_of_year_sin__week_day_sin', 'poly_week_of_year_sin__week_day_cos', 'poly_week_of_year_sin__hour_day_sin', 'poly_week_of_year_sin__hour_day_cos', 'poly_week_of_year_sin__sunrise_hour_sin', 'poly_week_of_year_sin__sunrise_hour_cos', 'poly_week_of_year_sin__sunset_hour_sin', 'poly_week_of_year_sin__sunset_hour_cos', 'poly_week_of_year_cos__week_day_sin', 'poly_week_of_year_cos__week_day_cos', 'poly_week_of_year_cos__hour_day_sin', 'poly_week_of_year_cos__hour_day_cos', 'poly_week_of_year_cos__sunrise_hour_sin', 'poly_week_of_year_cos__sunrise_hour_cos', 'poly_week_of_year_cos__sunset_hour_sin', 'poly_week_of_year_cos__sunset_hour_cos', 'poly_week_day_sin__week_day_cos', 'poly_week_day_sin__hour_day_sin', 'poly_week_day_sin__hour_day_cos', 'poly_week_day_sin__sunrise_hour_sin', 'poly_week_day_sin__sunrise_hour_cos', 'poly_week_day_sin__sunset_hour_sin', 'poly_week_day_sin__sunset_hour_cos', 'poly_week_day_cos__hour_day_sin', 'poly_week_day_cos__hour_day_cos', 'poly_week_day_cos__sunrise_hour_sin', 'poly_week_day_cos__sunrise_hour_cos', 'poly_week_day_cos__sunset_hour_sin', 'poly_week_day_cos__sunset_hour_cos', 'poly_hour_day_sin__hour_day_cos', 'poly_hour_day_sin__sunrise_hour_sin', 'poly_hour_day_sin__sunrise_hour_cos', 'poly_hour_day_sin__sunset_hour_sin', 'poly_hour_day_sin__sunset_hour_cos', 'poly_hour_day_cos__sunrise_hour_sin', 'poly_hour_day_cos__sunrise_hour_cos', 'poly_hour_day_cos__sunset_hour_sin', 'poly_hour_day_cos__sunset_hour_cos', 'poly_sunrise_hour_sin__sunrise_hour_cos', 'poly_sunrise_hour_sin__sunset_hour_sin', 'poly_sunrise_hour_sin__sunset_hour_cos', 'poly_sunrise_hour_cos__sunset_hour_sin', 'poly_sunrise_hour_cos__sunset_hour_cos', 'poly_sunset_hour_sin__sunset_hour_cos', 'temp_roll_mean_1_day', 'temp_roll_mean_7_day', 'temp_roll_max_1_day', 'temp_roll_min_1_day', 'temp_roll_max_7_day', 'temp_roll_min_7_day', 'holiday_previous_day', 'holiday_next_day', 'temp', 'holiday', 'dummy_variable']\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                lags      = 100,\n",
    "            )\n",
    "\n",
    "selector = RFECV(\n",
    "    estimator              = forecaster.regressor,\n",
    "    min_features_to_select = 1,\n",
    "    cv                     = 3\n",
    ")\n",
    "\n",
    "selected_lags, selected_exog = select_features(\n",
    "    selector             = selector,\n",
    "    forecaster           = forecaster,\n",
    "    y                    = data['users'],\n",
    "    exog                 = df_exogenous_features,\n",
    "    select_only_exog     = False,\n",
    "    subsample            = 0.1,\n",
    "    force_inclusion      = \"^dummy_variable\",\n",
    "    verbose              = True,\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive feature elimination\n",
      "-----------------------------\n",
      "Total number of features available: 88\n",
      "Total number of records available: 17347\n",
      "Total number of records used for feature selection: 1734\n",
      "Number of features selected: 78\n",
      "Selected lags: ['custom_predictor_0', 'custom_predictor_1', 'custom_predictor_2', 'custom_predictor_3', 'custom_predictor_4']\n",
      "Selected exog : \n",
      " ['month_sin', 'month_cos', 'week_of_year_sin', 'week_of_year_cos', 'week_day_sin', 'hour_day_sin', 'sunrise_hour_sin', 'sunrise_hour_cos', 'sunset_hour_sin', 'sunset_hour_cos', 'poly_month_sin__month_cos', 'poly_month_sin__week_of_year_sin', 'poly_month_sin__week_of_year_cos', 'poly_month_sin__week_day_sin', 'poly_month_sin__hour_day_sin', 'poly_month_sin__hour_day_cos', 'poly_month_sin__sunrise_hour_sin', 'poly_month_sin__sunrise_hour_cos', 'poly_month_sin__sunset_hour_sin', 'poly_month_sin__sunset_hour_cos', 'poly_month_cos__week_of_year_sin', 'poly_month_cos__week_of_year_cos', 'poly_month_cos__week_day_sin', 'poly_month_cos__week_day_cos', 'poly_month_cos__hour_day_sin', 'poly_month_cos__hour_day_cos', 'poly_month_cos__sunrise_hour_sin', 'poly_month_cos__sunrise_hour_cos', 'poly_month_cos__sunset_hour_sin', 'poly_month_cos__sunset_hour_cos', 'poly_week_of_year_sin__week_of_year_cos', 'poly_week_of_year_sin__week_day_sin', 'poly_week_of_year_sin__week_day_cos', 'poly_week_of_year_sin__hour_day_sin', 'poly_week_of_year_sin__hour_day_cos', 'poly_week_of_year_sin__sunrise_hour_cos', 'poly_week_of_year_sin__sunset_hour_sin', 'poly_week_of_year_sin__sunset_hour_cos', 'poly_week_of_year_cos__week_day_sin', 'poly_week_of_year_cos__week_day_cos', 'poly_week_of_year_cos__hour_day_sin', 'poly_week_of_year_cos__hour_day_cos', 'poly_week_of_year_cos__sunrise_hour_cos', 'poly_week_of_year_cos__sunset_hour_sin', 'poly_week_of_year_cos__sunset_hour_cos', 'poly_week_day_sin__week_day_cos', 'poly_week_day_sin__hour_day_sin', 'poly_week_day_sin__hour_day_cos', 'poly_week_day_sin__sunrise_hour_sin', 'poly_week_day_sin__sunrise_hour_cos', 'poly_week_day_sin__sunset_hour_sin', 'poly_week_day_sin__sunset_hour_cos', 'poly_week_day_cos__hour_day_sin', 'poly_week_day_cos__hour_day_cos', 'poly_week_day_cos__sunrise_hour_sin', 'poly_week_day_cos__sunrise_hour_cos', 'poly_week_day_cos__sunset_hour_sin', 'poly_week_day_cos__sunset_hour_cos', 'poly_hour_day_sin__hour_day_cos', 'poly_hour_day_sin__sunrise_hour_sin', 'poly_hour_day_sin__sunrise_hour_cos', 'poly_hour_day_sin__sunset_hour_sin', 'poly_hour_day_sin__sunset_hour_cos', 'poly_hour_day_cos__sunrise_hour_sin', 'poly_hour_day_cos__sunrise_hour_cos', 'poly_hour_day_cos__sunset_hour_sin', 'poly_hour_day_cos__sunset_hour_cos', 'poly_sunrise_hour_sin__sunrise_hour_cos', 'poly_sunrise_hour_sin__sunset_hour_cos', 'poly_sunrise_hour_cos__sunset_hour_sin', 'poly_sunrise_hour_cos__sunset_hour_cos', 'poly_sunset_hour_sin__sunset_hour_cos', 'temp_roll_mean_7_day', 'temp_roll_min_1_day', 'holiday_previous_day', 'holiday_next_day', 'temp', 'holiday', 'dummy_variable']\n"
     ]
    }
   ],
   "source": [
    "def create_predictors(y):\n",
    "    lags = y[-1:-6:-1]                \n",
    "    return lags\n",
    "\n",
    "\n",
    "forecaster = ForecasterAutoregCustom(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                fun_predictors = create_predictors,\n",
    "                window_size = 5,\n",
    "            )\n",
    "\n",
    "selector = RFECV(\n",
    "    estimator              = forecaster.regressor,\n",
    "    min_features_to_select = 1,\n",
    "    cv                     = 3\n",
    ")\n",
    "\n",
    "selected_lags, selected_exog = select_features(\n",
    "    selector             = selector,\n",
    "    forecaster           = forecaster,\n",
    "    y                    = data['users'],\n",
    "    exog                 = df_exogenous_features,\n",
    "    select_only_exog     = False,\n",
    "    subsample            = 0.1,\n",
    "    force_inclusion      = \"^dummy_variable\",\n",
    "    verbose              = True,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive feature elimination\n",
      "-----------------------------\n",
      "Total number of features available: 188\n",
      "Total number of records available: 17252\n",
      "Total number of records used for feature selection: 1725\n",
      "Number of features selected: 100\n",
      "Selected lags: [1, 2, 9, 10, 17, 23, 24, 25, 43, 72, 74, 96, 97]\n",
      "Selected exog : \n",
      " ['month_sin', 'month_cos', 'week_of_year_sin', 'week_of_year_cos', 'week_day_sin', 'week_day_cos', 'hour_day_sin', 'hour_day_cos', 'sunrise_hour_sin', 'sunrise_hour_cos', 'sunset_hour_sin', 'sunset_hour_cos', 'poly_month_sin__month_cos', 'poly_month_sin__week_of_year_sin', 'poly_month_sin__week_of_year_cos', 'poly_month_sin__week_day_sin', 'poly_month_sin__week_day_cos', 'poly_month_sin__hour_day_sin', 'poly_month_sin__hour_day_cos', 'poly_month_sin__sunrise_hour_sin', 'poly_month_sin__sunrise_hour_cos', 'poly_month_sin__sunset_hour_sin', 'poly_month_sin__sunset_hour_cos', 'poly_month_cos__week_of_year_sin', 'poly_month_cos__week_of_year_cos', 'poly_month_cos__week_day_sin', 'poly_month_cos__week_day_cos', 'poly_month_cos__hour_day_sin', 'poly_month_cos__hour_day_cos', 'poly_month_cos__sunrise_hour_sin', 'poly_month_cos__sunrise_hour_cos', 'poly_month_cos__sunset_hour_sin', 'poly_month_cos__sunset_hour_cos', 'poly_week_of_year_sin__week_of_year_cos', 'poly_week_of_year_sin__week_day_sin', 'poly_week_of_year_sin__week_day_cos', 'poly_week_of_year_sin__hour_day_sin', 'poly_week_of_year_sin__hour_day_cos', 'poly_week_of_year_sin__sunrise_hour_sin', 'poly_week_of_year_sin__sunrise_hour_cos', 'poly_week_of_year_sin__sunset_hour_sin', 'poly_week_of_year_sin__sunset_hour_cos', 'poly_week_of_year_cos__week_day_sin', 'poly_week_of_year_cos__week_day_cos', 'poly_week_of_year_cos__hour_day_sin', 'poly_week_of_year_cos__hour_day_cos', 'poly_week_of_year_cos__sunrise_hour_sin', 'poly_week_of_year_cos__sunrise_hour_cos', 'poly_week_of_year_cos__sunset_hour_sin', 'poly_week_of_year_cos__sunset_hour_cos', 'poly_week_day_sin__week_day_cos', 'poly_week_day_sin__hour_day_sin', 'poly_week_day_sin__hour_day_cos', 'poly_week_day_sin__sunrise_hour_sin', 'poly_week_day_sin__sunrise_hour_cos', 'poly_week_day_sin__sunset_hour_sin', 'poly_week_day_sin__sunset_hour_cos', 'poly_week_day_cos__hour_day_sin', 'poly_week_day_cos__hour_day_cos', 'poly_week_day_cos__sunrise_hour_sin', 'poly_week_day_cos__sunrise_hour_cos', 'poly_week_day_cos__sunset_hour_sin', 'poly_week_day_cos__sunset_hour_cos', 'poly_hour_day_sin__hour_day_cos', 'poly_hour_day_sin__sunrise_hour_sin', 'poly_hour_day_sin__sunrise_hour_cos', 'poly_hour_day_sin__sunset_hour_sin', 'poly_hour_day_sin__sunset_hour_cos', 'poly_hour_day_cos__sunrise_hour_sin', 'poly_hour_day_cos__sunrise_hour_cos', 'poly_hour_day_cos__sunset_hour_sin', 'poly_hour_day_cos__sunset_hour_cos', 'poly_sunrise_hour_sin__sunrise_hour_cos', 'poly_sunrise_hour_sin__sunset_hour_sin', 'poly_sunrise_hour_sin__sunset_hour_cos', 'poly_sunrise_hour_cos__sunset_hour_sin', 'poly_sunrise_hour_cos__sunset_hour_cos', 'poly_sunset_hour_sin__sunset_hour_cos', 'temp_roll_mean_1_day', 'temp_roll_mean_7_day', 'temp_roll_max_1_day', 'temp_roll_max_7_day', 'temp_roll_min_7_day', 'holiday_previous_day', 'holiday_next_day', 'temp', 'holiday', 'dummy_variable']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                lags      = 100,\n",
    "            )\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator    = forecaster.regressor,\n",
    "    threshold    = 0.25,\n",
    "    max_features = 25\n",
    ")\n",
    "\n",
    "selected_lags, selected_exog = select_features(\n",
    "    selector             = selector,\n",
    "    forecaster           = forecaster,\n",
    "    y                    = data['users'],\n",
    "    exog                 = df_exogenous_features,\n",
    "    select_only_exog     = False,\n",
    "    subsample            = 0.1,\n",
    "    force_inclusion      = \"^dummy_variable\",\n",
    "    verbose              = True,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'lag_8',\n",
      "       'lag_9', 'lag_10', 'month_sin', 'month_cos', 'week_of_year_sin',\n",
      "       'week_of_year_cos', 'week_day_sin', 'week_day_cos', 'hour_day_sin',\n",
      "       'hour_day_cos', 'sunrise_hour_sin', 'sunrise_hour_cos',\n",
      "       'sunset_hour_sin', 'sunset_hour_cos', 'poly_month_sin__month_cos',\n",
      "       'poly_month_sin__week_of_year_sin', 'poly_month_sin__week_of_year_cos',\n",
      "       'poly_month_sin__week_day_sin', 'poly_month_sin__week_day_cos',\n",
      "       'poly_month_sin__hour_day_sin', 'poly_month_sin__hour_day_cos',\n",
      "       'poly_month_sin__sunrise_hour_sin', 'poly_month_sin__sunrise_hour_cos',\n",
      "       'poly_month_sin__sunset_hour_sin', 'poly_month_sin__sunset_hour_cos',\n",
      "       'poly_month_cos__week_of_year_sin', 'poly_month_cos__week_of_year_cos',\n",
      "       'poly_month_cos__week_day_sin', 'poly_month_cos__week_day_cos',\n",
      "       'poly_month_cos__hour_day_sin', 'poly_month_cos__hour_day_cos',\n",
      "       'poly_month_cos__sunrise_hour_sin', 'poly_month_cos__sunrise_hour_cos',\n",
      "       'poly_month_cos__sunset_hour_sin', 'poly_month_cos__sunset_hour_cos',\n",
      "       'poly_week_of_year_sin__week_of_year_cos',\n",
      "       'poly_week_of_year_sin__week_day_sin',\n",
      "       'poly_week_of_year_sin__week_day_cos',\n",
      "       'poly_week_of_year_sin__hour_day_sin',\n",
      "       'poly_week_of_year_sin__hour_day_cos',\n",
      "       'poly_week_of_year_sin__sunrise_hour_sin',\n",
      "       'poly_week_of_year_sin__sunrise_hour_cos',\n",
      "       'poly_week_of_year_sin__sunset_hour_sin',\n",
      "       'poly_week_of_year_sin__sunset_hour_cos',\n",
      "       'poly_week_of_year_cos__week_day_sin',\n",
      "       'poly_week_of_year_cos__week_day_cos',\n",
      "       'poly_week_of_year_cos__hour_day_sin',\n",
      "       'poly_week_of_year_cos__hour_day_cos',\n",
      "       'poly_week_of_year_cos__sunrise_hour_sin',\n",
      "       'poly_week_of_year_cos__sunrise_hour_cos',\n",
      "       'poly_week_of_year_cos__sunset_hour_sin',\n",
      "       'poly_week_of_year_cos__sunset_hour_cos',\n",
      "       'poly_week_day_sin__week_day_cos', 'poly_week_day_sin__hour_day_sin',\n",
      "       'poly_week_day_sin__hour_day_cos',\n",
      "       'poly_week_day_sin__sunrise_hour_sin',\n",
      "       'poly_week_day_sin__sunrise_hour_cos',\n",
      "       'poly_week_day_sin__sunset_hour_sin',\n",
      "       'poly_week_day_sin__sunset_hour_cos', 'poly_week_day_cos__hour_day_sin',\n",
      "       'poly_week_day_cos__hour_day_cos',\n",
      "       'poly_week_day_cos__sunrise_hour_sin',\n",
      "       'poly_week_day_cos__sunrise_hour_cos',\n",
      "       'poly_week_day_cos__sunset_hour_sin',\n",
      "       'poly_week_day_cos__sunset_hour_cos', 'poly_hour_day_sin__hour_day_cos',\n",
      "       'poly_hour_day_sin__sunrise_hour_sin',\n",
      "       'poly_hour_day_sin__sunrise_hour_cos',\n",
      "       'poly_hour_day_sin__sunset_hour_sin',\n",
      "       'poly_hour_day_sin__sunset_hour_cos',\n",
      "       'poly_hour_day_cos__sunrise_hour_sin',\n",
      "       'poly_hour_day_cos__sunrise_hour_cos',\n",
      "       'poly_hour_day_cos__sunset_hour_sin',\n",
      "       'poly_hour_day_cos__sunset_hour_cos',\n",
      "       'poly_sunrise_hour_sin__sunrise_hour_cos',\n",
      "       'poly_sunrise_hour_sin__sunset_hour_sin',\n",
      "       'poly_sunrise_hour_sin__sunset_hour_cos',\n",
      "       'poly_sunrise_hour_cos__sunset_hour_sin',\n",
      "       'poly_sunrise_hour_cos__sunset_hour_cos',\n",
      "       'poly_sunset_hour_sin__sunset_hour_cos', 'temp_roll_mean_1_day',\n",
      "       'temp_roll_mean_7_day', 'temp_roll_max_1_day', 'temp_roll_min_1_day',\n",
      "       'temp_roll_max_7_day', 'temp_roll_min_7_day', 'holiday_previous_day',\n",
      "       'holiday_next_day', 'temp', 'holiday'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterAutoreg(\n\u001b[1;32m      5\u001b[0m                 regressor \u001b[38;5;241m=\u001b[39m Ridge(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m),\n\u001b[1;32m      6\u001b[0m                 lags      \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m             )\n\u001b[1;32m      9\u001b[0m selector \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(\n\u001b[1;32m     10\u001b[0m     estimator    \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mregressor,\n\u001b[1;32m     11\u001b[0m     n_features_to_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     n_jobs       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m selected_lags, selected_exog \u001b[38;5;241m=\u001b[39m \u001b[43mselect_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_exogenous_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselect_only_exog\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_inclusion\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^dummy_variable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m  \n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:1721\u001b[0m, in \u001b[0;36mselect_features\u001b[0;34m(selector, forecaster, y, exog, select_only_exog, subsample, force_inclusion, verbose)\u001b[0m\n\u001b[1;32m   1718\u001b[0m y_train_sample \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mloc[sample]\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_sample\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m-> 1721\u001b[0m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m select_only_exog:\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:246\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 246\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:277\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    276\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 277\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    285\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                lags      = 10,\n",
    "            )\n",
    "\n",
    "selector = SequentialFeatureSelector(\n",
    "    estimator    = forecaster.regressor,\n",
    "    n_features_to_select = 25,\n",
    "    direction    = 'forward',\n",
    "    cv           = ShuffleSplit(n_splits=1, test_size=0.3, random_state=951),\n",
    "    scoring      = 'neg_mean_absolute_error',\n",
    "    n_jobs       = -1\n",
    ")\n",
    "\n",
    "selected_lags, selected_exog = select_features(\n",
    "    selector             = selector,\n",
    "    forecaster           = forecaster,\n",
    "    y                    = data['users'],\n",
    "    exog                 = df_exogenous_features,\n",
    "    select_only_exog     = False,\n",
    "    subsample            = 0.1,\n",
    "    force_inclusion      = \"^dummy_variable\",\n",
    "    verbose              = True,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate time series with hourly frequency with reproducible results\n",
    "# ==============================================================================\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "import pytest\n",
    "\n",
    "exog, y = make_regression(n_samples=500, n_features=5, n_informative=2, random_state=123)\n",
    "exog = pd.DataFrame(\n",
    "    exog,\n",
    "    index = pd.date_range(start='2020-01-01', periods=len(exog), freq='H'),\n",
    "    columns=[f\"exog_{i}\" for i in range(exog.shape[1])]\n",
    ")\n",
    "y = pd.Series(y, index=exog.index, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_select_features_when_selector_is_RFE_and_select_only_exog_is_True():\n",
    "    forecaster = ForecasterAutoreg(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags      = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == [1, 2, 3, 4, 5]\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_and_select_only_exog_is_True_ForecasterAutoregCustom():\n",
    "    forecaster = ForecasterAutoregCustom(\n",
    "                    regressor = LinearRegression(),\n",
    "                    fun_predictors = lambda y: y[-1:-6:-1],\n",
    "                    window_size = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == ['custom_predictor_0', 'custom_predictor_1', 'custom_predictor_2',\n",
    "                            'custom_predictor_3', 'custom_predictor_4']\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_and_select_only_exog_is_False():\n",
    "    forecaster = ForecasterAutoreg(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags      = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=5)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = False,\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == [5]\n",
    "    assert selected_exog == ['exog_0', 'exog_1', 'exog_2', 'exog_3']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_and_select_only_exog_is_False_ForecasterAutoregCustom():\n",
    "    forecaster = ForecasterAutoregCustom(\n",
    "                    regressor = LinearRegression(),\n",
    "                    fun_predictors = lambda y: y[-1:-6:-1],\n",
    "                    window_size = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=5)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = False,\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == ['custom_predictor_4']\n",
    "    assert selected_exog == ['exog_0', 'exog_1', 'exog_2', 'exog_3']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_regex():\n",
    "    forecaster = ForecasterAutoreg(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags      = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        force_inclusion      = \"^exog_3\",\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == [1, 2, 3, 4, 5]\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4', 'exog_3']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_regex_ForecasterAutoregCustom():\n",
    "    forecaster = ForecasterAutoregCustom(\n",
    "                    regressor = LinearRegression(),\n",
    "                    fun_predictors = lambda y: y[-1:-6:-1],\n",
    "                    window_size = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        force_inclusion      = \"^exog_3\",\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == ['custom_predictor_0', 'custom_predictor_1', 'custom_predictor_2',\n",
    "                            'custom_predictor_3', 'custom_predictor_4']\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4', 'exog_3']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_list():\n",
    "    forecaster = ForecasterAutoreg(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags      = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        force_inclusion      = ['exog_3'],\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == [1, 2, 3, 4, 5]\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4', 'exog_3']\n",
    "\n",
    "\n",
    "def test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_list_ForecasterAutoregCustom():\n",
    "    forecaster = ForecasterAutoregCustom(\n",
    "                    regressor = LinearRegression(),\n",
    "                    fun_predictors = lambda y: y[-1:-6:-1],\n",
    "                    window_size = 5,\n",
    "                )\n",
    "\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "\n",
    "    selected_lags, selected_exog = select_features(\n",
    "        selector             = selector,\n",
    "        forecaster           = forecaster,\n",
    "        y                    = y,\n",
    "        exog                 = exog,\n",
    "        select_only_exog     = True,\n",
    "        force_inclusion      = ['exog_3'],\n",
    "        verbose              = False,\n",
    "    )\n",
    "\n",
    "    assert selected_lags == ['custom_predictor_0', 'custom_predictor_1', 'custom_predictor_2',\n",
    "                            'custom_predictor_3', 'custom_predictor_4']\n",
    "    assert selected_exog == ['exog_1', 'exog_2', 'exog_4', 'exog_3']\n",
    "\n",
    "def test_select_features_raise_error_when_forecaster_is_not_supported():\n",
    "    \"\"\"\n",
    "    Test that select_features raises an error when forecaster is not supported.\n",
    "    \"\"\"\n",
    "    forecaster = ForecasterAutoregDirect(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags      = 5,\n",
    "                    steps     = 3\n",
    "                )\n",
    "    selector = RFE(estimator=forecaster.regressor, n_features_to_select=3)\n",
    "    err_msg = re.escape(\n",
    "            \"`forecaster` must be one of the following classes: ['ForecasterAutoreg', \"\n",
    "            \"'ForecasterAutoregCustom', 'ForecasterAutoregMultiSeries', \"\n",
    "            \"'ForecasterAutoregMultiSeriesCustom'].\"\n",
    "        )\n",
    "    with pytest.raises(Exception, match = err_msg):\n",
    "        selected_lags, selected_exog = select_features(\n",
    "            selector             = selector,\n",
    "            forecaster           = forecaster,\n",
    "            y                    = y,\n",
    "            exog                 = exog,\n",
    "            select_only_exog     = True,\n",
    "            verbose              = False,\n",
    "        )\n",
    "\n",
    "test_select_features_when_selector_is_RFE_and_select_only_exog_is_True()\n",
    "test_select_features_when_selector_is_RFE_and_select_only_exog_is_True_ForecasterAutoregCustom()\n",
    "test_select_features_when_selector_is_RFE_and_select_only_exog_is_False()\n",
    "test_select_features_when_selector_is_RFE_and_select_only_exog_is_False_ForecasterAutoregCustom()\n",
    "test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_regex()\n",
    "test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_regex_ForecasterAutoregCustom()\n",
    "test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_list()\n",
    "test_select_features_when_selector_is_RFE_select_only_exog_is_True_and_force_inclusion_is_list_ForecasterAutoregCustom()\n",
    "test_select_features_raise_error_when_forecaster_is_not_supported()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
