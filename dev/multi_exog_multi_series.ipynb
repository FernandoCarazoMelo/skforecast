{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import copy, deepcopy\n",
    "import inspect\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterBase import ForecasterBase\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.exceptions import MissingValuesExogWarning\n",
    "from skforecast.utils import initialize_lags\n",
    "from skforecast.utils import initialize_weights\n",
    "from skforecast.utils import check_select_fit_kwargs\n",
    "from skforecast.utils import check_exog\n",
    "from skforecast.utils import get_exog_dtypes\n",
    "from skforecast.utils import check_exog_dtypes\n",
    "from skforecast.utils import check_interval\n",
    "from skforecast.utils import check_predict_input\n",
    "from skforecast.utils import preprocess_y\n",
    "from skforecast.utils import preprocess_last_window\n",
    "from skforecast.utils import preprocess_exog\n",
    "from skforecast.utils import expand_index\n",
    "from skforecast.utils import transform_series\n",
    "from skforecast.utils import transform_dataframe\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(series.shape)\n",
    "series.columns = ['l1', 'l2']\n",
    "series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(50),\n",
    "              'exog2': np.arange(50, 100),\n",
    "          })\n",
    "\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series({'exog1': np.arange(100, 150)})\n",
    "\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': exog_l1,\n",
    "    'l2': exog_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train X y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None None\n"
     ]
    }
   ],
   "source": [
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    y: np.ndarray, \n",
    "    series_name: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row\n",
    "    in X is associated with a value of y and it represents the lags that\n",
    "    precede it.\n",
    "    \n",
    "    Notice that, the returned matrix X_data, contains the lag 1 in the first\n",
    "    column, the lag 2 in the second column and so on.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy ndarray\n",
    "        1d numpy ndarray Training time series.\n",
    "    series_name : str\n",
    "        Name of the series.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_data : numpy ndarray\n",
    "        2d numpy ndarray with the lagged values (predictors). \n",
    "        Shape: (samples - max(self.lags), len(self.lags))\n",
    "    y_data : numpy ndarray\n",
    "        1d numpy ndarray with the values of the time series related to each \n",
    "        row of `X_data`. \n",
    "        Shape: (samples - max(self.lags), )\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    n_splits = len(y) - max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            (f\"The maximum lag ({max_lag}) must be less than the length \"\n",
    "                f\"of the series '{series_name}', ({len(y)}).\")\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        X_data[:, i] = y[max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[max_lag:]\n",
    "        \n",
    "    return X_data, y_data\n",
    "\n",
    "\n",
    "def check_exog_create_train_X_y(series, exog, key=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if len(exog) != len(series):\n",
    "        if key:\n",
    "            raise ValueError(\n",
    "                (f\"`exog` must have same number of samples as `series`.\\n\"\n",
    "                 f\"    length `exog`: {len(exog)} for series {key}\\n\"\n",
    "                 f\"    length `series`: {len(series)}\")\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                (f\"`exog` must have same number of samples as `series`. \"\n",
    "                 f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "            )\n",
    "    \n",
    "    check_exog(exog=exog, allow_nan=True)\n",
    "\n",
    "    if isinstance(exog, pd.Series):\n",
    "        # Needed for pandas concat\n",
    "        exog = exog.to_frame()\n",
    "    \n",
    "    exog = transform_dataframe(\n",
    "                df                = exog,\n",
    "                transformer       = transformer_exog,\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "    check_exog(exog=exog, allow_nan=False)\n",
    "    check_exog_dtypes(exog)\n",
    "\n",
    "    _, _ = preprocess_exog(exog=exog, return_values=False)\n",
    "    if not (exog.index[:len(series)] == series.index).all():\n",
    "        if key:\n",
    "            raise ValueError(\n",
    "                (f\"Different index for `series` and `exog` for series {key}. \"\n",
    "                 f\"They must be equal to ensure the correct alignment of values.\")\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                 \"to ensure the correct alignment of values.\")\n",
    "            )\n",
    "        \n",
    "    return exog\n",
    "\n",
    "\n",
    "def create_train_X_y(\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:\n",
    "    \"\"\"\n",
    "    Create training matrices from multiple time series and exogenous\n",
    "    variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    exog : pandas Series, pandas DataFrame, dict, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `series` and their indexes must be aligned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : pandas DataFrame\n",
    "        Training values (predictors).\n",
    "    y_train : pandas Series\n",
    "        Values (target) of the time series related to each row of `X_train`.\n",
    "        Shape: (len(series) - self.max_lag, )\n",
    "    y_index : pandas Index\n",
    "        Index of `series`.\n",
    "    y_train_index: pandas Index\n",
    "        Index of `y_train`.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f\"`series` must be a pandas DataFrame. Got {type(series)}.\")\n",
    "\n",
    "    series_col_names = list(series.columns)\n",
    "\n",
    "    if transformer_series is None:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "    elif not isinstance(transformer_series, dict):\n",
    "        transformer_series_ = {serie: clone(transformer_series) \n",
    "                               for serie in series_col_names}\n",
    "    else:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "        # Only elements already present in transformer_series_ are updated\n",
    "        transformer_series_.update(\n",
    "            (k, v) for k, v in deepcopy(transformer_series).items() \n",
    "            if k in transformer_series_\n",
    "        )\n",
    "        series_not_in_transformer_series = set(series.columns) - set(transformer_series.keys())\n",
    "        if series_not_in_transformer_series:\n",
    "            warnings.warn(\n",
    "                (f\"{series_not_in_transformer_series} not present in `transformer_series`.\"\n",
    "                 f\" No transformation is applied to these series.\"),\n",
    "                 IgnoredArgumentWarning\n",
    "            )\n",
    "    \n",
    "    if exog is not None:\n",
    "\n",
    "        if isinstance(exog, dict):\n",
    "            \n",
    "            exog_ = {serie: None for serie in series_col_names}\n",
    "            # Only elements already present in exog_ are updated\n",
    "            exog_.update(\n",
    "                (k, v) for k, v in deepcopy(exog).items() \n",
    "                if k in exog_\n",
    "            )\n",
    "            series_not_in_exog = set(series.columns) - set(exog.keys())\n",
    "            if series_not_in_exog:\n",
    "                # TODO: review warning\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_exog} not present in `exog`.\"\n",
    "                     f\" No transformation is applied to these series.\"),\n",
    "                     IgnoredArgumentWarning\n",
    "                )\n",
    "\n",
    "            for k, v in exog.items():\n",
    "                exog[k] = check_exog_create_train_X_y(series=series, exog=v, key=k)\n",
    "        else:   \n",
    "            exog = check_exog_create_train_X_y(series=series, exog=exog, key=None)\n",
    "            \n",
    "        # TODO: adapt get_exog_dtypes when dict\n",
    "        # exog_dtypes = get_exog_dtypes(exog=exog)\n",
    "    \n",
    "    X_levels = []\n",
    "    len_series = []\n",
    "    X_train_col_names = [f\"lag_{lag}\" for lag in lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        y_values = y.to_numpy()\n",
    "\n",
    "        if np.isnan(y_values).all():\n",
    "            raise ValueError(f\"All values of series '{serie}' are NaN.\")\n",
    "        \n",
    "        first_no_nan_idx = np.argmax(~np.isnan(y_values))\n",
    "        y_values = y_values[first_no_nan_idx:]\n",
    "\n",
    "        if np.isnan(y_values).any():\n",
    "            raise ValueError(\n",
    "                (f\"'{serie}' Time series has missing values in between or \"\n",
    "                    f\"at the end of the time series. When working with series \"\n",
    "                    f\"of different lengths, all series must be complete after \"\n",
    "                    f\"the first non-null value.\")\n",
    "            )\n",
    "        \n",
    "        y = transform_series(\n",
    "                series            = y.iloc[first_no_nan_idx:],\n",
    "                transformer       = transformer_series_[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "        y_values = y.to_numpy()\n",
    "        X_train_values, y_train_values = _create_lags(y=y_values, series_name=serie)\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_train_values), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_values), axis=0)\n",
    "\n",
    "        X_level = [serie]*len(X_train_values)\n",
    "        X_levels.extend(X_level)\n",
    "        len_series.append(len(y_train_values))\n",
    "    \n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                  data    = X_train,\n",
    "                  columns = X_train_col_names\n",
    "              )\n",
    "\n",
    "    if exog is not None:\n",
    "        # The first `self.max_lag` positions have to be removed from exog\n",
    "        # since they are not in X_train. Then Exog is cloned as many times \n",
    "        # as there are series, taking into account the length of the series.\n",
    "        if isinstance(exog, dict):\n",
    "            exog_to_train = []\n",
    "            for i, key in enumerate(exog):\n",
    "                exog_to_train.append(exog[key].iloc[-len_series[i]:, ])\n",
    "        else:\n",
    "            exog_to_train = [exog.iloc[-length:, ] for length in len_series]\n",
    "\n",
    "        exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)\n",
    "    else:\n",
    "        exog_to_train = None\n",
    "    \n",
    "    X_train = pd.concat([X_train, exog_to_train, X_levels], axis=1)\n",
    "    X_train_col_names = X_train.columns.to_list()\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                  data = y_train,\n",
    "                  name = 'y'\n",
    "              )\n",
    "\n",
    "    _, y_index = preprocess_y(y=series, return_values=False)\n",
    "\n",
    "    y_index_numpy = y_index.to_numpy()\n",
    "    y_train_index = pd.Index(\n",
    "                        np.concatenate(\n",
    "                            [y_index_numpy[-length:, ] \n",
    "                             for length in len_series]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    return X_train, y_train, y_index, y_train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['l1', 'l2'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_series = [50, 50]\n",
    "\n",
    "exog_to_train = []\n",
    "for i, key in enumerate(exog):\n",
    "\n",
    "    if isinstance(exog[key], pd.Series):\n",
    "        exog_ = exog[key].copy().to_frame()\n",
    "    else:\n",
    "        exog_ = exog[key]\n",
    "    \n",
    "    exog_to_train.append(exog[key].iloc[-len_series[i]:, ])\n",
    "\n",
    "\n",
    "exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(50),\n",
    "              'exog2': np.arange(50, 100),\n",
    "          })\n",
    "\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series(np.arange(100, 150), name='exog1')\n",
    "\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': None,\n",
    "    'l2': exog_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )\n",
    "\n",
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = StandardScaler()\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      exog1     exog2\n",
      "0 -1.697749 -1.697749\n",
      "1 -1.628453 -1.628453\n",
      "      exog1\n",
      "0 -1.697749\n",
      "1 -1.628453\n"
     ]
    }
   ],
   "source": [
    "for k, v in exog.items():\n",
    "    _ = check_exog_create_train_X_y(series=series, exog=v, key=k)\n",
    "    print(_.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_train_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[12], line 172\u001b[0m, in \u001b[0;36mcreate_train_X_y\u001b[1;34m(series, exog)\u001b[0m\n\u001b[0;32m    165\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    166\u001b[0m             (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries_not_in_exog\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not present in `exog`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m No transformation is applied to these series.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    168\u001b[0m              IgnoredArgumentWarning\n\u001b[0;32m    169\u001b[0m         )\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 172\u001b[0m         exog[k] \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_exog_create_train_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[0;32m    174\u001b[0m     exog \u001b[38;5;241m=\u001b[39m check_exog_create_train_X_y(series\u001b[38;5;241m=\u001b[39mseries, exog\u001b[38;5;241m=\u001b[39mexog, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[12], line 52\u001b[0m, in \u001b[0;36mcheck_exog_create_train_X_y\u001b[1;34m(series, exog, key)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_exog_create_train_X_y\u001b[39m(series, exog, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(series):\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     55\u001b[0m                 (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`exog` must have same number of samples as `series`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    length `exog`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(exog)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for series \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    length `series`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "create_train_X_y(series=series, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = pd.Series(np.arange(100, 150), name='exog1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>exog1</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.696469</td>\n",
       "      <td>103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>0.355915</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.240856</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag_1     lag_2     lag_3  exog1   l1   l2\n",
       "0   0.226851  0.286139  0.696469    103  1.0  0.0\n",
       "1   0.551315  0.226851  0.286139    104  1.0  0.0\n",
       "2   0.719469  0.551315  0.226851    105  1.0  0.0\n",
       "3   0.423106  0.719469  0.551315    106  1.0  0.0\n",
       "4   0.980764  0.423106  0.719469    107  1.0  0.0\n",
       "..       ...       ...       ...    ...  ...  ...\n",
       "89  0.593177  0.762548  0.355915    145  0.0  1.0\n",
       "90  0.691702  0.593177  0.762548    146  0.0  1.0\n",
       "91  0.151127  0.691702  0.593177    147  0.0  1.0\n",
       "92  0.398876  0.151127  0.691702    148  0.0  1.0\n",
       "93  0.240856  0.398876  0.151127    149  0.0  1.0\n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.create_train_X_y(series=series, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Parallelitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] ['exog1', 'exog2'] None None\n"
     ]
    }
   ],
   "source": [
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "exog_col_names = ['exog1', 'exog2']\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "\n",
    "print(max_lag, lags, exog_col_names, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    y: np.ndarray, \n",
    "    series_name: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"    \n",
    "    \"\"\"\n",
    "        \n",
    "    n_splits = len(y) - max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            (f\"The maximum lag ({max_lag}) must be less than the length \"\n",
    "                f\"of the series '{series_name}', ({len(y)}).\")\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        X_data[:, i] = y[max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[max_lag:]\n",
    "        \n",
    "    return X_data, y_data\n",
    "\n",
    "\n",
    "def create_train_X_y(\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:\n",
    "    \"\"\"    \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f\"`series` must be a pandas DataFrame. Got {type(series)}.\")\n",
    "\n",
    "    series_col_names = list(series.columns)\n",
    "\n",
    "    if transformer_series is None:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "    elif not isinstance(transformer_series, dict):\n",
    "        transformer_series_ = {serie: clone(transformer_series) \n",
    "                               for serie in series_col_names}\n",
    "    else:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "        # Only elements already present in transformer_series_ are updated\n",
    "        transformer_series_.update(\n",
    "            (k, v) for k, v in deepcopy(transformer_series).items() \n",
    "            if k in transformer_series_\n",
    "        )\n",
    "        series_not_in_transformer_series = set(series.columns) - set(transformer_series.keys())\n",
    "        if series_not_in_transformer_series:\n",
    "            warnings.warn(\n",
    "                (f\"{series_not_in_transformer_series} not present in `transformer_series`.\"\n",
    "                    f\" No transformation is applied to these series.\"),\n",
    "                    IgnoredArgumentWarning\n",
    "            )\n",
    "\n",
    "    if exog is not None:\n",
    "        if not isinstance(exog, dict):\n",
    "            exog_dict = {serie: exog for serie in series_col_names}\n",
    "        else:\n",
    "            exog_dict = {serie: None for serie in series_col_names}\n",
    "            # Only elements already present in exog_dict are updated\n",
    "            exog_dict.update(\n",
    "                (k, v) for k, v in exog.items() \n",
    "                if k in exog_dict\n",
    "            )\n",
    "            series_not_in_exog = set(series.columns) - set(exog.keys())\n",
    "            if series_not_in_exog:\n",
    "                # TODO: review warning\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_exog} not present in `exog`. All values \"\n",
    "                     f\"of the exogenous variables for these series will be NaN.\"),\n",
    "                     MissingValuesExogWarning\n",
    "                )\n",
    "\n",
    "        for k, v in exog_dict.items():\n",
    "            if v is not None:\n",
    "                if len(v) != len(series):\n",
    "                    # TODO: when series of different length, exog with nans at the begining\n",
    "                    raise ValueError(\n",
    "                        (f\"`exog` must have same number of samples as `series`.\\n\"\n",
    "                         f\"    length `exog`: {len(v)} for series {k}\\n\"\n",
    "                         f\"    length `series`: {len(series)}\")\n",
    "                    )\n",
    "                check_exog(exog=v, allow_nan=True)\n",
    "\n",
    "                # TODO: review this ValueError\n",
    "                _, _ = preprocess_exog(exog=v, return_values=False)\n",
    "                if not (v.index[:len(series)] == series.index).all():\n",
    "                    raise ValueError(\n",
    "                        (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                         \"to ensure the correct alignment of values.\")\n",
    "                    )\n",
    "    \n",
    "    X_levels = []\n",
    "    exog_levels = []\n",
    "    len_series = []\n",
    "    X_train_col_names = [f\"lag_{lag}\" for lag in lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        y_index_no_nan = y.dropna().index\n",
    "\n",
    "        # if np.isnan(y_values).all():\n",
    "        if len(y_index_no_nan) == 0:\n",
    "            raise ValueError(f\"All values of series '{serie}' are NaN.\")\n",
    "        \n",
    "        # first_no_nan_idx = np.argmax(~np.isnan(y_values))\n",
    "        # y_values = y_values[first_no_nan_idx:]\n",
    "\n",
    "        # if np.isnan(y_values).any():\n",
    "        #     raise ValueError(\n",
    "        #         (f\"'{serie}' Time series has missing values in between or \"\n",
    "        #             f\"at the end of the time series. When working with series \"\n",
    "        #             f\"of different lengths, all series must be complete after \"\n",
    "        #             f\"the first non-null value.\")\n",
    "        #     )\n",
    "        \n",
    "        y = transform_series(\n",
    "                series            = y,\n",
    "                transformer       = transformer_series_[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "        y_values = y.to_numpy()\n",
    "        X_train_values, y_train_values = _create_lags(y=y_values, series_name=serie)\n",
    "\n",
    "        delete_from_X_train = False\n",
    "        if delete_from_X_train:\n",
    "            rows_with_nan = np.isnan(X_train_values).any(axis=1)\n",
    "        else:\n",
    "            rows_with_nan = np.isnan(y_train_values)\n",
    "        \n",
    "        X_train_values = X_train_values[~rows_with_nan]\n",
    "        y_train_values = y_train_values[~rows_with_nan]\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_train_values), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_values), axis=0)\n",
    "\n",
    "        X_level = [serie]*len(X_train_values)\n",
    "        X_levels.extend(X_level)\n",
    "        # len_series.append(rows_with_nan)\n",
    "\n",
    "        if exog is not None:\n",
    "            if exog_dict[serie] is not None:\n",
    "                exog_level = exog_dict[serie].iloc[max_lag:, ].iloc[~rows_with_nan]\n",
    "                # TODO: poner check que index_exog contenga todos los valores de y_index_no_nan\n",
    "                #if not (exog_level.index == y_index_no_nan).all():\n",
    "                #    raise ValueError(\n",
    "                #        (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                #         \"to ensure the correct alignment of values.\")\n",
    "                #    )\n",
    "                if isinstance(exog_level, pd.Series):\n",
    "                    # Needed for pandas concat\n",
    "                    exog_level = exog_level.to_frame()\n",
    "            else:\n",
    "                exog_level = pd.DataFrame(\n",
    "                                 np.nan, \n",
    "                                 index=np.arange(len(X_train_values)), \n",
    "                                 columns=exog_col_names\n",
    "                             )\n",
    "            exog_levels.append(exog_level)\n",
    "\n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                  data    = X_train,\n",
    "                  columns = X_train_col_names\n",
    "              )\n",
    "\n",
    "    if exog is not None:\n",
    "        exog_train = pd.concat(exog_levels).reset_index(drop=True)\n",
    "        exog_train = transform_dataframe(\n",
    "                         df                = exog_train,\n",
    "                         transformer       = transformer_exog,\n",
    "                         fit               = True,\n",
    "                         inverse_transform = False\n",
    "                     )\n",
    "        \n",
    "        # check_exog_dtypes llama a check_exog\n",
    "        # check_exog(exog=exog_train, allow_nan=False)\n",
    "        check_exog_dtypes(exog_train)\n",
    "        exog_dtypes = get_exog_dtypes(exog=exog_train)\n",
    "    else:\n",
    "        exog_train = None\n",
    "    \n",
    "    X_train = pd.concat([X_train, exog_train, X_levels], axis=1)\n",
    "    X_train_col_names = X_train.columns.to_list()\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                  data = y_train,\n",
    "                  name = 'y'\n",
    "              )\n",
    "\n",
    "    _, y_index = preprocess_y(y=series, return_values=False)\n",
    "\n",
    "    # y_index_numpy = y_index.to_numpy()\n",
    "    # y_train_index = pd.Index(\n",
    "    #                     np.concatenate(\n",
    "    #                         [y_index_numpy[~np.isin(range(len(y_index_numpy)), rows_with_nan)]\n",
    "    #                          for rows_with_nan in len_series]\n",
    "    #                     )\n",
    "    #                 )\n",
    "\n",
    "    y_train_index = []\n",
    "    for serie in series.columns:\n",
    "        serie_index = series[serie].dropna().index[max_lag:, ]\n",
    "        y_train_index.append(serie_index)\n",
    "\n",
    "    y_train_index = pd.Index(np.concatenate(y_train_index))\n",
    "\n",
    "    return X_train, y_train, y_index, y_train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_2 = series.head(10).copy()\n",
    "series_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.545068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.342764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.304121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.417022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.681301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.480932</td>\n",
       "      <td>0.875457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.392118</td>\n",
       "      <td>0.510422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469       NaN\n",
       "1  0.286139       NaN\n",
       "2  0.226851       NaN\n",
       "3  0.551315  0.545068\n",
       "4  0.719469  0.342764\n",
       "5  0.423106  0.304121\n",
       "6  0.980764  0.417022\n",
       "7  0.684830  0.681301\n",
       "8  0.480932  0.875457\n",
       "9  0.392118  0.510422"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_3 = series_2.copy()\n",
    "series_3.iloc[:3, 1] = np.nan\n",
    "series_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(10),\n",
    "              'exog2': np.arange(50, 60),\n",
    "          })\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series(np.arange(100, 110), name='exog1').to_frame()\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': exog_l1,\n",
    "    'l2': exog_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None None\n"
     ]
    }
   ],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )\n",
    "\n",
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "# transformer_exog = StandardScaler()\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.545068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.342764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.304121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.417022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.681301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.480932</td>\n",
       "      <td>0.875457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.392118</td>\n",
       "      <td>0.510422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469       NaN\n",
       "1  0.286139       NaN\n",
       "2  0.226851       NaN\n",
       "3  0.551315  0.545068\n",
       "4  0.719469  0.342764\n",
       "5  0.423106  0.304121\n",
       "6  0.980764  0.417022\n",
       "7  0.684830  0.681301\n",
       "8  0.480932  0.875457\n",
       "9  0.392118  0.510422"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_create = series_3\n",
    "series_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55131477 0.71946897 0.42310646 0.9807642  0.68482974 0.4809319\n",
      " 0.39211752]\n",
      "(7,)\n",
      "[0.54506801 0.34276383 0.30412079 0.41702221 0.68130077 0.87545684\n",
      " 0.51042234]\n",
      "(7,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:346: MissingValuesExogWarning: `exog` has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesExogWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>exog1</th>\n",
       "      <th>exog2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.696469</td>\n",
       "      <td>3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.480932</td>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.980764</td>\n",
       "      <td>9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.545068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.342764</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.304121</td>\n",
       "      <td>0.342764</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.304121</td>\n",
       "      <td>0.342764</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.681301</td>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.304121</td>\n",
       "      <td>108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.875457</td>\n",
       "      <td>0.681301</td>\n",
       "      <td>0.417022</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag_1     lag_2     lag_3  exog1  exog2   l1   l2\n",
       "0   0.226851  0.286139  0.696469      3   53.0  1.0  0.0\n",
       "1   0.551315  0.226851  0.286139      4   54.0  1.0  0.0\n",
       "2   0.719469  0.551315  0.226851      5   55.0  1.0  0.0\n",
       "3   0.423106  0.719469  0.551315      6   56.0  1.0  0.0\n",
       "4   0.980764  0.423106  0.719469      7   57.0  1.0  0.0\n",
       "5   0.684830  0.980764  0.423106      8   58.0  1.0  0.0\n",
       "6   0.480932  0.684830  0.980764      9   59.0  1.0  0.0\n",
       "7        NaN       NaN       NaN    103    NaN  0.0  1.0\n",
       "8   0.545068       NaN       NaN    104    NaN  0.0  1.0\n",
       "9   0.342764  0.545068       NaN    105    NaN  0.0  1.0\n",
       "10  0.304121  0.342764  0.545068    106    NaN  0.0  1.0\n",
       "11  0.417022  0.304121  0.342764    107    NaN  0.0  1.0\n",
       "12  0.681301  0.417022  0.304121    108    NaN  0.0  1.0\n",
       "13  0.875457  0.681301  0.417022    109    NaN  0.0  1.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series_create, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55131477 0.71946897 0.42310646 0.9807642  0.68482974 0.4809319\n",
      " 0.39211752]\n",
      "(7,)\n",
      "[0.54506801 0.34276383 0.30412079 0.41702221 0.68130077 0.87545684\n",
      " 0.51042234]\n",
      "(7,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:346: MissingValuesExogWarning: `exog` has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesExogWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0.551315\n",
       "1     0.719469\n",
       "2     0.423106\n",
       "3     0.980764\n",
       "4     0.684830\n",
       "5     0.480932\n",
       "6     0.392118\n",
       "7     0.545068\n",
       "8     0.342764\n",
       "9     0.304121\n",
       "10    0.417022\n",
       "11    0.681301\n",
       "12    0.875457\n",
       "13    0.510422\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series_create, exog=exog)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:346: MissingValuesExogWarning: `exog` has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesExogWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series_create, exog=exog)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:346: MissingValuesExogWarning: `exog` has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesExogWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([3, 4, 5, 6, 7, 8, 9, 6, 7, 8, 9], dtype='int64')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series_create, exog=exog)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exog1</th>\n",
       "      <th>exog2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exog1  exog2\n",
       "0      0     50\n",
       "1      1     51\n",
       "2      2     52\n",
       "3      3     53\n",
       "4      4     54\n",
       "5      5     55\n",
       "6      6     56\n",
       "7      7     57\n",
       "8      8     58\n",
       "9      9     59"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rows_with_nan = np.array([])\n",
    "\n",
    "# exog['l1'].iloc[~X_train_rows_with_nan, ]\n",
    "exog['l1'][~exog['l1'].index.isin(X_train_rows_with_nan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_3 = pd.DataFrame({\n",
    "    'l1': np.arange(10),\n",
    "    'l2': np.arange(50, 60)\n",
    "})\n",
    "\n",
    "# series_3.iloc[:5, 1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>exog1</th>\n",
       "      <th>exog2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lag_1  lag_2  lag_3  exog1  exog2   l1   l2\n",
       "0     2.0    1.0    0.0   -1.5   -1.5  1.0  0.0\n",
       "1     3.0    2.0    1.0   -1.0   -1.0  1.0  0.0\n",
       "2     4.0    3.0    2.0   -0.5   -0.5  1.0  0.0\n",
       "3     5.0    4.0    3.0    0.0    0.0  1.0  0.0\n",
       "4     6.0    5.0    4.0    0.5    0.5  1.0  0.0\n",
       "5     7.0    6.0    5.0    1.0    1.0  1.0  0.0\n",
       "6     8.0    7.0    6.0    1.5    1.5  1.0  0.0\n",
       "7    52.0   51.0   50.0   -1.5   -1.5  0.0  1.0\n",
       "8    53.0   52.0   51.0   -1.0   -1.0  0.0  1.0\n",
       "9    54.0   53.0   52.0   -0.5   -0.5  0.0  1.0\n",
       "10   55.0   54.0   53.0    0.0    0.0  0.0  1.0\n",
       "11   56.0   55.0   54.0    0.5    0.5  0.0  1.0\n",
       "12   57.0   56.0   55.0    1.0    1.0  0.0  1.0\n",
       "13   58.0   57.0   56.0    1.5    1.5  0.0  1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series_3, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1':    exog1  exog2\n",
       " 0      0     50\n",
       " 1      1     51\n",
       " 2      2     52\n",
       " 3      3     53\n",
       " 4      4     54\n",
       " 5      5     55\n",
       " 6      6     56\n",
       " 7      7     57\n",
       " 8      8     58\n",
       " 9      9     59,\n",
       " 'l2':    exog1\n",
       " 0    100\n",
       " 1    101\n",
       " 2    102\n",
       " 3    103\n",
       " 4    104\n",
       " 5    105\n",
       " 6    106\n",
       " 7    107\n",
       " 8    108\n",
       " 9    109}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "serie = pd.Series(np.arange(10000))\n",
    "display(serie.head(4))\n",
    "serie.iloc[3] = np.nan\n",
    "display(serie.head(4))\n",
    "\n",
    "array = serie.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 µs ± 6.83 µs per loop (mean ± std. dev. of 4 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 4\n",
    "\n",
    "# Finding the positions of non-NaN values in the Series\n",
    "non_nan_positions_mostly_nan = np.argwhere(~np.isnan(array)).flatten()\n",
    "\n",
    "# Filtering the Series using iloc and the positions of non-NaN values\n",
    "filtered_series_non_nan_mostly_nan = serie.iloc[non_nan_positions_mostly_nan]\n",
    "filtered_series_non_nan_mostly_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.1 µs ± 1.71 µs per loop (mean ± std. dev. of 4 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 4\n",
    "\n",
    "serie.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 µs ± 6.53 µs per loop (mean ± std. dev. of 4 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 4\n",
    "\n",
    "serie[~serie.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaN\n",
       "1   NaN\n",
       "2   NaN\n",
       "3   NaN\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = pd.Series([np.nan]*10)\n",
    "display(serie.head(4))\n",
    "serie = serie.dropna().index\n",
    "len(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.603060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341\n",
       "2  0.226851  0.603060\n",
       "3       NaN  0.545068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "      dtype='int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.603060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341\n",
       "2  0.226851  0.603060\n",
       "3       NaN  0.545068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(series.head(4))\n",
    "serie = series['l1']\n",
    "serie = serie.dropna().index\n",
    "display(serie)\n",
    "display(series.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 2, 3, 4, 5, 1, 2, 3, 4, 5], dtype='int32')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[1,2,3,4,5], [1,2,3,4,5]]\n",
    "\n",
    "pd.Index(np.concatenate(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385573382160"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1_5x6 = np.array([[1, np.nan, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, np.nan, 16, 17, 18], [19, 20, 21, np.nan, 23, 24], [25, 26, 27, 28, 29, 30]])\n",
    "\n",
    "np.isnan(array1_5x6).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2_1d_5 = np.array([101, 102, 103, 104, 105])\n",
    "np.isnan(array2_1d_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.  4.  5.  6.]\n",
      " [ 7.  8.  9. 10. 11. 12.]\n",
      " [13. 14. nan 16. 17. 18.]\n",
      " [19. 20. 21. nan 23. 24.]\n",
      " [25. 26. 27. 28. 29. 30.]]\n",
      "[101 102 103 104 105]\n",
      "[0 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([105, 103, 102])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new example where the first array is 5x6 and the second array is 1D with length 5\n",
    "array1_5x6 = np.array([[1, np.nan, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, np.nan, 16, 17, 18], [19, 20, 21, np.nan, 23, 24], [25, 26, 27, 28, 29, 30]])\n",
    "array2_1d_5 = np.array([101, 102, 103, 104, 105])\n",
    "\n",
    "print(array1_5x6)\n",
    "print(array2_1d_5)\n",
    "\n",
    "# Find rows in the first array that contain NaN\n",
    "rows_with_nan = np.unique(np.argwhere(np.isnan(array1_5x6))[:, 0])\n",
    "# rows_with_nan = np.isnan(array1_5x6).any(axis=1)\n",
    "\n",
    "print(rows_with_nan)\n",
    "\n",
    "# Deleting the corresponding rows in the 1D array\n",
    "# array2_1d_5_filtered = np.delete(array2_1d_5, rows_with_nan)\n",
    "array2_1d_5_filtered = array2_1d_5[~rows_with_nan]\n",
    "array2_1d_5_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.603060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.342764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.417022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.480932</td>\n",
       "      <td>0.875457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "2  0.226851  0.603060\n",
       "4  0.719469  0.342764\n",
       "6  0.980764  0.417022\n",
       "8  0.480932  0.875457"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([True, False, True, False, True, False, True, False, True, False])\n",
    "\n",
    "series_2.iloc[array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 2],\n",
       "       [3, 3]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(array1_5x6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(array1_5x6))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 50])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 1D array for demonstration\n",
    "array_1d_example = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Filtering the 1D array to keep only positions that are not in `rows_with_nan`\n",
    "filtered_array_1d = array_1d_example[~np.isin(range(len(array_1d_example)), rows_with_nan)]\n",
    "filtered_array_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.9 ns ± 25.3 ns per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 10\n",
    "\n",
    "array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.1 ns ± 0.803 ns per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10000 -r 10\n",
    "\n",
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0 NaN\n",
       "1 NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.full(shape=(len([1,2])), fill_value=np.nan, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
