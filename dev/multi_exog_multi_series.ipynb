{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import copy, deepcopy\n",
    "import inspect\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterBase import ForecasterBase\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import initialize_lags\n",
    "from skforecast.utils import initialize_weights\n",
    "from skforecast.utils import check_select_fit_kwargs\n",
    "from skforecast.utils import check_exog\n",
    "from skforecast.utils import get_exog_dtypes\n",
    "from skforecast.utils import check_exog_dtypes\n",
    "from skforecast.utils import check_interval\n",
    "from skforecast.utils import check_predict_input\n",
    "from skforecast.utils import preprocess_y\n",
    "from skforecast.utils import preprocess_last_window\n",
    "from skforecast.utils import preprocess_exog\n",
    "from skforecast.utils import expand_index\n",
    "from skforecast.utils import transform_series\n",
    "from skforecast.utils import transform_dataframe\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(series.shape)\n",
    "series.columns = ['l1', 'l2']\n",
    "series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(50),\n",
    "              'exog2': np.arange(50, 100),\n",
    "          })\n",
    "\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series({'exog1': np.arange(100, 150)})\n",
    "\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': exog_l1,\n",
    "    'l2': exog_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train X y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None None\n"
     ]
    }
   ],
   "source": [
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    y: np.ndarray, \n",
    "    series_name: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row\n",
    "    in X is associated with a value of y and it represents the lags that\n",
    "    precede it.\n",
    "    \n",
    "    Notice that, the returned matrix X_data, contains the lag 1 in the first\n",
    "    column, the lag 2 in the second column and so on.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : numpy ndarray\n",
    "        1d numpy ndarray Training time series.\n",
    "    series_name : str\n",
    "        Name of the series.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_data : numpy ndarray\n",
    "        2d numpy ndarray with the lagged values (predictors). \n",
    "        Shape: (samples - max(self.lags), len(self.lags))\n",
    "    y_data : numpy ndarray\n",
    "        1d numpy ndarray with the values of the time series related to each \n",
    "        row of `X_data`. \n",
    "        Shape: (samples - max(self.lags), )\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    n_splits = len(y) - max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            (f\"The maximum lag ({max_lag}) must be less than the length \"\n",
    "                f\"of the series '{series_name}', ({len(y)}).\")\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        X_data[:, i] = y[max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[max_lag:]\n",
    "        \n",
    "    return X_data, y_data\n",
    "\n",
    "\n",
    "def check_exog_create_train_X_y(series, exog, key=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if len(exog) != len(series):\n",
    "        if key:\n",
    "            raise ValueError(\n",
    "                (f\"`exog` must have same number of samples as `series`.\\n\"\n",
    "                 f\"    length `exog`: {len(exog)} for series {key}\\n\"\n",
    "                 f\"    length `series`: {len(series)}\")\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                (f\"`exog` must have same number of samples as `series`. \"\n",
    "                 f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "            )\n",
    "    \n",
    "    check_exog(exog=exog, allow_nan=True)\n",
    "\n",
    "    if isinstance(exog, pd.Series):\n",
    "        # Needed for pandas concat\n",
    "        exog = exog.to_frame()\n",
    "    \n",
    "    exog = transform_dataframe(\n",
    "                df                = exog,\n",
    "                transformer       = transformer_exog,\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "    check_exog(exog=exog, allow_nan=False)\n",
    "    check_exog_dtypes(exog)\n",
    "\n",
    "    _, _ = preprocess_exog(exog=exog, return_values=False)\n",
    "    if not (exog.index[:len(series)] == series.index).all():\n",
    "        if key:\n",
    "            raise ValueError(\n",
    "                (f\"Different index for `series` and `exog` for series {key}. \"\n",
    "                 f\"They must be equal to ensure the correct alignment of values.\")\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                 \"to ensure the correct alignment of values.\")\n",
    "            )\n",
    "        \n",
    "    return exog\n",
    "\n",
    "\n",
    "def create_train_X_y(\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame, dict]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:\n",
    "    \"\"\"\n",
    "    Create training matrices from multiple time series and exogenous\n",
    "    variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    exog : pandas Series, pandas DataFrame, dict, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `series` and their indexes must be aligned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : pandas DataFrame\n",
    "        Training values (predictors).\n",
    "    y_train : pandas Series\n",
    "        Values (target) of the time series related to each row of `X_train`.\n",
    "        Shape: (len(series) - self.max_lag, )\n",
    "    y_index : pandas Index\n",
    "        Index of `series`.\n",
    "    y_train_index: pandas Index\n",
    "        Index of `y_train`.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f\"`series` must be a pandas DataFrame. Got {type(series)}.\")\n",
    "\n",
    "    series_col_names = list(series.columns)\n",
    "\n",
    "    if transformer_series is None:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "    elif not isinstance(transformer_series, dict):\n",
    "        transformer_series_ = {serie: clone(transformer_series) \n",
    "                               for serie in series_col_names}\n",
    "    else:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "        # Only elements already present in transformer_series_ are updated\n",
    "        transformer_series_.update(\n",
    "            (k, v) for k, v in deepcopy(transformer_series).items() \n",
    "            if k in transformer_series_\n",
    "        )\n",
    "        series_not_in_transformer_series = set(series.columns) - set(transformer_series.keys())\n",
    "        if series_not_in_transformer_series:\n",
    "            warnings.warn(\n",
    "                (f\"{series_not_in_transformer_series} not present in `transformer_series`.\"\n",
    "                 f\" No transformation is applied to these series.\"),\n",
    "                 IgnoredArgumentWarning\n",
    "            )\n",
    "    \n",
    "    if exog is not None:\n",
    "\n",
    "        if isinstance(exog, dict):\n",
    "            \n",
    "            exog_ = {serie: None for serie in series_col_names}\n",
    "            # Only elements already present in exog_ are updated\n",
    "            exog_.update(\n",
    "                (k, v) for k, v in deepcopy(exog).items() \n",
    "                if k in exog_\n",
    "            )\n",
    "            series_not_in_exog = set(series.columns) - set(exog.keys())\n",
    "            if series_not_in_exog:\n",
    "                # TODO: review warning\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_exog} not present in `exog`.\"\n",
    "                     f\" No transformation is applied to these series.\"),\n",
    "                     IgnoredArgumentWarning\n",
    "                )\n",
    "\n",
    "            for k, v in exog.items():\n",
    "                exog[k] = check_exog_create_train_X_y(series=series, exog=v, key=k)\n",
    "        else:   \n",
    "            exog = check_exog_create_train_X_y(series=series, exog=exog, key=None)\n",
    "            \n",
    "        # TODO: adapt get_exog_dtypes when dict\n",
    "        # exog_dtypes = get_exog_dtypes(exog=exog)\n",
    "    \n",
    "    X_levels = []\n",
    "    len_series = []\n",
    "    X_train_col_names = [f\"lag_{lag}\" for lag in lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        y_values = y.to_numpy()\n",
    "\n",
    "        if np.isnan(y_values).all():\n",
    "            raise ValueError(f\"All values of series '{serie}' are NaN.\")\n",
    "        \n",
    "        first_no_nan_idx = np.argmax(~np.isnan(y_values))\n",
    "        y_values = y_values[first_no_nan_idx:]\n",
    "\n",
    "        if np.isnan(y_values).any():\n",
    "            raise ValueError(\n",
    "                (f\"'{serie}' Time series has missing values in between or \"\n",
    "                    f\"at the end of the time series. When working with series \"\n",
    "                    f\"of different lengths, all series must be complete after \"\n",
    "                    f\"the first non-null value.\")\n",
    "            )\n",
    "        \n",
    "        y = transform_series(\n",
    "                series            = y.iloc[first_no_nan_idx:],\n",
    "                transformer       = transformer_series_[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "        y_values = y.to_numpy()\n",
    "        X_train_values, y_train_values = _create_lags(y=y_values, series_name=serie)\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_train_values), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_values), axis=0)\n",
    "\n",
    "        X_level = [serie]*len(X_train_values)\n",
    "        X_levels.extend(X_level)\n",
    "        len_series.append(len(y_train_values))\n",
    "    \n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                  data    = X_train,\n",
    "                  columns = X_train_col_names\n",
    "              )\n",
    "\n",
    "    if exog is not None:\n",
    "        # The first `self.max_lag` positions have to be removed from exog\n",
    "        # since they are not in X_train. Then Exog is cloned as many times \n",
    "        # as there are series, taking into account the length of the series.\n",
    "        if isinstance(exog, dict):\n",
    "            exog_to_train = []\n",
    "            for i, key in enumerate(exog):\n",
    "                exog_to_train.append(exog[key].iloc[-len_series[i]:, ])\n",
    "        else:\n",
    "            exog_to_train = [exog.iloc[-length:, ] for length in len_series]\n",
    "\n",
    "        exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)\n",
    "    else:\n",
    "        exog_to_train = None\n",
    "    \n",
    "    X_train = pd.concat([X_train, exog_to_train, X_levels], axis=1)\n",
    "    X_train_col_names = X_train.columns.to_list()\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                  data = y_train,\n",
    "                  name = 'y'\n",
    "              )\n",
    "\n",
    "    _, y_index = preprocess_y(y=series, return_values=False)\n",
    "\n",
    "    y_index_numpy = y_index.to_numpy()\n",
    "    y_train_index = pd.Index(\n",
    "                        np.concatenate(\n",
    "                            [y_index_numpy[-length:, ] \n",
    "                             for length in len_series]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    return X_train, y_train, y_index, y_train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['l1', 'l2'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaesc2\\AppData\\Local\\Temp\\ipykernel_24896\\1419059247.py:4: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "len_series = [50, 50]\n",
    "\n",
    "exog_to_train = []\n",
    "for i, key in enumerate(exog):\n",
    "\n",
    "    if isinstance(exog[key], pd.Series):\n",
    "        exog_ = exog[key].copy().to_frame()\n",
    "    else:\n",
    "        exog_ = exog[key]\n",
    "    \n",
    "    exog_to_train.append(exog[key].iloc[-len_series[i]:, ])\n",
    "\n",
    "\n",
    "exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(50),\n",
    "              'exog2': np.arange(50, 100),\n",
    "          })\n",
    "\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series(np.arange(100, 150), name='exog1')\n",
    "\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': exog_l1,\n",
    "    'l2': exog_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )\n",
    "\n",
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = StandardScaler()\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      exog1     exog2\n",
      "0 -1.697749 -1.697749\n",
      "1 -1.628453 -1.628453\n",
      "      exog1\n",
      "0 -1.697749\n",
      "1 -1.628453\n"
     ]
    }
   ],
   "source": [
    "for k, v in exog.items():\n",
    "    _ = check_exog_create_train_X_y(series=series, exog=v, key=k)\n",
    "    print(_.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>exog1</th>\n",
       "      <th>exog2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.696469</td>\n",
       "      <td>-1.489862</td>\n",
       "      <td>-1.489862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>-1.420566</td>\n",
       "      <td>-1.420566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>-1.351270</td>\n",
       "      <td>-1.351270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>-1.281974</td>\n",
       "      <td>-1.281974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>-1.212678</td>\n",
       "      <td>-1.212678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>0.355915</td>\n",
       "      <td>1.420566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>1.489862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>1.559158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>1.628453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.240856</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>1.697749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag_1     lag_2     lag_3     exog1     exog2   l1   l2\n",
       "0   0.226851  0.286139  0.696469 -1.489862 -1.489862  1.0  0.0\n",
       "1   0.551315  0.226851  0.286139 -1.420566 -1.420566  1.0  0.0\n",
       "2   0.719469  0.551315  0.226851 -1.351270 -1.351270  1.0  0.0\n",
       "3   0.423106  0.719469  0.551315 -1.281974 -1.281974  1.0  0.0\n",
       "4   0.980764  0.423106  0.719469 -1.212678 -1.212678  1.0  0.0\n",
       "..       ...       ...       ...       ...       ...  ...  ...\n",
       "89  0.593177  0.762548  0.355915  1.420566       NaN  0.0  1.0\n",
       "90  0.691702  0.593177  0.762548  1.489862       NaN  0.0  1.0\n",
       "91  0.151127  0.691702  0.593177  1.559158       NaN  0.0  1.0\n",
       "92  0.398876  0.151127  0.691702  1.628453       NaN  0.0  1.0\n",
       "93  0.240856  0.398876  0.151127  1.697749       NaN  0.0  1.0\n",
       "\n",
       "[94 rows x 7 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_train_X_y(series=series, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = pd.Series(np.arange(100, 150), name='exog1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>exog1</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.696469</td>\n",
       "      <td>103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.286139</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.551315</td>\n",
       "      <td>106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.423106</td>\n",
       "      <td>0.719469</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>0.355915</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>0.762548</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.593177</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.240856</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag_1     lag_2     lag_3  exog1   l1   l2\n",
       "0   0.226851  0.286139  0.696469    103  1.0  0.0\n",
       "1   0.551315  0.226851  0.286139    104  1.0  0.0\n",
       "2   0.719469  0.551315  0.226851    105  1.0  0.0\n",
       "3   0.423106  0.719469  0.551315    106  1.0  0.0\n",
       "4   0.980764  0.423106  0.719469    107  1.0  0.0\n",
       "..       ...       ...       ...    ...  ...  ...\n",
       "89  0.593177  0.762548  0.355915    145  0.0  1.0\n",
       "90  0.691702  0.593177  0.762548    146  0.0  1.0\n",
       "91  0.151127  0.691702  0.593177    147  0.0  1.0\n",
       "92  0.398876  0.151127  0.691702    148  0.0  1.0\n",
       "93  0.240856  0.398876  0.151127    149  0.0  1.0\n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.create_train_X_y(series=series, exog=exog)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Parallelitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None None\n"
     ]
    }
   ],
   "source": [
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    y: np.ndarray, \n",
    "    series_name: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"    \n",
    "    \"\"\"\n",
    "        \n",
    "    n_splits = len(y) - max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            (f\"The maximum lag ({max_lag}) must be less than the length \"\n",
    "                f\"of the series '{series_name}', ({len(y)}).\")\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        X_data[:, i] = y[max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[max_lag:]\n",
    "        \n",
    "    return X_data, y_data\n",
    "\n",
    "\n",
    "def create_train_X_y(\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:\n",
    "    \"\"\"    \n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f\"`series` must be a pandas DataFrame. Got {type(series)}.\")\n",
    "\n",
    "    series_col_names = list(series.columns)\n",
    "\n",
    "    if transformer_series is None:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "    elif not isinstance(transformer_series, dict):\n",
    "        transformer_series_ = {serie: clone(transformer_series) \n",
    "                               for serie in series_col_names}\n",
    "    else:\n",
    "        transformer_series_ = {serie: None for serie in series_col_names}\n",
    "        # Only elements already present in transformer_series_ are updated\n",
    "        transformer_series_.update(\n",
    "            (k, v) for k, v in deepcopy(transformer_series).items() \n",
    "            if k in transformer_series_\n",
    "        )\n",
    "        series_not_in_transformer_series = set(series.columns) - set(transformer_series.keys())\n",
    "        if series_not_in_transformer_series:\n",
    "            warnings.warn(\n",
    "                (f\"{series_not_in_transformer_series} not present in `transformer_series`.\"\n",
    "                    f\" No transformation is applied to these series.\"),\n",
    "                    IgnoredArgumentWarning\n",
    "            )\n",
    "\n",
    "    if exog is not None:\n",
    "        if not isinstance(exog, dict):\n",
    "            exog_ = {serie: exog for serie in series_col_names}\n",
    "        else:\n",
    "            exog_ = {serie: None for serie in series_col_names}\n",
    "            # Only elements already present in exog_ are updated\n",
    "            exog_.update(\n",
    "                (k, v) for k, v in exog.items() \n",
    "                if k in exog_\n",
    "            )\n",
    "            series_not_in_exog = set(series.columns) - set(exog.keys())\n",
    "            if series_not_in_exog:\n",
    "                # TODO: review warning\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_exog} not present in `exog`.\"\n",
    "                     f\" No transformation is applied to these series.\"),\n",
    "                     IgnoredArgumentWarning\n",
    "                )\n",
    "\n",
    "        for k, v in exog_.items():\n",
    "            if len(v) != len(series):\n",
    "                # TODO: when series of different length, exog with nans at the begining\n",
    "                raise ValueError(\n",
    "                    (f\"`exog` must have same number of samples as `series`.\\n\"\n",
    "                     f\"    length `exog`: {len(v)} for series {k}\\n\"\n",
    "                     f\"    length `series`: {len(series)}\")\n",
    "                )\n",
    "            check_exog(exog=v, allow_nan=True)\n",
    "\n",
    "            # TODO: review this ValueError\n",
    "            _, _ = preprocess_exog(exog=v, return_values=False)\n",
    "            if not (v.index[:len(series)] == series.index).all():\n",
    "                raise ValueError(\n",
    "                    (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                     \"to ensure the correct alignment of values.\")\n",
    "                )\n",
    "    \n",
    "    X_levels = []\n",
    "    exog_levels = []\n",
    "    len_series = []\n",
    "    X_train_col_names = [f\"lag_{lag}\" for lag in lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        y_values = y.to_numpy()\n",
    "\n",
    "        if np.isnan(y_values).all():\n",
    "            raise ValueError(f\"All values of series '{serie}' are NaN.\")\n",
    "        \n",
    "        first_no_nan_idx = np.argmax(~np.isnan(y_values))\n",
    "        y_values = y_values[first_no_nan_idx:]\n",
    "\n",
    "        if np.isnan(y_values).any():\n",
    "            raise ValueError(\n",
    "                (f\"'{serie}' Time series has missing values in between or \"\n",
    "                    f\"at the end of the time series. When working with series \"\n",
    "                    f\"of different lengths, all series must be complete after \"\n",
    "                    f\"the first non-null value.\")\n",
    "            )\n",
    "        \n",
    "        y = transform_series(\n",
    "                series            = y.iloc[first_no_nan_idx:],\n",
    "                transformer       = transformer_series_[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "\n",
    "        y_values = y.to_numpy()\n",
    "        X_train_values, y_train_values = _create_lags(y=y_values, series_name=serie)\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_train_values), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_train_values), axis=0)\n",
    "\n",
    "        X_level = [serie]*len(X_train_values)\n",
    "        X_levels.extend(X_level)\n",
    "        len_series.append(len(y_train_values))\n",
    "\n",
    "        if exog is not None:\n",
    "            exog_level = exog_[serie].iloc[-len(y_train_values):, ]\n",
    "            if isinstance(exog_level, pd.Series):\n",
    "                # Needed for pandas concat\n",
    "                exog_level = exog_level.to_frame()\n",
    "            exog_levels.append(exog_level)\n",
    "\n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                  data    = X_train,\n",
    "                  columns = X_train_col_names\n",
    "              )\n",
    "\n",
    "    if exog is not None:\n",
    "        exog_train = pd.concat(exog_levels).reset_index(drop=True)\n",
    "        exog_train = transform_dataframe(\n",
    "                         df                = exog_train,\n",
    "                         transformer       = transformer_exog,\n",
    "                         fit               = True,\n",
    "                         inverse_transform = False\n",
    "                     )\n",
    "        \n",
    "        # check_exog_dtypes llama a check_exog\n",
    "        # check_exog(exog=exog_train, allow_nan=False)\n",
    "        check_exog_dtypes(exog_train)\n",
    "        exog_dtypes = get_exog_dtypes(exog=exog_train)\n",
    "    else:\n",
    "        exog_train = None\n",
    "    \n",
    "    X_train = pd.concat([X_train, exog_train, X_levels], axis=1)\n",
    "    X_train_col_names = X_train.columns.to_list()\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                    data = y_train,\n",
    "                    name = 'y'\n",
    "                )\n",
    "\n",
    "    _, y_index = preprocess_y(y=series, return_values=False)\n",
    "\n",
    "    y_index_numpy = y_index.to_numpy()\n",
    "    y_train_index = pd.Index(\n",
    "                        np.concatenate(\n",
    "                            [y_index_numpy[-length:, ] for length in len_series]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    return X_train, y_train, y_index, y_train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_2 = series.head(10).copy()\n",
    "series_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exog for series l1\n",
    "exog_l1 = pd.DataFrame({\n",
    "              'exog1': np.arange(10),\n",
    "              'exog2': np.arange(50, 60),\n",
    "          })\n",
    "\n",
    "# Exog for series l2\n",
    "exog_l2 = pd.Series(np.arange(100, 110), name='exog1')\n",
    "\n",
    "# Dictionary with exog for each series\n",
    "exog = {\n",
    "    'l1': exog_l1,\n",
    "    'l2': exog_l2\n",
    "}\n",
    "\n",
    "exog = exog_l1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1 2 3] None None\n"
     ]
    }
   ],
   "source": [
    "# Create forecaster\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = LinearRegression(),\n",
    "                 lags = 3,\n",
    "                 transformer_series = None\n",
    "             )\n",
    "\n",
    "# Forecaster attributes needed\n",
    "max_lag = forecaster.max_lag\n",
    "lags = forecaster.lags\n",
    "transformer_series = forecaster.transformer_series\n",
    "transformer_exog = forecaster.transformer_exog\n",
    "# transformer_exog = StandardScaler()\n",
    "\n",
    "print(max_lag, lags, transformer_series, transformer_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_3 = pd.DataFrame({\n",
    "    'l1': np.arange(10000),\n",
    "    'l2': np.arange(10000)\n",
    "})\n",
    "\n",
    "exog_2 = pd.DataFrame({\n",
    "    'exog1': np.arange(10000),\n",
    "    'exog2': np.arange(10000)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.96 ms ± 81.9 µs per loop (mean ± std. dev. of 4 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000 -r 4\n",
    "\n",
    "create_train_X_y(series=series_3, exog=exog_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.85 ms ± 70.3 µs per loop (mean ± std. dev. of 4 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000 -r 4\n",
    "\n",
    "forecaster.create_train_X_y(series=series_3, exog=exog_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
