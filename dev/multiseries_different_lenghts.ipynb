{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                        ForecasterAutoregMultiSeries                          #\n",
    "#                                                                              #\n",
    "# This work by Joaquin Amat Rodrigo and Javier Escobar Ortiz is licensed       #\n",
    "# under the BSD 3-Clause License.                                              #\n",
    "################################################################################\n",
    "# coding=utf-8\n",
    "\n",
    "from typing import Union, Dict, List, Tuple, Any, Optional, Callable\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "from sklearn.base import clone\n",
    "from copy import copy, deepcopy\n",
    "import inspect\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterBase import ForecasterBase\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import initialize_lags\n",
    "from skforecast.utils import initialize_weights\n",
    "from skforecast.utils import check_select_fit_kwargs\n",
    "from skforecast.utils import check_y\n",
    "from skforecast.utils import check_exog\n",
    "from skforecast.utils import get_exog_dtypes\n",
    "from skforecast.utils import check_exog_dtypes\n",
    "from skforecast.utils import check_interval\n",
    "from skforecast.utils import check_predict_input\n",
    "from skforecast.utils import preprocess_y\n",
    "from skforecast.utils import preprocess_last_window\n",
    "from skforecast.utils import preprocess_exog\n",
    "from skforecast.utils import expand_index\n",
    "from skforecast.utils import transform_series\n",
    "from skforecast.utils import transform_dataframe\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(name)-10s %(levelname)-5s %(message)s', \n",
    "    level  = logging.INFO,\n",
    ")\n",
    "\n",
    "class ForecasterAutoregMultiSeries(ForecasterBase):\n",
    "    \"\"\"    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        regressor: object,\n",
    "        lags: Union[int, np.ndarray, list],\n",
    "        transformer_series: Optional[Union[object, dict]]=None,\n",
    "        transformer_exog: Optional[object]=None,\n",
    "        weight_func: Optional[Union[Callable, dict]]=None,\n",
    "        series_weights: Optional[dict]=None,\n",
    "        fit_kwargs: Optional[dict]=None,\n",
    "        forecaster_id: Optional[Union[str, int]]=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.regressor               = regressor\n",
    "        self.transformer_series      = transformer_series\n",
    "        self.transformer_series_     = None\n",
    "        self.transformer_exog        = transformer_exog\n",
    "        self.weight_func             = weight_func\n",
    "        self.weight_func_            = None\n",
    "        self.source_code_weight_func = None\n",
    "        self.series_weights          = series_weights\n",
    "        self.series_weights_         = None\n",
    "        self.index_type              = None\n",
    "        self.index_freq              = None\n",
    "        self.index_values            = None\n",
    "        self.training_range          = None\n",
    "        self.last_window             = None\n",
    "        self.included_exog           = False\n",
    "        self.exog_type               = None\n",
    "        self.exog_dtypes             = None\n",
    "        self.exog_col_names          = None\n",
    "        self.series_col_names        = None\n",
    "        self.X_train_col_names       = None\n",
    "        self.in_sample_residuals     = None\n",
    "        self.out_sample_residuals    = None\n",
    "        self.fitted                  = False\n",
    "        self.creation_date           = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.fit_date                = None\n",
    "        self.skforcast_version       = skforecast.__version__\n",
    "        self.python_version          = sys.version.split(\" \")[0]\n",
    "        self.forecaster_id           = forecaster_id\n",
    "        \n",
    "        self.lags = initialize_lags(type(self).__name__, lags)\n",
    "        self.max_lag = max(self.lags)\n",
    "        self.window_size = self.max_lag\n",
    "\n",
    "        self.weight_func, self.source_code_weight_func, self.series_weights = initialize_weights(\n",
    "            forecaster_name = type(self).__name__, \n",
    "            regressor       = regressor, \n",
    "            weight_func     = weight_func, \n",
    "            series_weights  = series_weights\n",
    "        )\n",
    "\n",
    "        self.fit_kwargs = check_select_fit_kwargs(\n",
    "                              regressor  = regressor,\n",
    "                              fit_kwargs = fit_kwargs\n",
    "                          )\n",
    "\n",
    "\n",
    "    def __repr__(\n",
    "        self\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.regressor, sklearn.pipeline.Pipeline):\n",
    "            name_pipe_steps = tuple(name + \"__\" for name in self.regressor.named_steps.keys())\n",
    "            params = {key : value for key, value in self.regressor.get_params().items() \\\n",
    "                      if key.startswith(name_pipe_steps)}\n",
    "        else:\n",
    "            params = self.regressor.get_params()\n",
    "\n",
    "        info = (\n",
    "            f\"{'=' * len(type(self).__name__)} \\n\"\n",
    "            f\"{type(self).__name__} \\n\"\n",
    "            f\"{'=' * len(type(self).__name__)} \\n\"\n",
    "            f\"Regressor: {self.regressor} \\n\"\n",
    "            f\"Lags: {self.lags} \\n\"\n",
    "            f\"Transformer for series: {self.transformer_series} \\n\"\n",
    "            f\"Transformer for exog: {self.transformer_exog} \\n\"\n",
    "            f\"Window size: {self.window_size} \\n\"\n",
    "            f\"Series levels (names): {self.series_col_names} \\n\"\n",
    "            f\"Series weights: {self.series_weights} \\n\"\n",
    "            f\"Weight function included: {True if self.weight_func is not None else False} \\n\"\n",
    "            f\"Exogenous included: {self.included_exog} \\n\"\n",
    "            f\"Type of exogenous variable: {self.exog_type} \\n\"\n",
    "            f\"Exogenous variables names: {self.exog_col_names} \\n\"\n",
    "            f\"Training range: {self.training_range.to_list() if self.fitted else None} \\n\"\n",
    "            f\"Training index type: {str(self.index_type).split('.')[-1][:-2] if self.fitted else None} \\n\"\n",
    "            f\"Training index frequency: {self.index_freq if self.fitted else None} \\n\"\n",
    "            f\"Regressor parameters: {params} \\n\"\n",
    "            f\"fit_kwargs: {self.fit_kwargs} \\n\"\n",
    "            f\"Creation date: {self.creation_date} \\n\"\n",
    "            f\"Last fit date: {self.fit_date} \\n\"\n",
    "            f\"Skforecast version: {self.skforcast_version} \\n\"\n",
    "            f\"Python version: {self.python_version} \\n\"\n",
    "            f\"Forecaster id: {self.forecaster_id} \\n\"\n",
    "        )\n",
    "\n",
    "        return info\n",
    "\n",
    "    \n",
    "    def _create_lags(\n",
    "        self, \n",
    "        y: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "          \n",
    "        n_splits = len(y) - self.max_lag\n",
    "        if n_splits <= 0:\n",
    "            raise ValueError(\n",
    "                (f\"The maximum lag ({self.max_lag}) must be less than the length \"\n",
    "                 f\"of the series ({len(y)}).\")\n",
    "            )\n",
    "        \n",
    "        X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "        for i, lag in enumerate(self.lags):\n",
    "            X_data[:, i] = y[self.max_lag - lag: -lag]\n",
    "\n",
    "        y_data = y[self.max_lag:]\n",
    "            \n",
    "        return X_data, y_data\n",
    "\n",
    "\n",
    "    def create_train_X_y(\n",
    "        self,\n",
    "        series: pd.DataFrame,\n",
    "        exog: Optional[Union[pd.Series, pd.DataFrame]]=None\n",
    "    ) -> Tuple[pd.DataFrame, pd.Series, pd.Index, pd.Index]:\n",
    "        \"\"\"        \n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(series, pd.DataFrame):\n",
    "            raise TypeError(f\"`series` must be a pandas DataFrame. Got {type(series)}.\")\n",
    "\n",
    "        series_col_names = list(series.columns)\n",
    "\n",
    "        if self.transformer_series is None:\n",
    "            self.transformer_series_ = {serie: None for serie in series_col_names}\n",
    "        elif not isinstance(self.transformer_series, dict):\n",
    "            self.transformer_series_ = {serie: clone(self.transformer_series) \n",
    "                                        for serie in series_col_names}\n",
    "        else:\n",
    "            self.transformer_series_ = {serie: None for serie in series_col_names}\n",
    "            # Only elements already present in transformer_series_ are updated\n",
    "            self.transformer_series_.update(\n",
    "                (k, v) for k, v in deepcopy(self.transformer_series).items() if k in self.transformer_series_\n",
    "            )\n",
    "            series_not_in_transformer_series = set(series.columns) - set(self.transformer_series.keys())\n",
    "            if series_not_in_transformer_series:\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_transformer_series} not present in `transformer_series`.\"\n",
    "                     f\" No transformation is applied to these series.\"),\n",
    "                     IgnoredArgumentWarning\n",
    "                )\n",
    "        \n",
    "        if exog is not None:\n",
    "            if len(exog) != len(series):\n",
    "                raise ValueError(\n",
    "                    (f\"`exog` must have same number of samples as `series`. \"\n",
    "                     f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "                )\n",
    "            check_exog(exog=exog, allow_nan=True)\n",
    "            if isinstance(exog, pd.Series):\n",
    "                exog = transform_series(\n",
    "                           series            = exog,\n",
    "                           transformer       = self.transformer_exog,\n",
    "                           fit               = True,\n",
    "                           inverse_transform = False\n",
    "                       )\n",
    "            else:\n",
    "                exog = transform_dataframe(\n",
    "                           df                = exog,\n",
    "                           transformer       = self.transformer_exog,\n",
    "                           fit               = True,\n",
    "                           inverse_transform = False\n",
    "                       )\n",
    "            \n",
    "            check_exog(exog=exog, allow_nan=False)\n",
    "            check_exog_dtypes(exog)\n",
    "            self.exog_dtypes = get_exog_dtypes(exog=exog)\n",
    "\n",
    "            _, exog_index = preprocess_exog(exog=exog, return_values=False)\n",
    "            if not (exog_index[:len(series.index)] == series.index).all():\n",
    "                raise ValueError(\n",
    "                    (\"Different index for `series` and `exog`. They must be equal \"\n",
    "                     \"to ensure the correct alignment of values.\")\n",
    "                )\n",
    "        \n",
    "        X_levels = []\n",
    "        len_series = []\n",
    "        X_train_col_names = [f\"lag_{lag}\" for lag in self.lags]\n",
    "\n",
    "        for i, serie in enumerate(series.columns):\n",
    "\n",
    "            y = series[serie]\n",
    "            # check_y(y=y)\n",
    "\n",
    "            # New ===================\n",
    "\n",
    "            y_values = y.to_numpy()\n",
    "\n",
    "            if np.isnan(y_values).all():\n",
    "                raise ValueError(f\"All values of series '{serie}' are missing.\")\n",
    "            \n",
    "            first_value_idx = np.where(~np.isnan(y_values))[0][0]\n",
    "            last_value_idx = np.where(~np.isnan(y_values))[0][-1]\n",
    "            y_values = y_values[first_value_idx:last_value_idx]\n",
    "\n",
    "            if len(series) != last_value_idx+1:\n",
    "                raise ValueError(f\"{serie} last value can not be NaN.\")\n",
    "\n",
    "            if np.isnan(y_values[first_value_idx:last_value_idx]).any():\n",
    "                raise ValueError(f\"{serie} has missing values between observations.\")\n",
    "            \n",
    "            # New ===================\n",
    "\n",
    "            y = transform_series(\n",
    "                    series            = y.iloc[first_value_idx:last_value_idx+1],\n",
    "                    transformer       = self.transformer_series_[serie],\n",
    "                    fit               = True,\n",
    "                    inverse_transform = False\n",
    "                )\n",
    "\n",
    "            # y_values, y_index = preprocess_y(y=y)\n",
    "            y_values = y.to_numpy()\n",
    "            X_train_values, y_train_values = self._create_lags(y=y_values)\n",
    "\n",
    "            if i == 0:\n",
    "                X_train = X_train_values\n",
    "                y_train = y_train_values\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X_train_values), axis=0)\n",
    "                y_train = np.concatenate((y_train, y_train_values), axis=0)\n",
    "\n",
    "            X_level = [serie]*len(X_train_values)\n",
    "            X_levels.extend(X_level)\n",
    "            len_series.append(len(y_train_values))\n",
    "        \n",
    "        X_levels = pd.Series(X_levels)\n",
    "        X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "\n",
    "        X_train = pd.DataFrame(\n",
    "                      data    = X_train,\n",
    "                      columns = X_train_col_names\n",
    "                  )\n",
    "\n",
    "        if exog is not None:\n",
    "            # The first `self.max_lag` positions have to be removed from exog\n",
    "            # since they are not in X_train. Then exog is cloned as many times\n",
    "            # as series.\n",
    "            exog_to_train = [exog.iloc[-length:, ] for length in len_series]\n",
    "            exog_to_train = pd.concat(exog_to_train).reset_index(drop=True)\n",
    "        else:\n",
    "            exog_to_train = None\n",
    "        \n",
    "        X_train = pd.concat([X_train, exog_to_train, X_levels], axis=1)\n",
    "        self.X_train_col_names = X_train.columns.to_list()\n",
    "\n",
    "        y_train = pd.Series(\n",
    "                      data = y_train,\n",
    "                      name = 'y'\n",
    "                  )\n",
    "\n",
    "        _, y_index = preprocess_y(y=series, return_values=False)\n",
    "\n",
    "        y_train_index = pd.Index(\n",
    "                            np.tile(\n",
    "                                y_index.to_numpy()[self.max_lag: ],\n",
    "                                reps = len(series_col_names)\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "        return X_train, y_train, y_index, y_train_index\n",
    "\n",
    "    \n",
    "    def create_sample_weights(\n",
    "        self,\n",
    "        series: pd.DataFrame,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train_index: pd.Index,\n",
    "    )-> np.ndarray:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        weights = None\n",
    "        weights_samples = None\n",
    "        weights_series = None\n",
    "\n",
    "        if self.series_weights is not None:\n",
    "            # Series not present in series_weights have a weight of 1 in all their samples.\n",
    "            # Keys in series_weights not present in series are ignored.\n",
    "            series_not_in_series_weights = set(series.columns) - set(self.series_weights.keys())\n",
    "            if series_not_in_series_weights:\n",
    "                warnings.warn(\n",
    "                    (f\"{series_not_in_series_weights} not present in `series_weights`. \"\n",
    "                     f\"A weight of 1 is given to all their samples.\"),\n",
    "                     IgnoredArgumentWarning\n",
    "                )\n",
    "            self.series_weights_ = {col: 1. for col in series.columns}\n",
    "            self.series_weights_.update((k, v) for k, v in self.series_weights.items() if k in self.series_weights_)\n",
    "            weights_series = [np.repeat(self.series_weights_[serie], sum(X_train[serie])) \n",
    "                              for serie in series.columns]\n",
    "            weights_series = np.concatenate(weights_series)\n",
    "\n",
    "        if self.weight_func is not None:\n",
    "            if isinstance(self.weight_func, Callable):\n",
    "                self.weight_func_ = {col: copy(self.weight_func) \n",
    "                                     for col in series.columns}\n",
    "            else:\n",
    "                # Series not present in weight_func have a weight of 1 in all their samples\n",
    "                series_not_in_weight_func = set(series.columns) - set(self.weight_func.keys())\n",
    "                if series_not_in_weight_func:\n",
    "                    warnings.warn(\n",
    "                        (f\"{series_not_in_weight_func} not present in `weight_func`. \"\n",
    "                         f\"A weight of 1 is given to all their samples.\"),\n",
    "                         IgnoredArgumentWarning\n",
    "                    )\n",
    "                self.weight_func_ = {col: lambda x: np.ones_like(x, dtype=float) \n",
    "                                     for col in series.columns}\n",
    "                self.weight_func_.update((k, v) for k, v in self.weight_func.items() if k in self.weight_func_)\n",
    "                \n",
    "            weights_samples = []\n",
    "            for key in self.weight_func_.keys():\n",
    "                idx = y_train_index[X_train[X_train[key] == 1.0].index]\n",
    "                weights_samples.append(self.weight_func_[key](idx))\n",
    "            weights_samples = np.concatenate(weights_samples)\n",
    "\n",
    "        if weights_series is not None:\n",
    "            weights = weights_series\n",
    "            if weights_samples is not None:\n",
    "                weights = weights * weights_samples\n",
    "        else:\n",
    "            if weights_samples is not None:\n",
    "                weights = weights_samples\n",
    "\n",
    "        if weights is not None:\n",
    "            if np.isnan(weights).any():\n",
    "                raise ValueError(\n",
    "                    \"The resulting `weights` cannot have NaN values.\"\n",
    "                )\n",
    "            if np.any(weights < 0):\n",
    "                raise ValueError(\n",
    "                    \"The resulting `weights` cannot have negative values.\"\n",
    "                )\n",
    "            if np.sum(weights) == 0:\n",
    "                raise ValueError(\n",
    "                    (\"The resulting `weights` cannot be normalized because \"\n",
    "                     \"the sum of the weights is zero.\")\n",
    "                )\n",
    "\n",
    "        return weights\n",
    "\n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        series: pd.DataFrame,\n",
    "        exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "        store_in_sample_residuals: bool=True\n",
    "    ) -> None:\n",
    "        \"\"\"        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Reset values in case the forecaster has already been fitted.\n",
    "        self.index_type          = None\n",
    "        self.index_freq          = None\n",
    "        self.index_values        = None\n",
    "        self.last_window         = None\n",
    "        self.included_exog       = False\n",
    "        self.exog_type           = None\n",
    "        self.exog_dtypes         = None\n",
    "        self.exog_col_names      = None\n",
    "        self.series_col_names    = None\n",
    "        self.X_train_col_names   = None\n",
    "        self.in_sample_residuals = None\n",
    "        self.fitted              = False\n",
    "        self.training_range      = None\n",
    "        \n",
    "        self.series_col_names = list(series.columns)        \n",
    "\n",
    "        if exog is not None:\n",
    "            self.included_exog = True\n",
    "            self.exog_type = type(exog)\n",
    "            self.exog_col_names = \\\n",
    "                 exog.columns.to_list() if isinstance(exog, pd.DataFrame) else [exog.name]\n",
    "\n",
    "            if len(set(self.exog_col_names) - set(self.series_col_names)) != len(self.exog_col_names):\n",
    "                raise ValueError(\n",
    "                    (f\"`exog` cannot contain a column named the same as one of the \"\n",
    "                     f\"series (column names of series).\\n\"\n",
    "                     f\"    `series` columns : {self.series_col_names}.\\n\"\n",
    "                     f\"    `exog`   columns : {self.exog_col_names}.\")\n",
    "                )\n",
    "\n",
    "        X_train, y_train, y_index, y_train_index = self.create_train_X_y(series=series, exog=exog)\n",
    "        sample_weight = self.create_sample_weights(\n",
    "                            series        = series,\n",
    "                            X_train       = X_train,\n",
    "                            y_train_index = y_train_index,\n",
    "                        )\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            self.regressor.fit(\n",
    "                X             = X_train,\n",
    "                y             = y_train,\n",
    "                sample_weight = sample_weight,\n",
    "                **self.fit_kwargs\n",
    "            )\n",
    "        else:\n",
    "            self.regressor.fit(X=X_train, y=y_train, **self.fit_kwargs)\n",
    "            \n",
    "        self.fitted = True\n",
    "        self.fit_date = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.training_range = y_index[[0, -1]]\n",
    "        self.index_type = type(y_index)\n",
    "        if isinstance(y_index, pd.DatetimeIndex):\n",
    "            self.index_freq = y_index.freqstr\n",
    "        else: \n",
    "            self.index_freq = y_index.step\n",
    "        self.index_values = y_index\n",
    "\n",
    "        in_sample_residuals = {}\n",
    "        \n",
    "        # This is done to save time during fit in functions such as backtesting()\n",
    "        if store_in_sample_residuals:\n",
    "\n",
    "            residuals = y_train - self.regressor.predict(X_train)\n",
    "\n",
    "            for serie in series.columns:\n",
    "                in_sample_residuals[serie] = residuals.loc[X_train[serie] == 1.].to_numpy()\n",
    "                if len(in_sample_residuals[serie]) > 1000:\n",
    "                    # Only up to 1000 residuals are stored\n",
    "                    rng = np.random.default_rng(seed=123)\n",
    "                    in_sample_residuals[serie] = rng.choice(\n",
    "                                                     a       = in_sample_residuals[serie], \n",
    "                                                     size    = 1000, \n",
    "                                                     replace = False\n",
    "                                                 )\n",
    "        else:\n",
    "            for serie in series.columns:\n",
    "                in_sample_residuals[serie] = None\n",
    "\n",
    "        self.in_sample_residuals = in_sample_residuals\n",
    "\n",
    "        # The last time window of training data is stored so that lags needed as\n",
    "        # predictors in the first iteration of `predict()` can be calculated.\n",
    "        self.last_window = series.iloc[-self.max_lag:, ].copy()\n",
    "\n",
    "\n",
    "    def _recursive_predict(\n",
    "        self,\n",
    "        steps: int,\n",
    "        level: str,\n",
    "        last_window: np.ndarray,\n",
    "        exog: Optional[np.ndarray]=None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"        \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = np.full(shape=steps, fill_value=np.nan)\n",
    "\n",
    "        for i in range(steps):\n",
    "            X = last_window[-self.lags].reshape(1, -1)\n",
    "            if exog is not None:\n",
    "                X = np.column_stack((X, exog[i, ].reshape(1, -1)))\n",
    "            \n",
    "            levels_dummies = np.zeros(shape=(1, len(self.series_col_names)), dtype=float)\n",
    "            levels_dummies[0][self.series_col_names.index(level)] = 1.\n",
    "\n",
    "            X = np.column_stack((X, levels_dummies.reshape(1, -1)))\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                # Suppress scikit-learn warning: \"X does not have valid feature names,\n",
    "                # but NoOpTransformer was fitted with feature names\".\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                prediction = self.regressor.predict(X)\n",
    "                predictions[i] = prediction.ravel()[0]\n",
    "\n",
    "            # Update `last_window` values. The first position is discarded and \n",
    "            # the new prediction is added at the end.\n",
    "            last_window = np.append(last_window[1:], prediction)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "            \n",
    "    def predict(\n",
    "        self,\n",
    "        steps: int,\n",
    "        levels: Optional[Union[str, list]]=None,\n",
    "        last_window: Optional[pd.DataFrame]=None,\n",
    "        exog: Optional[Union[pd.Series, pd.DataFrame]]=None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if levels is None:\n",
    "            levels = self.series_col_names\n",
    "        elif isinstance(levels, str):\n",
    "            levels = [levels]\n",
    "\n",
    "        if last_window is None:\n",
    "            last_window = deepcopy(self.last_window)\n",
    "        \n",
    "        check_predict_input(\n",
    "            forecaster_name  = type(self).__name__,\n",
    "            steps            = steps,\n",
    "            fitted           = self.fitted,\n",
    "            included_exog    = self.included_exog,\n",
    "            index_type       = self.index_type,\n",
    "            index_freq       = self.index_freq,\n",
    "            window_size      = self.window_size,\n",
    "            last_window      = last_window,\n",
    "            last_window_exog = None,\n",
    "            exog             = exog,\n",
    "            exog_type        = self.exog_type,\n",
    "            exog_col_names   = self.exog_col_names,\n",
    "            interval         = None,\n",
    "            alpha            = None,\n",
    "            max_steps        = None,\n",
    "            levels           = levels,\n",
    "            series_col_names = self.series_col_names\n",
    "        )\n",
    "        \n",
    "        if exog is not None:\n",
    "            if isinstance(exog, pd.DataFrame):\n",
    "                exog = transform_dataframe(\n",
    "                           df                = exog,\n",
    "                           transformer       = self.transformer_exog,\n",
    "                           fit               = False,\n",
    "                           inverse_transform = False\n",
    "                       )\n",
    "            else:\n",
    "                exog = transform_series(\n",
    "                           series            = exog,\n",
    "                           transformer       = self.transformer_exog,\n",
    "                           fit               = False,\n",
    "                           inverse_transform = False\n",
    "                       )\n",
    "            check_exog_dtypes(exog=exog)\n",
    "            exog_values = exog.to_numpy()[:steps]\n",
    "        else:\n",
    "            exog_values = None\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for level in levels:\n",
    "\n",
    "            last_window_level = transform_series(\n",
    "                                    series            = last_window[level],\n",
    "                                    transformer       = self.transformer_series_[level],\n",
    "                                    fit               = False,\n",
    "                                    inverse_transform = False\n",
    "                                )\n",
    "            last_window_values, last_window_index = preprocess_last_window(\n",
    "                                                        last_window = last_window_level\n",
    "                                                    )\n",
    "                \n",
    "            preds_level = self._recursive_predict(\n",
    "                              steps       = steps,\n",
    "                              level       = level,\n",
    "                              last_window = copy(last_window_values),\n",
    "                              exog        = copy(exog_values)\n",
    "                          )\n",
    "\n",
    "            preds_level = pd.Series(\n",
    "                              data  = preds_level,\n",
    "                              index = expand_index(\n",
    "                                          index = last_window_index,\n",
    "                                          steps = steps\n",
    "                                      ),\n",
    "                              name = level\n",
    "                          )\n",
    "\n",
    "            preds_level = transform_series(\n",
    "                              series            = preds_level,\n",
    "                              transformer       = self.transformer_series_[level],\n",
    "                              fit               = False,\n",
    "                              inverse_transform = True\n",
    "                          )\n",
    "\n",
    "            predictions.append(preds_level)    \n",
    "\n",
    "        predictions = pd.concat(predictions, axis=1)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    def set_params(self):\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>8.253175</td>\n",
       "      <td>21.047727</td>\n",
       "      <td>19.429739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>22.777826</td>\n",
       "      <td>26.578125</td>\n",
       "      <td>28.009863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>27.549099</td>\n",
       "      <td>31.751042</td>\n",
       "      <td>32.078922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>25.895533</td>\n",
       "      <td>24.567708</td>\n",
       "      <td>27.252276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>21.379238</td>\n",
       "      <td>18.191667</td>\n",
       "      <td>20.357737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1     item_2     item_3\n",
       "date                                       \n",
       "2012-01-01   8.253175  21.047727  19.429739\n",
       "2012-01-02  22.777826  26.578125  28.009863\n",
       "2012-01-03  27.549099  31.751042  32.078922\n",
       "2012-01-04  25.895533  24.567708  27.252276\n",
       "2012-01-05  21.379238  18.191667  20.357737"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "url = (\n",
    "       'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/'\n",
    "       'data/simulated_items_sales.csv'\n",
    ")\n",
    "data = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2012-01-01 00:00:00'), Timestamp('2015-01-01 00:00:00'))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index.min(), data.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_1      0\n",
       "item_2    367\n",
       "item_3    925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete observations of item_2 and item_3\n",
    "# ==============================================================================\n",
    "data['item_2'].loc[: '2013-01-01'] = np.nan\n",
    "data['item_3'].loc[: '2014-07-13'] = np.nan\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>exog_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>8.253175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>22.777826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>27.549099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>25.895533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>21.379238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1  item_2  item_3  exog_1\n",
       "date                                         \n",
       "2012-01-01   8.253175     NaN     NaN       0\n",
       "2012-01-02  22.777826     NaN     NaN       1\n",
       "2012-01-03  27.549099     NaN     NaN       2\n",
       "2012-01-04  25.895533     NaN     NaN       3\n",
       "2012-01-05  21.379238     NaN     NaN       4"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add exog\n",
    "# ==============================================================================\n",
    "data['exog_1'] = np.arange(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The maximum lag (5) must be less than the length of the series (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Create and fit forecaster multi series\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m forecaster \u001b[39m=\u001b[39m ForecasterAutoregMultiSeries(\n\u001b[0;32m      4\u001b[0m                  regressor          \u001b[39m=\u001b[39m Ridge(random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m),\n\u001b[0;32m      5\u001b[0m                  lags               \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m                  series_weights     \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     10\u001b[0m              )\n\u001b[1;32m---> 12\u001b[0m forecaster\u001b[39m.\u001b[39;49mfit(series\u001b[39m=\u001b[39;49mdata_train[[\u001b[39m'\u001b[39;49m\u001b[39mitem_1\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mitem_2\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mitem_3\u001b[39;49m\u001b[39m'\u001b[39;49m]],\n\u001b[0;32m     13\u001b[0m                exog\u001b[39m=\u001b[39;49mdata_train[\u001b[39m'\u001b[39;49m\u001b[39mexog_1\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     14\u001b[0m forecaster\n",
      "Cell \u001b[1;32mIn[164], line 444\u001b[0m, in \u001b[0;36mForecasterAutoregMultiSeries.fit\u001b[1;34m(self, series, exog, store_in_sample_residuals)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog_col_names) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseries_col_names)) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog_col_names):\n\u001b[0;32m    437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    438\u001b[0m             (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`exog` cannot contain a column named the same as one of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m              \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries (column names of series).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m              \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    `series` columns : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseries_col_names\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m              \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    `exog`   columns : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog_col_names\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    442\u001b[0m         )\n\u001b[1;32m--> 444\u001b[0m X_train, y_train, y_index, y_train_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_train_X_y(series\u001b[39m=\u001b[39;49mseries, exog\u001b[39m=\u001b[39;49mexog)\n\u001b[0;32m    445\u001b[0m sample_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_sample_weights(\n\u001b[0;32m    446\u001b[0m                     series        \u001b[39m=\u001b[39m series,\n\u001b[0;32m    447\u001b[0m                     X_train       \u001b[39m=\u001b[39m X_train,\n\u001b[0;32m    448\u001b[0m                     y_train_index \u001b[39m=\u001b[39m y_train_index,\n\u001b[0;32m    449\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[164], line 276\u001b[0m, in \u001b[0;36mForecasterAutoregMultiSeries.create_train_X_y\u001b[1;34m(self, series, exog)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39m# y_values, y_index = preprocess_y(y=y)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m y_values \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m--> 276\u001b[0m X_train_values, y_train_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_lags(y\u001b[39m=\u001b[39;49my_values)\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    279\u001b[0m     X_train \u001b[39m=\u001b[39m X_train_values\n",
      "Cell \u001b[1;32mIn[164], line 159\u001b[0m, in \u001b[0;36mForecasterAutoregMultiSeries._create_lags\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m n_splits \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_lag\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m n_splits \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe maximum lag (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_lag\u001b[39m}\u001b[39;00m\u001b[39m) must be less than the length \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof the series (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(y)\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    164\u001b[0m X_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(shape\u001b[39m=\u001b[39m(n_splits, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlags)), fill_value\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan, dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[39mfor\u001b[39;00m i, lag \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlags):\n",
      "\u001b[1;31mValueError\u001b[0m: The maximum lag (5) must be less than the length of the series (2)."
     ]
    }
   ],
   "source": [
    "# Create and fit forecaster multi series\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = Ridge(random_state=123),\n",
    "                 lags               = 5,\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None\n",
    "             )\n",
    "\n",
    "forecaster.fit(series=data_train[['item_1', 'item_2', 'item_3']],\n",
    "               exog=data_train['exog_1'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1667, 8)\n",
      "item_1 len: 922\n",
      "item_2 len: 555\n",
      "item_3 len: 190\n",
      "1667\n"
     ]
    }
   ],
   "source": [
    "X_train = forecaster.create_train_X_y(data_train[['item_1', 'item_2', 'item_3']])[0]\n",
    "\n",
    "len_1 = len(X_train.loc[X_train['item_1'] == 1.])\n",
    "len_2 = len(X_train.loc[X_train['item_2'] == 1.])\n",
    "len_3 = len(X_train.loc[X_train['item_3'] == 1.])\n",
    "\n",
    "print(X_train.shape)\n",
    "print('item_1 len:', len_1)\n",
    "print('item_2 len:', len_2)\n",
    "print('item_3 len:', len_3)\n",
    "print(len_1+len_2+len_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-07-11</th>\n",
       "      <td>25.662128</td>\n",
       "      <td>11.002083</td>\n",
       "      <td>10.396751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-12</th>\n",
       "      <td>23.773923</td>\n",
       "      <td>11.008333</td>\n",
       "      <td>16.139173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-13</th>\n",
       "      <td>22.609388</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>13.028927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-14</th>\n",
       "      <td>23.307307</td>\n",
       "      <td>10.895833</td>\n",
       "      <td>9.315334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-15</th>\n",
       "      <td>25.980745</td>\n",
       "      <td>10.489583</td>\n",
       "      <td>9.908915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1     item_2     item_3\n",
       "date                                       \n",
       "2014-07-11  25.662128  11.002083  10.396751\n",
       "2014-07-12  23.773923  11.008333  16.139173\n",
       "2014-07-13  22.609388   8.100000  13.028927\n",
       "2014-07-14  23.307307  10.895833   9.315334\n",
       "2014-07-15  25.980745  10.489583   9.908915"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-07-16</th>\n",
       "      <td>25.043682</td>\n",
       "      <td>11.216612</td>\n",
       "      <td>11.975669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-17</th>\n",
       "      <td>23.886202</td>\n",
       "      <td>11.921910</td>\n",
       "      <td>13.550978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-18</th>\n",
       "      <td>23.361114</td>\n",
       "      <td>11.997133</td>\n",
       "      <td>13.880225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-19</th>\n",
       "      <td>23.240882</td>\n",
       "      <td>12.390104</td>\n",
       "      <td>13.665341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-20</th>\n",
       "      <td>23.417151</td>\n",
       "      <td>12.690782</td>\n",
       "      <td>13.799332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1     item_2     item_3\n",
       "2014-07-16  25.043682  11.216612  11.975669\n",
       "2014-07-17  23.886202  11.921910  13.550978\n",
       "2014-07-18  23.361114  11.997133  13.880225\n",
       "2014-07-19  23.240882  12.390104  13.665341\n",
       "2014-07-20  23.417151  12.690782  13.799332"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(5, exog=data_test['exog_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
