{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\JoaquÃ­n Amat\\\\Documents\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(\n",
    "    np.array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "              0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "              0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "              0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "              0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "              0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "              0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "              0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "              0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "              0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]))\n",
    "\n",
    "exog = pd.Series(\n",
    "    np.array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "              0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "              0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "              0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "              0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "              0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "              0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "              0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "              0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "              0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]), \n",
    "    name='exog')\n",
    "\n",
    "out_sample_residuals = np.array(\n",
    "             [0.51312815, 0.66662455, 0.10590849, 0.13089495, 0.32198061,\n",
    "              0.66156434, 0.84650623, 0.55325734, 0.85445249, 0.38483781,\n",
    "              0.3167879 , 0.35426468, 0.17108183, 0.82911263, 0.33867085,\n",
    "              0.55237008, 0.57855147, 0.52153306, 0.00268806, 0.98834542,\n",
    "              0.90534158, 0.20763586, 0.29248941, 0.52001015, 0.90191137,\n",
    "              0.98363088, 0.25754206, 0.56435904, 0.80696868, 0.39437005,\n",
    "              0.73107304, 0.16106901, 0.60069857, 0.86586446, 0.98352161,\n",
    "              0.07936579, 0.42834727, 0.20454286, 0.45063649, 0.54776357,\n",
    "              0.09332671, 0.29686078, 0.92758424, 0.56900373, 0.457412  ,\n",
    "              0.75352599, 0.74186215, 0.04857903, 0.7086974 , 0.83924335])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_metric(\n",
    "    metric: str\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    Get the corresponding scikit-learn function to calculate the metric.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    metric : str\n",
    "        Metric used to quantify the goodness of fit of the model. Available metrics: \n",
    "        {'mean_squared_error', 'mean_absolute_error', \n",
    "         'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    metric : Callable\n",
    "        scikit-learn function to calculate the desired metric.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if metric not in ['mean_squared_error', 'mean_absolute_error',\n",
    "                      'mean_absolute_percentage_error', 'mean_squared_log_error']:\n",
    "        raise ValueError(\n",
    "            (f\"Allowed metrics are: 'mean_squared_error', 'mean_absolute_error', \"\n",
    "             f\"'mean_absolute_percentage_error' and 'mean_squared_log_error'. Got {metric}.\")\n",
    "        )\n",
    "    \n",
    "    metrics = {\n",
    "        'mean_squared_error': mean_squared_error,\n",
    "        'mean_absolute_error': mean_absolute_error,\n",
    "        'mean_absolute_percentage_error': mean_absolute_percentage_error,\n",
    "        'mean_squared_log_error': mean_squared_log_error\n",
    "    }\n",
    "    \n",
    "    metric = metrics[metric]\n",
    "    \n",
    "    return metric\n",
    "\n",
    "\n",
    "def _backtesting_forecaster_verbose(\n",
    "    index_values: pd.Index,\n",
    "    steps: int,\n",
    "    initial_train_size: int,\n",
    "    folds: int,\n",
    "    remainder: int,\n",
    "    gap: int,\n",
    "    refit: bool=False,\n",
    "    fixed_train_size: bool=True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Verbose for backtesting_forecaster functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    index_values : pandas Index\n",
    "        Values of the index of the series.\n",
    "    \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "\n",
    "    initial_train_size : int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "        \n",
    "    folds : int\n",
    "        Number of backtesting stages.\n",
    "\n",
    "    remainder : int\n",
    "        Number of observations in the last backtesting stage. \n",
    "\n",
    "    gap : int\n",
    "        Number of observations to exclude from the end of each train set before test.\n",
    "\n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration.\n",
    "\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Information of backtesting process\")\n",
    "    print(f\"----------------------------------\")\n",
    "    print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "    print(f\"Number of observations used for backtesting: {len(index_values) - initial_train_size}\")\n",
    "    print(f\"    Number of folds: {folds}\")\n",
    "    print(f\"    Number of steps per fold: {steps}\")\n",
    "    print(f\"    Number of steps to exclude from the end of each train set before test (gap): {gap}\")\n",
    "    if remainder != 0:\n",
    "        print(f\"    Last fold only includes {remainder} observations.\")\n",
    "    print(\"\")\n",
    "    for i in range(folds):\n",
    "        if refit:\n",
    "            # if fixed_train_size the train size doesn't increase but moves by `steps` in each iteration.\n",
    "            # if false the train size increases by `steps` in each iteration.\n",
    "            train_idx_start = i * (steps) if fixed_train_size else 0\n",
    "            train_idx_end = initial_train_size + i * (steps)\n",
    "        else:\n",
    "            # The train size doesn't increase and doesn't move\n",
    "            train_idx_start = 0\n",
    "            train_idx_end = initial_train_size\n",
    "        last_window_end = initial_train_size + i * (steps)\n",
    "        print(f\"Data partition in fold: {i}\")\n",
    "\n",
    "        if i < folds - 1:\n",
    "            print(\n",
    "                f\"    Training:   {index_values[train_idx_start]} -- \"\n",
    "                f\"{index_values[train_idx_end - 1]}  \"\n",
    "                f\"(n={len(index_values[train_idx_start:train_idx_end])})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"    Validation: {index_values[last_window_end + gap]} -- \"\n",
    "                f\"{index_values[last_window_end + steps - 1]}  \"\n",
    "                f\"(n={len(index_values[last_window_end:last_window_end + steps])})\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"    Training:   {index_values[train_idx_start]} -- \"\n",
    "                f\"{index_values[train_idx_end - 1]}  \"\n",
    "                f\"(n={len(index_values[train_idx_start:train_idx_end])})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"    Validation: {index_values[last_window_end + gap]} -- \"\n",
    "                f\"{index_values[-1]}  (n={len(index_values[last_window_end:])})\"\n",
    "            )\n",
    "    print(\"\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _backtesting_forecaster_refit(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    gap: int = 0,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    show_progress: bool=True\n",
    ") -> Tuple[Union[float, list], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with refit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect\n",
    "        Forecaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series.\n",
    "        \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If Callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or Callable.\n",
    "    \n",
    "    initial_train_size : int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "\n",
    "    gap : int, default 0\n",
    "        Number of observations to exclude from the end of each train set before test.\n",
    "        \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "        \n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "\n",
    "    interval : list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. For example, \n",
    "        interval of 95% should be as `interval = [2.5, 97.5]`. If `None`, no\n",
    "        intervals are estimated. Only available for forecaster of type \n",
    "        ForecasterAutoreg and ForecasterAutoregCustom.\n",
    "    \n",
    "    n_boot : int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "\n",
    "    in_sample_residuals : bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of\n",
    "        prediction error to create prediction intervals. If `False`, out_sample_residuals\n",
    "        are used if they are already stored inside the forecaster.\n",
    "            \n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used for backtesting.\n",
    "\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar. Defaults to True.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    metrics_value : float, list\n",
    "        Value(s) of the metric(s).\n",
    "\n",
    "    backtest_predictions : pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "            column pred = predictions.\n",
    "            column lower_bound = lower bound of the interval.\n",
    "            column upper_bound = upper bound interval of the interval.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    forecaster = deepcopy(forecaster)\n",
    "\n",
    "    if isinstance(metric, str):\n",
    "        metrics = _get_metric(metric=metric)\n",
    "    elif isinstance(metric, list):\n",
    "        metrics = [_get_metric(metric=m) if isinstance(m, str) else m for m in metric]\n",
    "    else:\n",
    "        metrics = metric\n",
    "\n",
    "    backtest_predictions = []\n",
    "    \n",
    "    folds = int(np.ceil((len(y) - initial_train_size) / (steps)))\n",
    "    remainder = (len(y) - initial_train_size) % steps\n",
    "    if remainder < gap:\n",
    "        remainder = 0\n",
    "        folds -= 1\n",
    "    \n",
    "    if type(forecaster).__name__ != 'ForecasterAutoregDirect' and folds > 50:\n",
    "        warnings.warn(\n",
    "            (f\"The forecaster will be fit {folds} times. This can take substantial amounts of time. \"\n",
    "             f\"If not feasible, try with `refit = False`. \\n\"),\n",
    "            LongTrainingWarning\n",
    "        )\n",
    "    elif type(forecaster).__name__ == 'ForecasterAutoregDirect' and folds*forecaster.steps > 50:\n",
    "        warnings.warn(\n",
    "            (f\"The forecaster will be fit {folds*forecaster.steps} times ({folds} folds * {forecaster.steps} regressors). \"\n",
    "             f\"This can take substantial amounts of time. If not feasible, try with `refit = False`. \\n\"),\n",
    "             LongTrainingWarning\n",
    "        )\n",
    "    \n",
    "    if verbose:\n",
    "        _backtesting_forecaster_verbose(\n",
    "            index_values       = y.index,\n",
    "            steps              = steps,\n",
    "            initial_train_size = initial_train_size,\n",
    "            folds              = folds,\n",
    "            remainder          = remainder,\n",
    "            gap                = gap,\n",
    "            refit              = True,\n",
    "            fixed_train_size   = fixed_train_size\n",
    "        )\n",
    "    \n",
    "    for i in tqdm(range(folds)) if show_progress else range(folds):\n",
    "        # In each iteration the model is fitted before making predictions.\n",
    "        # if fixed_train_size the train size doesn't increase but moves by `steps` in each iteration.\n",
    "        # if false the train size increases by `steps` in each iteration.\n",
    "        train_idx_start = i * (steps) if fixed_train_size else 0\n",
    "        train_idx_end = initial_train_size + i * (steps)\n",
    "\n",
    "        exog_train_values = exog.iloc[train_idx_start:train_idx_end, ] if exog is not None else None\n",
    "        next_window_exog = exog.iloc[train_idx_end:train_idx_end + steps, ] if exog is not None else None\n",
    "\n",
    "        forecaster.fit(y=y.iloc[train_idx_start:train_idx_end, ], exog=exog_train_values)\n",
    "\n",
    "        if i == folds - 1: # last fold\n",
    "            # If remainder > 0, only the remaining steps need to be predicted\n",
    "            steps = steps if remainder == 0 else remainder\n",
    "\n",
    "        if interval is None:\n",
    "            pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "            pred = forecaster.predict_interval(\n",
    "                       steps               = steps,\n",
    "                       exog                = next_window_exog,\n",
    "                       interval            = interval,\n",
    "                       n_boot              = n_boot,\n",
    "                       random_state        = random_state,\n",
    "                       in_sample_residuals = in_sample_residuals\n",
    "                   )\n",
    "        if gap > 0:\n",
    "            pred = pred.iloc[gap:, ]\n",
    "            \n",
    "        backtest_predictions.append(pred)\n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "        backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    if isinstance(metric, list):\n",
    "        metrics_values = [m(\n",
    "                            y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                            y_pred = backtest_predictions['pred']\n",
    "                          ) for m in metrics\n",
    "                         ]\n",
    "    else:\n",
    "        metrics_values = metrics(\n",
    "                            y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                            y_pred = backtest_predictions['pred']\n",
    "                         )\n",
    "\n",
    "    return metrics_values, backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 20\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 7\n",
      "    Number of steps per fold: 4\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 10\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 19  (n=20)\n",
      "    Validation: 30 -- 23  (n=4)\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 23  (n=24)\n",
      "    Validation: 34 -- 27  (n=4)\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 27  (n=28)\n",
      "    Validation: 38 -- 31  (n=4)\n",
      "Data partition in fold: 3\n",
      "    Training:   0 -- 31  (n=32)\n",
      "    Validation: 42 -- 35  (n=4)\n",
      "Data partition in fold: 4\n",
      "    Training:   0 -- 35  (n=36)\n",
      "    Validation: 46 -- 39  (n=4)\n",
      "Data partition in fold: 5\n",
      "    Training:   0 -- 39  (n=40)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\pandas\\core\\indexes\\range.py:966\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range[new_key]\n\u001b[0;32m    967\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mIndexError\u001b[0m: range object index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m forecaster \u001b[39m=\u001b[39m ForecasterAutoreg(regressor\u001b[39m=\u001b[39mLinearRegression(), lags\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m metric, backtest_predictions \u001b[39m=\u001b[39m _backtesting_forecaster_refit(\n\u001b[0;32m      3\u001b[0m                                     forecaster          \u001b[39m=\u001b[39;49m forecaster,\n\u001b[0;32m      4\u001b[0m                                     y                   \u001b[39m=\u001b[39;49m y,\n\u001b[0;32m      5\u001b[0m                                     exog                \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m                                     initial_train_size  \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m                                     gap                 \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m                                     fixed_train_size    \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      9\u001b[0m                                     steps               \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m                                     metric              \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m                                     interval            \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     12\u001b[0m                                     n_boot              \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m,\n\u001b[0;32m     13\u001b[0m                                     random_state        \u001b[39m=\u001b[39;49m \u001b[39m123\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m                                     in_sample_residuals \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     15\u001b[0m                                     verbose             \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m                                 )\n\u001b[0;32m     17\u001b[0m backtest_predictions\n",
      "Cell \u001b[1;32mIn[4], line 270\u001b[0m, in \u001b[0;36m_backtesting_forecaster_refit\u001b[1;34m(forecaster, y, steps, metric, initial_train_size, gap, fixed_train_size, exog, interval, n_boot, random_state, in_sample_residuals, verbose, show_progress)\u001b[0m\n\u001b[0;32m    263\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    264\u001b[0m         (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe forecaster will be fit \u001b[39m\u001b[39m{\u001b[39;00mfolds\u001b[39m*\u001b[39mforecaster\u001b[39m.\u001b[39msteps\u001b[39m}\u001b[39;00m\u001b[39m times (\u001b[39m\u001b[39m{\u001b[39;00mfolds\u001b[39m}\u001b[39;00m\u001b[39m folds * \u001b[39m\u001b[39m{\u001b[39;00mforecaster\u001b[39m.\u001b[39msteps\u001b[39m}\u001b[39;00m\u001b[39m regressors). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis can take substantial amounts of time. If not feasible, try with `refit = False`. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    266\u001b[0m          LongTrainingWarning\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m--> 270\u001b[0m     _backtesting_forecaster_verbose(\n\u001b[0;32m    271\u001b[0m         index_values       \u001b[39m=\u001b[39;49m y\u001b[39m.\u001b[39;49mindex,\n\u001b[0;32m    272\u001b[0m         steps              \u001b[39m=\u001b[39;49m steps,\n\u001b[0;32m    273\u001b[0m         initial_train_size \u001b[39m=\u001b[39;49m initial_train_size,\n\u001b[0;32m    274\u001b[0m         folds              \u001b[39m=\u001b[39;49m folds,\n\u001b[0;32m    275\u001b[0m         remainder          \u001b[39m=\u001b[39;49m remainder,\n\u001b[0;32m    276\u001b[0m         gap                \u001b[39m=\u001b[39;49m gap,\n\u001b[0;32m    277\u001b[0m         refit              \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    278\u001b[0m         fixed_train_size   \u001b[39m=\u001b[39;49m fixed_train_size\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    281\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(folds)) \u001b[39mif\u001b[39;00m show_progress \u001b[39melse\u001b[39;00m \u001b[39mrange\u001b[39m(folds):\n\u001b[0;32m    282\u001b[0m     \u001b[39m# In each iteration the model is fitted before making predictions.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39m# if fixed_train_size the train size doesn't increase but moves by `steps` in each iteration.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[39m# if false the train size increases by `steps` in each iteration.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     train_idx_start \u001b[39m=\u001b[39m i \u001b[39m*\u001b[39m (steps) \u001b[39mif\u001b[39;00m fixed_train_size \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 112\u001b[0m, in \u001b[0;36m_backtesting_forecaster_verbose\u001b[1;34m(index_values, steps, initial_train_size, folds, remainder, gap, refit, fixed_train_size)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m folds \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    106\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    107\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    Training:   \u001b[39m\u001b[39m{\u001b[39;00mindex_values[train_idx_start]\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mindex_values[train_idx_end\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(n=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index_values[train_idx_start:train_idx_end])\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    111\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m--> 112\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    Validation: \u001b[39m\u001b[39m{\u001b[39;00mindex_values[last_window_end\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49mgap]\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mindex_values[last_window_end\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39msteps\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(n=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index_values[last_window_end:last_window_end\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39msteps])\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    118\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    Training:   \u001b[39m\u001b[39m{\u001b[39;00mindex_values[train_idx_start]\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mindex_values[train_idx_end\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(n=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index_values[train_idx_start:train_idx_end])\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m     )\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\pandas\\core\\indexes\\range.py:968\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range[new_key]\n\u001b[0;32m    967\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 968\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    969\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m is out of bounds for axis 0 with size \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(key):\n\u001b[0;32m    972\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    973\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39monly integers, slices (`:`), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    974\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    975\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand integer or boolean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    976\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marrays are valid indices\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    977\u001b[0m     )\n",
      "\u001b[1;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    initial_train_size  = 20,\n",
    "                                    gap                 = 10,\n",
    "                                    fixed_train_size    = False,\n",
    "                                    steps               = 4,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    verbose             = True\n",
    "                                )\n",
    "backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 18\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 12\n",
      "Number of observations used for backtesting: 90\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 24\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 50\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:    0 -- 11 (n=12)\n",
      "    Validation: 62 --  85 (n=24)\n",
      "Data partition in fold: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 109 is out of bounds for axis 0 with size 102",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\pandas\\core\\indexes\\range.py:966\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range[new_key]\n\u001b[0;32m    967\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mIndexError\u001b[0m: range object index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m training_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index_values[train_idx_start:train_idx_end])\n\u001b[0;32m     48\u001b[0m validation_start \u001b[39m=\u001b[39m index_values[last_window_end \u001b[39m+\u001b[39m gap]\n\u001b[1;32m---> 49\u001b[0m validation_end \u001b[39m=\u001b[39m index_values[last_window_end \u001b[39m+\u001b[39;49m steps \u001b[39m+\u001b[39;49m gap \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m]\n\u001b[0;32m     50\u001b[0m validation_length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(index_values[last_window_end:last_window_end \u001b[39m+\u001b[39m steps])\n\u001b[0;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    Training:    \u001b[39m\u001b[39m{\u001b[39;00mtraining_start\u001b[39m}\u001b[39;00m\u001b[39m -- \u001b[39m\u001b[39m{\u001b[39;00mtraining_end\u001b[39m}\u001b[39;00m\u001b[39m (n=\u001b[39m\u001b[39m{\u001b[39;00mtraining_length\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\skforecast_p10\\lib\\site-packages\\pandas\\core\\indexes\\range.py:968\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range[new_key]\n\u001b[0;32m    967\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 968\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    969\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m is out of bounds for axis 0 with size \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(key):\n\u001b[0;32m    972\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    973\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39monly integers, slices (`:`), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    974\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    975\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand integer or boolean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    976\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marrays are valid indices\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    977\u001b[0m     )\n",
      "\u001b[1;31mIndexError\u001b[0m: index 109 is out of bounds for axis 0 with size 102"
     ]
    }
   ],
   "source": [
    "n = 102\n",
    "y = pd.Series(np.arange(n), index=pd.RangeIndex(n))\n",
    "index_values = y.index\n",
    "fixed_train_size = False\n",
    "initial_train_size = 12\n",
    "steps = 24\n",
    "gap=50\n",
    "refit = True\n",
    "\n",
    "folds = int(np.ceil((len(y) - initial_train_size) / (steps)))\n",
    "remainder = (len(y) - initial_train_size) % steps\n",
    "print(folds, remainder)\n",
    "if remainder < gap:\n",
    "    remainder = 0\n",
    "    folds -= 1\n",
    "else:\n",
    "    remainder = remainder - gap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Information of backtesting process\")\n",
    "print(f\"----------------------------------\")\n",
    "print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "print(f\"Number of observations used for backtesting: {len(index_values) - initial_train_size}\")\n",
    "print(f\"    Number of folds: {folds}\")\n",
    "print(f\"    Number of steps per fold: {steps}\")\n",
    "print(f\"    Number of steps to exclude from the end of each train set before test (gap): {gap}\")\n",
    "if remainder != 0:\n",
    "    print(f\"    Last fold only includes {remainder} observations.\")\n",
    "print(\"\")\n",
    "for i in range(folds):\n",
    "    if refit:\n",
    "        # If fixed_train_size the train size doesn't increase but moves by `steps` in\n",
    "        # each iteration. If false the train size increases by `steps` in each iteration.\n",
    "        train_idx_start = i * (steps) if fixed_train_size else 0\n",
    "        train_idx_end = initial_train_size + i * (steps)\n",
    "    else:\n",
    "        # The train size doesn't increase and doesn't move\n",
    "        train_idx_start = 0\n",
    "        train_idx_end = initial_train_size\n",
    "\n",
    "    last_window_end = initial_train_size + i * (steps)\n",
    "    print(f\"Data partition in fold: {i}\")\n",
    "\n",
    "    if i < folds - 1:\n",
    "        training_start = index_values[train_idx_start]\n",
    "        training_end = index_values[train_idx_end - 1]\n",
    "        training_length = len(index_values[train_idx_start:train_idx_end])\n",
    "        validation_start = index_values[last_window_end + gap]\n",
    "        validation_end = index_values[last_window_end + steps + gap - 1]\n",
    "        validation_length = len(index_values[last_window_end:last_window_end + steps])\n",
    "        print(\n",
    "            f\"    Training:    {training_start} -- {training_end} (n={training_length})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Validation: {validation_start} --  {validation_end} (n={validation_length})\"\n",
    "        )\n",
    "    else:\n",
    "        training_start = index_values[train_idx_start]\n",
    "        training_end = index_values[train_idx_end - 1]\n",
    "        training_length = len(index_values[train_idx_start:train_idx_end])\n",
    "        validation_start = index_values[last_window_end + gap]\n",
    "        validation_end = index_values[-1]\n",
    "        validation_length = len(index_values[last_window_end:]) - gap\n",
    "        print(\n",
    "            f\"    Training:    {training_start} --  {training_end} (n={training_length})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Validation: {validation_start} -- {validation_end} (n={validation_length})\"\n",
    "        )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 12\n",
      "Number of observations used for backtesting: 89\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 36\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 12\n",
      "    Last fold only includes 17 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 11  (n=12)\n",
      "    Validation: 24 -- 47  (n=36)\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 47  (n=48)\n",
      "    Validation: 60 -- 83  (n=36)\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 83  (n=84)\n",
      "    Validation: 96 -- 100  (n=17)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7968d429a12428181329e894ea6ebed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.Series(np.arange(101), index=pd.RangeIndex(101))\n",
    "index_values = y.index\n",
    "fixed_train_size = False\n",
    "initial_train_size = 12\n",
    "steps = 36\n",
    "gap=50\n",
    "refit = True\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    initial_train_size  = 12,\n",
    "                                    gap                 = 12,\n",
    "                                    fixed_train_size    = False,\n",
    "                                    steps               = 36,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    verbose             = True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test _backtesting_forecaster_refit\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytest import approx\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster_refit\n",
    "\n",
    "# Fixtures _backtesting_forecaster_refit Series (skforecast==0.4.2)\n",
    "# np.random.seed(123)\n",
    "# y = np.random.rand(50)\n",
    "# exog = np.random.rand(50)\n",
    "# out_sample_residuals = np.random.rand(50)\n",
    "\n",
    "y = pd.Series(\n",
    "    np.array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "              0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "              0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "              0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "              0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "              0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "              0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "              0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "              0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "              0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]))\n",
    "\n",
    "exog = pd.Series(\n",
    "    np.array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "              0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "              0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "              0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "              0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "              0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "              0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "              0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "              0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "              0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]), \n",
    "    name='exog')\n",
    "\n",
    "out_sample_residuals = np.array(\n",
    "             [0.51312815, 0.66662455, 0.10590849, 0.13089495, 0.32198061,\n",
    "              0.66156434, 0.84650623, 0.55325734, 0.85445249, 0.38483781,\n",
    "              0.3167879 , 0.35426468, 0.17108183, 0.82911263, 0.33867085,\n",
    "              0.55237008, 0.57855147, 0.52153306, 0.00268806, 0.98834542,\n",
    "              0.90534158, 0.20763586, 0.29248941, 0.52001015, 0.90191137,\n",
    "              0.98363088, 0.25754206, 0.56435904, 0.80696868, 0.39437005,\n",
    "              0.73107304, 0.16106901, 0.60069857, 0.86586446, 0.98352161,\n",
    "              0.07936579, 0.42834727, 0.20454286, 0.45063649, 0.54776357,\n",
    "              0.09332671, 0.29686078, 0.92758424, 0.56900373, 0.457412  ,\n",
    "              0.75352599, 0.74186215, 0.04857903, 0.7086974 , 0.83924335])\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "# * Test _backtesting_forecaster_refit No Interval                             *\n",
    "# ******************************************************************************\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoreg_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    ForecasterAutoreg.\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06598802629306816\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = True\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 3 lags of a time series.\n",
    "    \"\"\"\n",
    "    \n",
    "    lags = y[-1:-4:-1]\n",
    "    \n",
    "    return lags \n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    ForecasterAutoregCustom.\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06598802629306816\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoregCustom(\n",
    "                     regressor      = LinearRegression(), \n",
    "                     fun_predictors = create_predictors,\n",
    "                     window_size    = 3\n",
    "                 )\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = True\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    ForecasterAutoregDirect.\n",
    "    \"\"\"\n",
    "    expected_metric = 0.07076203468824618\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.5468482 , 0.44670961, 0.57651222, 0.52511275, 0.3686309 , 0.56234835, \n",
    "                     0.44276032, 0.52260065, 0.37665741, 0.5382938 , 0.48755548, 0.44534071])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoregDirect(\n",
    "                     regressor = LinearRegression(), \n",
    "                     lags      = 3,\n",
    "                     steps     = 4\n",
    "                 )\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = True\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06916732087926723\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 ,\n",
    "                     0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472])\n",
    "                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.05663345135204598\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,\n",
    "                     0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402])\n",
    "                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.061723961096013524\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,\n",
    "                     0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419])\n",
    "                                                                 }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "# * Test _backtesting_forecaster_refit Interval                                *\n",
    "# ******************************************************************************\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_no_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06598802629306816\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                     0.49152015, 0.4841678, 0.4076433, 0.50904672, 0.50249462, 0.49232817]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.03520425, 0.12926384,\n",
    "                            0.0495347 , 0.04527341, 0.0113795 , 0.13676538, 0.12478441, 0.06814153]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.78486946, 0.93084605,\n",
    "                            0.84533191, 0.90255909, 0.80099612, 0.88747244, 0.88292664, 0.88718366])                                                                 \n",
    "                                                                         }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   ) \n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_no_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06916732087926723\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.5096801 , \n",
    "                     0.49519677, 0.47997916, 0.49177914, 0.495797  , 0.57738724, 0.44370472]),\n",
    "    'lower_bound':np.array([0.19882822, 0.08272406, 0.18106389, 0.18777395, 0.1238825 , 0.06681772,\n",
    "                            0.09795868, 0.08383945, 0.10160946, 0.08917676, 0.23321023, 0.08685352]),\n",
    "    'upper_bound':np.array([0.95368172, 0.81704742, 0.93685716, 0.9407976 , 0.85396419, 0.86172991,\n",
    "                            0.88313129, 0.82354636, 0.93875053, 0.86176335, 0.96037185, 0.84205069])                                                                 \n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    \n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_yes_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.05663345135204598\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275, 0.46286083,\n",
    "                     0.43618422, 0.43552906, 0.48687517, 0.55455072, 0.55577332, 0.53943402]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.07440334, 0.11331854,\n",
    "                            0.01436362, 0.02747413, 0.14867238, 0.19834047, 0.19884259, 0.16964474]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.8225198 , 0.81894689,\n",
    "                            0.81179723, 0.84420112, 0.89407425, 0.93903702, 0.91748574, 0.93705358])                                                                 \n",
    "                                                                         }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    \n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = True'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.061723961096013524\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.43595809,\n",
    "                     0.4349167 , 0.42381237, 0.55165332, 0.53442833, 0.65361802, 0.51297419]),\n",
    "    'lower_bound':np.array([0.24619375, 0.10545295, 0.13120713, 0.08044217, 0.13725077, 0.08041239,\n",
    "                            0.05015513, 0.07677812, 0.17434611, 0.16051962, 0.29167326, 0.15775686]),\n",
    "    'upper_bound':np.array([0.95777604, 0.88685543, 0.90755063, 0.87811336, 0.86891022, 0.74808834,\n",
    "                            0.80296989, 0.77919033, 0.97680126, 0.8877086 , 1.07608747, 0.90555785])                                                                 \n",
    "                                                                         }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "# * Out sample residuals                                                       *\n",
    "# ******************************************************************************\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval yes.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    'in_sample_residuals = False'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06598802629306816\n",
    "    expected_predictions = pd.DataFrame({\n",
    "        'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339, \n",
    "                         0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817]),\n",
    "        'lower_bound':np.array([0.63654358, 0.62989756, 0.67156167, 0.70363265, 0.46905871, 0.73507276, \n",
    "                                0.64554988, 0.64183541, 0.48700909, 0.68845988, 0.63865297, 0.60684242]),\n",
    "        'upper_bound':np.array([1.54070487, 1.5131313 , 1.56749058, 1.62564968, 1.37322   , 1.61930035, \n",
    "                                1.54870568, 1.55335041, 1.39117037, 1.56935123, 1.51973211, 1.50300901])                                                                \n",
    "                                                                            }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.set_out_sample_residuals(residuals=out_sample_residuals, append=False)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = [5, 95],\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = False,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "# * Callable metric                                                           *\n",
    "# ******************************************************************************\n",
    "\n",
    "def my_metric(y_true, y_pred): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Callable metric\n",
    "    \"\"\"\n",
    "    metric = ((y_true - y_pred)/len(y_true)).mean()\n",
    "    \n",
    "    return metric\n",
    "\n",
    "def test_callable_metric_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test callable metric in _backtesting_forecaster_refit with backtesting mocked, interval no. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    \"\"\"\n",
    "    expected_metric = 0.005283745900436151\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = my_metric,\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_list_metrics_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test list of metrics in _backtesting_forecaster_refit with backtesting mocked, interval no. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    \"\"\"\n",
    "    expected_metrics = [0.06598802629306816, 0.06598802629306816]\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292, 0.52778339,\n",
    "                     0.49152015, 0.4841678 , 0.4076433 , 0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metrics, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = False,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = ['mean_squared_error', mean_squared_error],\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "\n",
    "    assert expected_metrics == approx(metrics)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "# * fixed_train_size = True                                                    *\n",
    "# ******************************************************************************\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06720844584333846\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.34597367, 0.50223873,\n",
    "                     0.47833829, 0.46082257, 0.37810191, 0.49508366, 0.48808014, 0.47323313])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "    \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    \"\"\"\n",
    "    expected_metric = 0.07217085374372428\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861, 0.4909399 , \n",
    "                     0.47942107, 0.46025344, 0.46649132, 0.47061725, 0.57603136, 0.41480551])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = None,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_no_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,\n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    \"\"\"\n",
    "    expected_metric = 0.05758244401484334\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.37689967, 0.44267729, \n",
    "                     0.42642836, 0.41604275, 0.45047245, 0.53784704, 0.53726274, 0.51516772])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 4,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_yes_remainder_with_mocked():\n",
    "    \"\"\"\n",
    "    Test output of _backtesting_forecaster_refit with backtesting mocked, interval no.\n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked,\n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error',\n",
    "    fixed_train_size=True\n",
    "    \"\"\"\n",
    "    expected_metric = 0.06425019123005545\n",
    "    expected_predictions = pd.DataFrame({\n",
    "    'pred':np.array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119, 0.41975558, \n",
    "                     0.4256614 , 0.41176005, 0.52357817, 0.509974  , 0.65354628, 0.48210726])\n",
    "                                                                }, index=pd.RangeIndex(start=38, stop=50, step=1))\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster          = forecaster,\n",
    "                                        y                   = y,\n",
    "                                        exog                = exog,\n",
    "                                        initial_train_size  = len(y_train),\n",
    "                                        fixed_train_size    = True,\n",
    "                                        steps               = 5,\n",
    "                                        metric              = 'mean_squared_error',\n",
    "                                        interval            = None,\n",
    "                                        n_boot              = 500,\n",
    "                                        random_state        = 123,\n",
    "                                        in_sample_residuals = True,\n",
    "                                        verbose             = False\n",
    "                                   )\n",
    "                                   \n",
    "    assert expected_metric == approx(metric)\n",
    "    pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ebb336064143138a916033c9d4c55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791eb308601e4e30a64294598513ad53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfdac7a42be43199f0aa2129c5d60d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab07ec1d8ac94508ae3109899aa12067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa6665c2f294c64b37b6f22001b1b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4114372d1948dd8ee41b5e1dcba7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f28a596ef7645e5ab328d7492dc4596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc09f3087e104b8ebf2f29aa6c8d9acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7982b722de3d452b924a030cda4d703a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a535ae35ea7f4e34af1509dc7c67cf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4834187c781f4a6092ffed18a7d9db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b9d8fc9faf4ed39ad507dc27a49a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf0a46846a943ddb032fb25335a24d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37  (n=38)\n",
      "    Validation: 38 -- 41  (n=4)\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41  (n=42)\n",
      "    Validation: 42 -- 45  (n=4)\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45  (n=46)\n",
      "    Validation: 46 -- 49  (n=4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5fcd35cb67449c8c94d1f1917e9325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37  (n=38)\n",
      "    Validation: 38 -- 41  (n=4)\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41  (n=42)\n",
      "    Validation: 42 -- 45  (n=4)\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45  (n=46)\n",
      "    Validation: 46 -- 49  (n=4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1a3aa7cda94f3e8a330a092fcfc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37  (n=38)\n",
      "    Validation: 38 -- 41  (n=4)\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41  (n=42)\n",
      "    Validation: 42 -- 45  (n=4)\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45  (n=46)\n",
      "    Validation: 46 -- 49  (n=4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92e72e256254cfc9531a6ba20c5c51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_fixed_train_size_no_exog_no_remainder_with_mocked()\n",
    "test_callable_metric_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_out_sample_residuals_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_yes_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_interval_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregDirect_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoregCustom_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_no_remainder_ForecasterAutoreg_with_mocked()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
