{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>8.253175</td>\n",
       "      <td>21.047727</td>\n",
       "      <td>19.429739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>22.777826</td>\n",
       "      <td>26.578125</td>\n",
       "      <td>28.009863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>27.549099</td>\n",
       "      <td>31.751042</td>\n",
       "      <td>32.078922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>25.895533</td>\n",
       "      <td>24.567708</td>\n",
       "      <td>27.252276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>21.379238</td>\n",
       "      <td>18.191667</td>\n",
       "      <td>20.357737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_1     item_2     item_3\n",
       "date                                       \n",
       "2012-01-01   8.253175  21.047727  19.429739\n",
       "2012-01-02  22.777826  26.578125  28.009863\n",
       "2012-01-03  27.549099  31.751042  32.078922\n",
       "2012-01-04  25.895533  24.567708  27.252276\n",
       "2012-01-05  21.379238  18.191667  20.357737"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "url = (\n",
    "       'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/'\n",
    "       'data/simulated_items_sales.csv'\n",
    ")\n",
    "data = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Forecaster multi series\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = Ridge(random_state=123),\n",
    "                 lags               = 24,\n",
    "                 transformer_series = StandardScaler(),\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b7070389124c23a2deac915f041b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'alpha': 0.7252189487445193}\n",
      "  Backtesting metric: 2.2076640698475622\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.7252189487445193}</td>\n",
       "      <td>2.207664</td>\n",
       "      <td>0.725219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.53623586010342}</td>\n",
       "      <td>2.207675</td>\n",
       "      <td>0.536236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.4441865222328282}</td>\n",
       "      <td>2.207680</td>\n",
       "      <td>0.444187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>2.207683</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.23598059857016607}</td>\n",
       "      <td>2.207693</td>\n",
       "      <td>0.235981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>2.335041</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.8509374761370117}</td>\n",
       "      <td>2.335057</td>\n",
       "      <td>0.850937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.7406154516747153}</td>\n",
       "      <td>2.335071</td>\n",
       "      <td>0.740615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>2.335076</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>2.335093</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     levels  \\\n",
       "8  [item_1, item_2, item_3]   \n",
       "6  [item_1, item_2, item_3]   \n",
       "4  [item_1, item_2, item_3]   \n",
       "3  [item_1, item_2, item_3]   \n",
       "9  [item_1, item_2, item_3]   \n",
       "2  [item_1, item_2, item_3]   \n",
       "7  [item_1, item_2, item_3]   \n",
       "5  [item_1, item_2, item_3]   \n",
       "0  [item_1, item_2, item_3]   \n",
       "1  [item_1, item_2, item_3]   \n",
       "\n",
       "                                                lags  \\\n",
       "8  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "6  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "9  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "7  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "5  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                           params  mean_absolute_error     alpha  \n",
       "8   {'alpha': 0.7252189487445193}             2.207664  0.725219  \n",
       "6     {'alpha': 0.53623586010342}             2.207675  0.536236  \n",
       "4   {'alpha': 0.4441865222328282}             2.207680  0.444187  \n",
       "3    {'alpha': 0.398196343012209}             2.207683  0.398196  \n",
       "9  {'alpha': 0.23598059857016607}             2.207693  0.235981  \n",
       "2   {'alpha': 0.9809565564007693}             2.335041  0.980957  \n",
       "7   {'alpha': 0.8509374761370117}             2.335057  0.850937  \n",
       "5   {'alpha': 0.7406154516747153}             2.335071  0.740615  \n",
       "0   {'alpha': 0.6995044937418831}             2.335076  0.699504  \n",
       "1   {'alpha': 0.5558016213920624}             2.335093  0.555802  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search Multi Series\n",
    "# ==============================================================================\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 0.01, 1),\n",
    "        'lags' : trial.suggest_categorical('lags', [24, 48])\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "              forecaster         = forecaster,\n",
    "              series             = data,\n",
    "              exog               = None,\n",
    "              levels             = levels, # Same as levels=None\n",
    "              search_space       = search_space,\n",
    "              steps              = 24,\n",
    "              metric             = 'mean_absolute_error',\n",
    "              initial_train_size = len(data_train),\n",
    "              refit              = True,\n",
    "              fixed_train_size   = True,\n",
    "              return_best        = True,\n",
    "              n_jobs             = 'auto',\n",
    "              verbose            = False,\n",
    "              show_progress      = True\n",
    "          )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "from sklearn.linear_model import Ridge\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _initialize_levels_model_selection_multiseries\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from typing import Union, Tuple, Optional, Callable, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _bayesian_search_optuna_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multivariate\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from tqdm import tqdm\n",
    "from functools import partialmethod\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fixtures\n",
    "# series_1 = np.random.rand(50)\n",
    "# series_2 = np.random.rand(50)\n",
    "series = pd.DataFrame({'l1': pd.Series(np.array(\n",
    "                                 [0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "                                  0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "                                  0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "                                  0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "                                  0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "                                  0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "                                  0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "                                  0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "                                  0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "                                  0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]\n",
    "                                       )\n",
    "                             ), \n",
    "                       'l2': pd.Series(np.array(\n",
    "                                 [0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "                                  0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "                                  0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "                                  0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "                                  0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "                                  0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "                                  0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "                                  0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "                                  0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "                                  0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]\n",
    "                                       )\n",
    "                             )\n",
    "         })\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 4 lags of a time series.\n",
    "    \"\"\"\n",
    "\n",
    "    lags = y[-1:-5:-1]\n",
    "\n",
    "    return lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1177: UserWarning: The 'lags_grid' argument is deprecated and will be removed in a future version. Use the 'search_space' argument to define the candidate values for the lags. Example: {'lags' : trial.suggest_categorical('lags', [3, 5])}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794be6347d574d58a9f031bad7be3b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {'l1': 4, 'l2': [2, 3]} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "def test_results_output_bayesian_search_forecaster_multivariate_optuna_engine_ForecasterAutoregMultiVariate():\n",
    "    \"\"\"\n",
    "    Test output of bayesian_search_forecaster_multivariate in \n",
    "    ForecasterAutoregMultiVariate with mocked using \n",
    "    optuna engine (mocked done in Skforecast v0.12.0).\n",
    "    \"\"\"\n",
    "    forecaster = ForecasterAutoregMultiVariate(\n",
    "                     regressor = Ridge(random_state=123),\n",
    "                     level     = 'l1',\n",
    "                     lags      = 2,\n",
    "                     steps     = 3\n",
    "                 )\n",
    "\n",
    "    steps = 3\n",
    "    n_validation = 12\n",
    "\n",
    "    def search_space(trial):\n",
    "        search_space  = {\n",
    "            'alpha' : trial.suggest_float('alpha', 1e-2, 1.0),\n",
    "            'lags'  : trial.suggest_categorical('lags', [2, {'l1': 4, 'l2': [2, 3]}])\n",
    "            }\n",
    "\n",
    "        return search_space\n",
    "\n",
    "    results = bayesian_search_forecaster_multivariate(\n",
    "                  forecaster         = forecaster,\n",
    "                  series             = series,\n",
    "                  steps              = steps,\n",
    "                  search_space       = search_space,\n",
    "                  metric             = 'mean_absolute_error',\n",
    "                  refit              = False,\n",
    "                  initial_train_size = len(series) - n_validation,\n",
    "                  n_trials           = 10,\n",
    "                  random_state       = 123,\n",
    "                  return_best        = False,\n",
    "                  verbose            = False,\n",
    "                  engine             = 'optuna'\n",
    "              )[0]\n",
    "    \n",
    "    expected_results = pd.DataFrame(\n",
    "        np.array([[list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "            {'alpha': 0.23598059857016607}, 0.19308110319514993,\n",
    "            0.23598059857016607],\n",
    "        [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "            {'alpha': 0.398196343012209}, 0.1931744420708601,\n",
    "            0.398196343012209],\n",
    "        [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "            {'alpha': 0.4441865222328282}, 0.1932004954044704,\n",
    "            0.4441865222328282],\n",
    "        [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "            {'alpha': 0.53623586010342}, 0.19325210858832276,\n",
    "            0.53623586010342],\n",
    "        [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "            {'alpha': 0.7252189487445193}, 0.19335589494249983,\n",
    "            0.7252189487445193],\n",
    "        [list(['l1']), np.array([1, 2]), {'alpha': 0.5558016213920624},\n",
    "            0.20131081099888368, 0.5558016213920624],\n",
    "        [list(['l1']), np.array([1, 2]), {'alpha': 0.6995044937418831},\n",
    "            0.2013710017368262, 0.6995044937418831],\n",
    "        [list(['l1']), np.array([1, 2]), {'alpha': 0.7406154516747153},\n",
    "            0.2013880862681147, 0.7406154516747153],\n",
    "        [list(['l1']), np.array([1, 2]), {'alpha': 0.8509374761370117},\n",
    "            0.20143363961627603, 0.8509374761370117],\n",
    "        [list(['l1']), np.array([1, 2]), {'alpha': 0.9809565564007693},\n",
    "            0.20148678375852938, 0.9809565564007693]], dtype=object),\n",
    "        columns=['levels', 'lags', 'params', 'mean_absolute_error', 'alpha'],\n",
    "        index=pd.Index([9, 3, 4, 6, 8, 1, 0, 5, 7, 2], dtype='int64')\n",
    "    )\n",
    "\n",
    "    expected_results['mean_absolute_error'] = expected_results['mean_absolute_error'].astype(float)\n",
    "    expected_results['alpha'] = expected_results['alpha'].astype(float)\n",
    "\n",
    "    pd.testing.assert_frame_equal(results, expected_results)\n",
    "    \n",
    "test_results_output_bayesian_search_forecaster_multivariate_optuna_engine_ForecasterAutoregMultiVariate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1177: UserWarning: The 'lags_grid' argument is deprecated and will be removed in a future version. Use the 'search_space' argument to define the candidate values for the lags. Example: {'lags' : trial.suggest_categorical('lags', [3, 5])}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a151eed476145e69acda1a6a4eb11a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/skforecast_11_py11/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {'l1': 4, 'l2': [2, 3]} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.23598059857016607}</td>\n",
       "      <td>0.193081</td>\n",
       "      <td>0.235981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.193174</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.4441865222328282}</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.444187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.53623586010342}</td>\n",
       "      <td>0.193252</td>\n",
       "      <td>0.536236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.7252189487445193}</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>0.725219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.201371</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.7406154516747153}</td>\n",
       "      <td>0.201388</td>\n",
       "      <td>0.740615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.8509374761370117}</td>\n",
       "      <td>0.201434</td>\n",
       "      <td>0.850937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.201487</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  levels                                lags                          params  \\\n",
       "9   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}  {'alpha': 0.23598059857016607}   \n",
       "3   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}    {'alpha': 0.398196343012209}   \n",
       "4   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.4441865222328282}   \n",
       "6   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}     {'alpha': 0.53623586010342}   \n",
       "8   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.7252189487445193}   \n",
       "1   [l1]                              [1, 2]   {'alpha': 0.5558016213920624}   \n",
       "0   [l1]                              [1, 2]   {'alpha': 0.6995044937418831}   \n",
       "5   [l1]                              [1, 2]   {'alpha': 0.7406154516747153}   \n",
       "7   [l1]                              [1, 2]   {'alpha': 0.8509374761370117}   \n",
       "2   [l1]                              [1, 2]   {'alpha': 0.9809565564007693}   \n",
       "\n",
       "   mean_absolute_error     alpha  \n",
       "9             0.193081  0.235981  \n",
       "3             0.193174  0.398196  \n",
       "4             0.193200  0.444187  \n",
       "6             0.193252  0.536236  \n",
       "8             0.193356  0.725219  \n",
       "1             0.201311  0.555802  \n",
       "0             0.201371  0.699504  \n",
       "5             0.201388  0.740615  \n",
       "7             0.201434  0.850937  \n",
       "2             0.201487  0.980957  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor = Ridge(random_state=123),\n",
    "                    level     = 'l1',\n",
    "                    lags      = 2,\n",
    "                    steps     = 3\n",
    "                )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 1e-2, 1.0),\n",
    "        'lags'  : trial.suggest_categorical('lags', [2, {'l1': 4, 'l2': [2, 3]}])\n",
    "        }\n",
    "\n",
    "    return search_space\n",
    "\n",
    "results = bayesian_search_forecaster_multivariate(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                steps              = steps,\n",
    "                search_space       = search_space,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = False,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False,\n",
    "                engine             = 'optuna'\n",
    "            )[0]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['l1']), {'l1': array([1, 2, 3, 4]), 'l2': array([2, 3])},\n",
       "        {'alpha': 0.23598059857016607}, 0.19308110319514993,\n",
       "        0.23598059857016607],\n",
       "       [list(['l1']), {'l1': array([1, 2, 3, 4]), 'l2': array([2, 3])},\n",
       "        {'alpha': 0.398196343012209}, 0.1931744420708601,\n",
       "        0.398196343012209],\n",
       "       [list(['l1']), {'l1': array([1, 2, 3, 4]), 'l2': array([2, 3])},\n",
       "        {'alpha': 0.4441865222328282}, 0.1932004954044704,\n",
       "        0.4441865222328282],\n",
       "       [list(['l1']), {'l1': array([1, 2, 3, 4]), 'l2': array([2, 3])},\n",
       "        {'alpha': 0.53623586010342}, 0.19325210858832276,\n",
       "        0.53623586010342],\n",
       "       [list(['l1']), {'l1': array([1, 2, 3, 4]), 'l2': array([2, 3])},\n",
       "        {'alpha': 0.7252189487445193}, 0.19335589494249983,\n",
       "        0.7252189487445193],\n",
       "       [list(['l1']), array([1, 2]), {'alpha': 0.5558016213920624},\n",
       "        0.20131081099888368, 0.5558016213920624],\n",
       "       [list(['l1']), array([1, 2]), {'alpha': 0.6995044937418831},\n",
       "        0.2013710017368262, 0.6995044937418831],\n",
       "       [list(['l1']), array([1, 2]), {'alpha': 0.7406154516747153},\n",
       "        0.2013880862681147, 0.7406154516747153],\n",
       "       [list(['l1']), array([1, 2]), {'alpha': 0.8509374761370117},\n",
       "        0.20143363961627603, 0.8509374761370117],\n",
       "       [list(['l1']), array([1, 2]), {'alpha': 0.9809565564007693},\n",
       "        0.20148678375852938, 0.9809565564007693]], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['levels', 'lags', 'params', 'mean_absolute_error', 'alpha'], dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([9, 3, 4, 6, 8, 1, 0, 5, 7, 2], dtype='int64')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_results = pd.DataFrame(\n",
    "    np.array([[list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "        {'alpha': 0.23598059857016607}, 0.19308110319514993,\n",
    "        0.23598059857016607],\n",
    "       [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "        {'alpha': 0.398196343012209}, 0.1931744420708601,\n",
    "        0.398196343012209],\n",
    "       [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "        {'alpha': 0.4441865222328282}, 0.1932004954044704,\n",
    "        0.4441865222328282],\n",
    "       [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "        {'alpha': 0.53623586010342}, 0.19325210858832276,\n",
    "        0.53623586010342],\n",
    "       [list(['l1']), {'l1': np.array([1, 2, 3, 4]), 'l2': np.array([2, 3])},\n",
    "        {'alpha': 0.7252189487445193}, 0.19335589494249983,\n",
    "        0.7252189487445193],\n",
    "       [list(['l1']), np.array([1, 2]), {'alpha': 0.5558016213920624},\n",
    "        0.20131081099888368, 0.5558016213920624],\n",
    "       [list(['l1']), np.array([1, 2]), {'alpha': 0.6995044937418831},\n",
    "        0.2013710017368262, 0.6995044937418831],\n",
    "       [list(['l1']), np.array([1, 2]), {'alpha': 0.7406154516747153},\n",
    "        0.2013880862681147, 0.7406154516747153],\n",
    "       [list(['l1']), np.array([1, 2]), {'alpha': 0.8509374761370117},\n",
    "        0.20143363961627603, 0.8509374761370117],\n",
    "       [list(['l1']), np.array([1, 2]), {'alpha': 0.9809565564007693},\n",
    "        0.20148678375852938, 0.9809565564007693]], dtype=object),\n",
    "    columns=['levels', 'lags', 'params', 'mean_absolute_error', 'alpha'],\n",
    "    index=pd.Index([9, 3, 4, 6, 8, 1, 0, 5, 7, 2], dtype='int64')\n",
    ")\n",
    "\n",
    "expected_results['mean_absolute_error'] = expected_results['mean_absolute_error'].astype(float)\n",
    "expected_results['alpha'] = expected_results['alpha'].astype(float)\n",
    "    \n",
    "pd.testing.assert_frame_equal(results, expected_results, check_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
