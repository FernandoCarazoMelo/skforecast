{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and lags search: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter and lag tuning involves systematically testing different values or combinations of hyperparameters (and/or lags) to find the optimal configuration that gives the best performance. The **skforecast** library provides two different methods to evaluate each candidate configuration:\n",
    "\n",
    "+ Backtesting: In this method, the model predicts several steps ahead in each iteration, using the same forecast horizon and retraining frequency strategy that would be used if the model were deployed. This simulates a real forecasting scenario where the model is retrained and updated over time.\n",
    "\n",
    "+ One-Step Ahead: Evaluates the model using only one-step-ahead predictions. This method is faster because it requires fewer iterations, but it only tests the model's performance in the immediate next time step.\n",
    "\n",
    "Each method uses a different evaluation strategy, so they may produce different results. However, in the long run, both methods are expected to converge to similar selections of optimal hyperparameters. The one-step-ahead method is much faster than backtesting because it requires fewer iterations, but it only tests the model's performance in the immediate next time step. It is recommended to backtest the final model for a more accurate multi-step performance estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document compares the results of each approach when applied to different forecasters and datasets. To do this, the skforecast functions `grid_search_forecaster`, `bayesian_search_forecaster`, `grid_search_forecaster_multiseries` and `bayesian_search_forecaster_multiseries` are used to search for the optimal hyperparameters and lags for each forecaster using the backtesting and one-step-ahead methods, respectively. The search is performed on the validation dataset, and the best configuration is then backtested on the test dataset. The time required to perform the search for each method is recorded, as is the performance of the best configuration found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!Mostrar plot con los resultados!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from copy import copy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import bayesian_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compare results using backtesting and one step ahead\n",
    "# ==============================================================================\n",
    "def grid_search_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    lags_grid,\n",
    "    param_grid,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of grid search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1 = grid_search_forecaster(\n",
    "                    forecaster         = forecaster,\n",
    "                    y                  = data.loc[:end_validation, target],\n",
    "                    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    steps              = steps,\n",
    "                    refit              = False,\n",
    "                    metric             = metric,\n",
    "                    initial_train_size = len(data.loc[:end_train]),\n",
    "                    method             = 'backtesting',\n",
    "                    fixed_train_size   = False,\n",
    "                    return_best        = True,\n",
    "                    n_jobs             = 'auto',\n",
    "                    verbose            = False,\n",
    "                    show_progress      = True\n",
    "                )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster(\n",
    "                                forecaster          = forecaster,\n",
    "                                y                   = data.loc[:, target],\n",
    "                                exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                                initial_train_size  = len(data.loc[:end_validation]),\n",
    "                                steps               = steps,\n",
    "                                metric              = metric,\n",
    "                                verbose             = False,\n",
    "                                show_progress       = False\n",
    "                             )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2 = grid_search_forecaster(\n",
    "                    forecaster         = forecaster,\n",
    "                    y                  = data.loc[:end_validation, target],\n",
    "                    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    metric             = metric,\n",
    "                    initial_train_size = len(data.loc[:end_train]),\n",
    "                    method             = 'one_step_ahead',\n",
    "                    return_best        = True,\n",
    "                    verbose            = False,\n",
    "                    show_progress      = True\n",
    "                )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster(\n",
    "                                forecaster          = forecaster,\n",
    "                                y                   = data.loc[:, target],\n",
    "                                exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                                initial_train_size  = len(data.loc[:end_validation]),\n",
    "                                steps               = steps,\n",
    "                                metric              = metric,\n",
    "                                verbose             = False,\n",
    "                                show_progress       = False\n",
    "                             )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "    \n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n",
    "\n",
    "\n",
    "def bayesian_search_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    search_space,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of bayesian search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "\n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1, _ = bayesian_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data.loc[:end_validation, target],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        refit              = False,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'backtesting',\n",
    "                        fixed_train_size   = False,\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        n_jobs             = 'auto',\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, pred_1 = backtesting_forecaster(\n",
    "                            forecaster          = forecaster,\n",
    "                            y                   = data.loc[:, target],\n",
    "                            exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                            initial_train_size  = len(data.loc[:end_validation]),\n",
    "                            steps               = steps,\n",
    "                            metric              = metric,\n",
    "                            verbose             = False,\n",
    "                            show_progress       = False\n",
    "                        )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2, _ = bayesian_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data.loc[:end_validation, target],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        steps              = steps,\n",
    "                        search_space       = search_space,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'one_step_ahead',\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, pred_2 = backtesting_forecaster(\n",
    "                            forecaster          = forecaster,\n",
    "                            y                   = data.loc[:, target],\n",
    "                            exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                            initial_train_size  = len(data.loc[:end_validation]),\n",
    "                            steps               = steps,\n",
    "                            metric              = metric,\n",
    "                            verbose             = False,\n",
    "                            show_progress       = False\n",
    "                        )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "\n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table to store results\n",
    "# ==============================================================================\n",
    "results_grid_search = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"forecaster\",\n",
    "        \"time_search_backtesting\",\n",
    "        \"time_search_one_step\",\n",
    "        \"metric_backtesting\",\n",
    "        \"metric_one_step\",\n",
    "    ],\n",
    "    index=[\n",
    "        \"h2o\",\n",
    "        \"bike_sharing_extended_features\",\n",
    "        \"website_visits\",\n",
    "        \"vic_electricity\",\n",
    "    ]\n",
    ")\n",
    "results_bayesian_search = results_grid_search.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecaster Autoreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: H2O dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\",\n",
    "    raw=False,\n",
    "    verbose=False,\n",
    ")\n",
    "end_train = \"2001-01-01 23:59:00\"\n",
    "end_validation = \"2006-01-01 23:59:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f896ce4a485409c80aedd9b74517133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7fdf16a1f548ecab005770c410fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3 20] \n",
      "  Parameters: {'max_depth': 2, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.18240283368659635\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b407b7fa7574e24822057f95cb183b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ef1262966b4992aa80015ccfa8a701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 2, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.16147435680094147\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 1.0854952335357666\n",
      "Execution time one step ahead: 0.2179419994354248\n",
      "Same lags  : False\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3 20]\n",
      "    params : {'max_depth': 2, 'n_estimators': 100}\n",
      "    metrics: 0.22615930424513603\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10]\n",
      "    params : {'max_depth': 2, 'n_estimators': 100}\n",
      "    metrics: 0.13519201944243026\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags      = 10\n",
    "            )\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'x',\n",
    "    exog_features           = None,\n",
    "    steps                   = 12,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"h2o\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: Bike sharing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset('bike_sharing_extended_features', verbose=False)\n",
    "end_train = '2012-03-31 23:59:00'\n",
    "end_validation = '2012-08-31 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [\n",
    "    'month_sin', \n",
    "    'month_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos',\n",
    "    'week_day_sin',\n",
    "    'week_day_cos',\n",
    "    'hour_day_sin',\n",
    "    'hour_day_cos',\n",
    "    'sunrise_hour_sin',\n",
    "    'sunrise_hour_cos',\n",
    "    'sunset_hour_sin',\n",
    "    'sunset_hour_cos',\n",
    "    'holiday_previous_day',\n",
    "    'holiday_next_day',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day',\n",
    "    'temp',\n",
    "    'holiday'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b30e2364dd4371a5e174d4121d7608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45aa26bc71f48ef94ef7216832b51d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m lags_grid \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m72\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m167\u001b[39m, \u001b[38;5;241m168\u001b[39m, \u001b[38;5;241m169\u001b[39m)]\n\u001b[1;32m      8\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m time_1, time_2, metric_1, metric_2 \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster_to_benchmark\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m results_grid_search\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbike_sharing_extended_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, :] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mtype\u001b[39m(forecaster)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m     29\u001b[0m     time_1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     metric_2,\n\u001b[1;32m     33\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m, in \u001b[0;36mgrid_search_benchmark\u001b[0;34m(data, forecaster_to_benchmark, lags_grid, param_grid, end_train, end_validation, target, exog_features, steps, metric)\u001b[0m\n\u001b[1;32m     20\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m copy(forecaster_to_benchmark)\n\u001b[1;32m     21\u001b[0m start  \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 22\u001b[0m results_1 \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbacktesting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     40\u001b[0m time_1 \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:908\u001b[0m, in \u001b[0;36mgrid_search_forecaster\u001b[0;34m(forecaster, y, param_grid, metric, initial_train_size, steps, method, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, output_file)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`method` must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacktesting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_step_ahead\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m     )\n\u001b[1;32m    906\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))\n\u001b[0;32m--> 908\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_grid_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:1277\u001b[0m, in \u001b[0;36m_evaluate_grid_hyperparameters\u001b[0;34m(forecaster, y, param_grid, metric, initial_train_size, steps, method, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, output_file)\u001b[0m\n\u001b[1;32m   1273\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mset_params(params)\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacktesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1277\u001b[0m     metric_values \u001b[38;5;241m=\u001b[39m \u001b[43mbacktesting_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1293\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1294\u001b[0m     metric_values \u001b[38;5;241m=\u001b[39m metric_values\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:764\u001b[0m, in \u001b[0;36mbacktesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, binned_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(forecaster)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasterAutoregDirect\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    757\u001b[0m    forecaster\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m<\u001b[39m steps \u001b[38;5;241m+\u001b[39m gap:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    759\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using a ForecasterAutoregDirect, the combination of steps \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+ gap (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mgap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) cannot be greater than the `steps` parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    761\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeclared when the forecaster is initialized (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecaster\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    762\u001b[0m     )\n\u001b[0;32m--> 764\u001b[0m metric_values, backtest_predictions \u001b[38;5;241m=\u001b[39m \u001b[43m_backtesting_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinned_residuals\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbinned_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric_values, backtest_predictions\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:559\u001b[0m, in \u001b[0;36m_backtesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, binned_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    554\u001b[0m         pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39miloc[gap:, ]\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n\u001b[1;32m    558\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m     \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_predict_forecaster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(backtest_predictions)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(backtest_predictions, pd\u001b[38;5;241m.\u001b[39mSeries):\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:536\u001b[0m, in \u001b[0;36m_backtesting_forecaster.<locals>._fit_predict_forecaster\u001b[0;34m(y, exog, forecaster, interval, fold)\u001b[0m\n\u001b[1;32m    529\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    530\u001b[0m         np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m(test_no_gap_iloc_start, test_no_gap_iloc_end)))\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;241m+\u001b[39m gap\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnext_window_exog\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     pred \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mpredict_interval(\n\u001b[1;32m    543\u001b[0m                steps               \u001b[38;5;241m=\u001b[39m steps,\n\u001b[1;32m    544\u001b[0m                last_window         \u001b[38;5;241m=\u001b[39m last_window_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m                binned_residuals    \u001b[38;5;241m=\u001b[39m binned_residuals,\n\u001b[1;32m    551\u001b[0m            )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:925\u001b[0m, in \u001b[0;36mForecasterAutoreg.predict\u001b[0;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03mPredict n steps ahead. It is an recursive process in which, each prediction,\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03mis used as a predictor for the next step.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    921\u001b[0m last_window_values, last_window_index, exog_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_predict_inputs(\n\u001b[1;32m    922\u001b[0m     steps\u001b[38;5;241m=\u001b[39msteps, last_window\u001b[38;5;241m=\u001b[39mlast_window, exog\u001b[38;5;241m=\u001b[39mexog\n\u001b[1;32m    923\u001b[0m )\n\u001b[0;32m--> 925\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog_values\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiator\u001b[38;5;241m.\u001b[39minverse_transform_next_window(predictions)\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:824\u001b[0m, in \u001b[0;36mForecasterAutoreg._recursive_predict\u001b[0;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# Suppress scikit-learn warning: \"X does not have valid feature names,\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# but NoOpTransformer was fitted with feature names\".\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 824\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    825\u001b[0m     predictions[i] \u001b[38;5;241m=\u001b[39m prediction\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# Update `last_window` values. The first position is discarded and \u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# the new prediction is added at the end.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/lightgbm/sklearn.py:1032\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m predict_params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m# number of threads can have values with special meaning which is only applied\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# in the scikit-learn interface, these should not reach the c++ side as-is\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[43m_choose_param_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_threads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mpredict(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     X,\n\u001b[1;32m   1037\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params,\n\u001b[1;32m   1044\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/lightgbm/basic.py:660\u001b[0m, in \u001b[0;36m_choose_param_value\u001b[0;34m(main_param_name, params, default_value)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# if main param name was not found, search for an alias\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m aliases:\n\u001b[0;32m--> 660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    661\u001b[0m         params[main_param_name] \u001b[38;5;241m=\u001b[39m params[param]\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "\n",
    "results_grid_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03f993990a044e0958bd7fd8cc54991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1100, 'max_depth': 9, 'learning_rate': 0.010416860203198298, 'subsample': 0.2755690967419942, 'colsample_bytree': 0.6560647401138757, 'gamma': 0.10155013994756559, 'reg_alpha': 0.8864717945956972, 'reg_lambda': 0.014015836934027859}\n",
      "  Backtesting metric: 64.00591134157926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1694: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc123ecc4ad4b1d913d7e4efb104e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.022664761670265286, 'subsample': 0.11400878440779749, 'colsample_bytree': 0.9845292840882569, 'gamma': 0.004802254183477721, 'reg_alpha': 0.05556023765455381, 'reg_lambda': 0.22785658420818355}\n",
      "  Backtesting metric: 43.1076403895807\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 92.9964451789856\n",
      "Execution time one step ahead: 31.856090784072876\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1100, 'max_depth': 9, 'learning_rate': 0.010416860203198298, 'subsample': 0.2755690967419942, 'colsample_bytree': 0.6560647401138757, 'gamma': 0.10155013994756559, 'reg_alpha': 0.8864717945956972, 'reg_lambda': 0.014015836934027859}\n",
      "    metrics: 54.63516407405189\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.022664761670265286, 'subsample': 0.11400878440779749, 'colsample_bytree': 0.9845292840882569, 'gamma': 0.004802254183477721, 'reg_alpha': 0.05556023765455381, 'reg_lambda': 0.22785658420818355}\n",
      "    metrics: 54.76711825082381\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 400, 1200, step=100),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample'       : trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma'           : trial.suggest_float('gamma', 0, 1),\n",
    "        'reg_alpha'       : trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda'      : trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: website visits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"website_visits\", verbose=False)\n",
    "data['date'] = pd.to_datetime(data['date'], format='%d/%m/%y')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('1D')\n",
    "data = data.sort_index()\n",
    "data['month'] = data.index.month\n",
    "data['month_day'] = data.index.day\n",
    "data['week_day'] = data.index.day_of_week\n",
    "one_hot_encoder = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(sparse_output=False, drop='if_binary'),\n",
    "        ['month', 'week_day', 'month_day'],\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")\n",
    "data = one_hot_encoder.fit_transform(data)\n",
    "end_train = '2021-03-30 23:59:00'\n",
    "end_validation = '2021-06-30 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [col for col in data.columns if col.startswith(('month_', 'week_day_', 'month_day_'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b3c37160674521af40fbd2b9c86ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5d31530f1a4ea1b9d9ea9a67e45147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 10.0}\n",
      "  Backtesting metric: 217.4710279660212\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ce07849efc4dad9bbafb6e330c0813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08549b2b307453a8c845f663c5f5bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 2.154434690031882}\n",
      "  Backtesting metric: 0.13819498740066696\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 3.8975088596343994\n",
      "Execution time one step ahead: 0.33811140060424805\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 10.0}\n",
      "    metrics: 165.59443777438304\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 2.154434690031882}\n",
      "    metrics: 164.06965690085286\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor     = Ridge(random_state=123),\n",
    "                 transformer_y = StandardScaler(),\n",
    "                 lags          = 10\n",
    "             )\n",
    "lags_grid = [7, 14, 21, [7, 14, 21]]\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 10)}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 7,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"website_visits\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd36433029cc42638b7300003687c384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 1.2524531789882662}\n",
      "  Backtesting metric: 224.33854613853265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1694: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce66ee9e22bb4e1e8bbf2d2166a1ca92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 2.083580929967405}\n",
      "  Backtesting metric: 0.13822004658108406\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 2.093299627304077\n",
      "Execution time one step ahead: 0.363466739654541\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 1.2524531789882662}\n",
      "    metrics: 166.84400582475766\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 2.083580929967405}\n",
      "    metrics: 164.24239262308248\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor     = Ridge(random_state=123),\n",
    "                 transformer_y = StandardScaler(),\n",
    "                 lags          = 10\n",
    "             )\n",
    "lags_grid = [7, 14, 21, [7, 14, 21]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 0.001, 1000, log=True),\n",
    "        'lags'  : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 7,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"website_visits\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: electricity consumption dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5952/1461443256.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(rule=\"H\", closed=\"left\", label=\"right\")\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name='vic_electricity', raw=False, verbose=False)\n",
    "data = data.drop(columns=\"Date\")\n",
    "data = (\n",
    "    data\n",
    "    .resample(rule=\"h\", closed=\"left\", label=\"right\")\n",
    "    .agg({\n",
    "        \"Demand\": \"mean\",\n",
    "        \"Temperature\": \"mean\",\n",
    "        \"Holiday\": \"mean\",\n",
    "    })\n",
    ")\n",
    "data = data.loc['2012-01-01 00:00:00': '2014-12-30 23:00:00'].copy()\n",
    "end_train = '2013-12-31 23:59:00'\n",
    "end_validation = '2014-11-30 23:59:00'\n",
    "data_train = data.loc[: end_train, :].copy()\n",
    "data_val   = data.loc[end_train:end_validation, :].copy()\n",
    "data_test  = data.loc[end_validation:, :].copy()\n",
    "exog_features = ['Temperature', 'Holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e35ffb942254b94b1610576e327eb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1e53db330a42b298f0eee29d49fd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Backtesting metric: 204.9942009003756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1202: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668c37fc0f1d4305b35c25d28af21419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac14f68c0a44db6b139d868933fab3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Backtesting metric: 63.72303165763874\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 505.49670457839966\n",
      "Execution time one step ahead: 19.314216375350952\n",
      "Same lags  : False\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "    metrics: 245.7862163569872\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "    metrics: 232.4500132249965\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'Demand',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"vic_electricity\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054610f1642244a18a845e1cefdc6fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.06908111764347266, 'subsample': 0.4582398297973883, 'colsample_bytree': 0.7641958651588321, 'gamma': 0.18249173045349998, 'reg_alpha': 0.17545175614749253, 'reg_lambda': 0.5315513738418384}\n",
      "  Backtesting metric: 191.8626391693285\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1694: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68a6c6a43e343f780db1ca5a062606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.05679576034204338, 'subsample': 0.10725502906361839, 'colsample_bytree': 0.9892976403836156, 'gamma': 0.006453374219829056, 'reg_alpha': 0.0038381442337546146, 'reg_lambda': 0.24053684218482807}\n",
      "  Backtesting metric: 55.35922291628681\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 165.5522973537445\n",
      "Execution time one step ahead: 30.94758677482605\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.06908111764347266, 'subsample': 0.4582398297973883, 'colsample_bytree': 0.7641958651588321, 'gamma': 0.18249173045349998, 'reg_alpha': 0.17545175614749253, 'reg_lambda': 0.5315513738418384}\n",
      "    metrics: 231.47139120775364\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.05679576034204338, 'subsample': 0.10725502906361839, 'colsample_bytree': 0.9892976403836156, 'gamma': 0.006453374219829056, 'reg_alpha': 0.0038381442337546146, 'reg_lambda': 0.24053684218482807}\n",
      "    metrics: 226.56310817545923\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 400, 1200, step=100),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample'       : trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma'           : trial.suggest_float('gamma', 0, 1),\n",
    "        'reg_alpha'       : trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda'      : trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'Demand',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"vic_electricity\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecaster AutoregDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca4fd564d244327a98ccca2d2b2ba03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90753c09f5a4f80acc239a7bd70c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'alpha': 1000.0}\n",
      "  Backtesting metric: 70.97601529392342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1202: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f790ea549b941aba202a388a76cf73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5b63a869614016b5e5f36b273389f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'alpha': 10.0}\n",
      "  Backtesting metric: 149.21210803148887\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 70.05097031593323\n",
      "Execution time one step ahead: 2.793152332305908\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'alpha': 1000.0}\n",
      "    metrics: 67.37528369177734\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'alpha': 10.0}\n",
      "    metrics: 67.9071044889169\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset('bike_sharing_extended_features', verbose=False)\n",
    "end_train = '2012-03-31 23:59:00'\n",
    "end_validation = '2012-08-31 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [\n",
    "    'month_sin', \n",
    "    'month_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos',\n",
    "    'week_day_sin',\n",
    "    'week_day_cos',\n",
    "    'hour_day_sin',\n",
    "    'hour_day_cos',\n",
    "    'sunrise_hour_sin',\n",
    "    'sunrise_hour_cos',\n",
    "    'sunset_hour_sin',\n",
    "    'sunset_hour_cos',\n",
    "    'holiday_previous_day',\n",
    "    'holiday_next_day',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day',\n",
    "    'temp',\n",
    "    'holiday'\n",
    "]\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = Ridge(random_state=123),\n",
    "                 steps     = 5,\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 10)}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad41d3b65b494e019dae417622e61c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'alpha': 925.1006260111275}\n",
      "  Backtesting metric: 70.99353356420917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1694: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6643e8163243b7989d7462d6a187f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'alpha': 6.403328042606579}\n",
      "  Backtesting metric: 149.21303984528487\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 47.63146901130676\n",
      "Execution time one step ahead: 2.4899234771728516\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'alpha': 925.1006260111275}\n",
      "    metrics: 67.37630319670156\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'alpha': 6.403328042606579}\n",
      "    metrics: 67.91191634391751\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = Ridge(random_state=123),\n",
    "                 steps     = 5,\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 0.001, 1000, log=True),\n",
    "        'lags'  : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>time_search_backtesting</th>\n",
       "      <th>time_search_one_step</th>\n",
       "      <th>metric_backtesting</th>\n",
       "      <th>metric_one_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>items_sales</th>\n",
       "      <td>ForecasterAutoregMultiVariate</td>\n",
       "      <td>2.846243</td>\n",
       "      <td>1.958241</td>\n",
       "      <td>1.040931</td>\n",
       "      <td>1.048112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                forecaster time_search_backtesting  \\\n",
       "items_sales  ForecasterAutoregMultiVariate                2.846243   \n",
       "\n",
       "            time_search_one_step metric_backtesting metric_one_step  \n",
       "items_sales             1.958241           1.040931        1.048112  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>time_search_backtesting</th>\n",
       "      <th>time_search_one_step</th>\n",
       "      <th>metric_backtesting</th>\n",
       "      <th>metric_one_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h2o</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bike_sharing_extended_features</th>\n",
       "      <td>ForecasterAutoregDirect</td>\n",
       "      <td>47.631469</td>\n",
       "      <td>2.489923</td>\n",
       "      <td>67.376303</td>\n",
       "      <td>67.911916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website_visits</th>\n",
       "      <td>ForecasterAutoreg</td>\n",
       "      <td>2.080067</td>\n",
       "      <td>0.377988</td>\n",
       "      <td>166.844006</td>\n",
       "      <td>164.242393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic_electricity</th>\n",
       "      <td>ForecasterAutoreg</td>\n",
       "      <td>165.552297</td>\n",
       "      <td>30.947587</td>\n",
       "      <td>231.471391</td>\n",
       "      <td>226.563108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             forecaster  \\\n",
       "h2o                                                 NaN   \n",
       "bike_sharing_extended_features  ForecasterAutoregDirect   \n",
       "website_visits                        ForecasterAutoreg   \n",
       "vic_electricity                       ForecasterAutoreg   \n",
       "\n",
       "                               time_search_backtesting time_search_one_step  \\\n",
       "h2o                                                NaN                  NaN   \n",
       "bike_sharing_extended_features               47.631469             2.489923   \n",
       "website_visits                                2.080067             0.377988   \n",
       "vic_electricity                             165.552297            30.947587   \n",
       "\n",
       "                               metric_backtesting metric_one_step  \n",
       "h2o                                           NaN             NaN  \n",
       "bike_sharing_extended_features          67.376303       67.911916  \n",
       "website_visits                         166.844006      164.242393  \n",
       "vic_electricity                        231.471391      226.563108  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bayesian_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForecasterAutoregMultiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compare results using backtesting and one step ahead\n",
    "# ==============================================================================\n",
    "def grid_search_multiseries_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    lags_grid,\n",
    "    param_grid,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    levels,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of grid search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1 = grid_search_forecaster_multiseries(\n",
    "                    forecaster         = forecaster,\n",
    "                    series             = data.loc[:end_validation, levels],\n",
    "                    levels             = levels,\n",
    "                    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    steps              = steps,\n",
    "                    refit              = False,\n",
    "                    metric             = metric,\n",
    "                    initial_train_size = len(data.loc[:end_train]),\n",
    "                    method             = 'backtesting',\n",
    "                    fixed_train_size   = False,\n",
    "                    return_best        = True,\n",
    "                    n_jobs             = 'auto',\n",
    "                    verbose            = False,\n",
    "                    show_progress      = True\n",
    "                )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, pred_1 = backtesting_forecaster_multiseries(\n",
    "                            forecaster          = forecaster,\n",
    "                            series              = data.loc[:, levels],\n",
    "                            exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                            initial_train_size  = len(data.loc[:end_validation]),\n",
    "                            levels              = levels,\n",
    "                            steps               = steps,\n",
    "                            metric              = metric,\n",
    "                            verbose             = False,\n",
    "                            show_progress       = False\n",
    "                        )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2 = grid_search_forecaster_multiseries(\n",
    "                    forecaster         = forecaster,\n",
    "                    series             = data.loc[:end_validation, levels],\n",
    "                    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                    levels             = levels,\n",
    "                    param_grid         = param_grid,\n",
    "                    lags_grid          = lags_grid,\n",
    "                    metric             = metric,\n",
    "                    initial_train_size = len(data.loc[:end_train]),\n",
    "                    method             = 'one_step_ahead',\n",
    "                    return_best        = True,\n",
    "                    verbose            = False,\n",
    "                    show_progress      = True\n",
    "                )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, pred_2 = backtesting_forecaster_multiseries(\n",
    "                            forecaster          = forecaster,\n",
    "                            series              = data.loc[:, levels],\n",
    "                            exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "                            levels              = levels,\n",
    "                            initial_train_size  = len(data.loc[:end_validation]),\n",
    "                            steps               = steps,\n",
    "                            metric              = metric,\n",
    "                            verbose             = False,\n",
    "                            show_progress       = False\n",
    "                        )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "    \n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n",
    "\n",
    "\n",
    "def bayesian_search_multiseries_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    search_space,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    levels,\n",
    "    #target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of bayesian search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "\n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1, _ = bayesian_search_forecaster_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = data.loc[:end_validation, levels],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        levels             = levels,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        refit              = False,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'backtesting',\n",
    "                        fixed_train_size   = False,\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        n_jobs             = 'auto',\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        levels              = levels,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2, _ = bayesian_search_forecaster_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = data.loc[:end_validation, levels],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        levels             = levels,\n",
    "                        steps              = steps,\n",
    "                        search_space       = search_space,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'one_step_ahead',\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        levels              = levels,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "\n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table to store results\n",
    "# ==============================================================================\n",
    "results_grid_search = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"forecaster\",\n",
    "        \"time_search_backtesting\",\n",
    "        \"time_search_one_step\",\n",
    "        \"metric_backtesting\",\n",
    "        \"metric_one_step\",\n",
    "    ],\n",
    "    index=[\n",
    "        \"items_sales\",\n",
    "    ]\n",
    ")\n",
    "results_bayesian_search = results_grid_search.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-05-15 23:59:00'\n",
    "end_validation = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "exog_features = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6fc51033b2498b926afc9417ce8f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d4c0c5277e4379aabc32694e8aa6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 2.281107158900761\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1708: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  if method == 'one_step_ahead':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a294674b3044fb8feee78f8871d264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2225c118854addbb97f7afd206b29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'max_depth': 3, 'n_estimators': 20}\n",
      "  Backtesting metric: 1.7788941749503342\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 1.6306736469268799\n",
      "Execution time one step ahead: 0.4385857582092285\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.43839579684015\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'max_depth': 3, 'n_estimators': 20}\n",
      "    metrics: 1.6408350320514384\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = \"ordinal\",\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid ={\n",
    "    '24 lags': 24,\n",
    "    '48 lags': 48\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20],\n",
    "    'max_depth': [3, 7]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"items_sales\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baac086910f45ed9b5d033eb76e8fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'n_estimators': 47, 'max_depth': 10, 'learning_rate': 0.10582782597735779}\n",
      "  Backtesting metric: 1.9340570479344343\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07b799bac5438bb23bf1b4f64c340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'n_estimators': 35, 'max_depth': 3, 'learning_rate': 0.3241126270021177}\n",
      "  Backtesting metric: 1.586531587692841\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 5.379574775695801\n",
      "Execution time one step ahead: 1.9274694919586182\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'n_estimators': 47, 'max_depth': 10, 'learning_rate': 0.10582782597735779}\n",
      "    metrics: 1.2509853110935267\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'n_estimators': 35, 'max_depth': 3, 'learning_rate': 0.3241126270021177}\n",
      "    metrics: 1.1872894242820913\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = \"ordinal\",\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid = [48, 72]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 50),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = bayesian_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"items_sales\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForecasterAutoregMultiVariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-05-15 23:59:00'\n",
    "end_validation = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "exog_features = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:83: IgnoredArgumentWarning: `levels` argument have no use when the forecaster is of type `ForecasterAutoregMultiVariate`. The level of this forecaster is 'item_1', to predict another level, change the `level` argument when initializing the forecaster. \n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=IgnoredArgumentWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffc0af89a22431ca17e4ec3ddb241a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd9e9ac72b948cc9699044133168f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 0.6819591626794975\n",
      "  Levels: ['item_1']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1708: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  if method == 'one_step_ahead':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a15ecb3b9044f7be2adf7344e1eceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9719554fe241ab95a46612b3aa98fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 0.743055091298141\n",
      "  Levels: ['item_1']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 2.846242666244507\n",
      "Execution time one step ahead: 1.9582414627075195\n",
      "Same lags  : False\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.0409310906937037\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.0481118869071948\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 steps              = 5,\n",
    "                 level              = 'item_1',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid ={\n",
    "    '24 lags': 24,\n",
    "    '48 lags': 48\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20],\n",
    "    'max_depth': [3, 7]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "\n",
    "results_grid_search.loc[\"items_sales\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection.model_selection import _evaluate_grid_hyperparameters\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\",\n",
    "    raw=True,\n",
    "    kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False,\n",
    ")\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"], format=\"%Y-%m-%d\")\n",
    "data = data.set_index(\"datetime\")\n",
    "data = data.asfreq(\"MS\")\n",
    "data = data[[\"y\"]]\n",
    "data = data.sort_index()\n",
    "end_train = \"2001-01-01 23:59:00\"\n",
    "end_validation = \"2006-01-01 23:59:00\"\n",
    "target = \"y\"\n",
    "exog_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1202: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags      = 10\n",
    "            )\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    steps              = 1,\n",
    "    method             = 'backtesting',\n",
    "    refit              = False,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    fixed_train_size   = False,\n",
    "    return_best        = False,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    method             = 'one_step_ahead',\n",
    "    return_best        = False,\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "assert results_backtesting.equals(results_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _calculate_metrics_multiseries vs _calculate_metrics_multiseries_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = 'ordinal',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "X, y = forecaster.create_train_X_y(series=data)\n",
    "X_train = X.loc[X.index <= end_train, :]\n",
    "y_train = y.loc[y.index <= end_train]\n",
    "X_test = X.loc[X.index > end_train, :]\n",
    "y_test = y.loc[y.index > end_train]\n",
    "\n",
    "forecaster.regressor.fit(X_train, y_train)\n",
    "pred = forecaster.regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _calculate_metrics_multiseries_one_step_ahead and _calculate_metrics_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics should be equal when using step=1 in backtesting\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "if forecaster.encoding in ['ordinal', 'ordinal_category']:\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(X_train[['_level_skforecast']]).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(X_test[['_level_skforecast']]).ravel()\n",
    "elif forecaster.encoding == 'onehot':\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_train.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_test.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "\n",
    "metrics_one_step_ahead = _calculate_metrics_multiseries_one_step_ahead(\n",
    "    y_true = y_test.to_numpy(),\n",
    "    y_true_index = y_test.index,\n",
    "    y_pred = pred,\n",
    "    y_pred_encoding = X_test_encoding,\n",
    "    y_train = y_train.to_numpy(),\n",
    "    y_train_index = y_train.index,\n",
    "    y_train_encoding = X_train_encoding,\n",
    "    levels = ['item_1', 'item_2', 'item_3'],\n",
    "    metrics = metrics,\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_one_step_ahead)\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries\n",
    "folds = _create_backtesting_folds(\n",
    "    data = data,\n",
    "    window_size = 24,\n",
    "    initial_train_size = len(data_train),\n",
    "    test_size = 1,\n",
    "    externally_fitted = False,\n",
    "    refit = False,\n",
    "    fixed_train_size = True,\n",
    "    gap = 0,\n",
    "    skip_folds = None,\n",
    "    allow_incomplete_fold = True,\n",
    "    return_all_indexes = False,\n",
    "    differentiation = None,\n",
    "    verbose = False\n",
    ")\n",
    "_, predictions = backtesting_forecaster_multiseries(\n",
    "    series=data,\n",
    "    forecaster=forecaster,\n",
    "    steps=1,\n",
    "    metric=metrics,\n",
    "    initial_train_size = len(data_train),\n",
    "    refit=False,\n",
    "    add_aggregated_metric=True,\n",
    "    show_progress=False\n",
    ")\n",
    "metrics_backtesting = _calculate_metrics_multiseries(\n",
    "    series = data,\n",
    "    predictions= predictions,\n",
    "    folds= folds,\n",
    "    span_index= data.index,\n",
    "    window_size = 24,\n",
    "    metrics= metrics,\n",
    "    levels= ['item_1', 'item_2', 'item_3'],\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_backtesting)\n",
    "\n",
    "assert metrics_backtesting.equals(metrics_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters_multiseries: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "exog_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1708: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  if method == 'one_step_ahead':\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "    lags               = 24,\n",
    "    encoding           = 'ordinal',\n",
    "    transformer_series = None,\n",
    "    transformer_exog   = None,\n",
    "    weight_func        = None,\n",
    "    series_weights     = None,\n",
    "    differentiation    = None,\n",
    "    dropna_from_series = False,\n",
    "    fit_kwargs         = None,\n",
    "    forecaster_id      = None\n",
    ")\n",
    "lags_grid = [3, 10]\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            steps                 = 1,\n",
    "                            metric                = metrics,\n",
    "                            aggregate_metric      = ['weighted_average', 'average', 'pooling'],\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            method                = 'backtesting',\n",
    "                            fixed_train_size      = True,\n",
    "                            gap                   = 0,\n",
    "                            skip_folds            = None,\n",
    "                            allow_incomplete_fold = True,\n",
    "                            levels                = None,\n",
    "                            exog                  = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            refit                 = False,\n",
    "                            n_jobs                = 'auto',\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False,\n",
    "                            suppress_warnings     = False\n",
    "                        )\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            metric                = metrics,\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            method                = 'one_step_ahead',\n",
    "                            exog                  = data.loc[:data_train, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False\n",
    "                        )\n",
    "\n",
    "assert results_backtesting.equals(results_one_step_ahead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
