{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and lags search: backtesting vs one-step-ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter and lag tuning involves systematically testing different values or combinations of hyperparameters (and/or lags) to find the optimal configuration that gives the best performance. The **skforecast** library provides two different methods to evaluate each candidate configuration:\n",
    "\n",
    "+ Backtesting: In this method, the model predicts several steps ahead in each iteration, using the same forecast horizon and retraining frequency strategy that would be used if the model were deployed. This simulates a real forecasting scenario where the model is retrained and updated over time.\n",
    "\n",
    "+ One-Step Ahead: Evaluates the model using only one-step-ahead predictions. This method is faster because it requires fewer iterations, but it only tests the model's performance in the immediate next time step.\n",
    "\n",
    "Each method uses a different evaluation strategy, so they may produce different results. However, in the long run, both methods are expected to converge to similar selections of optimal hyperparameters. The one-step-ahead method is much faster than backtesting because it requires fewer iterations, but it only tests the model's performance in the immediate next time step. It is recommended to backtest the final model for a more accurate multi-step performance estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document compares the results of each approach when applied to different forecasters and data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!Mostrar plot con los resultados!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from copy import copy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import bayesian_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compare results using backtesting and one step ahead\n",
    "# ==============================================================================\n",
    "def grid_search_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    lags_grid,\n",
    "    param_grid,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of grid search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1 = grid_search_forecaster(\n",
    "                forecaster         = forecaster,\n",
    "                y                  = data.loc[:end_validation, target],\n",
    "                exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                param_grid         = param_grid,\n",
    "                lags_grid          = lags_grid,\n",
    "                steps              = steps,\n",
    "                refit              = False,\n",
    "                metric             = metric,\n",
    "                initial_train_size = len(data.loc[:end_train]),\n",
    "                method             = 'backtesting',\n",
    "                fixed_train_size   = False,\n",
    "                return_best        = True,\n",
    "                n_jobs             = 'auto',\n",
    "                verbose            = False,\n",
    "                show_progress      = True\n",
    "            )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster(\n",
    "        forecaster          = forecaster,\n",
    "        y                   = data.loc[:, target],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2 = grid_search_forecaster(\n",
    "                forecaster         = forecaster,\n",
    "                y                  = data.loc[:end_validation, target],\n",
    "                exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                steps              = steps,\n",
    "                param_grid         = param_grid,\n",
    "                lags_grid          = lags_grid,\n",
    "                metric             = metric,\n",
    "                initial_train_size = len(data.loc[:end_train]),\n",
    "                method             = 'one_step_ahead',\n",
    "                return_best        = True,\n",
    "                verbose            = False,\n",
    "                show_progress      = True\n",
    "            )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster(\n",
    "        forecaster          = forecaster,\n",
    "        y                   = data.loc[:, target],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "    \n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n",
    "\n",
    "\n",
    "def bayesian_search_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    search_space,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of bayesian search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "\n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1, _ = bayesian_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data.loc[:end_validation, target],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        refit              = False,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'backtesting',\n",
    "                        fixed_train_size   = False,\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        n_jobs             = 'auto',\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster(\n",
    "        forecaster          = forecaster,\n",
    "        y                   = data.loc[:, target],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2, _ = bayesian_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data.loc[:end_validation, target],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        steps              = steps,\n",
    "                        search_space       = search_space,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'one_step_ahead',\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster(\n",
    "        forecaster          = forecaster,\n",
    "        y                   = data.loc[:, target],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "\n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table to store results\n",
    "# ==============================================================================\n",
    "results_grid_search = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"forecaster\",\n",
    "        \"time_search_backtesting\",\n",
    "        \"time_search_one_step\",\n",
    "        \"metric_backtesting\",\n",
    "        \"metric_one_step\",\n",
    "    ],\n",
    "    index=[\n",
    "        \"h2o\",\n",
    "        \"bike_sharing_extended_features\",\n",
    "        \"website_visits\",\n",
    "        \"vic_electricity\",\n",
    "    ]\n",
    ")\n",
    "results_bayesian_search = results_grid_search.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecaster Autoreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: H2O dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\",\n",
    "    raw=True,\n",
    "    kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False,\n",
    ")\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"], format=\"%Y-%m-%d\")\n",
    "data = data.set_index(\"datetime\")\n",
    "data = data.asfreq(\"MS\")\n",
    "data = data[[\"y\"]]\n",
    "data = data.sort_index()\n",
    "end_train = \"2001-01-01 23:59:00\"\n",
    "end_validation = \"2006-01-01 23:59:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6ca698c81548b29ef1e96f2a3ded11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33986197adc04ef9b676eef42e0afcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3 20] \n",
      "  Parameters: {'max_depth': 2, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.18240283368659635\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51f9b265c3648ab90259109283467f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0290382a4248b4a34a7e2daecc6522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 2, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.16147435680094147\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 1.0717644691467285\n",
      "Execution time one step ahead: 0.21580886840820312\n",
      "Same lags  : False\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3 20]\n",
      "    params : {'max_depth': 2, 'n_estimators': 100}\n",
      "    metrics: 0.22615930424513603\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10]\n",
      "    params : {'max_depth': 2, 'n_estimators': 100}\n",
      "    metrics: 0.13519201944243026\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags      = 10\n",
    "            )\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "time_1, time_2, metric_1, metric_2 = grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'y',\n",
    "    exog_features           = None,\n",
    "    steps                   = 12,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"h2o\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: Bike sharing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset('bike_sharing_extended_features', verbose=False)\n",
    "end_train = '2012-03-31 23:59:00'\n",
    "end_validation = '2012-08-31 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [\n",
    "    'month_sin', \n",
    "    'month_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos',\n",
    "    'week_day_sin',\n",
    "    'week_day_cos',\n",
    "    'hour_day_sin',\n",
    "    'hour_day_cos',\n",
    "    'sunrise_hour_sin',\n",
    "    'sunrise_hour_cos',\n",
    "    'sunset_hour_sin',\n",
    "    'sunset_hour_cos',\n",
    "    'holiday_previous_day',\n",
    "    'holiday_next_day',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day',\n",
    "    'temp',\n",
    "    'holiday'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120543ca7cc443179887e1f6d24c92fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824e3dc5a8914cc781cea1bda837be3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m lags_grid \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m72\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m167\u001b[39m, \u001b[38;5;241m168\u001b[39m, \u001b[38;5;241m169\u001b[39m)]\n\u001b[1;32m      8\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m]\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m \u001b[43mgrid_search_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster_to_benchmark\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m results_grid_search\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbike_sharing_extended_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, :] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mtype\u001b[39m(forecaster)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m     29\u001b[0m     time_1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     metric_2,\n\u001b[1;32m     33\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mgrid_search_benchmark\u001b[0;34m(data, forecaster_to_benchmark, lags_grid, param_grid, end_train, end_validation, target, exog_features, steps, metric)\u001b[0m\n\u001b[1;32m     20\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m copy(forecaster_to_benchmark)\n\u001b[1;32m     21\u001b[0m start  \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 22\u001b[0m results_1 \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexog_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbacktesting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     40\u001b[0m time_1 \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:909\u001b[0m, in \u001b[0;36mgrid_search_forecaster\u001b[0;34m(forecaster, y, param_grid, steps, metric, initial_train_size, method, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, output_file)\u001b[0m\n\u001b[1;32m    906\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbacktesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 909\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_grid_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     results \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters_one_step_ahead(\n\u001b[1;32m    931\u001b[0m         forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m    932\u001b[0m         y                     \u001b[38;5;241m=\u001b[39m y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         output_file           \u001b[38;5;241m=\u001b[39m output_file\n\u001b[1;32m    942\u001b[0m     )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:1256\u001b[0m, in \u001b[0;36m_evaluate_grid_hyperparameters\u001b[0;34m(forecaster, y, param_grid, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, output_file)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[1;32m   1255\u001b[0m     forecaster\u001b[38;5;241m.\u001b[39mset_params(params)\n\u001b[0;32m-> 1256\u001b[0m     metric_values \u001b[38;5;241m=\u001b[39m \u001b[43mbacktesting_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1272\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1273\u001b[0m     metric_values \u001b[38;5;241m=\u001b[39m metric_values\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m   1274\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1276\u001b[0m         category \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, \n\u001b[1;32m   1277\u001b[0m         message  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe forecaster will be fit.*\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1278\u001b[0m     )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:764\u001b[0m, in \u001b[0;36mbacktesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, binned_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(forecaster)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasterAutoregDirect\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    757\u001b[0m    forecaster\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m<\u001b[39m steps \u001b[38;5;241m+\u001b[39m gap:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    759\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using a ForecasterAutoregDirect, the combination of steps \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+ gap (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mgap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) cannot be greater than the `steps` parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    761\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeclared when the forecaster is initialized (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecaster\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    762\u001b[0m     )\n\u001b[0;32m--> 764\u001b[0m metric_values, backtest_predictions \u001b[38;5;241m=\u001b[39m \u001b[43m_backtesting_forecaster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinned_residuals\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbinned_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric_values, backtest_predictions\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:559\u001b[0m, in \u001b[0;36m_backtesting_forecaster\u001b[0;34m(forecaster, y, steps, metric, initial_train_size, fixed_train_size, gap, skip_folds, allow_incomplete_fold, exog, refit, interval, n_boot, random_state, in_sample_residuals, binned_residuals, n_jobs, verbose, show_progress)\u001b[0m\n\u001b[1;32m    554\u001b[0m         pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39miloc[gap:, ]\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred\n\u001b[1;32m    558\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m     \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_predict_forecaster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m backtest_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(backtest_predictions)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(backtest_predictions, pd\u001b[38;5;241m.\u001b[39mSeries):\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection/model_selection.py:536\u001b[0m, in \u001b[0;36m_backtesting_forecaster.<locals>._fit_predict_forecaster\u001b[0;34m(y, exog, forecaster, interval, fold)\u001b[0m\n\u001b[1;32m    529\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    530\u001b[0m         np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mrange\u001b[39m(test_no_gap_iloc_start, test_no_gap_iloc_end)))\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;241m+\u001b[39m gap\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m               \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m               \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnext_window_exog\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     pred \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mpredict_interval(\n\u001b[1;32m    543\u001b[0m                steps               \u001b[38;5;241m=\u001b[39m steps,\n\u001b[1;32m    544\u001b[0m                last_window         \u001b[38;5;241m=\u001b[39m last_window_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m                binned_residuals    \u001b[38;5;241m=\u001b[39m binned_residuals,\n\u001b[1;32m    551\u001b[0m            )\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:925\u001b[0m, in \u001b[0;36mForecasterAutoreg.predict\u001b[0;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03mPredict n steps ahead. It is an recursive process in which, each prediction,\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03mis used as a predictor for the next step.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    921\u001b[0m last_window_values, last_window_index, exog_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_predict_inputs(\n\u001b[1;32m    922\u001b[0m     steps\u001b[38;5;241m=\u001b[39msteps, last_window\u001b[38;5;241m=\u001b[39mlast_window, exog\u001b[38;5;241m=\u001b[39mexog\n\u001b[1;32m    923\u001b[0m )\n\u001b[0;32m--> 925\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog_values\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdifferentiator\u001b[38;5;241m.\u001b[39minverse_transform_next_window(predictions)\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/ForecasterAutoreg/ForecasterAutoreg.py:824\u001b[0m, in \u001b[0;36mForecasterAutoreg._recursive_predict\u001b[0;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# Suppress scikit-learn warning: \"X does not have valid feature names,\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# but NoOpTransformer was fitted with feature names\".\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 824\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    825\u001b[0m     predictions[i] \u001b[38;5;241m=\u001b[39m prediction\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# Update `last_window` values. The first position is discarded and \u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# the new prediction is added at the end.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/lightgbm/sklearn.py:1033\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m# number of threads can have values with special meaning which is only applied\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# in the scikit-learn interface, these should not reach the c++ side as-is\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m-> 1033\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_n_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_threads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mpredict(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     X,\n\u001b[1;32m   1037\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params,\n\u001b[1;32m   1044\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/lightgbm/sklearn.py:817\u001b[0m, in \u001b[0;36mLGBMModel._process_n_jobs\u001b[0;34m(self, n_jobs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert special values of n_jobs to their actual values according to the formulas that apply.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \n\u001b[1;32m    805\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03m    The value of n_jobs with special values converted to actual number of threads.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 817\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMCpuCount\u001b[49m\u001b[43m(\u001b[49m\u001b[43monly_physical_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_jobs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    819\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(_LGBMCpuCount(only_physical_cores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m n_jobs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/lightgbm/compat.py:266\u001b[0m, in \u001b[0;36m_LGBMCpuCount\u001b[0;34m(only_physical_cores)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_LGBMCpuCount\u001b[39m(only_physical_cores: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43monly_physical_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_physical_cores\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/parallel.py:638\u001b[0m, in \u001b[0;36mcpu_count\u001b[0;34m(only_physical_cores)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloky\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43monly_physical_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_physical_cores\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py:119\u001b[0m, in \u001b[0;36mcpu_count\u001b[0;34m(only_physical_cores)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# On Windows, attempting to use more than 61 CPUs would result in a\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# OS-level error. See https://bugs.python.org/issue26903. According to\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# https://learn.microsoft.com/en-us/windows/win32/procthread/processor-groups\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# it might be possible to go beyond with a lot of extra work but this\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# does not look easy.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     os_cpu_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(os_cpu_count, _MAX_WINDOWS_WORKERS)\n\u001b[0;32m--> 119\u001b[0m cpu_count_user \u001b[38;5;241m=\u001b[39m \u001b[43m_cpu_count_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos_cpu_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m aggregate_cpu_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmin\u001b[39m(os_cpu_count, cpu_count_user), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_physical_cores:\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py:224\u001b[0m, in \u001b[0;36m_cpu_count_user\u001b[0;34m(os_cpu_count)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Number of user defined available CPUs\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m cpu_count_affinity \u001b[38;5;241m=\u001b[39m _cpu_count_affinity(os_cpu_count)\n\u001b[0;32m--> 224\u001b[0m cpu_count_cgroup \u001b[38;5;241m=\u001b[39m \u001b[43m_cpu_count_cgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos_cpu_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# User defined soft-limit passed as a loky specific environment variable.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m cpu_count_loky \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOKY_MAX_CPU_COUNT\u001b[39m\u001b[38;5;124m\"\u001b[39m, os_cpu_count))\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py12/lib/python3.12/site-packages/joblib/externals/loky/backend/context.py:161\u001b[0m, in \u001b[0;36m_cpu_count_cgroup\u001b[0;34m(os_cpu_count)\u001b[0m\n\u001b[1;32m    157\u001b[0m         cpu_quota_us, cpu_period_us \u001b[38;5;241m=\u001b[39m fh\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cfs_quota_fname) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cfs_period_fname):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# cgroup v1\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html#management\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfs_quota_fname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    162\u001b[0m         cpu_quota_us \u001b[38;5;241m=\u001b[39m fh\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cfs_period_fname) \u001b[38;5;28;01mas\u001b[39;00m fh:\n",
      "File \u001b[0;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "\n",
    "results_grid_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292985a9e45c40f48a87d3e5d1a2ec1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1100, 'max_depth': 9, 'learning_rate': 0.010416860203198298, 'subsample': 0.2755690967419942, 'colsample_bytree': 0.6560647401138757, 'gamma': 0.10155013994756559, 'reg_alpha': 0.8864717945956972, 'reg_lambda': 0.014015836934027859}\n",
      "  Backtesting metric: 64.00591134157926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:2177: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f4a6fe6fb941b7ba7784f02967728a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.022664761670265286, 'subsample': 0.11400878440779749, 'colsample_bytree': 0.9845292840882569, 'gamma': 0.004802254183477721, 'reg_alpha': 0.05556023765455381, 'reg_lambda': 0.22785658420818355}\n",
      "  Backtesting metric: 43.1076403895807\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 96.7142424583435\n",
      "Execution time one step ahead: 32.7284996509552\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1100, 'max_depth': 9, 'learning_rate': 0.010416860203198298, 'subsample': 0.2755690967419942, 'colsample_bytree': 0.6560647401138757, 'gamma': 0.10155013994756559, 'reg_alpha': 0.8864717945956972, 'reg_lambda': 0.014015836934027859}\n",
      "    metrics: 54.63516407405189\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.022664761670265286, 'subsample': 0.11400878440779749, 'colsample_bytree': 0.9845292840882569, 'gamma': 0.004802254183477721, 'reg_alpha': 0.05556023765455381, 'reg_lambda': 0.22785658420818355}\n",
      "    metrics: 54.76711825082381\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 400, 1200, step=100),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample'       : trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma'           : trial.suggest_float('gamma', 0, 1),\n",
    "        'reg_alpha'       : trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda'      : trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: website visits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"website_visits\", raw=True, verbose=False)\n",
    "data['date'] = pd.to_datetime(data['date'], format='%d/%m/%y')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('1D')\n",
    "data = data.sort_index()\n",
    "data['month'] = data.index.month\n",
    "data['month_day'] = data.index.day\n",
    "data['week_day'] = data.index.day_of_week\n",
    "one_hot_encoder = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(sparse_output=False, drop='if_binary'),\n",
    "        ['month', 'week_day', 'month_day'],\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")\n",
    "data = one_hot_encoder.fit_transform(data)\n",
    "end_train = '2021-03-30 23:59:00'\n",
    "end_validation = '2021-06-30 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [col for col in data.columns if col.startswith(('month_', 'week_day_', 'month_day_'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda5b95c3a574f22ba21edd8ebd249ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab038e092b9d44d4b3247d24c833609e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 10.0}\n",
      "  Backtesting metric: 92723.37385771735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1435: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1667d31c13bf4294b7cecefb656bd673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8c998e2eb54a10afa10f9845b8691f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 0.46415888336127775}\n",
      "  Backtesting metric: 0.03135946751580578\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 3.9623405933380127\n",
      "Execution time one step ahead: 0.4341268539428711\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 10.0}\n",
      "    metrics: 165.59443777438304\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 0.46415888336127775}\n",
      "    metrics: 170.6888738025913\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor     = Ridge(random_state=123),\n",
    "                 transformer_y = StandardScaler(),\n",
    "                 lags          = 10\n",
    "             )\n",
    "lags_grid = [7, 14, 21, [7, 14, 21]]\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 10)}\n",
    "\n",
    "grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 7,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"website_visits\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f754c2ca714c42838fc72db4e28f4334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 1.2524531789882662}\n",
      "  Backtesting metric: 224.33854613853265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:2177: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c703faa4fc4ab3bf14bcc638285dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] \n",
      "  Parameters: {'alpha': 2.083580929967405}\n",
      "  Backtesting metric: 0.13822004658108406\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 2.0646800994873047\n",
      "Execution time one step ahead: 0.3663356304168701\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 1.2524531789882662}\n",
      "    metrics: 166.84400582475766\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "    params : {'alpha': 2.083580929967405}\n",
      "    metrics: 164.24239262308248\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor     = Ridge(random_state=123),\n",
    "                 transformer_y = StandardScaler(),\n",
    "                 lags          = 10\n",
    "             )\n",
    "lags_grid = [7, 14, 21, [7, 14, 21]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 0.001, 1000, log=True),\n",
    "        'lags'  : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 7,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"website_visits\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: electricity consumption dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7071/1461443256.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(rule=\"H\", closed=\"left\", label=\"right\")\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name='vic_electricity', raw=False, verbose=False)\n",
    "data = data.drop(columns=\"Date\")\n",
    "data = (\n",
    "    data\n",
    "    .resample(rule=\"H\", closed=\"left\", label=\"right\")\n",
    "    .agg({\n",
    "        \"Demand\": \"mean\",\n",
    "        \"Temperature\": \"mean\",\n",
    "        \"Holiday\": \"mean\",\n",
    "    })\n",
    ")\n",
    "data = data.loc['2012-01-01 00:00:00': '2014-12-30 23:00:00'].copy()\n",
    "end_train = '2013-12-31 23:59:00'\n",
    "end_validation = '2014-11-30 23:59:00'\n",
    "data_train = data.loc[: end_train, :].copy()\n",
    "data_val   = data.loc[end_train:end_validation, :].copy()\n",
    "data_test  = data.loc[end_validation:, :].copy()\n",
    "exog_features = ['Temperature', 'Holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf9f17d8070456daa25b46743e8bc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a61c985084a5f85e51c165efd4403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Backtesting metric: 94957.10876856494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1435: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc05e009f753483ca2799830cd11afb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7639ac7278df4f46978b26d64049beb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "  Backtesting metric: 9478.226436015197\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 490.7595374584198\n",
      "Execution time one step ahead: 18.60087752342224\n",
      "Same lags  : True\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "    metrics: 245.7862163569872\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "    metrics: 245.7862163569872\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, (1, 2, 3, 23, 24, 25, 167, 168, 169)]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'Demand',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"vic_electricity\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a0d607a691477890d8c31011439869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.06908111764347266, 'subsample': 0.4582398297973883, 'colsample_bytree': 0.7641958651588321, 'gamma': 0.18249173045349998, 'reg_alpha': 0.17545175614749253, 'reg_lambda': 0.5315513738418384}\n",
      "  Backtesting metric: 191.8626391693285\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:2177: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab939e35d7134284afce984aa6fed6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3  23  24  25 167 168 169] \n",
      "  Parameters: {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.05679576034204338, 'subsample': 0.10725502906361839, 'colsample_bytree': 0.9892976403836156, 'gamma': 0.006453374219829056, 'reg_alpha': 0.0038381442337546146, 'reg_lambda': 0.24053684218482807}\n",
      "  Backtesting metric: 55.35922291628681\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 158.8924789428711\n",
      "Execution time one step ahead: 28.4509916305542\n",
      "Same lags  : True\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.06908111764347266, 'subsample': 0.4582398297973883, 'colsample_bytree': 0.7641958651588321, 'gamma': 0.18249173045349998, 'reg_alpha': 0.17545175614749253, 'reg_lambda': 0.5315513738418384}\n",
      "    metrics: 231.47139120775364\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [  1   2   3  23  24  25 167 168 169]\n",
      "    params : {'n_estimators': 1200, 'max_depth': 10, 'learning_rate': 0.05679576034204338, 'subsample': 0.10725502906361839, 'colsample_bytree': 0.9892976403836156, 'gamma': 0.006453374219829056, 'reg_alpha': 0.0038381442337546146, 'reg_lambda': 0.24053684218482807}\n",
      "    metrics: 226.56310817545923\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 400, 1200, step=100),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample'       : trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma'           : trial.suggest_float('gamma', 0, 1),\n",
    "        'reg_alpha'       : trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda'      : trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'Demand',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"vic_electricity\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecaster AutoregDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c7e60d4f7c462893e64f9122157238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01038e91ac54402e8973e7852571f98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'alpha': 1000.0}\n",
      "  Backtesting metric: 10439.128519885262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1435: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff97f1913554b948bff7b2c086b0833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faae8d4eca744cba2160f961909fc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'alpha': 46.41588833612773}\n",
      "  Backtesting metric: 43422.71251085582\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 67.24604392051697\n",
      "Execution time one step ahead: 4.050391912460327\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'alpha': 1000.0}\n",
      "    metrics: 67.37528369177734\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'alpha': 46.41588833612773}\n",
      "    metrics: 67.87100222922518\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset('bike_sharing_extended_features', verbose=False)\n",
    "end_train = '2012-03-31 23:59:00'\n",
    "end_validation = '2012-08-31 23:59:00'\n",
    "data_train = data.loc[: end_train, :]\n",
    "data_val   = data.loc[end_train:end_validation, :]\n",
    "data_test  = data.loc[end_validation:, :]\n",
    "exog_features = [\n",
    "    'month_sin', \n",
    "    'month_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos',\n",
    "    'week_day_sin',\n",
    "    'week_day_cos',\n",
    "    'hour_day_sin',\n",
    "    'hour_day_cos',\n",
    "    'sunrise_hour_sin',\n",
    "    'sunrise_hour_cos',\n",
    "    'sunset_hour_sin',\n",
    "    'sunset_hour_cos',\n",
    "    'holiday_previous_day',\n",
    "    'holiday_next_day',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day',\n",
    "    'temp',\n",
    "    'holiday'\n",
    "]\n",
    "\n",
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = Ridge(random_state=123),\n",
    "                 steps     = 5,\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 10)}\n",
    "\n",
    "grid_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1090e33f0c374f8cbe8fa386909a534c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'alpha': 925.1006260111275}\n",
      "  Backtesting metric: 70.99353356420917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:2177: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee534a0e38c44b06b8f6a0a6d5f52123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'alpha': 6.403328042606579}\n",
      "  Backtesting metric: 149.21303984528487\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 45.40154194831848\n",
      "Execution time one step ahead: 2.209826707839966\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'alpha': 925.1006260111275}\n",
      "    metrics: 67.37630319670156\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'alpha': 6.403328042606579}\n",
      "    metrics: 67.91191634391751\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = Ridge(random_state=123),\n",
    "                 steps     = 5,\n",
    "                 lags      = 10\n",
    "             )\n",
    "lags_grid = [48, 72, [1, 2, 3, 23, 24, 25, 167, 168, 169]]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'alpha' : trial.suggest_float('alpha', 0.001, 1000, log=True),\n",
    "        'lags'  : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "bayesian_search_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    target                  = 'users',\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_bayesian_search.loc[\"bike_sharing_extended_features\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>time_search_backtesting</th>\n",
       "      <th>time_search_one_step</th>\n",
       "      <th>metric_backtesting</th>\n",
       "      <th>metric_one_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h2o</th>\n",
       "      <td>ForecasterAutoreg</td>\n",
       "      <td>1.05103</td>\n",
       "      <td>0.21661</td>\n",
       "      <td>0.226159</td>\n",
       "      <td>0.135192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bike_sharing_extended_features</th>\n",
       "      <td>ForecasterAutoreg</td>\n",
       "      <td>1.05103</td>\n",
       "      <td>0.21661</td>\n",
       "      <td>0.226159</td>\n",
       "      <td>0.135192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website_visits</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic_electricity</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       forecaster time_search_backtesting  \\\n",
       "h2o                             ForecasterAutoreg                 1.05103   \n",
       "bike_sharing_extended_features  ForecasterAutoreg                 1.05103   \n",
       "website_visits                                NaN                     NaN   \n",
       "vic_electricity                               NaN                     NaN   \n",
       "\n",
       "                               time_search_one_step metric_backtesting  \\\n",
       "h2o                                         0.21661           0.226159   \n",
       "bike_sharing_extended_features              0.21661           0.226159   \n",
       "website_visits                                  NaN                NaN   \n",
       "vic_electricity                                 NaN                NaN   \n",
       "\n",
       "                               metric_one_step  \n",
       "h2o                                   0.135192  \n",
       "bike_sharing_extended_features        0.135192  \n",
       "website_visits                             NaN  \n",
       "vic_electricity                            NaN  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecaster</th>\n",
       "      <th>time_search_backtesting</th>\n",
       "      <th>time_search_one_step</th>\n",
       "      <th>metric_backtesting</th>\n",
       "      <th>metric_one_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h2o</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bike_sharing_extended_features</th>\n",
       "      <td>ForecasterAutoreg</td>\n",
       "      <td>1.05103</td>\n",
       "      <td>0.21661</td>\n",
       "      <td>0.226159</td>\n",
       "      <td>0.135192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website_visits</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic_electricity</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       forecaster time_search_backtesting  \\\n",
       "h2o                                           NaN                     NaN   \n",
       "bike_sharing_extended_features  ForecasterAutoreg                 1.05103   \n",
       "website_visits                                NaN                     NaN   \n",
       "vic_electricity                               NaN                     NaN   \n",
       "\n",
       "                               time_search_one_step metric_backtesting  \\\n",
       "h2o                                             NaN                NaN   \n",
       "bike_sharing_extended_features              0.21661           0.226159   \n",
       "website_visits                                  NaN                NaN   \n",
       "vic_electricity                                 NaN                NaN   \n",
       "\n",
       "                               metric_one_step  \n",
       "h2o                                        NaN  \n",
       "bike_sharing_extended_features        0.135192  \n",
       "website_visits                             NaN  \n",
       "vic_electricity                            NaN  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bayesian_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForecasterAutoregMultiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compare results using backtesting and one step ahead\n",
    "# ==============================================================================\n",
    "def grid_search_multiseries_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    lags_grid,\n",
    "    param_grid,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    levels,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of grid search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1 = grid_search_forecaster_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = data.loc[:end_validation, levels],\n",
    "                levels             = levels,\n",
    "                exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                param_grid         = param_grid,\n",
    "                lags_grid          = lags_grid,\n",
    "                steps              = steps,\n",
    "                refit              = False,\n",
    "                metric             = metric,\n",
    "                initial_train_size = len(data.loc[:end_train]),\n",
    "                method             = 'backtesting',\n",
    "                fixed_train_size   = False,\n",
    "                return_best        = True,\n",
    "                n_jobs             = 'auto',\n",
    "                verbose            = False,\n",
    "                show_progress      = True\n",
    "            )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        levels              = levels,\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2 = grid_search_forecaster_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = data.loc[:end_validation, levels],\n",
    "                exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                levels             = levels,\n",
    "                param_grid         = param_grid,\n",
    "                lags_grid          = lags_grid,\n",
    "                steps              = steps,\n",
    "                metric             = metric,\n",
    "                initial_train_size = len(data.loc[:end_train]),\n",
    "                method             = 'one_step_ahead',\n",
    "                return_best        = True,\n",
    "                verbose            = False,\n",
    "                show_progress      = True\n",
    "            )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        levels              = levels,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "    \n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]\n",
    "\n",
    "\n",
    "def bayesian_search_multiseries_benchmark(\n",
    "    data,\n",
    "    forecaster_to_benchmark,\n",
    "    search_space,\n",
    "    end_train,\n",
    "    end_validation,\n",
    "    levels,\n",
    "    #target,\n",
    "    exog_features,\n",
    "    steps,\n",
    "    metric\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare results of bayesian search using backtesting and one-step-ahead.\n",
    "    \"\"\"\n",
    "\n",
    "    # Method: backtesting\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_1, _ = bayesian_search_forecaster_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = data.loc[:end_validation, levels],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        levels             = levels,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        refit              = False,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'backtesting',\n",
    "                        fixed_train_size   = False,\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        n_jobs             = 'auto',\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_1 = end - start\n",
    "    metric_1, predictions_1 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        levels              = levels,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    # Method: one step ahead\n",
    "    forecaster = copy(forecaster_to_benchmark)\n",
    "    start  = time()\n",
    "    results_2, _ = bayesian_search_forecaster_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = data.loc[:end_validation, levels],\n",
    "                        exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                        levels             = levels,\n",
    "                        steps              = steps,\n",
    "                        search_space       = search_space,\n",
    "                        metric             = metric,\n",
    "                        initial_train_size = len(data.loc[:end_train]),\n",
    "                        method             = 'one_step_ahead',\n",
    "                        n_trials           = 20,\n",
    "                        random_state       = 123,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False,\n",
    "                        show_progress      = True\n",
    "                    )\n",
    "    end = time()\n",
    "    time_2 = end - start\n",
    "    metric_2, predictions_2 = backtesting_forecaster_multiseries(\n",
    "        forecaster          = forecaster,\n",
    "        series              = data.loc[:, levels],\n",
    "        exog                = data.loc[:, exog_features] if exog_features else None,\n",
    "        levels              = levels,\n",
    "        initial_train_size  = len(data.loc[:end_validation]),\n",
    "        steps               = steps,\n",
    "        metric              = metric,\n",
    "        verbose             = False,\n",
    "        show_progress       = False\n",
    "    )\n",
    "\n",
    "    print(\"Benchmark results\")\n",
    "    print(\"-----------------\")\n",
    "    print('Execution time backtesting   :', time_1)\n",
    "    print('Execution time one step ahead:', time_2)\n",
    "    print(f\"Same lags  : {np.array_equal(results_1.loc[0, 'lags'], results_2.loc[0, 'lags'])}\")\n",
    "    print(f\"Same params: {results_1.loc[0, 'params'] == results_2.loc[0, 'params']}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: backtesting\")\n",
    "    print(f\"    lags   : {results_1.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_1.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_1.loc[0, metric]}\")\n",
    "    print(\"\")\n",
    "    print(\"Method: one step ahead\")\n",
    "    print(f\"    lags   : {results_2.loc[0, 'lags']}\")\n",
    "    print(f\"    params : {results_2.loc[0, 'params']}\")\n",
    "    print(f\"    metrics: {metric_2.loc[0, metric]}\")\n",
    "\n",
    "    return time_1, time_2, metric_1.loc[0, metric], metric_2.loc[0, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table to store results\n",
    "# ==============================================================================\n",
    "results_grid_search = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"forecaster\",\n",
    "        \"time_search_backtesting\",\n",
    "        \"time_search_one_step\",\n",
    "        \"metric_backtesting\",\n",
    "        \"metric_one_step\",\n",
    "    ],\n",
    "    index=[\n",
    "        \"items_sales\",\n",
    "    ]\n",
    ")\n",
    "results_bayesian_search = results_grid_search.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-05-15 23:59:00'\n",
    "end_validation = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "exog_features = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493fda36de004a90b8fb53a528daf13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4c8c614c464477b4bf549e4641f96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 2.281107158900761\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47dc9d6807d409f883b7c55053a6e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6fc79b41b04cc2afa2ed3a0cc22d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'max_depth': 3, 'n_estimators': 20}\n",
      "  Backtesting metric: 1.7788941749503342\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 1.6039478778839111\n",
      "Execution time one step ahead: 0.7105159759521484\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.43839579684015\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'max_depth': 3, 'n_estimators': 20}\n",
      "    metrics: 1.6408350320514384\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = \"ordinal\",\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid ={\n",
    "    '24 lags': 24,\n",
    "    '48 lags': 48\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20],\n",
    "    'max_depth': [3, 7]\n",
    "}\n",
    "\n",
    "grid_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"items_sales\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1afa27b95624ebda1b44eb226135a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'n_estimators': 47, 'max_depth': 10, 'learning_rate': 0.10582782597735779}\n",
      "  Backtesting metric: 1.9340570479344343\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9694985b87b445b1855a8616fae970ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'n_estimators': 35, 'max_depth': 3, 'learning_rate': 0.3241126270021177}\n",
      "  Backtesting metric: 1.586531587692841\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 5.048365592956543\n",
      "Execution time one step ahead: 1.8876800537109375\n",
      "Same lags  : False\n",
      "Same params: False\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'n_estimators': 47, 'max_depth': 10, 'learning_rate': 0.10582782597735779}\n",
      "    metrics: 1.2509853110935267\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72]\n",
      "    params : {'n_estimators': 35, 'max_depth': 3, 'learning_rate': 0.3241126270021177}\n",
      "    metrics: 1.1872894242820913\n"
     ]
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = \"ordinal\",\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid = [48, 72]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 50),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "bayesian_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    search_space            = search_space,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 36,\n",
    "    metric                  = 'mean_absolute_error'\n",
    ")\n",
    "results_grid_search.loc[\"items_sales\", :] = [\n",
    "    type(forecaster).__name__,\n",
    "    time_1,\n",
    "    time_2,\n",
    "    metric_1,\n",
    "    metric_2,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForecasterAutoregMultiVariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-05-15 23:59:00'\n",
    "end_validation = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "exog_features = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8e909ee74247c7b3327b74222aa8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd5fa63dec04a29918025cda4cdb1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 0.7515349140955219\n",
      "  Levels: ['item_1']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c8ded7b6bd4486a8488a41ccccf8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9049315fad4b08bf1f25fa72b5dd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
      "  Parameters: {'max_depth': 7, 'n_estimators': 20}\n",
      "  Backtesting metric: 0.8146025385778681\n",
      "  Levels: ['item_1']\n",
      "\n",
      "Benchmark results\n",
      "-----------------\n",
      "Execution time backtesting   : 3.104400873184204\n",
      "Execution time one step ahead: 2.043469190597534\n",
      "Same lags  : False\n",
      "Same params: True\n",
      "\n",
      "Method: backtesting\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.0409310906937037\n",
      "\n",
      "Method: one step ahead\n",
      "    lags   : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "    params : {'max_depth': 7, 'n_estimators': 20}\n",
      "    metrics: 1.0481118869071948\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 steps              = 5,\n",
    "                 level              = 'item_1',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid ={\n",
    "    '24 lags': 24,\n",
    "    '48 lags': 48\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20],\n",
    "    'max_depth': [3, 7]\n",
    "}\n",
    "\n",
    "grid_search_multiseries_benchmark(\n",
    "    data                    = data,\n",
    "    forecaster_to_benchmark = forecaster,\n",
    "    lags_grid               = lags_grid,\n",
    "    param_grid              = param_grid,\n",
    "    end_train               = end_train,\n",
    "    end_validation          = end_validation,\n",
    "    levels                  = levels,\n",
    "    exog_features           = exog_features,\n",
    "    steps                   = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters vs _evaluate_grid_hyperparameters_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection.model_selection import _evaluate_grid_hyperparameters\n",
    "from skforecast.model_selection.model_selection import _evaluate_grid_hyperparameters_one_step_ahead\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\",\n",
    "    raw=True,\n",
    "    kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False,\n",
    ")\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"], format=\"%Y-%m-%d\")\n",
    "data = data.set_index(\"datetime\")\n",
    "data = data.asfreq(\"MS\")\n",
    "data = data[[\"y\"]]\n",
    "data = data.sort_index()\n",
    "end_train = \"2001-01-01 23:59:00\"\n",
    "end_validation = \"2006-01-01 23:59:00\"\n",
    "target = \"y\"\n",
    "exog_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection/model_selection.py:1435: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags      = 10\n",
    "            )\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    steps              = 1,\n",
    "    refit              = False,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    fixed_train_size   = False,\n",
    "    return_best        = False,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters_one_step_ahead(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = data.loc[:end_validation, target],\n",
    "    exog               = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "    param_grid         = param_grid,\n",
    "    lags_grid          = lags_grid,\n",
    "    metric             = ['mean_squared_error', 'mean_absolute_error'],\n",
    "    initial_train_size = len(data.loc[:end_train]),\n",
    "    return_best        = False,\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    ")\n",
    "\n",
    "assert results_backtesting.equals(results_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _calculate_metrics_multiseries vs _calculate_metrics_multiseries_one_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries_one_step_ahead\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = 'ordinal',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "X, y = forecaster.create_train_X_y(series=data)\n",
    "X_train = X.loc[X.index <= end_train, :]\n",
    "y_train = y.loc[y.index <= end_train]\n",
    "X_test = X.loc[X.index > end_train, :]\n",
    "y_test = y.loc[y.index > end_train]\n",
    "\n",
    "forecaster.regressor.fit(X_train, y_train)\n",
    "pred = forecaster.regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>0.820748</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.537711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2.330964</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>0.989540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.093253</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.835301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.787517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.081655</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.823316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_percentage_error  \\\n",
       "0            item_1             0.820748                        0.040761   \n",
       "1            item_2             2.330964                        0.152464   \n",
       "2            item_3             3.093253                        0.207347   \n",
       "3           average             2.081655                        0.133524   \n",
       "4  weighted_average             2.081655                        0.133524   \n",
       "5           pooling             2.081655                        0.133524   \n",
       "\n",
       "   mean_absolute_scaled_error  \n",
       "0                    0.537711  \n",
       "1                    0.989540  \n",
       "2                    0.835301  \n",
       "3                    0.787517  \n",
       "4                    0.787517  \n",
       "5                    0.823316  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test results _calculate_metrics_multiseries_one_step_ahead and _calculate_metrics_multiseries\n",
    "# ==============================================================================\n",
    "# Metrics should be equal when using step=1 in backtesting\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries_one_step_ahead\n",
    "metrics = [mean_absolute_error, mean_absolute_percentage_error, mean_absolute_scaled_error]\n",
    "metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "\n",
    "if forecaster.encoding in ['ordinal', 'ordinal_category']:\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(X_train[['_level_skforecast']]).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(X_test[['_level_skforecast']]).ravel()\n",
    "elif forecaster.encoding == 'onehot':\n",
    "    X_train_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_train.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "    X_test_encoding = forecaster.encoder.inverse_transform(\n",
    "                            X_test.loc[:, forecaster.encoding_mapping.keys()]\n",
    "                        ).ravel()\n",
    "\n",
    "metrics_one_step_ahead = _calculate_metrics_multiseries_one_step_ahead(\n",
    "    y_true = y_test.to_numpy(),\n",
    "    y_true_index = y_test.index,\n",
    "    y_pred = pred,\n",
    "    y_pred_encoding = X_test_encoding,\n",
    "    y_train = y_train.to_numpy(),\n",
    "    y_train_index = y_train.index,\n",
    "    y_train_encoding = X_train_encoding,\n",
    "    levels = ['item_1', 'item_2', 'item_3'],\n",
    "    metrics = metrics,\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_one_step_ahead)\n",
    "\n",
    "# Metrics with _calculate_metrics_multiseries\n",
    "folds = _create_backtesting_folds(\n",
    "    data = data,\n",
    "    window_size = 24,\n",
    "    initial_train_size = len(data_train),\n",
    "    test_size = 1,\n",
    "    externally_fitted = False,\n",
    "    refit = False,\n",
    "    fixed_train_size = True,\n",
    "    gap = 0,\n",
    "    skip_folds = None,\n",
    "    allow_incomplete_fold = True,\n",
    "    return_all_indexes = False,\n",
    "    differentiation = None,\n",
    "    verbose = False\n",
    ")\n",
    "_, predictions = backtesting_forecaster_multiseries(\n",
    "    series=data,\n",
    "    forecaster=forecaster,\n",
    "    steps=1,\n",
    "    metric=metrics,\n",
    "    initial_train_size = len(data_train),\n",
    "    refit=False,\n",
    "    add_aggregated_metric=True,\n",
    "    show_progress=False\n",
    ")\n",
    "metrics_backtesting = _calculate_metrics_multiseries(\n",
    "    series = data,\n",
    "    predictions= predictions,\n",
    "    folds= folds,\n",
    "    span_index= data.index,\n",
    "    window_size = 24,\n",
    "    metrics= metrics,\n",
    "    levels= ['item_1', 'item_2', 'item_3'],\n",
    "    add_aggregated_metric = True\n",
    ")\n",
    "\n",
    "display(metrics_backtesting)\n",
    "\n",
    "assert metrics_backtesting.equals(metrics_one_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _evaluate_grid_hyperparameters_multiseries vs _evaluate_grid_hyperparameters_multiseries_one_step_ahead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries_one_step_ahead\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "exog_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:2029: UserWarning: One-step-ahead predictions are used for faster model comparison, but they may not fully represent multi-step prediction performance. It is recommended to backtest the final model for a more accurate multi-step performance estimate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "    lags               = 24,\n",
    "    encoding           = 'ordinal',\n",
    "    transformer_series = None,\n",
    "    transformer_exog   = None,\n",
    "    weight_func        = None,\n",
    "    series_weights     = None,\n",
    "    differentiation    = None,\n",
    "    dropna_from_series = False,\n",
    "    fit_kwargs         = None,\n",
    "    forecaster_id      = None\n",
    ")\n",
    "lags_grid = [3, 10]\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "results_backtesting = _evaluate_grid_hyperparameters_multiseries(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            steps                 = 1,\n",
    "                            metric                = metrics,\n",
    "                            aggregate_metric      = ['weighted_average', 'average', 'pooling'],\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            fixed_train_size      = True,\n",
    "                            gap                   = 0,\n",
    "                            skip_folds            = None,\n",
    "                            allow_incomplete_fold = True,\n",
    "                            levels                = None,\n",
    "                            exog                  = data.loc[:end_validation, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            refit                 = False,\n",
    "                            n_jobs                = 'auto',\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False,\n",
    "                            suppress_warnings     = False\n",
    "                        )\n",
    "\n",
    "results_one_step_ahead = _evaluate_grid_hyperparameters_multiseries_one_step_ahead(\n",
    "                            forecaster            = forecaster,\n",
    "                            series                = data,\n",
    "                            param_grid            = param_grid,\n",
    "                            metric                = metrics,\n",
    "                            initial_train_size    = len(data_train),\n",
    "                            exog                  = data.loc[:data_train, exog_features] if exog_features else None,\n",
    "                            lags_grid             = lags_grid,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            show_progress         = False\n",
    "                        )\n",
    "\n",
    "assert results_backtesting.equals(results_one_step_ahead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 steps              = 2,\n",
    "                 level              = 'item_1',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "X, y = forecaster.create_train_X_y(series=data)\n",
    "train_size = len(data_train) - forecaster.window_size_diff\n",
    "X_train = X.iloc[:train_size, :]\n",
    "X_test = X.iloc[train_size:, :]\n",
    "y_train = {k: v.iloc[:train_size] for k, v in y.items()}\n",
    "y_test  = {k: v.iloc[train_size:] for k, v in y.items()}\n",
    "\n",
    "step=1\n",
    "\n",
    "X_train_step, y_train_step = forecaster.filter_train_X_y_for_step(\n",
    "                                                    step    = step,\n",
    "                                                    X_train = X_train,\n",
    "                                                    y_train = y_train\n",
    "                                                  )\n",
    "X_test_step, y_test_step = forecaster.filter_train_X_y_for_step(\n",
    "                                step    = step,  \n",
    "                                X_train = X_test,\n",
    "                                y_train = y_test\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                lags               = 24,\n",
    "                encoding           = 'ordinal',\n",
    "                transformer_series = None,\n",
    "                transformer_exog   = None,\n",
    "                weight_func        = None,\n",
    "                fit_kwargs         = None,\n",
    "                forecaster_id      = None\n",
    "            )\n",
    "\n",
    "X, y, *_ = forecaster._create_train_X_y(series=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_16</th>\n",
       "      <th>lag_17</th>\n",
       "      <th>lag_18</th>\n",
       "      <th>lag_19</th>\n",
       "      <th>lag_20</th>\n",
       "      <th>lag_21</th>\n",
       "      <th>lag_22</th>\n",
       "      <th>lag_23</th>\n",
       "      <th>lag_24</th>\n",
       "      <th>_level_skforecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-25</th>\n",
       "      <td>28.018830</td>\n",
       "      <td>23.981037</td>\n",
       "      <td>20.794986</td>\n",
       "      <td>22.503533</td>\n",
       "      <td>24.018768</td>\n",
       "      <td>24.772249</td>\n",
       "      <td>29.245869</td>\n",
       "      <td>26.636444</td>\n",
       "      <td>20.228468</td>\n",
       "      <td>18.976196</td>\n",
       "      <td>...</td>\n",
       "      <td>20.006161</td>\n",
       "      <td>20.069327</td>\n",
       "      <td>20.533871</td>\n",
       "      <td>21.106643</td>\n",
       "      <td>21.379238</td>\n",
       "      <td>25.895533</td>\n",
       "      <td>27.549099</td>\n",
       "      <td>22.777826</td>\n",
       "      <td>8.253175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-26</th>\n",
       "      <td>28.747482</td>\n",
       "      <td>28.018830</td>\n",
       "      <td>23.981037</td>\n",
       "      <td>20.794986</td>\n",
       "      <td>22.503533</td>\n",
       "      <td>24.018768</td>\n",
       "      <td>24.772249</td>\n",
       "      <td>29.245869</td>\n",
       "      <td>26.636444</td>\n",
       "      <td>20.228468</td>\n",
       "      <td>...</td>\n",
       "      <td>21.620184</td>\n",
       "      <td>20.006161</td>\n",
       "      <td>20.069327</td>\n",
       "      <td>20.533871</td>\n",
       "      <td>21.106643</td>\n",
       "      <td>21.379238</td>\n",
       "      <td>25.895533</td>\n",
       "      <td>27.549099</td>\n",
       "      <td>22.777826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-27</th>\n",
       "      <td>23.908368</td>\n",
       "      <td>28.747482</td>\n",
       "      <td>28.018830</td>\n",
       "      <td>23.981037</td>\n",
       "      <td>20.794986</td>\n",
       "      <td>22.503533</td>\n",
       "      <td>24.018768</td>\n",
       "      <td>24.772249</td>\n",
       "      <td>29.245869</td>\n",
       "      <td>26.636444</td>\n",
       "      <td>...</td>\n",
       "      <td>21.717691</td>\n",
       "      <td>21.620184</td>\n",
       "      <td>20.006161</td>\n",
       "      <td>20.069327</td>\n",
       "      <td>20.533871</td>\n",
       "      <td>21.106643</td>\n",
       "      <td>21.379238</td>\n",
       "      <td>25.895533</td>\n",
       "      <td>27.549099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-28</th>\n",
       "      <td>21.423930</td>\n",
       "      <td>23.908368</td>\n",
       "      <td>28.747482</td>\n",
       "      <td>28.018830</td>\n",
       "      <td>23.981037</td>\n",
       "      <td>20.794986</td>\n",
       "      <td>22.503533</td>\n",
       "      <td>24.018768</td>\n",
       "      <td>24.772249</td>\n",
       "      <td>29.245869</td>\n",
       "      <td>...</td>\n",
       "      <td>21.751748</td>\n",
       "      <td>21.717691</td>\n",
       "      <td>21.620184</td>\n",
       "      <td>20.006161</td>\n",
       "      <td>20.069327</td>\n",
       "      <td>20.533871</td>\n",
       "      <td>21.106643</td>\n",
       "      <td>21.379238</td>\n",
       "      <td>25.895533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-29</th>\n",
       "      <td>24.786455</td>\n",
       "      <td>21.423930</td>\n",
       "      <td>23.908368</td>\n",
       "      <td>28.747482</td>\n",
       "      <td>28.018830</td>\n",
       "      <td>23.981037</td>\n",
       "      <td>20.794986</td>\n",
       "      <td>22.503533</td>\n",
       "      <td>24.018768</td>\n",
       "      <td>24.772249</td>\n",
       "      <td>...</td>\n",
       "      <td>21.758617</td>\n",
       "      <td>21.751748</td>\n",
       "      <td>21.717691</td>\n",
       "      <td>21.620184</td>\n",
       "      <td>20.006161</td>\n",
       "      <td>20.069327</td>\n",
       "      <td>20.533871</td>\n",
       "      <td>21.106643</td>\n",
       "      <td>21.379238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>21.738537</td>\n",
       "      <td>19.434599</td>\n",
       "      <td>15.148365</td>\n",
       "      <td>22.075515</td>\n",
       "      <td>25.114921</td>\n",
       "      <td>25.982370</td>\n",
       "      <td>18.457338</td>\n",
       "      <td>14.950277</td>\n",
       "      <td>20.415604</td>\n",
       "      <td>20.758476</td>\n",
       "      <td>...</td>\n",
       "      <td>20.488914</td>\n",
       "      <td>18.975586</td>\n",
       "      <td>21.678973</td>\n",
       "      <td>17.274616</td>\n",
       "      <td>13.292155</td>\n",
       "      <td>19.417643</td>\n",
       "      <td>16.099237</td>\n",
       "      <td>19.913343</td>\n",
       "      <td>23.642604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>20.586030</td>\n",
       "      <td>21.738537</td>\n",
       "      <td>19.434599</td>\n",
       "      <td>15.148365</td>\n",
       "      <td>22.075515</td>\n",
       "      <td>25.114921</td>\n",
       "      <td>25.982370</td>\n",
       "      <td>18.457338</td>\n",
       "      <td>14.950277</td>\n",
       "      <td>20.415604</td>\n",
       "      <td>...</td>\n",
       "      <td>19.785106</td>\n",
       "      <td>20.488914</td>\n",
       "      <td>18.975586</td>\n",
       "      <td>21.678973</td>\n",
       "      <td>17.274616</td>\n",
       "      <td>13.292155</td>\n",
       "      <td>19.417643</td>\n",
       "      <td>16.099237</td>\n",
       "      <td>19.913343</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>28.127390</td>\n",
       "      <td>20.586030</td>\n",
       "      <td>21.738537</td>\n",
       "      <td>19.434599</td>\n",
       "      <td>15.148365</td>\n",
       "      <td>22.075515</td>\n",
       "      <td>25.114921</td>\n",
       "      <td>25.982370</td>\n",
       "      <td>18.457338</td>\n",
       "      <td>14.950277</td>\n",
       "      <td>...</td>\n",
       "      <td>30.684650</td>\n",
       "      <td>19.785106</td>\n",
       "      <td>20.488914</td>\n",
       "      <td>18.975586</td>\n",
       "      <td>21.678973</td>\n",
       "      <td>17.274616</td>\n",
       "      <td>13.292155</td>\n",
       "      <td>19.417643</td>\n",
       "      <td>16.099237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>21.555782</td>\n",
       "      <td>28.127390</td>\n",
       "      <td>20.586030</td>\n",
       "      <td>21.738537</td>\n",
       "      <td>19.434599</td>\n",
       "      <td>15.148365</td>\n",
       "      <td>22.075515</td>\n",
       "      <td>25.114921</td>\n",
       "      <td>25.982370</td>\n",
       "      <td>18.457338</td>\n",
       "      <td>...</td>\n",
       "      <td>19.140787</td>\n",
       "      <td>30.684650</td>\n",
       "      <td>19.785106</td>\n",
       "      <td>20.488914</td>\n",
       "      <td>18.975586</td>\n",
       "      <td>21.678973</td>\n",
       "      <td>17.274616</td>\n",
       "      <td>13.292155</td>\n",
       "      <td>19.417643</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>18.605453</td>\n",
       "      <td>21.555782</td>\n",
       "      <td>28.127390</td>\n",
       "      <td>20.586030</td>\n",
       "      <td>21.738537</td>\n",
       "      <td>19.434599</td>\n",
       "      <td>15.148365</td>\n",
       "      <td>22.075515</td>\n",
       "      <td>25.114921</td>\n",
       "      <td>25.982370</td>\n",
       "      <td>...</td>\n",
       "      <td>22.466396</td>\n",
       "      <td>19.140787</td>\n",
       "      <td>30.684650</td>\n",
       "      <td>19.785106</td>\n",
       "      <td>20.488914</td>\n",
       "      <td>18.975586</td>\n",
       "      <td>21.678973</td>\n",
       "      <td>17.274616</td>\n",
       "      <td>13.292155</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3219 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                lag_1      lag_2      lag_3      lag_4      lag_5      lag_6  \\\n",
       "date                                                                           \n",
       "2012-01-25  28.018830  23.981037  20.794986  22.503533  24.018768  24.772249   \n",
       "2012-01-26  28.747482  28.018830  23.981037  20.794986  22.503533  24.018768   \n",
       "2012-01-27  23.908368  28.747482  28.018830  23.981037  20.794986  22.503533   \n",
       "2012-01-28  21.423930  23.908368  28.747482  28.018830  23.981037  20.794986   \n",
       "2012-01-29  24.786455  21.423930  23.908368  28.747482  28.018830  23.981037   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2014-12-28  21.738537  19.434599  15.148365  22.075515  25.114921  25.982370   \n",
       "2014-12-29  20.586030  21.738537  19.434599  15.148365  22.075515  25.114921   \n",
       "2014-12-30  28.127390  20.586030  21.738537  19.434599  15.148365  22.075515   \n",
       "2014-12-31  21.555782  28.127390  20.586030  21.738537  19.434599  15.148365   \n",
       "2015-01-01  18.605453  21.555782  28.127390  20.586030  21.738537  19.434599   \n",
       "\n",
       "                lag_7      lag_8      lag_9     lag_10  ...     lag_16  \\\n",
       "date                                                    ...              \n",
       "2012-01-25  29.245869  26.636444  20.228468  18.976196  ...  20.006161   \n",
       "2012-01-26  24.772249  29.245869  26.636444  20.228468  ...  21.620184   \n",
       "2012-01-27  24.018768  24.772249  29.245869  26.636444  ...  21.717691   \n",
       "2012-01-28  22.503533  24.018768  24.772249  29.245869  ...  21.751748   \n",
       "2012-01-29  20.794986  22.503533  24.018768  24.772249  ...  21.758617   \n",
       "...               ...        ...        ...        ...  ...        ...   \n",
       "2014-12-28  18.457338  14.950277  20.415604  20.758476  ...  20.488914   \n",
       "2014-12-29  25.982370  18.457338  14.950277  20.415604  ...  19.785106   \n",
       "2014-12-30  25.114921  25.982370  18.457338  14.950277  ...  30.684650   \n",
       "2014-12-31  22.075515  25.114921  25.982370  18.457338  ...  19.140787   \n",
       "2015-01-01  15.148365  22.075515  25.114921  25.982370  ...  22.466396   \n",
       "\n",
       "               lag_17     lag_18     lag_19     lag_20     lag_21     lag_22  \\\n",
       "date                                                                           \n",
       "2012-01-25  20.069327  20.533871  21.106643  21.379238  25.895533  27.549099   \n",
       "2012-01-26  20.006161  20.069327  20.533871  21.106643  21.379238  25.895533   \n",
       "2012-01-27  21.620184  20.006161  20.069327  20.533871  21.106643  21.379238   \n",
       "2012-01-28  21.717691  21.620184  20.006161  20.069327  20.533871  21.106643   \n",
       "2012-01-29  21.751748  21.717691  21.620184  20.006161  20.069327  20.533871   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2014-12-28  18.975586  21.678973  17.274616  13.292155  19.417643  16.099237   \n",
       "2014-12-29  20.488914  18.975586  21.678973  17.274616  13.292155  19.417643   \n",
       "2014-12-30  19.785106  20.488914  18.975586  21.678973  17.274616  13.292155   \n",
       "2014-12-31  30.684650  19.785106  20.488914  18.975586  21.678973  17.274616   \n",
       "2015-01-01  19.140787  30.684650  19.785106  20.488914  18.975586  21.678973   \n",
       "\n",
       "               lag_23     lag_24  _level_skforecast  \n",
       "date                                                 \n",
       "2012-01-25  22.777826   8.253175                  0  \n",
       "2012-01-26  27.549099  22.777826                  0  \n",
       "2012-01-27  25.895533  27.549099                  0  \n",
       "2012-01-28  21.379238  25.895533                  0  \n",
       "2012-01-29  21.106643  21.379238                  0  \n",
       "...               ...        ...                ...  \n",
       "2014-12-28  19.913343  23.642604                  2  \n",
       "2014-12-29  16.099237  19.913343                  2  \n",
       "2014-12-30  19.417643  16.099237                  2  \n",
       "2014-12-31  13.292155  19.417643                  2  \n",
       "2015-01-01  17.274616  13.292155                  2  \n",
       "\n",
       "[3219 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6a6fa6d21c4ea481d1d76071a90240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72] \n",
      "  Parameters: {'n_estimators': 40, 'max_depth': 4, 'learning_rate': 0.1836972385860176}\n",
      "  Backtesting metric: 1.9355197828331292\n",
      "  Levels: ['item_1', 'item_2', 'item_3']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error__weighted_average</th>\n",
       "      <th>mean_absolute_error__average</th>\n",
       "      <th>mean_absolute_error__pooling</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 40, 'max_depth': 4, 'learning...</td>\n",
       "      <td>1.935520</td>\n",
       "      <td>1.935520</td>\n",
       "      <td>1.935520</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.183697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 35, 'max_depth': 3, 'learning...</td>\n",
       "      <td>1.949453</td>\n",
       "      <td>1.949453</td>\n",
       "      <td>1.949453</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.324113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 38, 'max_depth': 5, 'learning...</td>\n",
       "      <td>1.997867</td>\n",
       "      <td>1.997867</td>\n",
       "      <td>1.997867</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 23, 'max_depth': 5, 'learning...</td>\n",
       "      <td>2.008125</td>\n",
       "      <td>2.008125</td>\n",
       "      <td>2.008125</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.235981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 13, 'max_depth': 6, 'learning...</td>\n",
       "      <td>2.110749</td>\n",
       "      <td>2.110749</td>\n",
       "      <td>2.110749</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.436554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 24, 'max_depth': 8, 'learning...</td>\n",
       "      <td>2.157664</td>\n",
       "      <td>2.157664</td>\n",
       "      <td>2.157664</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 27, 'max_depth': 10, 'learnin...</td>\n",
       "      <td>2.443927</td>\n",
       "      <td>2.443927</td>\n",
       "      <td>2.443927</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 22, 'max_depth': 6, 'learning...</td>\n",
       "      <td>2.569656</td>\n",
       "      <td>2.569656</td>\n",
       "      <td>2.569656</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 36, 'max_depth': 9, 'learning...</td>\n",
       "      <td>2.621470</td>\n",
       "      <td>2.621470</td>\n",
       "      <td>2.621470</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.727211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 6, 'learning...</td>\n",
       "      <td>2.746263</td>\n",
       "      <td>2.746263</td>\n",
       "      <td>2.746263</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.985704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     levels  \\\n",
       "0  [item_1, item_2, item_3]   \n",
       "1  [item_1, item_2, item_3]   \n",
       "2  [item_1, item_2, item_3]   \n",
       "3  [item_1, item_2, item_3]   \n",
       "4  [item_1, item_2, item_3]   \n",
       "5  [item_1, item_2, item_3]   \n",
       "6  [item_1, item_2, item_3]   \n",
       "7  [item_1, item_2, item_3]   \n",
       "8  [item_1, item_2, item_3]   \n",
       "9  [item_1, item_2, item_3]   \n",
       "\n",
       "                                                lags  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "5  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "6  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "7  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "8  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "9  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'n_estimators': 40, 'max_depth': 4, 'learning...   \n",
       "1  {'n_estimators': 35, 'max_depth': 3, 'learning...   \n",
       "2  {'n_estimators': 38, 'max_depth': 5, 'learning...   \n",
       "3  {'n_estimators': 23, 'max_depth': 5, 'learning...   \n",
       "4  {'n_estimators': 13, 'max_depth': 6, 'learning...   \n",
       "5  {'n_estimators': 24, 'max_depth': 8, 'learning...   \n",
       "6  {'n_estimators': 27, 'max_depth': 10, 'learnin...   \n",
       "7  {'n_estimators': 22, 'max_depth': 6, 'learning...   \n",
       "8  {'n_estimators': 36, 'max_depth': 9, 'learning...   \n",
       "9  {'n_estimators': 20, 'max_depth': 6, 'learning...   \n",
       "\n",
       "   mean_absolute_error__weighted_average  mean_absolute_error__average  \\\n",
       "0                               1.935520                      1.935520   \n",
       "1                               1.949453                      1.949453   \n",
       "2                               1.997867                      1.997867   \n",
       "3                               2.008125                      2.008125   \n",
       "4                               2.110749                      2.110749   \n",
       "5                               2.157664                      2.157664   \n",
       "6                               2.443927                      2.443927   \n",
       "7                               2.569656                      2.569656   \n",
       "8                               2.621470                      2.621470   \n",
       "9                               2.746263                      2.746263   \n",
       "\n",
       "   mean_absolute_error__pooling  n_estimators  max_depth  learning_rate  \n",
       "0                      1.935520          40.0        4.0       0.183697  \n",
       "1                      1.949453          35.0        3.0       0.324113  \n",
       "2                      1.997867          38.0        5.0       0.234583  \n",
       "3                      2.008125          23.0        5.0       0.235981  \n",
       "4                      2.110749          13.0        6.0       0.436554  \n",
       "5                      2.157664          24.0        8.0       0.444187  \n",
       "6                      2.443927          27.0       10.0       0.687981  \n",
       "7                      2.569656          22.0        6.0       0.894455  \n",
       "8                      2.621470          36.0        9.0       0.727211  \n",
       "9                      2.746263          20.0        6.0       0.985704  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = \"ordinal\",\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "lags_grid = [48, 72]\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 50),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'lags'            : trial.suggest_categorical('lags', lags_grid)\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "results, trial = bayesian_search_forecaster_multiseries(\n",
    "    series                    = data,\n",
    "    forecaster = forecaster,\n",
    "    method='one_step_ahead',\n",
    "    initial_train_size= len(data_train),\n",
    "    search_space               = search_space,\n",
    "    levels                  = levels,\n",
    "    metric='mean_absolute_error',\n",
    "    steps                   = 36,\n",
    "    verbose=False\n",
    ")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
