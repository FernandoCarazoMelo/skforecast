{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7c8824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:53:35.028706Z",
     "start_time": "2022-07-08T15:53:34.980669Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a49d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:28:40.437598Z",
     "start_time": "2022-07-08T15:28:40.417718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/jaesc2/GitHub/skforecast')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dd3842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:28:41.404349Z",
     "start_time": "2022-07-08T15:28:41.395375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Path.cwd().parent.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a85a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738fd9e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:53:36.676416Z",
     "start_time": "2022-07-08T15:53:36.156473Z"
    }
   },
   "outputs": [],
   "source": [
    "## ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "from typing import Union, Dict, List, Tuple, Any, Optional\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "from sklearn.base import clone\n",
    "from copy import copy\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.utils import check_y\n",
    "from skforecast.utils import check_exog\n",
    "from skforecast.utils import preprocess_y\n",
    "from skforecast.utils import preprocess_last_window\n",
    "from skforecast.utils import preprocess_exog\n",
    "from skforecast.utils import expand_index\n",
    "from skforecast.utils import check_predict_input\n",
    "from skforecast.utils import transform_series\n",
    "from skforecast.utils import transform_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd755b2d",
   "metadata": {},
   "source": [
    "## Create_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16033119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy_forecaster():\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        regressor,\n",
    "        lags: Union[int, np.ndarray, list],\n",
    "        transformer_series: Optional[object]=None,\n",
    "        transformer_exog: Optional[object]=None,\n",
    "        series_weights: Optional[dict]=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.regressor            = regressor\n",
    "        self.transformer_series   = transformer_series\n",
    "        self.transformer_exog     = transformer_exog\n",
    "        self.series_weights       = series_weights\n",
    "        self.index_type           = None\n",
    "        self.index_freq           = None\n",
    "        self.index_values         = None\n",
    "        self.training_range       = None\n",
    "        self.last_window          = None\n",
    "        self.included_exog        = False\n",
    "        self.exog_type            = None\n",
    "        self.exog_col_names       = None\n",
    "        self.series_levels        = None\n",
    "        self.X_train_col_names    = None\n",
    "        self.in_sample_residuals  = None\n",
    "        self.out_sample_residuals = None\n",
    "        self.fitted               = False\n",
    "        self.creation_date        = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.fit_date             = None\n",
    "        self.skforcast_version    = skforecast.__version__\n",
    "        self.python_version       = sys.version.split(\" \")[0]\n",
    "        \n",
    "        if isinstance(lags, int) and lags < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "\n",
    "        if isinstance(lags, (list, np.ndarray)):\n",
    "            for lag in lags:\n",
    "                if not isinstance(lag, (int, np.int64, np.int32)):\n",
    "                    raise TypeError('All values in `lags` must be int.')\n",
    "            \n",
    "        if isinstance(lags, (list, range, np.ndarray)) and min(lags) < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "            \n",
    "        if isinstance(lags, int):\n",
    "            self.lags = np.arange(lags) + 1\n",
    "        elif isinstance(lags, (list, range)):\n",
    "            self.lags = np.array(lags)\n",
    "        elif isinstance(lags, np.ndarray):\n",
    "            self.lags = lags\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                '`lags` argument must be int, 1d numpy ndarray, range or list. '\n",
    "                f\"Got {type(lags)}\"\n",
    "            )\n",
    "\n",
    "        if series_weights is not None:\n",
    "            if 'sample_weight' not in inspect.getfullargspec(self.regressor.fit)[0]:\n",
    "                warnings.warm(\n",
    "                    f\"\"\"\n",
    "                    Argument `series_weights` is ignored since regressor {self.regressor}\n",
    "                    does not accept `sample_weight` in its `fit` method.\n",
    "                    \"\"\"\n",
    "                )\n",
    "                self.series_weights = None\n",
    "            \n",
    "        self.max_lag = max(self.lags)\n",
    "        self.window_size = self.max_lag\n",
    "\n",
    "\n",
    "    def __repr__(\n",
    "        self\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Information displayed when a ForecasterAutoregMultiSeries object is printed.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.regressor, sklearn.pipeline.Pipeline):\n",
    "            name_pipe_steps = tuple(name + \"__\" for name in self.regressor.named_steps.keys())\n",
    "            params = {key : value for key, value in self.regressor.get_params().items() \\\n",
    "                     if key.startswith(name_pipe_steps)}\n",
    "        else:\n",
    "            params = self.regressor.get_params()\n",
    "\n",
    "        info = (\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"{str(type(self)).split('.')[1]} \\n\"\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"Regressor: {self.regressor} \\n\"\n",
    "            f\"Lags: {self.lags} \\n\"\n",
    "            f\"Transformer for series: {self.transformer_series} \\n\"\n",
    "            f\"Transformer for exog: {self.transformer_exog} \\n\"\n",
    "            f\"Window size: {self.window_size} \\n\"\n",
    "            f\"Series levels (names): {self.series_levels} \\n\"\n",
    "            f\"Series weights: {self.series_weights} \\n\"\n",
    "            f\"Included exogenous: {self.included_exog} \\n\"\n",
    "            f\"Type of exogenous variable: {self.exog_type} \\n\"\n",
    "            f\"Exogenous variables names: {self.exog_col_names} \\n\"\n",
    "            f\"Training range: {self.training_range.to_list() if self.fitted else None} \\n\"\n",
    "            f\"Training index type: {str(self.index_type).split('.')[-1][:-2] if self.fitted else None} \\n\"\n",
    "            f\"Training index frequency: {self.index_freq if self.fitted else None} \\n\"\n",
    "            f\"Regressor parameters: {params} \\n\"\n",
    "            f\"Creation date: {self.creation_date} \\n\"\n",
    "            f\"Last fit date: {self.fit_date} \\n\"\n",
    "            f\"Skforecast version: {self.skforcast_version} \\n\"\n",
    "            f\"Python version: {self.python_version} \\n\"\n",
    "        )\n",
    "\n",
    "        return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60fc6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = dummy_forecaster(\n",
    "                 regressor = 'dummy',\n",
    "                 lags = 5\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c94e1137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b915eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.max_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c648026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    self, \n",
    "    y: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "    n_splits = len(y) - self.max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            f'The maximum lag ({self.max_lag}) must be less than the length '\n",
    "            f'of the series ({len(y)}).'\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(self.lags):\n",
    "        X_data[:, i] = y[self.max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[self.max_lag:]\n",
    "        \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c6cf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4., 3., 2., 1., 0.],\n",
       "        [5., 4., 3., 2., 1.],\n",
       "        [6., 5., 4., 3., 2.],\n",
       "        [7., 6., 5., 4., 3.],\n",
       "        [8., 7., 6., 5., 4.]]),\n",
       " array([5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_lags(forecaster, np.array(list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5fca5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_X_y(\n",
    "    self,\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f'`series` must be a pandas DataFrame. Got {type(series)}.')\n",
    "\n",
    "    series_levels = list(series.columns)\n",
    "\n",
    "    if self.transformer_series is None:\n",
    "        dict_transformers = {level: None for level in series_levels}\n",
    "        self.transformer_series = dict_transformers\n",
    "    elif not isinstance(self.transformer_series, dict):\n",
    "        dict_transformers = {level: clone(self.transformer_series) \n",
    "                                for level in series_levels}\n",
    "        self.transformer_series = dict_transformers\n",
    "    else:\n",
    "        if list(self.transformer_series.keys()) != series_levels:\n",
    "            raise ValueError(\n",
    "                (f'When `transformer_series` parameter is a `dict`, its keys '\n",
    "                    f'must be the same as `series_levels` : {series_levels}.')\n",
    "            )\n",
    "    \n",
    "    X_train_col_names = [f\"{level}_lag_{lag}\" for level in series_levels for lag in self.lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        check_y(y=y)\n",
    "        y = transform_series(\n",
    "                series            = y,\n",
    "                transformer       = self.transformer_series[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "        y_values, y_index = preprocess_y(y=y)\n",
    "        X_train_values, y_train_values = self._create_lags(y=y_values)\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.hstack((X_train, X_train_values))\n",
    "            y_train = np.append(y_train, y_train_values)\n",
    "\n",
    "    if exog is not None:\n",
    "        if len(exog) != len(series):\n",
    "            raise ValueError(\n",
    "                f'`exog` must have same number of samples as `series`. '\n",
    "                f'length `exog`: ({len(exog)}), length `series`: ({len(series)})'\n",
    "            )\n",
    "        check_exog(exog=exog)\n",
    "        if isinstance(exog, pd.Series):\n",
    "            exog = transform_series(\n",
    "                        series            = exog,\n",
    "                        transformer       = self.transformer_exog,\n",
    "                        fit               = True,\n",
    "                        inverse_transform = False\n",
    "                    )\n",
    "        else:\n",
    "            exog = transform_dataframe(\n",
    "                        df                = exog,\n",
    "                        transformer       = self.transformer_exog,\n",
    "                        fit               = True,\n",
    "                        inverse_transform = False\n",
    "                    )\n",
    "        exog_values, exog_index = preprocess_exog(exog=exog)\n",
    "        if not (exog_index[:len(y_index)] == y_index).all():\n",
    "            raise ValueError(\n",
    "                ('Different index for `series` and `exog`. They must be equal '\n",
    "                    'to ensure the correct alignment of values.')      \n",
    "            )\n",
    "        col_names_exog = exog.columns if isinstance(exog, pd.DataFrame) else [exog.name]\n",
    "        X_train_col_names.extend(col_names_exog)\n",
    "\n",
    "        # The first `self.max_lag` positions have to be removed from exog\n",
    "        # since they are not in X_train. Then exog is cloned as many times\n",
    "        # as series.\n",
    "        if exog_values.ndim == 1:\n",
    "            X_train = np.column_stack((\n",
    "                        X_train,\n",
    "                        np.tile(exog_values[self.max_lag:, ], series.shape[1])\n",
    "                        )) \n",
    "\n",
    "        else:\n",
    "            X_train = np.column_stack((\n",
    "                        X_train,\n",
    "                        np.tile(exog_values[self.max_lag:, ], [series.shape[1], 1])\n",
    "                        ))\n",
    "\n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "    X_train_col_names.extend(X_levels.columns)\n",
    "    X_train = np.column_stack((X_train, X_levels.values))\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                data    = X_train,\n",
    "                columns = X_train_col_names\n",
    "            )\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                data  = y_train,\n",
    "                name  = 'y'\n",
    "            )\n",
    "    \n",
    "    self.X_train_col_names = X_train_col_names\n",
    "\n",
    "    return X_train, y_train, y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bee2295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 100, 100],\n",
       "       [  1,   1, 101, 101],\n",
       "       [  2,   2, 102, 102],\n",
       "       [  3,   3, 103, 103],\n",
       "       [  4,   4, 104, 104]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_1 = pd.DataFrame({'1': pd.Series(np.arange(5)),  \n",
    "                         '2': pd.Series(np.arange(5))\n",
    "                        })\n",
    "\n",
    "series_2 = pd.DataFrame({'1': pd.Series(np.arange(100, 105)),  \n",
    "                         '2': pd.Series(np.arange(100, 105))\n",
    "                        })\n",
    "\n",
    "X_train = np.hstack((series_1.values, series_2.values))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7a0e159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l2_lag_1', 'l2_lag_2', 'l2_lag_3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = np.array([1,2,3])\n",
    "levels = ['l1', 'l2']\n",
    "\n",
    "[f\"{level}_lag_{lag}\" for level in levels for lag in lags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81b45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fb9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81344f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64a312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food_digital",
   "language": "python",
   "name": "food_digital"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
