{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7c8824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:53:35.028706Z",
     "start_time": "2022-07-08T15:53:34.980669Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a49d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:28:40.437598Z",
     "start_time": "2022-07-08T15:28:40.417718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/jaesc2/GitHub/skforecast')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dd3842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:28:41.404349Z",
     "start_time": "2022-07-08T15:28:41.395375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Path.cwd().parent.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a85a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738fd9e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T15:53:36.676416Z",
     "start_time": "2022-07-08T15:53:36.156473Z"
    }
   },
   "outputs": [],
   "source": [
    "## ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "from typing import Union, Dict, List, Tuple, Any, Optional\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "from sklearn.base import clone\n",
    "from copy import copy\n",
    "\n",
    "import skforecast\n",
    "from skforecast.ForecasterBase import ForecasterBase\n",
    "from skforecast.utils import check_y\n",
    "from skforecast.utils import check_exog\n",
    "from skforecast.utils import preprocess_y\n",
    "from skforecast.utils import preprocess_last_window\n",
    "from skforecast.utils import preprocess_exog\n",
    "from skforecast.utils import expand_index\n",
    "from skforecast.utils import check_predict_input\n",
    "from skforecast.utils import transform_series\n",
    "from skforecast.utils import transform_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd755b2d",
   "metadata": {},
   "source": [
    "## Create_train_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16033119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy_forecaster():\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        regressor,\n",
    "        lags: Union[int, np.ndarray, list],\n",
    "        transformer_series: Optional[object]=None,\n",
    "        transformer_exog: Optional[object]=None,\n",
    "        series_weights: Optional[dict]=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.regressor            = regressor\n",
    "        self.transformer_series   = transformer_series\n",
    "        self.transformer_exog     = transformer_exog\n",
    "        self.series_weights       = series_weights\n",
    "        self.index_type           = None\n",
    "        self.index_freq           = None\n",
    "        self.index_values         = None\n",
    "        self.training_range       = None\n",
    "        self.last_window          = None\n",
    "        self.included_exog        = False\n",
    "        self.exog_type            = None\n",
    "        self.exog_col_names       = None\n",
    "        self.series_levels        = None\n",
    "        self.X_train_col_names    = None\n",
    "        self.in_sample_residuals  = None\n",
    "        self.out_sample_residuals = None\n",
    "        self.fitted               = False\n",
    "        self.creation_date        = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.fit_date             = None\n",
    "        self.skforcast_version    = skforecast.__version__\n",
    "        self.python_version       = sys.version.split(\" \")[0]\n",
    "        \n",
    "        if isinstance(lags, int) and lags < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "\n",
    "        if isinstance(lags, (list, np.ndarray)):\n",
    "            for lag in lags:\n",
    "                if not isinstance(lag, (int, np.int64, np.int32)):\n",
    "                    raise TypeError('All values in `lags` must be int.')\n",
    "            \n",
    "        if isinstance(lags, (list, range, np.ndarray)) and min(lags) < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "            \n",
    "        if isinstance(lags, int):\n",
    "            self.lags = np.arange(lags) + 1\n",
    "        elif isinstance(lags, (list, range)):\n",
    "            self.lags = np.array(lags)\n",
    "        elif isinstance(lags, np.ndarray):\n",
    "            self.lags = lags\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                '`lags` argument must be int, 1d numpy ndarray, range or list. '\n",
    "                f\"Got {type(lags)}\"\n",
    "            )\n",
    "\n",
    "        if series_weights is not None:\n",
    "            if 'sample_weight' not in inspect.getfullargspec(self.regressor.fit)[0]:\n",
    "                warnings.warm(\n",
    "                    f\"\"\"\n",
    "                    Argument `series_weights` is ignored since regressor {self.regressor}\n",
    "                    does not accept `sample_weight` in its `fit` method.\n",
    "                    \"\"\"\n",
    "                )\n",
    "                self.series_weights = None\n",
    "            \n",
    "        self.max_lag = max(self.lags)\n",
    "        self.window_size = self.max_lag\n",
    "\n",
    "\n",
    "    def __repr__(\n",
    "        self\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Information displayed when a ForecasterAutoregMultiSeries object is printed.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.regressor, sklearn.pipeline.Pipeline):\n",
    "            name_pipe_steps = tuple(name + \"__\" for name in self.regressor.named_steps.keys())\n",
    "            params = {key : value for key, value in self.regressor.get_params().items() \\\n",
    "                     if key.startswith(name_pipe_steps)}\n",
    "        else:\n",
    "            params = self.regressor.get_params()\n",
    "\n",
    "        info = (\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"{str(type(self)).split('.')[1]} \\n\"\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"Regressor: {self.regressor} \\n\"\n",
    "            f\"Lags: {self.lags} \\n\"\n",
    "            f\"Transformer for series: {self.transformer_series} \\n\"\n",
    "            f\"Transformer for exog: {self.transformer_exog} \\n\"\n",
    "            f\"Window size: {self.window_size} \\n\"\n",
    "            f\"Series levels (names): {self.series_levels} \\n\"\n",
    "            f\"Series weights: {self.series_weights} \\n\"\n",
    "            f\"Included exogenous: {self.included_exog} \\n\"\n",
    "            f\"Type of exogenous variable: {self.exog_type} \\n\"\n",
    "            f\"Exogenous variables names: {self.exog_col_names} \\n\"\n",
    "            f\"Training range: {self.training_range.to_list() if self.fitted else None} \\n\"\n",
    "            f\"Training index type: {str(self.index_type).split('.')[-1][:-2] if self.fitted else None} \\n\"\n",
    "            f\"Training index frequency: {self.index_freq if self.fitted else None} \\n\"\n",
    "            f\"Regressor parameters: {params} \\n\"\n",
    "            f\"Creation date: {self.creation_date} \\n\"\n",
    "            f\"Last fit date: {self.fit_date} \\n\"\n",
    "            f\"Skforecast version: {self.skforcast_version} \\n\"\n",
    "            f\"Python version: {self.python_version} \\n\"\n",
    "        )\n",
    "\n",
    "        return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60fc6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = dummy_forecaster(\n",
    "                 regressor = 'dummy',\n",
    "                 lags = 5\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c94e1137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b915eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.max_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c648026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lags(\n",
    "    self, \n",
    "    y: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \n",
    "    n_splits = len(y) - self.max_lag\n",
    "    if n_splits <= 0:\n",
    "        raise ValueError(\n",
    "            f'The maximum lag ({self.max_lag}) must be less than the length '\n",
    "            f'of the series ({len(y)}).'\n",
    "        )\n",
    "    \n",
    "    X_data = np.full(shape=(n_splits, len(self.lags)), fill_value=np.nan, dtype=float)\n",
    "\n",
    "    for i, lag in enumerate(self.lags):\n",
    "        X_data[:, i] = y[self.max_lag - lag: -lag]\n",
    "\n",
    "    y_data = y[self.max_lag:]\n",
    "        \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c6cf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4., 3., 2., 1., 0.],\n",
       "        [5., 4., 3., 2., 1.],\n",
       "        [6., 5., 4., 3., 2.],\n",
       "        [7., 6., 5., 4., 3.],\n",
       "        [8., 7., 6., 5., 4.]]),\n",
       " array([5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_lags(forecaster, np.array(list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5fca5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_X_y(\n",
    "    self,\n",
    "    series: pd.DataFrame,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "    if not isinstance(series, pd.DataFrame):\n",
    "        raise TypeError(f'`series` must be a pandas DataFrame. Got {type(series)}.')\n",
    "\n",
    "    series_levels = list(series.columns)\n",
    "\n",
    "    if self.transformer_series is None:\n",
    "        dict_transformers = {level: None for level in series_levels}\n",
    "        self.transformer_series = dict_transformers\n",
    "    elif not isinstance(self.transformer_series, dict):\n",
    "        dict_transformers = {level: clone(self.transformer_series) \n",
    "                                for level in series_levels}\n",
    "        self.transformer_series = dict_transformers\n",
    "    else:\n",
    "        if list(self.transformer_series.keys()) != series_levels:\n",
    "            raise ValueError(\n",
    "                (f'When `transformer_series` parameter is a `dict`, its keys '\n",
    "                    f'must be the same as `series_levels` : {series_levels}.')\n",
    "            )\n",
    "    \n",
    "    X_train_col_names = [f\"{level}_lag_{lag}\" for level in series_levels for lag in self.lags]\n",
    "\n",
    "    for i, serie in enumerate(series.columns):\n",
    "\n",
    "        y = series[serie]\n",
    "        check_y(y=y)\n",
    "        y = transform_series(\n",
    "                series            = y,\n",
    "                transformer       = self.transformer_series[serie],\n",
    "                fit               = True,\n",
    "                inverse_transform = False\n",
    "            )\n",
    "        y_values, y_index = preprocess_y(y=y)\n",
    "        X_train_values, y_train_values = self._create_lags(y=y_values)\n",
    "\n",
    "        if i == 0:\n",
    "            X_train = X_train_values\n",
    "            y_train = y_train_values\n",
    "        else:\n",
    "            X_train = np.hstack((X_train, X_train_values))\n",
    "            y_train = np.append(y_train, y_train_values)\n",
    "\n",
    "    if exog is not None:\n",
    "        if len(exog) != len(series):\n",
    "            raise ValueError(\n",
    "                f'`exog` must have same number of samples as `series`. '\n",
    "                f'length `exog`: ({len(exog)}), length `series`: ({len(series)})'\n",
    "            )\n",
    "        check_exog(exog=exog)\n",
    "        if isinstance(exog, pd.Series):\n",
    "            exog = transform_series(\n",
    "                        series            = exog,\n",
    "                        transformer       = self.transformer_exog,\n",
    "                        fit               = True,\n",
    "                        inverse_transform = False\n",
    "                    )\n",
    "        else:\n",
    "            exog = transform_dataframe(\n",
    "                        df                = exog,\n",
    "                        transformer       = self.transformer_exog,\n",
    "                        fit               = True,\n",
    "                        inverse_transform = False\n",
    "                    )\n",
    "        exog_values, exog_index = preprocess_exog(exog=exog)\n",
    "        if not (exog_index[:len(y_index)] == y_index).all():\n",
    "            raise ValueError(\n",
    "                ('Different index for `series` and `exog`. They must be equal '\n",
    "                    'to ensure the correct alignment of values.')      \n",
    "            )\n",
    "        col_names_exog = exog.columns if isinstance(exog, pd.DataFrame) else [exog.name]\n",
    "        X_train_col_names.extend(col_names_exog)\n",
    "\n",
    "        # The first `self.max_lag` positions have to be removed from exog\n",
    "        # since they are not in X_train. Then exog is cloned as many times\n",
    "        # as series.\n",
    "        if exog_values.ndim == 1:\n",
    "            X_train = np.column_stack((\n",
    "                        X_train,\n",
    "                        np.tile(exog_values[self.max_lag:, ], series.shape[1])\n",
    "                        )) \n",
    "\n",
    "        else:\n",
    "            X_train = np.column_stack((\n",
    "                        X_train,\n",
    "                        np.tile(exog_values[self.max_lag:, ], [series.shape[1], 1])\n",
    "                        ))\n",
    "\n",
    "    X_levels = pd.Series(X_levels)\n",
    "    X_levels = pd.get_dummies(X_levels, dtype=float)\n",
    "    X_train_col_names.extend(X_levels.columns)\n",
    "    X_train = np.column_stack((X_train, X_levels.values))\n",
    "\n",
    "    X_train = pd.DataFrame(\n",
    "                data    = X_train,\n",
    "                columns = X_train_col_names\n",
    "            )\n",
    "\n",
    "    y_train = pd.Series(\n",
    "                data  = y_train,\n",
    "                name  = 'y'\n",
    "            )\n",
    "    \n",
    "    self.X_train_col_names = X_train_col_names\n",
    "\n",
    "    return X_train, y_train, y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bee2295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 100, 100],\n",
       "       [  1,   1, 101, 101],\n",
       "       [  2,   2, 102, 102],\n",
       "       [  3,   3, 103, 103],\n",
       "       [  4,   4, 104, 104]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_1 = pd.DataFrame({'1': pd.Series(np.arange(5)),  \n",
    "                         '2': pd.Series(np.arange(5))\n",
    "                        })\n",
    "\n",
    "series_2 = pd.DataFrame({'1': pd.Series(np.arange(100, 105)),  \n",
    "                         '2': pd.Series(np.arange(100, 105))\n",
    "                        })\n",
    "\n",
    "X_train = np.hstack((series_1.values, series_2.values))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7a0e159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l2_lag_1', 'l2_lag_2', 'l2_lag_3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = np.array([1,2,3])\n",
    "levels = ['l1', 'l2']\n",
    "\n",
    "[f\"{level}_lag_{lag}\" for level in levels for lag in lags]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbbe03",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd81b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecasterAutoregMultiVariate(ForecasterBase):\n",
    "        \n",
    "    def __init__(\n",
    "        self,\n",
    "        regressor: dict[str, object],\n",
    "        lags: dict[str, Union[int, np.ndarray, list]],\n",
    "        transformer_series: Optional[Union[object, dict[str, object]]]=None,\n",
    "        transformer_exog: Optional[Union[object, dict[str, object]]]=None,\n",
    "        series_weights: Optional[dict[str, float]]=None,\n",
    "        weight_func: Optional[Union[callable, dict[str, callable]]]=None\n",
    "    ) -> None:\n",
    "        \n",
    "        self.regressor               = regressor\n",
    "        self.transformer_series      = transformer_series\n",
    "        self.transformer_exog        = transformer_exog\n",
    "        self.series_weights          = series_weights\n",
    "        self.weight_func             = weight_func\n",
    "        self.source_code_weight_func = None\n",
    "        self.index_type              = None\n",
    "        self.index_freq              = None\n",
    "        self.index_values            = None\n",
    "        self.training_range          = None\n",
    "        self.last_window             = None\n",
    "        self.included_exog           = False\n",
    "        self.exog_type               = None\n",
    "        self.exog_col_names          = None\n",
    "        self.series_levels           = None\n",
    "        self.X_train_col_names       = None\n",
    "        self.in_sample_residuals     = None\n",
    "        self.out_sample_residuals    = None\n",
    "        self.fitted                  = False\n",
    "        self.creation_date           = pd.Timestamp.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.fit_date                = None\n",
    "        self.skforcast_version       = skforecast.__version__\n",
    "        self.python_version          = sys.version.split(\" \")[0]\n",
    "        \n",
    "        if not isinstance(self.regressor, dict):\n",
    "            raise TypeError(\n",
    "                ('The `regressor` argument must be a `dict` containing the levels of '\n",
    "                 'the forecaster (column names of the series) as keys and the '\n",
    "                 'corresponding regressor for each level. {level (str) : regressor}.')\n",
    "            )\n",
    "\n",
    "        for key in self.regressor:\n",
    "            if not isinstance(key, str):\n",
    "                raise TypeError(\n",
    "                    f\"All regressor dict keys must be a string.\\n\"\n",
    "                    f\"    Key {key} is a {type(key)}\"\n",
    "                )\n",
    "\n",
    "        # Next crear lags dict, si es un dict comprobar que coinciden las keys\n",
    "\n",
    "        if isinstance(lags, int) and lags < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "\n",
    "        if isinstance(lags, (list, np.ndarray)):\n",
    "            for lag in lags:\n",
    "                if not isinstance(lag, (int, np.int64, np.int32)):\n",
    "                    raise TypeError('All values in `lags` must be int.')\n",
    "            \n",
    "        if isinstance(lags, (list, range, np.ndarray)) and min(lags) < 1:\n",
    "            raise ValueError('Minimum value of lags allowed is 1.')\n",
    "            \n",
    "        if isinstance(lags, int):\n",
    "            self.lags = np.arange(lags) + 1\n",
    "        elif isinstance(lags, (list, range)):\n",
    "            self.lags = np.array(lags)\n",
    "        elif isinstance(lags, np.ndarray):\n",
    "            self.lags = lags\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                '`lags` argument must be int, 1d numpy ndarray, range or list. '\n",
    "                f\"Got {type(lags)}\"\n",
    "            )\n",
    "\n",
    "        if series_weights is not None:\n",
    "            if 'sample_weight' not in inspect.getfullargspec(self.regressor.fit)[0]:\n",
    "                warnings.warm(\n",
    "                    f\"\"\"\n",
    "                    Argument `series_weights` is ignored since regressor {self.regressor}\n",
    "                    does not accept `sample_weight` in its `fit` method.\n",
    "                    \"\"\"\n",
    "                )\n",
    "                self.series_weights = None\n",
    "            \n",
    "        self.max_lag = max(self.lags)\n",
    "        self.window_size = self.max_lag\n",
    "\n",
    "\n",
    "    def __repr__(\n",
    "        self\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Information displayed when a ForecasterAutoregMultiSeries object is printed.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.regressor, sklearn.pipeline.Pipeline):\n",
    "            name_pipe_steps = tuple(name + \"__\" for name in self.regressor.named_steps.keys())\n",
    "            params = {key : value for key, value in self.regressor.get_params().items() \\\n",
    "                     if key.startswith(name_pipe_steps)}\n",
    "        else:\n",
    "            params = self.regressor.get_params()\n",
    "\n",
    "        info = (\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"{str(type(self)).split('.')[1]} \\n\"\n",
    "            f\"{'=' * len(str(type(self)).split('.')[1])} \\n\"\n",
    "            f\"Regressor: {self.regressor} \\n\"\n",
    "            f\"Lags: {self.lags} \\n\"\n",
    "            f\"Transformer for series: {self.transformer_series} \\n\"\n",
    "            f\"Transformer for exog: {self.transformer_exog} \\n\"\n",
    "            f\"Window size: {self.window_size} \\n\"\n",
    "            f\"Series levels (names): {self.series_levels} \\n\"\n",
    "            f\"Series weights: {self.series_weights} \\n\"\n",
    "            f\"Included exogenous: {self.included_exog} \\n\"\n",
    "            f\"Type of exogenous variable: {self.exog_type} \\n\"\n",
    "            f\"Exogenous variables names: {self.exog_col_names} \\n\"\n",
    "            f\"Training range: {self.training_range.to_list() if self.fitted else None} \\n\"\n",
    "            f\"Training index type: {str(self.index_type).split('.')[-1][:-2] if self.fitted else None} \\n\"\n",
    "            f\"Training index frequency: {self.index_freq if self.fitted else None} \\n\"\n",
    "            f\"Regressor parameters: {params} \\n\"\n",
    "            f\"Creation date: {self.creation_date} \\n\"\n",
    "            f\"Last fit date: {self.fit_date} \\n\"\n",
    "            f\"Skforecast version: {self.skforcast_version} \\n\"\n",
    "            f\"Python version: {self.python_version} \\n\"\n",
    "        )\n",
    "\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29fb9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in {'1':1, 2:2}.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81344f50",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`lags` argument must be int, 1d numpy ndarray, range or list.\nGot : [<class 'str'>, <class 'int'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m2\u001b[39m}\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m      2\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m      4\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m`lags` argument must be int, 1d numpy ndarray, range or list.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot : \u001b[39m\u001b[39m{\u001b[39;00m[\u001b[39mtype\u001b[39m(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m2\u001b[39m}\u001b[39m.\u001b[39mkeys()]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: `lags` argument must be int, 1d numpy ndarray, range or list.\nGot : [<class 'str'>, <class 'int'>]"
     ]
    }
   ],
   "source": [
    "for key in {'1':1, 2:2}.keys():\n",
    "    if not isinstance(key, str):\n",
    "        raise TypeError(\n",
    "            f\"All regressor dict keys must be a string.\\n\"\n",
    "            f\"    Key {key} is a {type(key)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa64a312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[str, int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(key) for key in {'1':1, 2:2}.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66ec90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(10).reshape(-1, 1)\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "weights = [1, 1, 1, 1, -1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b99aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaesc2\\AppData\\Local\\Temp\\ipykernel_6968\\380885746.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X=x, y=y, sample_weight=weights)\n",
      "c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:667: RuntimeWarning: invalid value encountered in add\n",
      "  out[0] += prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-inf, -inf, -inf,  nan,  nan,  nan,  nan,  inf,  inf,  inf])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X=x, y=y, sample_weight=weights)\n",
    "model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "043a46aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to `sample_weight`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mx, y\u001b[39m=\u001b[39my, sample_weight\u001b[39m=\u001b[39mweights)\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39mpredict(y)\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast\\lib\\site-packages\\sklearn\\linear_model\\_base.py:688\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    682\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    684\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    685\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39maccept_sparse, y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    686\u001b[0m )\n\u001b[1;32m--> 688\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    689\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mdtype, only_non_negative\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    693\u001b[0m     X,\n\u001b[0;32m    694\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m \u001b[39m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast\\lib\\site-packages\\sklearn\\utils\\validation.py:1736\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[1;34m(sample_weight, X, dtype, copy, only_non_negative)\u001b[0m\n\u001b[0;32m   1729\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1730\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msample_weight.shape == \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1731\u001b[0m                 sample_weight\u001b[39m.\u001b[39mshape, (n_samples,)\n\u001b[0;32m   1732\u001b[0m             )\n\u001b[0;32m   1733\u001b[0m         )\n\u001b[0;32m   1735\u001b[0m \u001b[39mif\u001b[39;00m only_non_negative:\n\u001b[1;32m-> 1736\u001b[0m     check_non_negative(sample_weight, \u001b[39m\"\u001b[39;49m\u001b[39m`sample_weight`\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1738\u001b[0m \u001b[39mreturn\u001b[39;00m sample_weight\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast\\lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     X_min \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmin()\n\u001b[0;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m X_min \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNegative values in data passed to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to `sample_weight`"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=x, y=y, sample_weight=weights)\n",
    "model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "464e8d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "np.any(np.array(weights) < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149ca45",
   "metadata": {},
   "source": [
    "## ForecasterAutoregDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3717b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c3c52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y/%m/%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data['y']\n",
    "data = data.sort_index()\n",
    "\n",
    "# Split train-test\n",
    "# ==============================================================================\n",
    "steps = 36\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "# fig, ax=plt.subplots(figsize=(9, 4))\n",
    "# data_train.plot(ax=ax, label='train')\n",
    "# data_test.plot(ax=ax, label='test')\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6ea1a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================= \n",
       "ForecasterAutoregDirect \n",
       "======================= \n",
       "Regressor: Ridge() \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Included weights function: False \n",
       "Window size: 15 \n",
       "Maximum steps predicted: 5 \n",
       "Included exogenous: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': 'deprecated', 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001} \n",
       "Creation date: 2022-10-31 17:32:31 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.6.0 \n",
       "Python version: 3.9.13 "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = Ridge(),\n",
    "                 steps     = 5,\n",
    "                 lags      = 15\n",
    "             )\n",
    "\n",
    "# forecaster.fit(y=data_train)\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0471a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aa = {'a1':3, 'a2':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a5be09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 3, 'l2': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = 3\n",
    "multivariate_series = ['l1', 'l2']\n",
    "\n",
    "dict_lags = {serie: lags for serie in multivariate_series}\n",
    "lags = dict_lags\n",
    "\n",
    "lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83653789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': [1, 2, 3], 'l2': [1, 2, 3]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags = [1, 2, 3]\n",
    "multivariate_series = ['l1', 'l2']\n",
    "\n",
    "lags = {serie: lags for serie in multivariate_series}\n",
    "\n",
    "lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8053ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': [1, 2, 3], 'l2': [1, 2, 3]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4faf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l2_lag_1', 'l2_lag_2', 'l2_lag_3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{key}_lag_{lag}\" for key in lags for lag in lags[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c03760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "serie = 'l1'\n",
    "series = ['1', '2', '3']\n",
    "\n",
    "if serie not in series:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5c52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('skforecast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6ffed84beb63baa96f7d22d816ccf3255c078420a09b57d1f48b4641bbf1489e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
