{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data['y']\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-validation dates\n",
    "# ==============================================================================\n",
    "end_train = '2002-01-01 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fc3ae7564743859cbfc9c89cff053e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.344471182248395\n",
      "mae forecast: 0.19922359134545478\n",
      "mae in sample: 0.08497591817460318\n",
      "mase: 2.344471182248395\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(data.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 127\n",
      "Number of observations used for backtesting: 77\n",
      "    Number of folds: 8\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 7 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-02-01 00:00:00 -- 2002-11-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-12-01 00:00:00 -- 2003-09-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2003-10-01 00:00:00 -- 2004-07-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2004-08-01 00:00:00 -- 2005-05-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2005-06-01 00:00:00 -- 2006-03-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2006-04-01 00:00:00 -- 2007-01-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-02-01 00:00:00 -- 2007-11-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-12-01 00:00:00 -- 2008-06-01 00:00:00  (n=7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f765cfa0b5d435ca390ee4cb6f56920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.462755601999461\n",
      "mae forecast: 0.23185816123376632\n",
      "mae in sample: 0.09414582634408604\n",
      "mase: 2.462755601999461\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 3,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "refit_intervals = [\n",
    "    ('1991-07-01 00:00:00', '2002-01-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2004-07-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2007-01-01 00:00:00')\n",
    "]\n",
    "\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "y_train = pd.concat([data.loc[start:end] for start, end in refit_intervals])\n",
    "y_train = y_train.loc[~y_train.index.duplicated(keep='first')]\n",
    "naive_in_sample_foreast = y_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(y_train.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b558978c7cb4241b6b311e92542ca04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error\n",
       "0  item_1                    1.091527\n",
       "1  item_2                    1.563339\n",
       "2  item_3                    0.959262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase: [1.09152723 1.56333908 0.95926186]\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster: no aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast / mae_in_sample\n",
    "print(f\"mase: {mase}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == mase).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0468466ba1843e5b622d58dd32f9253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "      <td>1.691320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "      <td>3.707672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "      <td>3.571717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>1.173480</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0            item_1                    1.091527             1.691320\n",
       "1            item_2                    1.563339             3.707672\n",
       "2            item_3                    0.959262             3.571717\n",
       "3           average                    1.204709             2.990236\n",
       "4  weighted_average                    1.204709             2.990236\n",
       "5           pooling                    1.173480             2.990236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backtesting forecaster: aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          aggregate_metric      = True,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample_foreast = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast/mae_in_sample\n",
    "average_mase = mase.mean()\n",
    "weighted_average_mase = np.average(mase, weights=predictions.notna().sum())\n",
    "average_mae = mae_foreast.mean()\n",
    "weighted_average_mae = np.average(mae_foreast, weights=predictions.notna().sum())\n",
    "\n",
    "pooled_y_true_y_pred = pd.merge(\n",
    "    data.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    predictions.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    on=['datetime', 'variable'],\n",
    "    suffixes=('_true', '_pred'),\n",
    "    how='inner'\n",
    ")\n",
    "pooled_mae_foreast = mean_absolute_error(\n",
    "    pooled_y_true_y_pred['value_true'],\n",
    "    pooled_y_true_y_pred['value_pred']\n",
    ")\n",
    "pooled_naive_in_sample_foreast = np.concatenate([np.diff(data.loc[:end_train, col]) for col in data.columns])\n",
    "pooled_mae_in_sample_forecast = np.mean(np.abs(pooled_naive_in_sample_foreast))\n",
    "pooled_mase = pooled_mae_foreast/pooled_mae_in_sample_forecast\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': ['average', 'weighted_average', 'pooling'],\n",
    "    'mean_absolute_scaled_error': [average_mase, weighted_average_mase, pooled_mase],\n",
    "    'mean_absolute_error': [average_mae, weighted_average_mae, pooled_mae_foreast]\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    metric.query('levels in [\"average\", \"weighted_average\", \"pooling\"]').reset_index(drop=True),\n",
    "    expected_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 927\n",
      "Number of observations used for backtesting: 170\n",
      "    Number of folds: 17\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-16 00:00:00 -- 2014-07-25 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-26 00:00:00 -- 2014-08-04 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-05 00:00:00 -- 2014-08-14 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-15 00:00:00 -- 2014-08-24 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-25 00:00:00 -- 2014-09-03 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-04 00:00:00 -- 2014-09-13 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-14 00:00:00 -- 2014-09-23 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-24 00:00:00 -- 2014-10-03 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-04 00:00:00 -- 2014-10-13 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-14 00:00:00 -- 2014-10-23 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-10-24 00:00:00 -- 2014-11-02 00:00:00  (n=10)\n",
      "Fold: 11\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-03 00:00:00 -- 2014-11-12 00:00:00  (n=10)\n",
      "Fold: 12\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-13 00:00:00 -- 2014-11-22 00:00:00  (n=10)\n",
      "Fold: 13\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-23 00:00:00 -- 2014-12-02 00:00:00  (n=10)\n",
      "Fold: 14\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-03 00:00:00 -- 2014-12-12 00:00:00  (n=10)\n",
      "Fold: 15\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-13 00:00:00 -- 2014-12-22 00:00:00  (n=10)\n",
      "Fold: 16\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-23 00:00:00 -- 2015-01-01 00:00:00  (n=10)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e73a8aac794bdc89b923520e79207d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.106355</td>\n",
       "      <td>1.690569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.571983</td>\n",
       "      <td>3.670363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>1.005813</td>\n",
       "      <td>3.715934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0  item_1                    1.106355             1.690569\n",
       "1  item_2                    1.571983             3.670363\n",
       "2  item_3                    1.005813             3.715934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69056888 3.67036308 3.71593437]\n",
      "mae in sample: [1.52805244 2.33486251 3.69445992]\n",
      "mase: [1.10635527 1.57198253 1.00581261]\n",
      "mase average: 1.2280501371035948\n",
      "mase weighted average: 1.228050137103595\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 10,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "# Manual check\n",
    "refit_intervals = [\n",
    "    ('2012-01-01 00:00:00', '2014-07-15 00:00:00'),\n",
    "    ('2012-04-10 00:00:00', '2014-10-23 00:00:00')\n",
    "]\n",
    "\n",
    "mae_forecast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "data_train = pd.concat([data.loc[start:end, :] for start, end in refit_intervals])\n",
    "data_train = data_train.loc[~data_train.index.duplicated(keep='first'), :]\n",
    "naive_in_sample_foreast = data_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_forecast/mae_in_sample\n",
    "mase_average = mase.mean()\n",
    "mase_weighted_average = np.average(mase, weights=predictions.notna().sum())\n",
    "\n",
    "print(f\"mae forecast: {mae_forecast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mase}\")\n",
    "print(f\"mase average: {mase_average}\")\n",
    "print(f\"mase weighted average: {mase_weighted_average}\")\n",
    "assert (metric.loc[metric['levels']=='average', 'mean_absolute_scaled_error'] == mase_average).all()\n",
    "assert (metric.loc[metric['levels']=='weighted_average', 'mean_absolute_scaled_error'] == mase_weighted_average).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "end_val = '2014-10-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_val = data.loc[end_train:end_val, :].copy()\n",
    "data_test  = data.loc[end_val:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 models compared for 3 level(s). Number of iterations: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0c25d0e48f40289f3a79f1817cf54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76dd4c6ab604f08869aa52232129231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.011987</td>\n",
       "      <td>1.182015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.012102</td>\n",
       "      <td>1.182061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.285467</td>\n",
       "      <td>1.289339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.285631</td>\n",
       "      <td>1.289404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.411347</td>\n",
       "      <td>1.338739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.411571</td>\n",
       "      <td>1.338827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.986100</td>\n",
       "      <td>1.956731</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.988957</td>\n",
       "      <td>1.957852</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.990710</td>\n",
       "      <td>1.958540</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aggregation       lags lags_label                  params  \\\n",
       "0     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 0}   \n",
       "1     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 1}   \n",
       "2     pooling     [1, 2]     [1, 2]            {'alpha': 0}   \n",
       "3     pooling     [1, 2]     [1, 2]            {'alpha': 1}   \n",
       "4     pooling        [1]        [1]            {'alpha': 0}   \n",
       "5     pooling        [1]        [1]            {'alpha': 1}   \n",
       "6     pooling  [1, 2, 3]  [1, 2, 3]  {'alpha': 10000000000}   \n",
       "7     pooling     [1, 2]     [1, 2]  {'alpha': 10000000000}   \n",
       "8     pooling        [1]        [1]  {'alpha': 10000000000}   \n",
       "\n",
       "   mean_absolute_error  mean_absolute_scaled_error        alpha  \n",
       "0             3.011987                    1.182015            0  \n",
       "1             3.012102                    1.182061            1  \n",
       "2             3.285467                    1.289339            0  \n",
       "3             3.285631                    1.289404            1  \n",
       "4             3.411347                    1.338739            0  \n",
       "5             3.411571                    1.338827            1  \n",
       "6             4.986100                    1.956731  10000000000  \n",
       "7             4.988957                    1.957852  10000000000  \n",
       "8             4.990710                    1.958540  10000000000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "lags_grid =[1, 2, 3]\n",
    "param_grid = {'alpha': [0, 1, 10000000000]}\n",
    "\n",
    "results = grid_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          lags_grid             = lags_grid,\n",
    "                          param_grid            = param_grid,\n",
    "                          steps                 = 12,\n",
    "                          metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "                          aggregate_metric      = 'pooling',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True\n",
    "                      )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e984248b82cf455f91c5213279da3246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.4807958141120149}</td>\n",
       "      <td>2.562235</td>\n",
       "      <td>0.480796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.667878511469039}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>0.667879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.6709608626961889}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>0.670961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.2579065805327433}</td>\n",
       "      <td>3.012016</td>\n",
       "      <td>0.257907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aggregation             lags                         params  \\\n",
       "0  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.4807958141120149}   \n",
       "1  weighted_average  [1, 2, 3, 4, 5]   {'alpha': 0.667878511469039}   \n",
       "2  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.6709608626961889}   \n",
       "3  weighted_average        [1, 2, 3]  {'alpha': 0.2579065805327433}   \n",
       "\n",
       "   mean_absolute_error     alpha  \n",
       "0             2.562235  0.480796  \n",
       "1             2.562239  0.667879  \n",
       "2             2.562239  0.670961  \n",
       "3             3.012016  0.257907  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1,\n",
    "                 encoding= 'ordinal'\n",
    "             )\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'             : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'alpha'            : trial.suggest_float('alpha', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          search_space          = search_space,\n",
    "                          steps                 = 12,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          aggregate_metric      = 'weighted_average',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          engine                = 'optuna',\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "THIS_DIR = \"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests\"\n",
    "series_dict = joblib.load(THIS_DIR+ \"/\" + 'fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load(THIS_DIR+ \"/\" +'fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n",
    "series_with_nans = series.copy()\n",
    "series_with_nans.loc[:10, 'l2'] = np.nan\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 2 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-3:-1]\n",
    "\n",
    "    return lags\n",
    "\n",
    "def create_predictors_14(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 14 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-15:-1]\n",
    "\n",
    "    return lags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf4e9e77ec344a6ba873ee4ff5dcc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "        regressor=LGBMRegressor(\n",
    "            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "        ),\n",
    "        lags=14,\n",
    "        encoding='ordinal',\n",
    "        dropna_from_series=False,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "    )\n",
    "\n",
    "metrics, predictions = backtesting_forecaster_multiseries(\n",
    "        forecaster            = forecaster,\n",
    "        series                = series_dict,\n",
    "        exog                  = exog_dict,\n",
    "        steps                 = 24,\n",
    "        metric                = 'mean_absolute_error',\n",
    "        aggregate_metric      = None,\n",
    "        initial_train_size    = len(series_dict_train['id_1000']),\n",
    "        fixed_train_size      = True,\n",
    "        gap                   = 0,\n",
    "        allow_incomplete_fold = True,\n",
    "        refit                 = False,\n",
    "        n_jobs                = 'auto',\n",
    "        verbose               = False,\n",
    "        show_progress         = True,\n",
    "        suppress_warnings     = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
