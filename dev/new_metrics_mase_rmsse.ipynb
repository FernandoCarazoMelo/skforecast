{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.4.2\n",
      "skforecast: 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import skforecast\n",
    "\n",
    "print(f'sklearn: {sklearn.__version__}')\n",
    "print(f'skforecast: {skforecast.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skforecast\n",
      "  Using cached skforecast-0.12.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.20 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.3,>=1.2 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (2.2.2)\n",
      "Requirement already satisfied: tqdm<4.67,>=4.57 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (4.66.4)\n",
      "Requirement already satisfied: scikit-learn<1.5,>=1.2 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (1.4.2)\n",
      "Requirement already satisfied: optuna<3.7,>=2.10 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (3.6.1)\n",
      "Requirement already satisfied: joblib<1.5,>=1.1 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from skforecast) (1.4.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from optuna<3.7,>=2.10->skforecast) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from optuna<3.7,>=2.10->skforecast) (6.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from optuna<3.7,>=2.10->skforecast) (24.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from optuna<3.7,>=2.10->skforecast) (2.0.30)\n",
      "Requirement already satisfied: PyYAML in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from optuna<3.7,>=2.10->skforecast) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from pandas<2.3,>=1.2->skforecast) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from pandas<2.3,>=1.2->skforecast) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from pandas<2.3,>=1.2->skforecast) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from scikit-learn<1.5,>=1.2->skforecast) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from scikit-learn<1.5,>=1.2->skforecast) (3.5.0)\n",
      "Requirement already satisfied: Mako in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna<3.7,>=2.10->skforecast) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from alembic>=1.5.0->optuna<3.7,>=2.10->skforecast) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=1.2->skforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna<3.7,>=2.10->skforecast) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ubuntu/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna<3.7,>=2.10->skforecast) (2.1.5)\n",
      "Using cached skforecast-0.12.1-py3-none-any.whl (560 kB)\n",
      "Installing collected packages: skforecast\n",
      "Successfully installed skforecast-0.12.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install skforecast\n",
    "!pip uninstall skforecast -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data['y']\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-validation dates\n",
    "# ==============================================================================\n",
    "end_train = '2002-01-01 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9896df821b64acc829b64a72553a7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.344471182248395\n",
      "mae forecast: 0.19922359134545478\n",
      "mae in sample: 0.08497591817460318\n",
      "mase: 2.344471182248395\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(data.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 127\n",
      "Number of observations used for backtesting: 77\n",
      "    Number of folds: 8\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 7 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-02-01 00:00:00 -- 2002-11-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-12-01 00:00:00 -- 2003-09-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2003-10-01 00:00:00 -- 2004-07-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2004-08-01 00:00:00 -- 2005-05-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2005-06-01 00:00:00 -- 2006-03-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2006-04-01 00:00:00 -- 2007-01-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-02-01 00:00:00 -- 2007-11-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-12-01 00:00:00 -- 2008-06-01 00:00:00  (n=7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d34fb761dbd4447ada2f61bd5649a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.462755601999461\n",
      "mae forecast: 0.23185816123376632\n",
      "mae in sample: 0.09414582634408604\n",
      "mase: 2.462755601999461\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 3,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "refit_intervals = [\n",
    "    ('1991-07-01 00:00:00', '2002-01-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2004-07-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2007-01-01 00:00:00')\n",
    "]\n",
    "\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "y_train = pd.concat([data.loc[start:end] for start, end in refit_intervals])\n",
    "y_train = y_train.loc[~y_train.index.duplicated(keep='first')]\n",
    "naive_in_sample_foreast = y_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(y_train.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8916ef2524bc4c41942830de342357a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "mean_absolute_scaled_error() missing 1 required positional argument: 'y_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Backtesting forecaster: no aggregation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterAutoregMultiSeries(\n\u001b[1;32m      4\u001b[0m                  regressor \u001b[38;5;241m=\u001b[39m Ridge(),\n\u001b[1;32m      5\u001b[0m                  lags      \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m      6\u001b[0m              )\n\u001b[0;32m----> 8\u001b[0m metric, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbacktesting_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_scaled_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBacktesting MASE:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m display(metric)\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:788\u001b[0m, in \u001b[0;36mbacktesting_forecaster_multiseries\u001b[0;34m(forecaster, series, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, levels, exog, refit, interval, n_boot, random_state, in_sample_residuals, n_jobs, verbose, show_progress, suppress_warnings)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    762\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`forecaster` must be of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmulti_series_forecasters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor all other types of forecasters use the functions available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `model_selection` module. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecaster_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    767\u001b[0m check_backtesting_input(\n\u001b[1;32m    768\u001b[0m     forecaster            \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[1;32m    769\u001b[0m     steps                 \u001b[38;5;241m=\u001b[39m steps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m     suppress_warnings     \u001b[38;5;241m=\u001b[39m suppress_warnings\n\u001b[1;32m    786\u001b[0m )\n\u001b[0;32m--> 788\u001b[0m metrics_levels, backtest_predictions \u001b[38;5;241m=\u001b[39m \u001b[43m_backtesting_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_sample_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics_levels, backtest_predictions\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:603\u001b[0m, in \u001b[0;36m_backtesting_forecaster_multiseries\u001b[0;34m(forecaster, series, steps, metric, initial_train_size, fixed_train_size, gap, allow_incomplete_fold, levels, exog, refit, interval, n_boot, random_state, in_sample_residuals, n_jobs, verbose, show_progress, suppress_warnings)\u001b[0m\n\u001b[1;32m    593\u001b[0m predictions_level \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m    594\u001b[0m     series[level],\n\u001b[1;32m    595\u001b[0m     backtest_predictions[level],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     suffixes    \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_true\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    600\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions_level\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m--> 603\u001b[0m     metrics_level \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    610\u001b[0m     metrics_levels\u001b[38;5;241m.\u001b[39mappend(metrics_level)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:604\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    593\u001b[0m predictions_level \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m    594\u001b[0m     series[level],\n\u001b[1;32m    595\u001b[0m     backtest_predictions[level],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     suffixes    \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_true\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    600\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions_level\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    603\u001b[0m     metrics_level \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 604\u001b[0m         \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics\n\u001b[1;32m    609\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m     metrics_levels\u001b[38;5;241m.\u001b[39mappend(metrics_level)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: mean_absolute_scaled_error() missing 1 required positional argument: 'y_train'"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster: no aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast / mae_in_sample\n",
    "print(f\"mase: {mase}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == mase).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6010388680de4f399d9abee6d8e52d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "      <td>1.691320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "      <td>3.707672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "      <td>3.571717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>1.173480</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0            item_1                    1.091527             1.691320\n",
       "1            item_2                    1.563339             3.707672\n",
       "2            item_3                    0.959262             3.571717\n",
       "3           average                    1.204709             2.990236\n",
       "4  weighted_average                    1.204709             2.990236\n",
       "5           pooling                    1.173480             2.990236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backtesting forecaster: aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          add_aggregated_metric = True,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample_foreast = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast/mae_in_sample\n",
    "average_mase = mase.mean()\n",
    "weighted_average_mase = np.average(mase, weights=predictions.notna().sum())\n",
    "average_mae = mae_foreast.mean()\n",
    "weighted_average_mae = np.average(mae_foreast, weights=predictions.notna().sum())\n",
    "\n",
    "pooled_y_true_y_pred = pd.merge(\n",
    "    data.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    predictions.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    on=['datetime', 'variable'],\n",
    "    suffixes=('_true', '_pred'),\n",
    "    how='inner'\n",
    ")\n",
    "pooled_mae_foreast = mean_absolute_error(\n",
    "    pooled_y_true_y_pred['value_true'],\n",
    "    pooled_y_true_y_pred['value_pred']\n",
    ")\n",
    "pooled_naive_in_sample_foreast = np.concatenate([np.diff(data.loc[:end_train, col]) for col in data.columns])\n",
    "pooled_mae_in_sample_forecast = np.mean(np.abs(pooled_naive_in_sample_foreast))\n",
    "pooled_mase = pooled_mae_foreast/pooled_mae_in_sample_forecast\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': ['average', 'weighted_average', 'pooling'],\n",
    "    'mean_absolute_scaled_error': [average_mase, weighted_average_mase, pooled_mase],\n",
    "    'mean_absolute_error': [average_mae, weighted_average_mae, pooled_mae_foreast]\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    metric.query('levels in [\"average\", \"weighted_average\", \"pooling\"]').reset_index(drop=True),\n",
    "    expected_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 927\n",
      "Number of observations used for backtesting: 170\n",
      "    Number of folds: 17\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-16 00:00:00 -- 2014-07-25 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-26 00:00:00 -- 2014-08-04 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-05 00:00:00 -- 2014-08-14 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-15 00:00:00 -- 2014-08-24 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-25 00:00:00 -- 2014-09-03 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-04 00:00:00 -- 2014-09-13 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-14 00:00:00 -- 2014-09-23 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-24 00:00:00 -- 2014-10-03 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-04 00:00:00 -- 2014-10-13 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-14 00:00:00 -- 2014-10-23 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-10-24 00:00:00 -- 2014-11-02 00:00:00  (n=10)\n",
      "Fold: 11\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-03 00:00:00 -- 2014-11-12 00:00:00  (n=10)\n",
      "Fold: 12\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-13 00:00:00 -- 2014-11-22 00:00:00  (n=10)\n",
      "Fold: 13\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-23 00:00:00 -- 2014-12-02 00:00:00  (n=10)\n",
      "Fold: 14\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-03 00:00:00 -- 2014-12-12 00:00:00  (n=10)\n",
      "Fold: 15\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-13 00:00:00 -- 2014-12-22 00:00:00  (n=10)\n",
      "Fold: 16\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-23 00:00:00 -- 2015-01-01 00:00:00  (n=10)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bf728e386140c598998b855d1ff597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.106355</td>\n",
       "      <td>1.690569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.571983</td>\n",
       "      <td>3.670363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>1.005813</td>\n",
       "      <td>3.715934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0  item_1                    1.106355             1.690569\n",
       "1  item_2                    1.571983             3.670363\n",
       "2  item_3                    1.005813             3.715934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69056888 3.67036308 3.71593437]\n",
      "mae in sample: [1.52805244 2.33486251 3.69445992]\n",
      "mase: [1.10635527 1.57198253 1.00581261]\n",
      "mase average: 1.2280501371035948\n",
      "mase weighted average: 1.228050137103595\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 10,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "# Manual check\n",
    "refit_intervals = [\n",
    "    ('2012-01-01 00:00:00', '2014-07-15 00:00:00'),\n",
    "    ('2012-04-10 00:00:00', '2014-10-23 00:00:00')\n",
    "]\n",
    "\n",
    "mae_forecast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "data_train = pd.concat([data.loc[start:end, :] for start, end in refit_intervals])\n",
    "data_train = data_train.loc[~data_train.index.duplicated(keep='first'), :]\n",
    "naive_in_sample_foreast = data_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_forecast/mae_in_sample\n",
    "mase_average = mase.mean()\n",
    "mase_weighted_average = np.average(mase, weights=predictions.notna().sum())\n",
    "\n",
    "print(f\"mae forecast: {mae_forecast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mase}\")\n",
    "print(f\"mase average: {mase_average}\")\n",
    "print(f\"mase weighted average: {mase_weighted_average}\")\n",
    "assert (metric.loc[metric['levels']=='average', 'mean_absolute_scaled_error'] == mase_average).all()\n",
    "assert (metric.loc[metric['levels']=='weighted_average', 'mean_absolute_scaled_error'] == mase_weighted_average).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "end_val = '2014-10-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_val = data.loc[end_train:end_val, :].copy()\n",
    "data_test  = data.loc[end_val:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 models compared for 3 level(s). Number of iterations: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7c4a302cae4da38ffe2d9a5097ad33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbfc6cfa7164d39ab124b0ea1eb8dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.011987</td>\n",
       "      <td>1.182015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.012102</td>\n",
       "      <td>1.182061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.285467</td>\n",
       "      <td>1.289339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.285631</td>\n",
       "      <td>1.289404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.411347</td>\n",
       "      <td>1.338739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.411571</td>\n",
       "      <td>1.338827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.986100</td>\n",
       "      <td>1.956731</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.988957</td>\n",
       "      <td>1.957852</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.990710</td>\n",
       "      <td>1.958540</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aggregation       lags lags_label                  params  \\\n",
       "0     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 0}   \n",
       "1     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 1}   \n",
       "2     pooling     [1, 2]     [1, 2]            {'alpha': 0}   \n",
       "3     pooling     [1, 2]     [1, 2]            {'alpha': 1}   \n",
       "4     pooling        [1]        [1]            {'alpha': 0}   \n",
       "5     pooling        [1]        [1]            {'alpha': 1}   \n",
       "6     pooling  [1, 2, 3]  [1, 2, 3]  {'alpha': 10000000000}   \n",
       "7     pooling     [1, 2]     [1, 2]  {'alpha': 10000000000}   \n",
       "8     pooling        [1]        [1]  {'alpha': 10000000000}   \n",
       "\n",
       "   mean_absolute_error  mean_absolute_scaled_error        alpha  \n",
       "0             3.011987                    1.182015            0  \n",
       "1             3.012102                    1.182061            1  \n",
       "2             3.285467                    1.289339            0  \n",
       "3             3.285631                    1.289404            1  \n",
       "4             3.411347                    1.338739            0  \n",
       "5             3.411571                    1.338827            1  \n",
       "6             4.986100                    1.956731  10000000000  \n",
       "7             4.988957                    1.957852  10000000000  \n",
       "8             4.990710                    1.958540  10000000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "lags_grid =[1, 2, 3]\n",
    "param_grid = {'alpha': [0, 1, 10000000000]}\n",
    "\n",
    "results = grid_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          lags_grid             = lags_grid,\n",
    "                          param_grid            = param_grid,\n",
    "                          steps                 = 12,\n",
    "                          metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "                          aggregate_metric      = 'pooling',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True\n",
    "                      )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16863ddbb5d94f28993a7b3f329bfbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.4807958141120149}</td>\n",
       "      <td>2.562235</td>\n",
       "      <td>0.480796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.667878511469039}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>0.667879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.6709608626961889}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>0.670961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.2579065805327433}</td>\n",
       "      <td>3.012016</td>\n",
       "      <td>0.257907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aggregation             lags                         params  \\\n",
       "0  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.4807958141120149}   \n",
       "1  weighted_average  [1, 2, 3, 4, 5]   {'alpha': 0.667878511469039}   \n",
       "2  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.6709608626961889}   \n",
       "3  weighted_average        [1, 2, 3]  {'alpha': 0.2579065805327433}   \n",
       "\n",
       "   mean_absolute_error     alpha  \n",
       "0             2.562235  0.480796  \n",
       "1             2.562239  0.667879  \n",
       "2             2.562239  0.670961  \n",
       "3             3.012016  0.257907  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1,\n",
    "                 encoding= 'ordinal'\n",
    "             )\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'             : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'alpha'            : trial.suggest_float('alpha', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          search_space          = search_space,\n",
    "                          steps                 = 12,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          aggregate_metric      = 'weighted_average',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          engine                = 'optuna',\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "THIS_DIR = \"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests\"\n",
    "series_dict = joblib.load(THIS_DIR+ \"/\" + 'fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load(THIS_DIR+ \"/\" +'fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n",
    "series_with_nans = series.copy()\n",
    "series_with_nans.loc[:10, 'l2'] = np.nan\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 2 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-3:-1]\n",
    "\n",
    "    return lags\n",
    "\n",
    "def create_predictors_14(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 14 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-15:-1]\n",
    "\n",
    "    return lags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6c10516f664fc49972d9bf57becd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.112515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  levels  mean_absolute_error\n",
       "0     l1             0.112515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), \n",
    "                            lags=2, transformer_series=None,\n",
    "                            encoding='onehot')\n",
    "\n",
    "\n",
    "n_validation = 20\n",
    "steps = 5\n",
    "gap = 3\n",
    "\n",
    "metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "                    forecaster            = forecaster,\n",
    "                    series                = series_with_nans,\n",
    "                    steps                 = steps,\n",
    "                    levels                = 'l1',\n",
    "                    metric                = 'mean_absolute_error',\n",
    "                    initial_train_size    = len(series_with_nans) - n_validation,\n",
    "                    gap                   = gap,\n",
    "                    allow_incomplete_fold = True,\n",
    "                    refit                 = False,\n",
    "                    fixed_train_size      = False,\n",
    "                    exog                  = series_with_nans['l1'].rename('exog_1'),\n",
    "                    interval              = [5, 95],\n",
    "                    n_boot                = 150,\n",
    "                    random_state          = 123,\n",
    "                    in_sample_residuals   = True,\n",
    "                    verbose               = False\n",
    "                )\n",
    "\n",
    "expected_metric = pd.DataFrame({'levels': ['l1'], \n",
    "                                    'mean_absolute_error': [0.11243765852459384]})\n",
    "metrics_levels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
