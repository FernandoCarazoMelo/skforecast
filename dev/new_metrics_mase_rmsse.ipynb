{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data['y']\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-validation dates\n",
    "# ==============================================================================\n",
    "end_train = '2002-01-01 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937e312d24af45559df603190a922159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.344471182248395\n",
      "mae forecast: 0.19922359134545478\n",
      "mae in sample: 0.08497591817460318\n",
      "mase: 2.344471182248395\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(data.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.344471182248395"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = data.loc[end_train:]\n",
    "y_pred = predictions['pred']\n",
    "y_train = data.loc[:end_train]\n",
    "mean_absolute_scaled_error(y_true, y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 127\n",
      "Number of observations used for backtesting: 77\n",
      "    Number of folds: 8\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 7 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-02-01 00:00:00 -- 2002-11-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-12-01 00:00:00 -- 2003-09-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2003-10-01 00:00:00 -- 2004-07-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2004-08-01 00:00:00 -- 2005-05-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2005-06-01 00:00:00 -- 2006-03-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2006-04-01 00:00:00 -- 2007-01-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-02-01 00:00:00 -- 2007-11-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-12-01 00:00:00 -- 2008-06-01 00:00:00  (n=7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ea2830573b470fa90c2757c385246a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.462755601999461\n",
      "mae forecast: 0.23185816123376632\n",
      "mae in sample: 0.09414582634408604\n",
      "mase: 2.462755601999461\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 3,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "refit_intervals = [\n",
    "    ('1991-07-01 00:00:00', '2002-01-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2004-07-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2007-01-01 00:00:00')\n",
    "]\n",
    "\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "y_train = pd.concat([data.loc[start:end] for start, end in refit_intervals])\n",
    "y_train = y_train.loc[~y_train.index.duplicated(keep='first')]\n",
    "naive_in_sample_foreast = y_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(y_train.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edc0e7e85f3488aadd24c74617e53bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error\n",
       "0  item_1                    1.091527\n",
       "1  item_2                    1.563339\n",
       "2  item_3                    0.959262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69131952 3.70767238 3.57171715]\n",
      "mae in sample: [1.54949824 2.37163672 3.72340161]\n",
      "mase: [1.09152723 1.56333908 0.95926186]\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == mae_foreast/mae_in_sample).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e93585278f4afd88f1bf0038ac2b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>1.204709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           levels  mean_absolute_scaled_error\n",
       "average  [item_1, item_2, item_3]                    1.204709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69131952 3.70767238 3.57171715]\n",
      "mae in sample: [1.54949824 2.37163672 3.72340161]\n",
      "mase: [1.09152723 1.56333908 0.95926186]\n",
      "average mase: 1.2047093909443507\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          aggregate_metric      = 'average',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast/mae_in_sample\n",
    "average_mase = mase.mean()\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mase}\")\n",
    "print(f\"average mase: {average_mase}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == average_mase).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 927\n",
      "Number of observations used for backtesting: 170\n",
      "    Number of folds: 17\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-16 00:00:00 -- 2014-07-25 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-26 00:00:00 -- 2014-08-04 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-05 00:00:00 -- 2014-08-14 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-15 00:00:00 -- 2014-08-24 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-25 00:00:00 -- 2014-09-03 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-04 00:00:00 -- 2014-09-13 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-14 00:00:00 -- 2014-09-23 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-24 00:00:00 -- 2014-10-03 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-04 00:00:00 -- 2014-10-13 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-14 00:00:00 -- 2014-10-23 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-10-24 00:00:00 -- 2014-11-02 00:00:00  (n=10)\n",
      "Fold: 11\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-03 00:00:00 -- 2014-11-12 00:00:00  (n=10)\n",
      "Fold: 12\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-13 00:00:00 -- 2014-11-22 00:00:00  (n=10)\n",
      "Fold: 13\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-23 00:00:00 -- 2014-12-02 00:00:00  (n=10)\n",
      "Fold: 14\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-03 00:00:00 -- 2014-12-12 00:00:00  (n=10)\n",
      "Fold: 15\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-13 00:00:00 -- 2014-12-22 00:00:00  (n=10)\n",
      "Fold: 16\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-23 00:00:00 -- 2015-01-01 00:00:00  (n=10)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac85b63c1414b52bd6ade66e8afbd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>1.22805</td>\n",
       "      <td>3.025622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           levels  mean_absolute_scaled_error  \\\n",
       "average  [item_1, item_2, item_3]                     1.22805   \n",
       "\n",
       "         mean_absolute_error  \n",
       "average             3.025622  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69056888 3.67036308 3.71593437]\n",
      "mae in sample: [1.52805244 2.33486251 3.69445992]\n",
      "mase: [1.10635527 1.57198253 1.00581261]\n",
      "average mase: 1.2280501371035948\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          aggregate_metric      = 'average',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 10,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "# Manual check\n",
    "refit_intervals = [\n",
    "    ('2012-01-01 00:00:00', '2014-07-15 00:00:00'),\n",
    "    ('2012-04-10 00:00:00', '2014-10-23 00:00:00')\n",
    "]\n",
    "\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "data_train = pd.concat([data.loc[start:end, :] for start, end in refit_intervals])\n",
    "data_train = data_train.loc[~data_train.index.duplicated(keep='first'), :]\n",
    "naive_in_sample_foreast = data_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast/mae_in_sample\n",
    "average_mase = mase.mean()\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mase}\")\n",
    "print(f\"average mase: {average_mase}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == average_mase).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "end_val = '2014-10-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_val = data.loc[end_train:end_val, :].copy()\n",
    "data_test  = data.loc[end_val:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 models compared for 3 level(s). Number of iterations: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5fecf449744a0c9a6556ff16e5177d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24970fbf29454b7391f3633b9fd9d758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m lags_grid \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      6\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10000000000\u001b[39m]}\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_scaled_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted_average\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m results\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1122\u001b[0m, in \u001b[0;36mgrid_search_forecaster_multiseries\u001b[0;34m(forecaster, series, param_grid, steps, metric, initial_train_size, aggregate_metric, fixed_train_size, gap, allow_incomplete_fold, levels, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, suppress_warnings, output_file)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03mExhaustive search over specified parameter values for a Forecaster object.\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03mValidation is done using multi-series backtesting.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ParameterGrid(param_grid))\n\u001b[0;32m-> 1122\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_grid_hyperparameters_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m              \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m              \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m              \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m              \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m              \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m              \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m              \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m              \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlags_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m              \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m              \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m              \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m              \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m              \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1523\u001b[0m, in \u001b[0;36m_evaluate_grid_hyperparameters_multiseries\u001b[0;34m(forecaster, series, param_grid, steps, metric, initial_train_size, aggregate_metric, fixed_train_size, gap, allow_incomplete_fold, levels, exog, lags_grid, refit, return_best, n_jobs, verbose, show_progress, suppress_warnings, output_file)\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1521\u001b[0m                     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m row]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1523\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m     \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlags_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m       \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlags_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags_label_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m     \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_dict\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m          \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1531\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(metric_dict\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results, results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "lags_grid =[1, 2, 3]\n",
    "param_grid = {'alpha': [0, 1, 10000000000]}\n",
    "\n",
    "results = grid_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          lags_grid             = lags_grid,\n",
    "                          param_grid            = param_grid,\n",
    "                          steps                 = 12,\n",
    "                          metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "                          aggregate_metric      = 'weighted_average',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True\n",
    "                      )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac284ec7ef448ccb1ffd35a70a083f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-07-01 16:03:27,368] Trial 0 failed with parameters: {'lags': 3, 'alpha': 0.3041663082077828} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,368] Trial 0 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,474] Trial 1 failed with parameters: {'lags': 5, 'alpha': 0.4807958141120149} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,475] Trial 1 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,576] Trial 2 failed with parameters: {'lags': 3, 'alpha': 0.5328387113359249} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,577] Trial 2 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,665] Trial 3 failed with parameters: {'lags': 3, 'alpha': 0.7561447366456374} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,666] Trial 3 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,752] Trial 4 failed with parameters: {'lags': 3, 'alpha': 0.4582398297973883} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,754] Trial 4 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,846] Trial 5 failed with parameters: {'lags': 3, 'alpha': 0.2579065805327433} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,847] Trial 5 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:27,933] Trial 6 failed with parameters: {'lags': 5, 'alpha': 0.6709608626961889} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:27,935] Trial 6 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:28,020] Trial 7 failed with parameters: {'lags': 3, 'alpha': 0.6499211596098246} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:28,021] Trial 7 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:28,109] Trial 8 failed with parameters: {'lags': 3, 'alpha': 0.4256097900600827} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:28,111] Trial 8 failed with value 'item_1'.\n",
      "[W 2024-07-01 16:03:28,208] Trial 9 failed with parameters: {'lags': 5, 'alpha': 0.667878511469039} because of the following error: The value 'i' could not be cast to float.\n",
      "[W 2024-07-01 16:03:28,209] Trial 9 failed with value 'item_1'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m     search_space  \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags\u001b[39m\u001b[38;5;124m'\u001b[39m             : trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m]),\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m            : trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m search_space\n\u001b[0;32m---> 14\u001b[0m results, best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mbayesian_search_forecaster_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_absolute_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted_average\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs_create_study\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs_study_optimize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m results\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1706\u001b[0m, in \u001b[0;36mbayesian_search_forecaster_multiseries\u001b[0;34m(forecaster, series, search_space, steps, metric, initial_train_size, aggregate_metric, fixed_train_size, gap, allow_incomplete_fold, levels, exog, lags_grid, refit, n_trials, random_state, return_best, n_jobs, verbose, show_progress, suppress_warnings, output_file, engine, kwargs_create_study, kwargs_study_optimize)\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1703\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`engine` only allows \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1704\u001b[0m     )\n\u001b[0;32m-> 1706\u001b[0m results, best_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_bayesian_search_optuna_multiseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m                          \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maggregate_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfixed_train_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mallow_incomplete_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs_create_study\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs_create_study\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs_study_optimize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs_study_optimize\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, best_trial\n",
      "File \u001b[0;32m~/varios/skforecast/skforecast/model_selection_multiseries/model_selection_multiseries.py:1975\u001b[0m, in \u001b[0;36m_bayesian_search_optuna_multiseries\u001b[0;34m(forecaster, series, search_space, steps, metric, initial_train_size, aggregate_metric, fixed_train_size, gap, allow_incomplete_fold, levels, exog, refit, n_trials, random_state, return_best, n_jobs, verbose, show_progress, suppress_warnings, output_file, kwargs_create_study, kwargs_study_optimize)\u001b[0m\n\u001b[1;32m   1972\u001b[0m     study\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;241m=\u001b[39m TPESampler(seed\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   1974\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(_objective, n_trials\u001b[38;5;241m=\u001b[39mn_trials, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_study_optimize)\n\u001b[0;32m-> 1975\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1978\u001b[0m     handler\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/optuna/study/study.py:157\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/optuna/storages/_in_memory.py:234\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    231\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'             : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'alpha'            : trial.suggest_float('alpha', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          search_space          = search_space,\n",
    "                          steps                 = 12,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          aggregate_metric      = 'weighted_average',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          engine                = 'optuna',\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "\n",
    "results.head(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
