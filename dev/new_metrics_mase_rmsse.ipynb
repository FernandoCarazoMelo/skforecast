{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.3.0\n",
      "skforecast: 0.13.0\n",
      "numpy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import skforecast\n",
    "import numpy\n",
    "\n",
    "print(f'sklearn: {sklearn.__version__}')\n",
    "print(f'skforecast: {skforecast.__version__}')\n",
    "print(f'numpy: {numpy.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data['y']\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-validation dates\n",
    "# ==============================================================================\n",
    "end_train = '2002-01-01 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d32097701714840bcf4b6ddfe9160a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.344471182248395\n",
      "mae forecast: 0.19922359134545478\n",
      "mae in sample: 0.08497591817460318\n",
      "mase: 2.344471182248395\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(data.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 127\n",
      "Number of observations used for backtesting: 77\n",
      "    Number of folds: 8\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 7 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-02-01 00:00:00 -- 2002-11-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2002-12-01 00:00:00 -- 2003-09-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1991-07-01 00:00:00 -- 2002-01-01 00:00:00  (n=127)\n",
      "    Validation: 2003-10-01 00:00:00 -- 2004-07-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2004-08-01 00:00:00 -- 2005-05-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2005-06-01 00:00:00 -- 2006-03-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1991-07-01 00:00:00 -- 2004-07-01 00:00:00  (n=157)\n",
      "    Validation: 2006-04-01 00:00:00 -- 2007-01-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-02-01 00:00:00 -- 2007-11-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1991-07-01 00:00:00 -- 2007-01-01 00:00:00  (n=187)\n",
      "    Validation: 2007-12-01 00:00:00 -- 2008-06-01 00:00:00  (n=7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dd6c6bd419488fa3229b116e2dcb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE: 2.462755601999461\n",
      "mae forecast: 0.23185816123376632\n",
      "mae in sample: 0.09414582634408604\n",
      "mase: 2.462755601999461\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = RandomForestRegressor(random_state=123),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = False,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 3,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(f\"Backtesting MASE: {metric}\")\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "refit_intervals = [\n",
    "    ('1991-07-01 00:00:00', '2002-01-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2004-07-01 00:00:00'),\n",
    "    ('1991-07-01 00:00:00', '2007-01-01 00:00:00')\n",
    "]\n",
    "\n",
    "mae_foreast = mean_absolute_error(data.loc[end_train:], predictions)\n",
    "y_train = pd.concat([data.loc[start:end] for start, end in refit_intervals])\n",
    "y_train = y_train.loc[~y_train.index.duplicated(keep='first')]\n",
    "naive_in_sample_foreast = y_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(y_train.loc[naive_in_sample_foreast.index], naive_in_sample_foreast)\n",
    "print(f\"mae forecast: {mae_foreast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mae_foreast/mae_in_sample}\")\n",
    "assert metric == mae_foreast/mae_in_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c357f5e51164a42b261db2528ecc131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error\n",
       "0  item_1                    1.091527\n",
       "1  item_2                    1.563339\n",
       "2  item_3                    0.959262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mase: [1.09152723 1.56333908 0.95926186]\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster: no aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = 'mean_absolute_scaled_error',\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast / mae_in_sample\n",
    "print(f\"mase: {mase}\")\n",
    "assert (metric['mean_absolute_scaled_error'] == mase).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884bdce37bd349e6836e15733d481b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.091527</td>\n",
       "      <td>1.691320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.563339</td>\n",
       "      <td>3.707672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>0.959262</td>\n",
       "      <td>3.571717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>1.204709</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>1.173480</td>\n",
       "      <td>2.990236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0            item_1                    1.091527             1.691320\n",
       "1            item_2                    1.563339             3.707672\n",
       "2            item_3                    0.959262             3.571717\n",
       "3           average                    1.204709             2.990236\n",
       "4  weighted_average                    1.204709             2.990236\n",
       "5           pooling                    1.173480             2.990236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Backtesting forecaster: aggregation\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          add_aggregated_metric = True,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "mae_foreast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "naive_in_sample_foreast = data.loc[:end_train].shift(1).dropna().drop_duplicates()\n",
    "mae_in_sample_foreast = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_foreast/mae_in_sample\n",
    "average_mase = mase.mean()\n",
    "weighted_average_mase = np.average(mase, weights=predictions.notna().sum())\n",
    "average_mae = mae_foreast.mean()\n",
    "weighted_average_mae = np.average(mae_foreast, weights=predictions.notna().sum())\n",
    "\n",
    "pooled_y_true_y_pred = pd.merge(\n",
    "    data.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    predictions.melt(ignore_index=False).reset_index(names='datetime'),\n",
    "    on=['datetime', 'variable'],\n",
    "    suffixes=('_true', '_pred'),\n",
    "    how='inner'\n",
    ")\n",
    "pooled_mae_foreast = mean_absolute_error(\n",
    "    pooled_y_true_y_pred['value_true'],\n",
    "    pooled_y_true_y_pred['value_pred']\n",
    ")\n",
    "pooled_naive_in_sample_foreast = np.concatenate([np.diff(data.loc[:end_train, col]) for col in data.columns])\n",
    "pooled_mae_in_sample_forecast = np.mean(np.abs(pooled_naive_in_sample_foreast))\n",
    "pooled_mase = pooled_mae_foreast/pooled_mae_in_sample_forecast\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': ['average', 'weighted_average', 'pooling'],\n",
    "    'mean_absolute_scaled_error': [average_mase, weighted_average_mase, pooled_mase],\n",
    "    'mean_absolute_error': [average_mae, weighted_average_mae, pooled_mae_foreast]\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    metric.query('levels in [\"average\", \"weighted_average\", \"pooling\"]').reset_index(drop=True),\n",
    "    expected_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 927\n",
      "Number of observations used for backtesting: 170\n",
      "    Number of folds: 17\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-16 00:00:00 -- 2014-07-25 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-07-26 00:00:00 -- 2014-08-04 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-05 00:00:00 -- 2014-08-14 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-15 00:00:00 -- 2014-08-24 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-08-25 00:00:00 -- 2014-09-03 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-04 00:00:00 -- 2014-09-13 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-14 00:00:00 -- 2014-09-23 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-09-24 00:00:00 -- 2014-10-03 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-04 00:00:00 -- 2014-10-13 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   2012-01-01 00:00:00 -- 2014-07-15 00:00:00  (n=927)\n",
      "    Validation: 2014-10-14 00:00:00 -- 2014-10-23 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-10-24 00:00:00 -- 2014-11-02 00:00:00  (n=10)\n",
      "Fold: 11\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-03 00:00:00 -- 2014-11-12 00:00:00  (n=10)\n",
      "Fold: 12\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-13 00:00:00 -- 2014-11-22 00:00:00  (n=10)\n",
      "Fold: 13\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-11-23 00:00:00 -- 2014-12-02 00:00:00  (n=10)\n",
      "Fold: 14\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-03 00:00:00 -- 2014-12-12 00:00:00  (n=10)\n",
      "Fold: 15\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-13 00:00:00 -- 2014-12-22 00:00:00  (n=10)\n",
      "Fold: 16\n",
      "    Training:   2012-04-10 00:00:00 -- 2014-10-23 00:00:00  (n=927)\n",
      "    Validation: 2014-12-23 00:00:00 -- 2015-01-01 00:00:00  (n=10)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b43171349143ea9f62acba94535e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting MASE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.106355</td>\n",
       "      <td>1.690569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>1.571983</td>\n",
       "      <td>3.670363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>1.005813</td>\n",
       "      <td>3.715934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_scaled_error  mean_absolute_error\n",
       "0  item_1                    1.106355             1.690569\n",
       "1  item_2                    1.571983             3.670363\n",
       "2  item_3                    1.005813             3.715934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae forecast: [1.69056888 3.67036308 3.71593437]\n",
      "mae in sample: [1.52805244 2.33486251 3.69445992]\n",
      "mase: [1.10635527 1.57198253 1.00581261]\n",
      "mase average: 1.2280501371035948\n",
      "mase weighted average: 1.228050137103595\n"
     ]
    }
   ],
   "source": [
    "# Backtesting forecaster\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "\n",
    "metric, predictions = backtesting_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data,\n",
    "                          steps                 = 10,\n",
    "                          metric                = ['mean_absolute_scaled_error', 'mean_absolute_error'],\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          gap                   = 0,\n",
    "                          allow_incomplete_fold = True,\n",
    "                          refit                 = 10,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = True,\n",
    "                          show_progress         = True  \n",
    "                      )\n",
    "\n",
    "print(\"Backtesting MASE:\")\n",
    "display(metric)\n",
    "\n",
    "# Manual check\n",
    "# ==============================================================================\n",
    "# Manual check\n",
    "refit_intervals = [\n",
    "    ('2012-01-01 00:00:00', '2014-07-15 00:00:00'),\n",
    "    ('2012-04-10 00:00:00', '2014-10-23 00:00:00')\n",
    "]\n",
    "\n",
    "mae_forecast = mean_absolute_error(\n",
    "    data.loc[end_train:], predictions, multioutput=\"raw_values\"\n",
    ")\n",
    "data_train = pd.concat([data.loc[start:end, :] for start, end in refit_intervals])\n",
    "data_train = data_train.loc[~data_train.index.duplicated(keep='first'), :]\n",
    "naive_in_sample_foreast = data_train.shift(1).dropna()\n",
    "mae_in_sample = mean_absolute_error(\n",
    "    data.loc[naive_in_sample_foreast.index],\n",
    "    naive_in_sample_foreast,\n",
    "    multioutput=\"raw_values\",\n",
    ")\n",
    "mase = mae_forecast/mae_in_sample\n",
    "mase_average = mase.mean()\n",
    "mase_weighted_average = np.average(mase, weights=predictions.notna().sum())\n",
    "\n",
    "print(f\"mae forecast: {mae_forecast}\")\n",
    "print(f\"mae in sample: {mae_in_sample}\")\n",
    "print(f\"mase: {mase}\")\n",
    "print(f\"mase average: {mase_average}\")\n",
    "print(f\"mase weighted average: {mase_weighted_average}\")\n",
    "assert (metric.loc[metric['levels']=='average', 'mean_absolute_scaled_error'] == mase_average).all()\n",
    "assert (metric.loc[metric['levels']=='weighted_average', 'mean_absolute_scaled_error'] == mase_weighted_average).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "end_val = '2014-10-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_val = data.loc[end_train:end_val, :].copy()\n",
    "data_test  = data.loc[end_val:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 models compared for 3 level(s). Number of iterations: 9.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5e069ad72840d585a15c77277d71f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc5f483182e4f85a3960fe6691a4ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.011987</td>\n",
       "      <td>1.182015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.012102</td>\n",
       "      <td>1.182061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.285467</td>\n",
       "      <td>1.289339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.285631</td>\n",
       "      <td>1.289404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>3.411347</td>\n",
       "      <td>1.338739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>3.411571</td>\n",
       "      <td>1.338827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.986100</td>\n",
       "      <td>1.956731</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.988957</td>\n",
       "      <td>1.957852</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pooling</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'alpha': 10000000000}</td>\n",
       "      <td>4.990710</td>\n",
       "      <td>1.958540</td>\n",
       "      <td>10000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aggregation       lags lags_label                  params  \\\n",
       "0     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 0}   \n",
       "1     pooling  [1, 2, 3]  [1, 2, 3]            {'alpha': 1}   \n",
       "2     pooling     [1, 2]     [1, 2]            {'alpha': 0}   \n",
       "3     pooling     [1, 2]     [1, 2]            {'alpha': 1}   \n",
       "4     pooling        [1]        [1]            {'alpha': 0}   \n",
       "5     pooling        [1]        [1]            {'alpha': 1}   \n",
       "6     pooling  [1, 2, 3]  [1, 2, 3]  {'alpha': 10000000000}   \n",
       "7     pooling     [1, 2]     [1, 2]  {'alpha': 10000000000}   \n",
       "8     pooling        [1]        [1]  {'alpha': 10000000000}   \n",
       "\n",
       "   mean_absolute_error  mean_absolute_scaled_error        alpha  \n",
       "0             3.011987                    1.182015            0  \n",
       "1             3.012102                    1.182061            1  \n",
       "2             3.285467                    1.289339            0  \n",
       "3             3.285631                    1.289404            1  \n",
       "4             3.411347                    1.338739            0  \n",
       "5             3.411571                    1.338827            1  \n",
       "6             4.986100                    1.956731  10000000000  \n",
       "7             4.988957                    1.957852  10000000000  \n",
       "8             4.990710                    1.958540  10000000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1 \n",
    "             )\n",
    "lags_grid =[1, 2, 3]\n",
    "param_grid = {'alpha': [0, 1, 10000000000]}\n",
    "\n",
    "results = grid_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          lags_grid             = lags_grid,\n",
    "                          param_grid            = param_grid,\n",
    "                          steps                 = 12,\n",
    "                          metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "                          aggregate_metric      = 'pooling',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True\n",
    "                      )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61824259dd0347cfb9617a01a30ab1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.4807958141120149}</td>\n",
       "      <td>2.562235</td>\n",
       "      <td>1.046785</td>\n",
       "      <td>0.480796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.667878511469039}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>1.046787</td>\n",
       "      <td>0.667879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'alpha': 0.6709608626961889}</td>\n",
       "      <td>2.562239</td>\n",
       "      <td>1.046787</td>\n",
       "      <td>0.670961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.2579065805327433}</td>\n",
       "      <td>3.012016</td>\n",
       "      <td>1.243240</td>\n",
       "      <td>0.257907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aggregation             lags                         params  \\\n",
       "0  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.4807958141120149}   \n",
       "1  weighted_average  [1, 2, 3, 4, 5]   {'alpha': 0.667878511469039}   \n",
       "2  weighted_average  [1, 2, 3, 4, 5]  {'alpha': 0.6709608626961889}   \n",
       "3  weighted_average        [1, 2, 3]  {'alpha': 0.2579065805327433}   \n",
       "\n",
       "   mean_absolute_error  mean_absolute_scaled_error     alpha  \n",
       "0             2.562235                    1.046785  0.480796  \n",
       "1             2.562239                    1.046787  0.667879  \n",
       "2             2.562239                    1.046787  0.670961  \n",
       "3             3.012016                    1.243240  0.257907  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor = Ridge(),\n",
    "                 lags      = 1,\n",
    "                 encoding= 'ordinal'\n",
    "             )\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'             : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'alpha'            : trial.suggest_float('alpha', 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "                          forecaster            = forecaster,\n",
    "                          series                = data.loc[:end_val, :],\n",
    "                          search_space          = search_space,\n",
    "                          steps                 = 12,\n",
    "                          metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "                          aggregate_metric      = 'weighted_average',\n",
    "                          refit                 = False,\n",
    "                          initial_train_size    = len(data.loc[:end_train]),\n",
    "                          fixed_train_size      = True,\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          engine                = 'optuna',\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 30\n",
      "Number of observations used for backtesting: 20\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 5\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 3\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   0 -- 29  (n=30)\n",
      "    Validation: 33 -- 37  (n=5)\n",
      "Fold: 1\n",
      "    Training:   0 -- 29  (n=30)\n",
      "    Validation: 38 -- 42  (n=5)\n",
      "Fold: 2\n",
      "    Training:   0 -- 29  (n=30)\n",
      "    Validation: 43 -- 47  (n=5)\n",
      "Fold: 3\n",
      "    Training:   0 -- 29  (n=30)\n",
      "    Validation: 48 -- 49  (n=2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/ForecasterAutoregMultiSeries/ForecasterAutoregMultiSeries.py:383: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d85ec472f1a4643a9237c825aec9cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (1, 2)\n[right]: (1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 106\u001b[0m\n\u001b[1;32m     82\u001b[0m expected_metric \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     83\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.11243765852459384\u001b[39m]})\n\u001b[1;32m     84\u001b[0m expected_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     85\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.49746847\u001b[39m, \u001b[38;5;241m0.24620019\u001b[39m, \u001b[38;5;241m0.74208308\u001b[39m],\n\u001b[1;32m     86\u001b[0m                         [\u001b[38;5;241m0.46715961\u001b[39m, \u001b[38;5;241m0.27280913\u001b[39m, \u001b[38;5;241m0.69897019\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m     index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mRangeIndex(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m33\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    104\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_levels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(expected_predictions, backtest_predictions)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/_testing/asserters.py:614\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[0;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: DataFrame are different\n\nDataFrame shape mismatch\n[left]:  (1, 2)\n[right]: (1, 3)"
     ]
    }
   ],
   "source": [
    "# Unit test backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "# THIS_DIR = Path(__file__).parent\n",
    "series_dict = joblib.load('/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load('/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests/fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n",
    "series_with_nans = series.copy()\n",
    "#series_with_nans['l2'].iloc[:10] = np.nan\n",
    "#series_with_nans.loc[:10, 'l2'] = np.nan\n",
    "series_with_nans.iloc[:10, series_with_nans.columns.get_loc('l2')] = np.nan\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 2 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-3:-1]\n",
    "\n",
    "    return lags\n",
    "\n",
    "def create_predictors_14(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 14 lags of a time series.\n",
    "    \"\"\"\n",
    "    lags = y[-1:-15:-1]\n",
    "\n",
    "    return lags\n",
    "\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(regressor=Ridge(random_state=123), \n",
    "                            lags=2, transformer_series=None,\n",
    "                            encoding='onehot')\n",
    "\n",
    "\n",
    "n_validation = 20\n",
    "steps = 5\n",
    "gap = 3\n",
    "\n",
    "metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "                    forecaster            = forecaster,\n",
    "                    series                = series_with_nans,\n",
    "                    steps                 = steps,\n",
    "                    levels                = 'l1',\n",
    "                    metric                = 'mean_absolute_error',\n",
    "                    initial_train_size    = len(series_with_nans) - n_validation,\n",
    "                    gap                   = gap,\n",
    "                    allow_incomplete_fold = True,\n",
    "                    refit                 = False,\n",
    "                    fixed_train_size      = False,\n",
    "                    exog                  = series_with_nans['l1'].rename('exog_1'),\n",
    "                    interval              = [5, 95],\n",
    "                    n_boot                = 150,\n",
    "                    random_state          = 123,\n",
    "                    in_sample_residuals   = True,\n",
    "                    verbose               = True\n",
    "                )\n",
    "\n",
    "expected_metric = pd.DataFrame({'levels': ['l1'], \n",
    "                                    'mean_absolute_error': [0.11243765852459384]})\n",
    "expected_predictions = pd.DataFrame(\n",
    "    data = np.array([[0.49746847, 0.24620019, 0.74208308],\n",
    "                        [0.46715961, 0.27280913, 0.69897019],\n",
    "                        [0.42170236, 0.21384761, 0.6338432 ],\n",
    "                        [0.47242371, 0.23550111, 0.68264162],\n",
    "                        [0.66450589, 0.4128072 , 0.87549193],\n",
    "                        [0.67311291, 0.42184464, 0.91772752],\n",
    "                        [0.48788629, 0.29353581, 0.71969688],\n",
    "                        [0.55141437, 0.34355962, 0.76355521],\n",
    "                        [0.33369285, 0.09677024, 0.54391075],\n",
    "                        [0.43287852, 0.18117983, 0.64386456],\n",
    "                        [0.46643379, 0.21516552, 0.7110484 ],\n",
    "                        [0.6535986 , 0.45924812, 0.88540919],\n",
    "                        [0.38328273, 0.17542798, 0.59542356],\n",
    "                        [0.49931045, 0.26238785, 0.70952835],\n",
    "                        [0.70119564, 0.44949695, 0.91218168],\n",
    "                        [0.49290276, 0.24163448, 0.73751736],\n",
    "                        [0.54653561, 0.35218513, 0.7783462 ]]),\n",
    "    columns = ['l1', 'l1_lower_bound', 'l1_upper_bound'],\n",
    "    index = pd.RangeIndex(start=33, stop=50, step=1)\n",
    ")\n",
    "                                \n",
    "pd.testing.assert_frame_equal(expected_metric, metrics_levels)\n",
    "pd.testing.assert_frame_equal(expected_predictions, backtest_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
