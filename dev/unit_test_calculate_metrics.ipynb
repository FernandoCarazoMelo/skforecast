{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _calculate_metrics_multiseries\n",
    "from skforecast.metrics import add_y_train_argument\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.metrics import mean_absolute_scaled_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    data={\n",
    "        \"item_1\": [\n",
    "            8.253175, 22.777826, 27.549099, 25.895533, 21.379238, 21.106643,\n",
    "            20.533871, 20.069327, 20.006161, 21.620184, 21.717691, 21.751748,\n",
    "            21.758617, 20.784194, 18.976196, 20.228468, 26.636444, 29.245869,\n",
    "            24.772249, 24.018768, 22.503533, 20.794986, 23.981037, 28.018830,\n",
    "            28.747482, 23.908368, 21.423930, 24.786455, 24.615778, 27.388275,\n",
    "            25.724191, 22.825491, 23.066582, 23.788066, 23.360304, 23.119966,\n",
    "            21.763739, 23.008517, 22.861086, 22.807790, 23.424717, 22.208947,\n",
    "            19.558775, 20.788390, 23.619240, 25.061150, 27.646380, 25.609772,\n",
    "            22.504042, 20.838095\n",
    "        ],\n",
    "        \"item_2\": [\n",
    "            21.047727, 26.578125, 31.751042, 24.567708, 18.191667, 17.812500,\n",
    "            19.510417, 24.098958, 20.223958, 19.161458, 16.042708, 14.815625,\n",
    "            17.031250, 17.009375, 17.096875, 19.255208, 28.060417, 28.779167,\n",
    "            19.265625, 19.178125, 19.688542, 21.690625, 25.332292, 26.675000,\n",
    "            26.611458, 19.759375, 20.038542, 24.680208, 25.032292, 28.111458,\n",
    "            21.542708, 16.605208, 18.593750, 20.667708, 21.977083, 29.040625,\n",
    "            18.979167, 18.459375, 17.295833, 17.282292, 20.844792, 19.858333,\n",
    "            18.446875, 19.239583, 19.903125, 22.970833, 28.195833, 20.221875,\n",
    "            19.176042, 21.991667\n",
    "        ],\n",
    "        \"item_3\": [\n",
    "            19.429739, 28.009863, 32.078922, 27.252276, 20.357737, 19.879148,\n",
    "            18.043499, 26.287368, 16.315997, 21.772584, 18.729748, 12.552534,\n",
    "            18.996209, 18.534327, 15.418361, 16.304852, 30.076258, 28.886334,\n",
    "            20.286651, 21.367727, 20.248170, 19.799975, 25.931558, 27.698196,\n",
    "            30.725005, 19.573577, 23.310162, 24.959233, 24.399246, 29.094136,\n",
    "            22.639513, 18.372362, 21.256450, 22.430527, 19.575067, 31.767626,\n",
    "            20.086271, 21.380186, 17.553807, 17.369879, 21.829746, 16.208510,\n",
    "            25.067215, 21.863615, 17.887458, 23.005424, 25.013939, 22.142083,\n",
    "            23.673005, 25.238480\n",
    "        ],\n",
    "    },\n",
    "    index=pd.date_range(start=\"2012-01-01\", end=\"2012-02-19\"),\n",
    ")\n",
    "\n",
    "\n",
    "predictions_different_lenght = pd.DataFrame(\n",
    "    data={\n",
    "        \"item_1\": [\n",
    "            25.849411, 24.507137, 23.885447, 23.597504, 23.464140, 23.402371,\n",
    "            23.373762, 23.360511, 23.354374, 23.351532, 23.354278, 23.351487,\n",
    "            23.350195, 23.349596, 23.349319, 23.349190, 23.349131, 23.349103,\n",
    "            23.349090, 23.349084, 23.474207, 23.407034, 23.375922, 23.361512,\n",
    "            23.354837\n",
    "        ],\n",
    "        \"item_2\": [\n",
    "            24.561460, 23.611980, 23.172218, 22.968536, 22.874199, 22.830506,\n",
    "            22.810269, 22.800896, 22.796555, 22.794544, 22.414996, 22.617821,\n",
    "            22.711761, 22.755271, 22.775423, 22.784756, 22.789079, 22.791082,\n",
    "            22.792009, 22.792439, 21.454419, 22.172918, 22.505700, 22.659831,\n",
    "            22.731219\n",
    "        ],\n",
    "        \"item_3\": [\n",
    "            26.168069, 24.057472, 23.079925, 22.627163, 22.417461, 22.320335,\n",
    "            22.275350, 22.254515, 22.244865, 22.240395, 21.003848, 21.665604,\n",
    "            np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n",
    "            np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "        ],\n",
    "    },\n",
    "    index=pd.date_range(start=\"2012-01-26\", periods=25)\n",
    ")\n",
    "\n",
    "\n",
    "span_index = span_index = pd.date_range(start=\"2012-01-01\", end=\"2012-02-19\", freq=\"D\")\n",
    "\n",
    "folds = [\n",
    "    [[0, 25], [24, 25], [25, 35], [25, 35], False],\n",
    "    [[0, 25], [34, 35], [35, 45], [35, 45], False],\n",
    "    [[0, 25], [44, 45], [45, 50], [45, 50], False],\n",
    "]\n",
    "\n",
    "levels = [\"item_1\", \"item_2\", \"item_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1.477567</td>\n",
       "      <td>0.610914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>3.480129</td>\n",
       "      <td>1.170113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3.173683</td>\n",
       "      <td>0.707757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average</td>\n",
       "      <td>2.710460</td>\n",
       "      <td>0.829595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>2.613332</td>\n",
       "      <td>0.855141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pooling</td>\n",
       "      <td>2.613332</td>\n",
       "      <td>0.793768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_scaled_error\n",
       "0            item_1             1.477567                    0.610914\n",
       "1            item_2             3.480129                    1.170113\n",
       "2            item_3             3.173683                    0.707757\n",
       "3           average             2.710460                    0.829595\n",
       "4  weighted_average             2.613332                    0.855141\n",
       "5           pooling             2.613332                    0.793768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_calculate_metrics_multiseries_output_when_aggregated_metric_and_predictions_have_different_length(\n",
    "    metrics=[mean_absolute_error, mean_absolute_scaled_error]\n",
    "):\n",
    "\n",
    "    metrics = [add_y_train_argument(metric) for metric in metrics]\n",
    "    results = _calculate_metrics_multiseries(\n",
    "        series=data,\n",
    "        predictions=predictions_different_lenght,\n",
    "        folds=folds,\n",
    "        span_index=span_index,\n",
    "        metrics=metrics,\n",
    "        levels=levels,\n",
    "        add_aggregated_metric=True,\n",
    "    )\n",
    "\n",
    "    expected = pd.DataFrame(\n",
    "        data={\n",
    "            \"levels\": [\n",
    "                \"item_1\",\n",
    "                \"item_2\",\n",
    "                \"item_3\",\n",
    "                \"average\",\n",
    "                \"weighted_average\",\n",
    "                \"pooling\",\n",
    "            ],\n",
    "            \"mean_absolute_error\": [\n",
    "                1.477567,\n",
    "                3.480129,\n",
    "                3.173683,\n",
    "                2.710460,\n",
    "                2.613332,\n",
    "                2.613332,\n",
    "            ],\n",
    "            \"mean_absolute_scaled_error\": [\n",
    "                0.610914,\n",
    "                1.170113,\n",
    "                0.707757,\n",
    "                0.829595,\n",
    "                0.855141,\n",
    "                0.793768,\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    display(results)\n",
    "    pd.testing.assert_frame_equal(results, expected)\n",
    "\n",
    "\n",
    "test_calculate_metrics_multiseries_output_when_aggregated_metric_and_predictions_have_different_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.iloc[25:] - predictions).abs().stack().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.613332193548387"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([1.477567, 3.480129, 3.173683], weights=[25, 25, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_1000    153\n",
       "id_1001    153\n",
       "id_1003     80\n",
       "id_1004     31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit test backtesting_forecaster_multiseries\n",
    "# ==============================================================================\n",
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "THIS_DIR = Path(\"/home/ubuntu/varios/skforecast/skforecast/model_selection_multiseries/tests\")\n",
    "series_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load(THIS_DIR/'fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n",
    "series_with_nans = series.copy()\n",
    "series_with_nans.iloc[:10, series_with_nans.columns.get_loc('l2')] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2598295151.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[117], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "@pytest.mark.parametrize(\"forecaster\", \n",
    "    [ForecasterAutoregMultiSeries(\n",
    "        regressor=LGBMRegressor(\n",
    "            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "        ),\n",
    "        lags=14,\n",
    "        encoding='ordinal',\n",
    "        dropna_from_series=False,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "    ), \n",
    "    ForecasterAutoregMultiSeriesCustom(\n",
    "        regressor=LGBMRegressor(\n",
    "            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "        ),\n",
    "        fun_predictors=create_predictors_14, \n",
    "        window_size=14,\n",
    "        encoding='ordinal',\n",
    "        dropna_from_series=False,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "    )], \n",
    "    ids=lambda forecaster: f'forecaster: {type(forecaster).__name__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DataFrame.columns are different\n\nDataFrame.columns values are different (33.33333 %)\n[left]:  Index(['levels', 'mean_absolute_error', 'mean_absolute_scaled_error'], dtype='object')\n[right]: Index(['levels', 'mean_absolute_error', 'mean_squared_error'], dtype='object')\nAt positional index 2, first diff: mean_absolute_scaled_error != mean_squared_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m     pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(metrics, expected_metrics)\n\u001b[1;32m     66\u001b[0m     pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(predictions\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m), expected_predictions)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mtest_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_series_and_exog_dict_with_mocked_multiple_aggregated_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 65\u001b[0m, in \u001b[0;36mtest_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_series_and_exog_dict_with_mocked_multiple_aggregated_metrics\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     expected_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     40\u001b[0m         data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_1000\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m286.6227398656757\u001b[39m, \u001b[38;5;241m105816.86051259708\u001b[39m],\n\u001b[1;32m     41\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_1001\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1364.7345740769094\u001b[39m, \u001b[38;5;241m2175934.9583102698\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m         columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     48\u001b[0m     )\u001b[38;5;241m.\u001b[39mastype({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m})\n\u001b[1;32m     50\u001b[0m     expected_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     51\u001b[0m     data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1438.14154717\u001b[39m, \u001b[38;5;241m2090.79352613\u001b[39m, \u001b[38;5;241m2166.9832933\u001b[39m, \u001b[38;5;241m7285.52781428\u001b[39m],\n\u001b[1;32m     52\u001b[0m                    [\u001b[38;5;241m1438.14154717\u001b[39m, \u001b[38;5;241m2089.11038884\u001b[39m, \u001b[38;5;241m2074.55994929\u001b[39m, \u001b[38;5;241m7488.18398744\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     index\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mdate_range(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2016-08-01\u001b[39m\u001b[38;5;124m'\u001b[39m, periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(predictions\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m), expected_predictions)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32mtesting.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtesting.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/skforecast_13_py11/lib/python3.11/site-packages/pandas/_testing/asserters.py:614\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[0;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: DataFrame.columns are different\n\nDataFrame.columns values are different (33.33333 %)\n[left]:  Index(['levels', 'mean_absolute_error', 'mean_absolute_scaled_error'], dtype='object')\n[right]: Index(['levels', 'mean_absolute_error', 'mean_squared_error'], dtype='object')\nAt positional index 2, first diff: mean_absolute_scaled_error != mean_squared_error"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "        regressor=LGBMRegressor(\n",
    "            n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "        ),\n",
    "        lags=14,\n",
    "        encoding='ordinal',\n",
    "        dropna_from_series=False,\n",
    "        transformer_series=StandardScaler(),\n",
    "        transformer_exog=StandardScaler(),\n",
    "    )\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_series_and_exog_dict_with_mocked_multiple_aggregated_metrics():\n",
    "    \"\"\"\n",
    "    Test output of backtesting_forecaster_multiseries in ForecasterAutoregMultiSeries \n",
    "    and ForecasterAutoregMultiSeriesCustom when series and exog are\n",
    "    dictionaries and multiple aggregated metrics are calculated.\n",
    "    (mocked done in Skforecast v0.12.0).\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics, predictions = backtesting_forecaster_multiseries(\n",
    "        forecaster            = forecaster,\n",
    "        series                = series_dict,\n",
    "        exog                  = exog_dict,\n",
    "        steps                 = 24,\n",
    "        metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "        add_aggregated_metric = True,\n",
    "        initial_train_size    = len(series_dict_train['id_1000']),\n",
    "        fixed_train_size      = True,\n",
    "        gap                   = 0,\n",
    "        allow_incomplete_fold = True,\n",
    "        refit                 = False,\n",
    "        n_jobs                = 'auto',\n",
    "        verbose               = False,\n",
    "        show_progress         = False,\n",
    "        suppress_warnings     = True\n",
    "    )\n",
    "\n",
    "    expected_metrics = pd.DataFrame(\n",
    "        data=np.array([['id_1000', 286.6227398656757, 105816.86051259708],\n",
    "        ['id_1001', 1364.7345740769094, 2175934.9583102698],\n",
    "        ['id_1003', 237.4894217124842, 95856.72602398091],\n",
    "        ['id_1004', 1267.85941538558, 2269796.338792736],\n",
    "        ['average', 789.1765377601623, 1161851.2209098958],\n",
    "        ['weighted_average', 745.7085483145497, 1024317.153152019],\n",
    "        ['pooling', 745.7085483145497, 1024317.1531520189]], dtype=object),\n",
    "        columns=['levels', 'mean_absolute_error', 'mean_squared_error']\n",
    "    ).astype({'mean_absolute_error': float, 'mean_squared_error': float})\n",
    "    \n",
    "    expected_predictions = pd.DataFrame(\n",
    "    data=np.array([[1438.14154717, 2090.79352613, 2166.9832933, 7285.52781428],\n",
    "                   [1438.14154717, 2089.11038884, 2074.55994929, 7488.18398744],\n",
    "                   [1438.14154717, 2089.11038884, 2035.99448247, 7488.18398744],\n",
    "                   [1403.93625654, 2089.11038884, 2035.99448247, 7488.18398744],\n",
    "                   [1403.93625654, 2089.11038884, 2035.99448247, 7488.18398744],\n",
    "                   [1403.93625654, 2076.10228838, 2035.99448247, 7250.69119259],\n",
    "                   [1403.93625654, 2076.10228838, np.nan, 7085.32315355],\n",
    "                   [1403.93625654, 2000.42985714, np.nan, 7285.52781428],\n",
    "                   [1403.93625654, 2013.4379576, np.nan, 7285.52781428],\n",
    "                   [1403.93625654, 2013.4379576, np.nan, 7285.52781428]]),\n",
    "    columns=['id_1000', 'id_1001', 'id_1003', 'id_1004'],\n",
    "    index=pd.date_range('2016-08-01', periods=10, freq='D')\n",
    ")\n",
    "\n",
    "    pd.testing.assert_frame_equal(metrics, expected_metrics)\n",
    "    pd.testing.assert_frame_equal(predictions.head(10), expected_predictions)\n",
    "\n",
    "test_output_backtesting_forecaster_multiseries_ForecasterAutoregMultiSeries_series_and_exog_dict_with_mocked_multiple_aggregated_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1000</th>\n",
       "      <th>id_1001</th>\n",
       "      <th>id_1003</th>\n",
       "      <th>id_1004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-01</th>\n",
       "      <td>1438.141547</td>\n",
       "      <td>2090.793526</td>\n",
       "      <td>2166.983293</td>\n",
       "      <td>7285.527814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-02</th>\n",
       "      <td>1438.141547</td>\n",
       "      <td>2089.110389</td>\n",
       "      <td>2074.559949</td>\n",
       "      <td>7488.183987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-03</th>\n",
       "      <td>1438.141547</td>\n",
       "      <td>2089.110389</td>\n",
       "      <td>2035.994482</td>\n",
       "      <td>7488.183987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-04</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2089.110389</td>\n",
       "      <td>2035.994482</td>\n",
       "      <td>7488.183987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-05</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2089.110389</td>\n",
       "      <td>2035.994482</td>\n",
       "      <td>7488.183987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-06</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2076.102288</td>\n",
       "      <td>2035.994482</td>\n",
       "      <td>7250.691193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-07</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2076.102288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7085.323154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-08</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2000.429857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7285.527814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-09</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2013.437958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7285.527814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-10</th>\n",
       "      <td>1403.936257</td>\n",
       "      <td>2013.437958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7285.527814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_1000      id_1001      id_1003      id_1004\n",
       "2016-08-01  1438.141547  2090.793526  2166.983293  7285.527814\n",
       "2016-08-02  1438.141547  2089.110389  2074.559949  7488.183987\n",
       "2016-08-03  1438.141547  2089.110389  2035.994482  7488.183987\n",
       "2016-08-04  1403.936257  2089.110389  2035.994482  7488.183987\n",
       "2016-08-05  1403.936257  2089.110389  2035.994482  7488.183987\n",
       "2016-08-06  1403.936257  2076.102288  2035.994482  7250.691193\n",
       "2016-08-07  1403.936257  2076.102288          NaN  7085.323154\n",
       "2016-08-08  1403.936257  2000.429857          NaN  7285.527814\n",
       "2016-08-09  1403.936257  2013.437958          NaN  7285.527814\n",
       "2016-08-10  1403.936257  2013.437958          NaN  7285.527814"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics, predictions = backtesting_forecaster_multiseries(\n",
    "        forecaster            = forecaster,\n",
    "        series                = series_dict,\n",
    "        exog                  = exog_dict,\n",
    "        steps                 = 24,\n",
    "        metric                = ['mean_absolute_error', 'mean_absolute_scaled_error'],\n",
    "        add_aggregated_metric = True,\n",
    "        initial_train_size    = len(series_dict_train['id_1000']),\n",
    "        fixed_train_size      = True,\n",
    "        gap                   = 0,\n",
    "        allow_incomplete_fold = True,\n",
    "        refit                 = False,\n",
    "        n_jobs                = 'auto',\n",
    "        verbose               = False,\n",
    "        show_progress         = False,\n",
    "        suppress_warnings     = True\n",
    "    )\n",
    "\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_scaled_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_1000</td>\n",
       "      <td>286.622740</td>\n",
       "      <td>1.301728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1001</td>\n",
       "      <td>1364.734574</td>\n",
       "      <td>3.878227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_1003</td>\n",
       "      <td>237.489422</td>\n",
       "      <td>0.994727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_1004</td>\n",
       "      <td>1267.859415</td>\n",
       "      <td>1.060634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>average</td>\n",
       "      <td>789.176538</td>\n",
       "      <td>1.808829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted_average</td>\n",
       "      <td>745.708548</td>\n",
       "      <td>2.170242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pooling</td>\n",
       "      <td>745.708548</td>\n",
       "      <td>1.771577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             levels  mean_absolute_error  mean_absolute_scaled_error\n",
       "0           id_1000           286.622740                    1.301728\n",
       "1           id_1001          1364.734574                    3.878227\n",
       "2           id_1003           237.489422                    0.994727\n",
       "3           id_1004          1267.859415                    1.060634\n",
       "4           average           789.176538                    1.808829\n",
       "5  weighted_average           745.708548                    2.170242\n",
       "6           pooling           745.708548                    1.771577"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947270993025895"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = series_dict_test['id_1003'].loc[predictions.index]\n",
    "y_pred = predictions['id_1003']\n",
    "y_train = series_dict_train['id_1003']\n",
    "\n",
    "if not isinstance(y_true, (pd.Series, np.ndarray)):\n",
    "    raise TypeError(\"y_true must be a pandas Series or numpy array\")\n",
    "if not isinstance(y_pred, (pd.Series, np.ndarray)):\n",
    "    raise TypeError(\"y_pred must be a pandas Series or numpy array\")\n",
    "if not isinstance(y_train, (list, pd.Series, np.ndarray)):\n",
    "    raise TypeError(\"y_train must be a list, pandas Series or numpy array\")\n",
    "if isinstance(y_train, list):\n",
    "    for x in y_train:\n",
    "        if not isinstance(x, (pd.Series, np.ndarray)):\n",
    "            raise TypeError(\n",
    "                \"When `y_train` is a list, each element must be a pandas Series \"\n",
    "                \"or numpy array\"\n",
    "            )\n",
    "if len(y_true) != len(y_pred):\n",
    "    raise ValueError(\"y_true and y_pred must have the same length\")\n",
    "if len(y_true) == 0 or len(y_pred) == 0:\n",
    "    raise ValueError(\"y_true and y_pred must have at least one element\")\n",
    "\n",
    "if isinstance(y_train, list):\n",
    "    naive_forecast = np.concatenate([np.diff(x) for x in y_train])\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / np.mean(np.abs(naive_forecast))\n",
    "\n",
    "else:\n",
    "    mase = np.mean(np.abs(y_true - y_pred)) / np.nanmean(np.abs(np.diff(y_train)))\n",
    "\n",
    "mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946632167597738"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_scaled_error(series_dict_test['id_1003'].loc[predictions.index], predictions['id_1003'], series_dict_train['id_1003'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2016-01-01    2294.750893\n",
       "2016-01-02    1750.000198\n",
       "2016-01-03    1455.750492\n",
       "2016-01-04    2141.000198\n",
       "2016-01-05    2384.870697\n",
       "                 ...     \n",
       "2016-07-27    1830.871780\n",
       "2016-07-28    1776.250992\n",
       "2016-07-29    1644.001091\n",
       "2016-07-30    1943.500587\n",
       "2016-07-31    3658.369995\n",
       "Freq: D, Name: id_1003, Length: 213, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_dict_train['id_1003']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
