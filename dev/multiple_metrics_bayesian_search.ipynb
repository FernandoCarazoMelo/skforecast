{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df7c8824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:21.287123Z",
     "start_time": "2022-04-14T15:24:21.265791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent.parent))\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a85a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58184bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:23.165175Z",
     "start_time": "2022-04-14T15:24:22.494521Z"
    }
   },
   "outputs": [],
   "source": [
    "# random search forecaster\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skforecast.model_selection.model_selection import bayesian_search_forecaster\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "360794f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:25.448031Z",
     "start_time": "2022-04-14T15:24:25.134042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00  (n=29)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y/%m/%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}  (n={len(data.loc[:end_train])})\")\n",
    "print(f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}  (n={len(data.loc[end_train:end_val])})\")\n",
    "print(f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}  (n={len(data.loc[end_val:])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "788937b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98ceb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bayesian_search_optuna(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(metric, list) and len(metric) != len(set(metric)):\n",
    "            raise ValueError(\n",
    "                'When `metrics` is a `list`, each metric name must be unique.'\n",
    "            )\n",
    "    if isinstance(forecaster, ForecasterAutoregCustom):\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                '`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.'\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric_list = [] \n",
    "    else: \n",
    "        metric_list = {(m if isinstance(m, str) else m.__name__): [] for m in metric}\n",
    "\n",
    "    metrics_values = [] # This variable will be modified inside _objective function. \n",
    "    # It isa trick to extract multiple values from _objective function since\n",
    "    # only the optimized value can be returned.\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y,\n",
    "        exog               = exog,\n",
    "        initial_train_size = initial_train_size,\n",
    "        fixed_train_size   = fixed_train_size,\n",
    "        steps              = steps,\n",
    "        metric             = metric,\n",
    "        refit              = refit,\n",
    "        verbose            = verbose,\n",
    "        search_space       = search_space,\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(**search_space(trial))\n",
    "        \n",
    "        metrics, _ = backtesting_forecaster(\n",
    "                                forecaster         = forecaster,\n",
    "                                y                  = y,\n",
    "                                exog               = exog,\n",
    "                                steps              = steps,\n",
    "                                metric             = metric,\n",
    "                                initial_train_size = initial_train_size,\n",
    "                                fixed_train_size   = fixed_train_size,\n",
    "                                refit              = refit,\n",
    "                                verbose            = verbose\n",
    "                            )\n",
    "        # Store metrics in the variable metrics_values defined outside _objective.\n",
    "        nonlocal metrics_values\n",
    "        metrics_values.append(metrics)\n",
    "\n",
    "        if isinstance(metrics, list):\n",
    "            return abs(metrics[0])\n",
    "        else:\n",
    "            return abs(metrics)\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)}, {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    for lags in tqdm(lags_grid, desc='loop lags_grid', position=0, ncols=90):\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)    \n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise Exception(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "\n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "            if isinstance(metric, list):\n",
    "                for m, m_value in zip(metric, metrics_values[i]):\n",
    "                    if isinstance(m, str):\n",
    "                        m_name = m\n",
    "                    else:\n",
    "                        m_name = m.__name__\n",
    "                    metric_list[m_name].append(m_value)\n",
    "            else:\n",
    "                metric_list.append(trial.value)\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "        \n",
    "    if isinstance(metric, list):\n",
    "        results = pd.DataFrame({\n",
    "                    'lags'  : lags_list,\n",
    "                    'params': params_list,\n",
    "                    **metric_list})\n",
    "        results = results.sort_values(by=list(metric_list)[0], ascending=True)\n",
    "    else:\n",
    "        results = pd.DataFrame({\n",
    "                    'lags'  : lags_list,\n",
    "                    'params': params_list,\n",
    "                    'metric': metric_list})\n",
    "        results = results.sort_values(by='metric', ascending=True)\n",
    "        \n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results['metric'].iloc[0]\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best\n",
    "\n",
    "\n",
    "def bayesian_search_forecaster(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: Union[callable, dict],\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    engine: str='skopt',\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={},\n",
    "    kwargs_gp_minimize: dict={},\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting and \n",
    "    optuna or skopt library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable (optuna), dict (skopt)\n",
    "        If optuna engine: callable\n",
    "            Function with argument `trial` which returns a dictionary with parameters names \n",
    "            (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "            trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "        If skopt engine: dict\n",
    "            Dictionary with parameters names (`str`) as keys and Space object from skopt \n",
    "            (Real, Integer, Categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    engine : str, default `'skopt'`\n",
    "        If 'optuna':\n",
    "            Bayesian optimization runs through the optuna library \n",
    "\n",
    "        If 'skopt':\n",
    "            Bayesian optimization runs through the skopt library\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    kwargs_gp_minimize : dict, default `{}`\n",
    "        Only applies to engine='skopt'.\n",
    "            Other keyword arguments (key, value mappings) to pass to skopt.gp_minimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object (optuna), scipy object (skopt)   \n",
    "        If optuna engine:\n",
    "            The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "        If skopt engine:\n",
    "            The best optimization result returned as a OptimizeResult object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if engine not in ['optuna', 'skopt']:\n",
    "        raise ValueError(\n",
    "                f\"\"\"`engine` only allows 'optuna' or 'skopt', got {engine}.\"\"\"\n",
    "              )\n",
    "\n",
    "    if engine == 'optuna':\n",
    "        results, results_opt_best = _bayesian_search_optuna(\n",
    "                                        forecaster            = forecaster,\n",
    "                                        y                     = y,\n",
    "                                        exog                  = exog,\n",
    "                                        lags_grid             = lags_grid,\n",
    "                                        search_space          = search_space,\n",
    "                                        steps                 = steps,\n",
    "                                        metric                = metric,\n",
    "                                        refit                 = refit,\n",
    "                                        initial_train_size    = initial_train_size,\n",
    "                                        fixed_train_size      = fixed_train_size,\n",
    "                                        n_trials              = n_trials,\n",
    "                                        random_state          = random_state,\n",
    "                                        return_best           = return_best,\n",
    "                                        verbose               = verbose,\n",
    "                                        kwargs_create_study   = kwargs_create_study,\n",
    "                                        kwargs_study_optimize = kwargs_study_optimize\n",
    "                                    )\n",
    "    else:\n",
    "        results, results_opt_best = _bayesian_search_skopt(\n",
    "                                        forecaster         = forecaster,\n",
    "                                        y                  = y,\n",
    "                                        exog               = exog,\n",
    "                                        lags_grid          = lags_grid,\n",
    "                                        search_space       = search_space,\n",
    "                                        steps              = steps,\n",
    "                                        metric             = metric,\n",
    "                                        refit              = refit,\n",
    "                                        initial_train_size = initial_train_size,\n",
    "                                        fixed_train_size   = fixed_train_size,\n",
    "                                        n_trials           = n_trials,\n",
    "                                        random_state       = random_state,\n",
    "                                        return_best        = return_best,\n",
    "                                        verbose            = verbose,\n",
    "                                        kwargs_gp_minimize = kwargs_gp_minimize\n",
    "                                    )\n",
    "\n",
    "    return results, results_opt_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d29533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 40, 20 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:06<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 40, 20 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:06<00:00,  3.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.068957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.069021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.069073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.069073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.069073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.069430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.069501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.069218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.069218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.069218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lags  n_estimators  min_samples_leaf max_features    metric\n",
       "1   [1 2 3 4 5]            12          1.258033         sqrt  0.068957\n",
       "2   [1 2 3 4 5]            13          2.283083         sqrt  0.069021\n",
       "3   [1 2 3 4 5]            14          1.081208         sqrt  0.069073\n",
       "4   [1 2 3 4 5]            14          1.907712         log2  0.069073\n",
       "5   [1 2 3 4 5]            14          3.218291         log2  0.069073\n",
       "6   [1 2 3 4 5]            15          1.670328         sqrt  0.069430\n",
       "7   [1 2 3 4 5]            16          3.038426         log2  0.069501\n",
       "8   [1 2 3 4 5]            17          1.454068         sqrt  0.069218\n",
       "9   [1 2 3 4 5]            17          1.525829         log2  0.069218\n",
       "10  [1 2 3 4 5]            17          1.739441         log2  0.069218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.071194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.070824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.071127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.071127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.071127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.070912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.070671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.070486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.070486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1 2 3 4 5]</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.070486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lags  n_estimators  min_samples_leaf max_features    metric\n",
       "1   [1 2 3 4 5]            12          1.258033         sqrt  0.071194\n",
       "2   [1 2 3 4 5]            13          2.283083         sqrt  0.070824\n",
       "3   [1 2 3 4 5]            14          1.081208         sqrt  0.071127\n",
       "4   [1 2 3 4 5]            14          1.907712         log2  0.071127\n",
       "5   [1 2 3 4 5]            14          3.218291         log2  0.071127\n",
       "6   [1 2 3 4 5]            15          1.670328         sqrt  0.070912\n",
       "7   [1 2 3 4 5]            16          3.038426         log2  0.070671\n",
       "8   [1 2 3 4 5]            17          1.454068         sqrt  0.070486\n",
       "9   [1 2 3 4 5]            17          1.525829         log2  0.070486\n",
       "10  [1 2 3 4 5]            17          1.739441         log2  0.070486"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_1, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = ['mean_absolute_error', 'mean_squared_error'],\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 20,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "\n",
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_2, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_squared_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 20,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "\n",
    "results_1 = results_1.rename(columns={'mean_squared_error': 'metric'})\n",
    "results_2 = results_2.rename(columns={'mean_squared_error': 'metric'})\n",
    "\n",
    "results_1.lags = results_1.lags.astype(str)\n",
    "results_2.lags = results_2.lags.astype(str)\n",
    "\n",
    "cols = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features', 'metric']\n",
    "cols_to_sort = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features']\n",
    "\n",
    "results_1 = results_1[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "results_2 = results_2[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "\n",
    "equal_hiperparameters = (results_1[cols_to_sort] == results_2[cols_to_sort]).all(axis=1)\n",
    "\n",
    "results_1 = results_1[equal_hiperparameters]\n",
    "results_2 = results_2[equal_hiperparameters]\n",
    "\n",
    "\n",
    "no_match = results_1.metric != results_2.metric\n",
    "display(results_1[no_match])\n",
    "display(results_2[no_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ece7df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bayesian_search_optuna(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(metric, list) and len(metric) != len(set(metric)):\n",
    "            raise ValueError(\n",
    "                'When `metrics` is a `list`, each metric name must be unique.'\n",
    "            )\n",
    "    if isinstance(forecaster, ForecasterAutoregCustom):\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                '`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.'\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric = [metric] \n",
    "    metric_list = {(m if isinstance(m, str) else m.__name__): [] for m in metric}\n",
    "\n",
    "    metrics_values = [] # This variable will be modified inside _objective function. \n",
    "    # It isa trick to extract multiple values from _objective function since\n",
    "    # only the optimized value can be returned.\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y,\n",
    "        exog               = exog,\n",
    "        initial_train_size = initial_train_size,\n",
    "        fixed_train_size   = fixed_train_size,\n",
    "        steps              = steps,\n",
    "        metric             = metric,\n",
    "        refit              = refit,\n",
    "        verbose            = verbose,\n",
    "        search_space       = search_space,\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(**search_space(trial))\n",
    "        \n",
    "        metrics, _ = backtesting_forecaster(\n",
    "                                forecaster         = forecaster,\n",
    "                                y                  = y,\n",
    "                                exog               = exog,\n",
    "                                steps              = steps,\n",
    "                                metric             = metric,\n",
    "                                initial_train_size = initial_train_size,\n",
    "                                fixed_train_size   = fixed_train_size,\n",
    "                                refit              = refit,\n",
    "                                verbose            = verbose\n",
    "                            )\n",
    "        # Store metrics in the variable metrics_values defined outside _objective.\n",
    "        nonlocal metrics_values\n",
    "        metrics_values.append(metrics)\n",
    "\n",
    "        return abs(metrics[0])\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)}, {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    for lags in tqdm(lags_grid, desc='loop lags_grid', position=0, ncols=90):\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)    \n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise Exception(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "\n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "\n",
    "            for m, m_value in zip(metric, metrics_values[i]):\n",
    "                if isinstance(m, str):\n",
    "                    m_name = m\n",
    "                else:\n",
    "                    m_name = m.__name__\n",
    "                metric_list[m_name].append(m_value)\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "        \n",
    "    results = pd.DataFrame({\n",
    "                'lags'  : lags_list,\n",
    "                'params': params_list,\n",
    "                **metric_list})\n",
    "    results = results.sort_values(by=list(metric_list)[0], ascending=True)\n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results['metric'].iloc[0]\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best\n",
    "\n",
    "\n",
    "def bayesian_search_forecaster(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: Union[callable, dict],\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    engine: str='skopt',\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={},\n",
    "    kwargs_gp_minimize: dict={},\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting and \n",
    "    optuna or skopt library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable (optuna), dict (skopt)\n",
    "        If optuna engine: callable\n",
    "            Function with argument `trial` which returns a dictionary with parameters names \n",
    "            (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "            trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "        If skopt engine: dict\n",
    "            Dictionary with parameters names (`str`) as keys and Space object from skopt \n",
    "            (Real, Integer, Categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    engine : str, default `'skopt'`\n",
    "        If 'optuna':\n",
    "            Bayesian optimization runs through the optuna library \n",
    "\n",
    "        If 'skopt':\n",
    "            Bayesian optimization runs through the skopt library\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    kwargs_gp_minimize : dict, default `{}`\n",
    "        Only applies to engine='skopt'.\n",
    "            Other keyword arguments (key, value mappings) to pass to skopt.gp_minimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object (optuna), scipy object (skopt)   \n",
    "        If optuna engine:\n",
    "            The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "        If skopt engine:\n",
    "            The best optimization result returned as a OptimizeResult object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if engine not in ['optuna', 'skopt']:\n",
    "        raise ValueError(\n",
    "                f\"\"\"`engine` only allows 'optuna' or 'skopt', got {engine}.\"\"\"\n",
    "              )\n",
    "\n",
    "    if engine == 'optuna':\n",
    "        results, results_opt_best = _bayesian_search_optuna(\n",
    "                                        forecaster            = forecaster,\n",
    "                                        y                     = y,\n",
    "                                        exog                  = exog,\n",
    "                                        lags_grid             = lags_grid,\n",
    "                                        search_space          = search_space,\n",
    "                                        steps                 = steps,\n",
    "                                        metric                = metric,\n",
    "                                        refit                 = refit,\n",
    "                                        initial_train_size    = initial_train_size,\n",
    "                                        fixed_train_size      = fixed_train_size,\n",
    "                                        n_trials              = n_trials,\n",
    "                                        random_state          = random_state,\n",
    "                                        return_best           = return_best,\n",
    "                                        verbose               = verbose,\n",
    "                                        kwargs_create_study   = kwargs_create_study,\n",
    "                                        kwargs_study_optimize = kwargs_study_optimize\n",
    "                                    )\n",
    "    else:\n",
    "        results, results_opt_best = _bayesian_search_skopt(\n",
    "                                        forecaster         = forecaster,\n",
    "                                        y                  = y,\n",
    "                                        exog               = exog,\n",
    "                                        lags_grid          = lags_grid,\n",
    "                                        search_space       = search_space,\n",
    "                                        steps              = steps,\n",
    "                                        metric             = metric,\n",
    "                                        refit              = refit,\n",
    "                                        initial_train_size = initial_train_size,\n",
    "                                        fixed_train_size   = fixed_train_size,\n",
    "                                        n_trials           = n_trials,\n",
    "                                        random_state       = random_state,\n",
    "                                        return_best        = return_best,\n",
    "                                        verbose            = verbose,\n",
    "                                        kwargs_gp_minimize = kwargs_gp_minimize\n",
    "                                    )\n",
    "\n",
    "    return results, results_opt_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dc9bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 40, 20 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:06<00:00,  3.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.695...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>19</td>\n",
       "      <td>2.695594</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.340...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.340209</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3.617...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>19</td>\n",
       "      <td>3.617716</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.381...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.381725</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.442...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.442591</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.798...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.798371</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.335...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.335378</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 1.267...</td>\n",
       "      <td>0.216278</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>1.267145</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 1.250...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>1.250557</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_leaf': 2.680...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>10</td>\n",
       "      <td>2.680245</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_leaf': 2.095...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>18</td>\n",
       "      <td>2.095406</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.022...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.022208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.779...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.779373</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.167...</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.167195</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_leaf': 3.607...</td>\n",
       "      <td>0.217384</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>18</td>\n",
       "      <td>3.607976</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.969...</td>\n",
       "      <td>0.217384</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>20</td>\n",
       "      <td>2.969488</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.420...</td>\n",
       "      <td>0.217988</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>20</td>\n",
       "      <td>2.420271</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 11, 'min_samples_leaf': 2.448...</td>\n",
       "      <td>0.217988</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>11</td>\n",
       "      <td>2.448482</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.450...</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>20</td>\n",
       "      <td>2.450473</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_leaf': 1.014...</td>\n",
       "      <td>0.218439</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>10</td>\n",
       "      <td>1.014037</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "35  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 2.695...   \n",
       "14        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.340...   \n",
       "34  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3.617...   \n",
       "33  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.381...   \n",
       "32  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.442...   \n",
       "15        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.798...   \n",
       "12        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.335...   \n",
       "13        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 1.267...   \n",
       "16        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 1.250...   \n",
       "37  [1, 2, 3, 4, 5]  {'n_estimators': 10, 'min_samples_leaf': 2.680...   \n",
       "36  [1, 2, 3, 4, 5]  {'n_estimators': 18, 'min_samples_leaf': 2.095...   \n",
       "38  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 2.022...   \n",
       "18        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 2.779...   \n",
       "17        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 2.167...   \n",
       "24  [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "4         [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "19        [1, 2, 3]  {'n_estimators': 18, 'min_samples_leaf': 3.607...   \n",
       "39  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.969...   \n",
       "7         [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "27  [1, 2, 3, 4, 5]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "28  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "9         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "3         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "23  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "8         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "29  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "1         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "6         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "0         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "26  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "21  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "20  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "31  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.420...   \n",
       "11        [1, 2, 3]  {'n_estimators': 11, 'min_samples_leaf': 2.448...   \n",
       "22  [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "2         [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "25  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "5         [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "30  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.450...   \n",
       "10        [1, 2, 3]  {'n_estimators': 10, 'min_samples_leaf': 1.014...   \n",
       "\n",
       "    mean_absolute_error  mean_squared_error  n_estimators  min_samples_leaf  \\\n",
       "35             0.216278            0.068307            19          2.695594   \n",
       "14             0.216278            0.068307            20          2.340209   \n",
       "34             0.216278            0.068307            19          3.617716   \n",
       "33             0.216278            0.068307            20          2.381725   \n",
       "32             0.216278            0.068307            20          2.442591   \n",
       "15             0.216278            0.068307            20          2.798371   \n",
       "12             0.216278            0.068307            20          2.335378   \n",
       "13             0.216278            0.068307            20          1.267145   \n",
       "16             0.216676            0.068559            19          1.250557   \n",
       "37             0.216676            0.068559            10          2.680245   \n",
       "36             0.216676            0.068559            18          2.095406   \n",
       "38             0.216676            0.068559            19          2.022208   \n",
       "18             0.216676            0.068559            19          2.779373   \n",
       "17             0.216676            0.068559            19          2.167195   \n",
       "24             0.217299            0.068957            12          1.258033   \n",
       "4              0.217299            0.068957            12          1.258033   \n",
       "19             0.217384            0.069033            18          3.607976   \n",
       "39             0.217384            0.069033            20          2.969488   \n",
       "7              0.217401            0.069021            13          2.283083   \n",
       "27             0.217401            0.069021            13          2.283083   \n",
       "28             0.217481            0.069073            14          1.907712   \n",
       "9              0.217481            0.069073            14          3.218291   \n",
       "3              0.217481            0.069073            14          1.081208   \n",
       "23             0.217481            0.069073            14          1.081208   \n",
       "8              0.217481            0.069073            14          1.907712   \n",
       "29             0.217481            0.069073            14          3.218291   \n",
       "1              0.217677            0.069218            17          1.739441   \n",
       "6              0.217677            0.069218            17          1.525829   \n",
       "0              0.217677            0.069218            17          1.454068   \n",
       "26             0.217677            0.069218            17          1.525829   \n",
       "21             0.217677            0.069218            17          1.739441   \n",
       "20             0.217677            0.069218            17          1.454068   \n",
       "31             0.217988            0.069411            20          2.420271   \n",
       "11             0.217988            0.069411            11          2.448482   \n",
       "22             0.218018            0.069430            15          1.670328   \n",
       "2              0.218018            0.069430            15          1.670328   \n",
       "25             0.218105            0.069501            16          3.038426   \n",
       "5              0.218105            0.069501            16          3.038426   \n",
       "30             0.218439            0.069700            20          2.450473   \n",
       "10             0.218439            0.069700            10          1.014037   \n",
       "\n",
       "   max_features  \n",
       "35         sqrt  \n",
       "14         sqrt  \n",
       "34         sqrt  \n",
       "33         sqrt  \n",
       "32         sqrt  \n",
       "15         sqrt  \n",
       "12         sqrt  \n",
       "13         sqrt  \n",
       "16         sqrt  \n",
       "37         sqrt  \n",
       "36         sqrt  \n",
       "38         sqrt  \n",
       "18         sqrt  \n",
       "17         sqrt  \n",
       "24         sqrt  \n",
       "4          sqrt  \n",
       "19         sqrt  \n",
       "39         sqrt  \n",
       "7          sqrt  \n",
       "27         sqrt  \n",
       "28         log2  \n",
       "9          log2  \n",
       "3          sqrt  \n",
       "23         sqrt  \n",
       "8          log2  \n",
       "29         log2  \n",
       "1          log2  \n",
       "6          log2  \n",
       "0          sqrt  \n",
       "26         log2  \n",
       "21         log2  \n",
       "20         sqrt  \n",
       "31         sqrt  \n",
       "11         sqrt  \n",
       "22         sqrt  \n",
       "2          sqrt  \n",
       "25         log2  \n",
       "5          log2  \n",
       "30         sqrt  \n",
       "10         sqrt  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_1, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = ['mean_absolute_error', 'mean_squared_error'],\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 20,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae39beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 40, 20 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:07<00:00,  3.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_leaf': 3.649...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>18</td>\n",
       "      <td>3.649222</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3.617...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>19</td>\n",
       "      <td>3.617716</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.381...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.381725</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.442...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.442591</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.335...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.335378</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 1.267...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>1.267145</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.340...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.340209</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.798...</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>20</td>\n",
       "      <td>2.798371</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.779...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.779373</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_leaf': 2.967...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>10</td>\n",
       "      <td>2.967911</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.897...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.897469</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 1.250...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>1.250557</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 2.167...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>2.167195</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3.568...</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>19</td>\n",
       "      <td>3.568321</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_leaf': 3.607...</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>18</td>\n",
       "      <td>3.607976</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 18, 'min_samples_leaf': 2.804...</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>18</td>\n",
       "      <td>2.804798</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 11, 'min_samples_leaf': 2.448...</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>11</td>\n",
       "      <td>2.448482</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.420...</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>20</td>\n",
       "      <td>2.420271</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 2.450...</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>20</td>\n",
       "      <td>2.450473</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_leaf': 1.014...</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>10</td>\n",
       "      <td>1.014037</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "35  [1, 2, 3, 4, 5]  {'n_estimators': 18, 'min_samples_leaf': 3.649...   \n",
       "34  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3.617...   \n",
       "33  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.381...   \n",
       "32  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.442...   \n",
       "12        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.335...   \n",
       "13        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 1.267...   \n",
       "14        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.340...   \n",
       "15        [1, 2, 3]  {'n_estimators': 20, 'min_samples_leaf': 2.798...   \n",
       "18        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 2.779...   \n",
       "37  [1, 2, 3, 4, 5]  {'n_estimators': 10, 'min_samples_leaf': 2.967...   \n",
       "36  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 2.897...   \n",
       "16        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 1.250...   \n",
       "17        [1, 2, 3]  {'n_estimators': 19, 'min_samples_leaf': 2.167...   \n",
       "38  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3.568...   \n",
       "4         [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "24  [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "27  [1, 2, 3, 4, 5]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "7         [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "19        [1, 2, 3]  {'n_estimators': 18, 'min_samples_leaf': 3.607...   \n",
       "39  [1, 2, 3, 4, 5]  {'n_estimators': 18, 'min_samples_leaf': 2.804...   \n",
       "29  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "3         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "23  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "8         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "28  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "9         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "1         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "6         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "20  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "21  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "26  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "0         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "11        [1, 2, 3]  {'n_estimators': 11, 'min_samples_leaf': 2.448...   \n",
       "31  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.420...   \n",
       "22  [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "2         [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "25  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "5         [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "30  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 2.450...   \n",
       "10        [1, 2, 3]  {'n_estimators': 10, 'min_samples_leaf': 1.014...   \n",
       "\n",
       "    mean_squared_error  n_estimators  min_samples_leaf max_features  \n",
       "35            0.068307            18          3.649222         sqrt  \n",
       "34            0.068307            19          3.617716         sqrt  \n",
       "33            0.068307            20          2.381725         sqrt  \n",
       "32            0.068307            20          2.442591         sqrt  \n",
       "12            0.068307            20          2.335378         sqrt  \n",
       "13            0.068307            20          1.267145         sqrt  \n",
       "14            0.068307            20          2.340209         sqrt  \n",
       "15            0.068307            20          2.798371         sqrt  \n",
       "18            0.068559            19          2.779373         sqrt  \n",
       "37            0.068559            10          2.967911         sqrt  \n",
       "36            0.068559            19          2.897469         sqrt  \n",
       "16            0.068559            19          1.250557         sqrt  \n",
       "17            0.068559            19          2.167195         sqrt  \n",
       "38            0.068559            19          3.568321         sqrt  \n",
       "4             0.068957            12          1.258033         sqrt  \n",
       "24            0.068957            12          1.258033         sqrt  \n",
       "27            0.069021            13          2.283083         sqrt  \n",
       "7             0.069021            13          2.283083         sqrt  \n",
       "19            0.069033            18          3.607976         sqrt  \n",
       "39            0.069033            18          2.804798         sqrt  \n",
       "29            0.069073            14          3.218291         log2  \n",
       "3             0.069073            14          1.081208         sqrt  \n",
       "23            0.069073            14          1.081208         sqrt  \n",
       "8             0.069073            14          1.907712         log2  \n",
       "28            0.069073            14          1.907712         log2  \n",
       "9             0.069073            14          3.218291         log2  \n",
       "1             0.069218            17          1.739441         log2  \n",
       "6             0.069218            17          1.525829         log2  \n",
       "20            0.069218            17          1.454068         sqrt  \n",
       "21            0.069218            17          1.739441         log2  \n",
       "26            0.069218            17          1.525829         log2  \n",
       "0             0.069218            17          1.454068         sqrt  \n",
       "11            0.069411            11          2.448482         sqrt  \n",
       "31            0.069411            20          2.420271         sqrt  \n",
       "22            0.069430            15          1.670328         sqrt  \n",
       "2             0.069430            15          1.670328         sqrt  \n",
       "25            0.069501            16          3.038426         log2  \n",
       "5             0.069501            16          3.038426         log2  \n",
       "30            0.069700            20          2.450473         sqrt  \n",
       "10            0.069700            10          1.014037         sqrt  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_2, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_squared_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 20,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34e72e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = results_1.rename(columns={'mean_squared_error': 'metric'})\n",
    "results_2 = results_2.rename(columns={'mean_squared_error': 'metric'})\n",
    "\n",
    "results_1.lags = results_1.lags.astype(str)\n",
    "results_2.lags = results_2.lags.astype(str)\n",
    "\n",
    "cols = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features', 'metric']\n",
    "cols_to_sort = ['lags', 'n_estimators', 'min_samples_leaf', 'max_features']\n",
    "\n",
    "results_1 = results_1[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "results_2 = results_2[cols].sort_values(by=cols_to_sort).reset_index(drop=True)\n",
    "\n",
    "equal_hiperparameters = (results_1[cols_to_sort] == results_2[cols_to_sort]).all(axis=1)\n",
    "\n",
    "results_1 = results_1[equal_hiperparameters]\n",
    "results_2 = results_2[equal_hiperparameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6515111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lags, n_estimators, min_samples_leaf, max_features, metric]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [lags, n_estimators, min_samples_leaf, max_features, metric]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "no_match = results_1.metric != results_2.metric\n",
    "display(results_1[no_match])\n",
    "display(results_2[no_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477db131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1040de6fa7fac918a6f2fa3117abdc75aadd79ddb8896e3fabb1dd7d4a742299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
