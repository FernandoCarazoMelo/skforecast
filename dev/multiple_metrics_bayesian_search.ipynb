{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df7c8824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:21.287123Z",
     "start_time": "2022-04-14T15:24:21.265791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent.parent))\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a85a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "58184bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:23.165175Z",
     "start_time": "2022-04-14T15:24:22.494521Z"
    }
   },
   "outputs": [],
   "source": [
    "# random search forecaster\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skforecast.model_selection.model_selection import bayesian_search_forecaster\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "360794f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:24:25.448031Z",
     "start_time": "2022-04-14T15:24:25.134042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00  (n=29)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "url = ('https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv')\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y/%m/%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}  (n={len(data.loc[:end_train])})\")\n",
    "print(f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}  (n={len(data.loc[end_train:end_val])})\")\n",
    "print(f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}  (n={len(data.loc[end_val:])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "788937b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ece7df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bayesian_search_optuna(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(metric, list) and len(metric) != len(set(metric)):\n",
    "            raise ValueError(\n",
    "                'When `metrics` is a `list`, each metric name must be unique.'\n",
    "            )\n",
    "    if isinstance(forecaster, ForecasterAutoregCustom):\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                '`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregCustom`.'\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric_list = [] \n",
    "    else: \n",
    "        metric_list = {(m if isinstance(m, str) else m.__name__): [] for m in metric}\n",
    "\n",
    "    metrics_values = [] # This variable will be modified inside _objective function. \n",
    "    # It isa trick to extract multiple values from _objective function since\n",
    "    # only the optimized value can be returned.\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        forecaster         = forecaster,\n",
    "        y                  = y,\n",
    "        exog               = exog,\n",
    "        initial_train_size = initial_train_size,\n",
    "        fixed_train_size   = fixed_train_size,\n",
    "        steps              = steps,\n",
    "        metric             = metric,\n",
    "        refit              = refit,\n",
    "        verbose            = verbose,\n",
    "        search_space       = search_space,\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(**search_space(trial))\n",
    "        \n",
    "        metrics, _ = backtesting_forecaster(\n",
    "                                forecaster         = forecaster,\n",
    "                                y                  = y,\n",
    "                                exog               = exog,\n",
    "                                steps              = steps,\n",
    "                                metric             = metric,\n",
    "                                initial_train_size = initial_train_size,\n",
    "                                fixed_train_size   = fixed_train_size,\n",
    "                                refit              = refit,\n",
    "                                verbose            = verbose\n",
    "                            )\n",
    "        # Store metrics in the variable metrics_values defined outside _objective.\n",
    "        nonlocal metrics_values\n",
    "        metrics_values.append(metrics)\n",
    "\n",
    "        if isinstance(metrics, list):\n",
    "            return abs(metrics[0])\n",
    "        else:\n",
    "            return abs(metrics)\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)}, {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    for lags in tqdm(lags_grid, desc='loop lags_grid', position=0, ncols=90):\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)    \n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise Exception(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "\n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "            if isinstance(metric, list):\n",
    "                for m, m_value in zip(metric, metrics_values[i]):\n",
    "                    if isinstance(m, str):\n",
    "                        m_name = m\n",
    "                    else:\n",
    "                        m_name = m.__name__\n",
    "                    metric_list[m_name].append(m_value)\n",
    "            else:\n",
    "                metric_list.append(trial.value)\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "        \n",
    "    if isinstance(metric, list):\n",
    "        results = pd.DataFrame({\n",
    "                    'lags'  : lags_list,\n",
    "                    'params': params_list,\n",
    "                    **metric_list})\n",
    "        results = results.sort_values(by=list(metric_list)[0], ascending=True)\n",
    "    else:\n",
    "        results = pd.DataFrame({\n",
    "                    'lags'  : lags_list,\n",
    "                    'params': params_list,\n",
    "                    'metric': metric_list})\n",
    "        results = results.sort_values(by='metric', ascending=True)\n",
    "        \n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results['metric'].iloc[0]\n",
    "        \n",
    "        if isinstance(forecaster, (ForecasterAutoreg, ForecasterAutoregDirect, \n",
    "        ForecasterAutoregMultiOutput)):\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best\n",
    "\n",
    "\n",
    "def bayesian_search_forecaster(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    search_space: Union[callable, dict],\n",
    "    steps: int,\n",
    "    metric: Union[str, callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: bool=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    verbose: bool=True,\n",
    "    engine: str='skopt',\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={},\n",
    "    kwargs_gp_minimize: dict={},\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using time series backtesting and \n",
    "    optuna or skopt library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregDirect,\n",
    "    ForecasterAutoregMultiOutput\n",
    "        Forcaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "        \n",
    "    search_space : callable (optuna), dict (skopt)\n",
    "        If optuna engine: callable\n",
    "            Function with argument `trial` which returns a dictionary with parameters names \n",
    "            (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "            trial.suggest_int, trial.suggest_categorical) as values.\n",
    "\n",
    "        If skopt engine: dict\n",
    "            Dictionary with parameters names (`str`) as keys and Space object from skopt \n",
    "            (Real, Integer, Categorical) as values.\n",
    "\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error',\n",
    "             'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "    \n",
    "        If callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "\n",
    "        If list:\n",
    "            List containing several strings and/or callable.\n",
    "\n",
    "\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    " \n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "           \n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoreg`, `ForecasterAutoregDirect` or `ForecasterAutoregMultiOutput`.\n",
    "        \n",
    "    refit : bool, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration of backtesting.\n",
    "        \n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "        \n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "\n",
    "    engine : str, default `'skopt'`\n",
    "        If 'optuna':\n",
    "            Bayesian optimization runs through the optuna library \n",
    "\n",
    "        If 'skopt':\n",
    "            Bayesian optimization runs through the skopt library\n",
    "\n",
    "    kwargs_create_study : dict, default `{'direction':'minimize', 'sampler':TPESampler(seed=123)}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Only applies to engine='optuna'.\n",
    "            Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    kwargs_gp_minimize : dict, default `{}`\n",
    "        Only applies to engine='skopt'.\n",
    "            Other keyword arguments (key, value mappings) to pass to skopt.gp_minimize().\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "            column lags = predictions.\n",
    "            column params = lower bound of the interval.\n",
    "            column metric = metric value estimated for the combination of parameters.\n",
    "            additional n columns with param = value.\n",
    "\n",
    "    results_opt_best : optuna object (optuna), scipy object (skopt)   \n",
    "        If optuna engine:\n",
    "            The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "        If skopt engine:\n",
    "            The best optimization result returned as a OptimizeResult object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if engine not in ['optuna', 'skopt']:\n",
    "        raise ValueError(\n",
    "                f\"\"\"`engine` only allows 'optuna' or 'skopt', got {engine}.\"\"\"\n",
    "              )\n",
    "\n",
    "    if engine == 'optuna':\n",
    "        results, results_opt_best = _bayesian_search_optuna(\n",
    "                                        forecaster            = forecaster,\n",
    "                                        y                     = y,\n",
    "                                        exog                  = exog,\n",
    "                                        lags_grid             = lags_grid,\n",
    "                                        search_space          = search_space,\n",
    "                                        steps                 = steps,\n",
    "                                        metric                = metric,\n",
    "                                        refit                 = refit,\n",
    "                                        initial_train_size    = initial_train_size,\n",
    "                                        fixed_train_size      = fixed_train_size,\n",
    "                                        n_trials              = n_trials,\n",
    "                                        random_state          = random_state,\n",
    "                                        return_best           = return_best,\n",
    "                                        verbose               = verbose,\n",
    "                                        kwargs_create_study   = kwargs_create_study,\n",
    "                                        kwargs_study_optimize = kwargs_study_optimize\n",
    "                                    )\n",
    "    else:\n",
    "        results, results_opt_best = _bayesian_search_skopt(\n",
    "                                        forecaster         = forecaster,\n",
    "                                        y                  = y,\n",
    "                                        exog               = exog,\n",
    "                                        lags_grid          = lags_grid,\n",
    "                                        search_space       = search_space,\n",
    "                                        steps              = steps,\n",
    "                                        metric             = metric,\n",
    "                                        refit              = refit,\n",
    "                                        initial_train_size = initial_train_size,\n",
    "                                        fixed_train_size   = fixed_train_size,\n",
    "                                        n_trials           = n_trials,\n",
    "                                        random_state       = random_state,\n",
    "                                        return_best        = return_best,\n",
    "                                        verbose            = verbose,\n",
    "                                        kwargs_gp_minimize = kwargs_gp_minimize\n",
    "                                    )\n",
    "\n",
    "    return results, results_opt_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1dc9bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20, 10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:05<00:00,  2.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.069021</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.069501</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "14  [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "4         [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "17  [1, 2, 3, 4, 5]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "7         [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "9         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "13  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "18  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "8         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "19  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "3         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "10  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "11  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "16  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "1         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "6         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "0         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "12  [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "2         [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "5         [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "15  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "\n",
       "    mean_absolute_error  mean_squared_error  n_estimators  min_samples_leaf  \\\n",
       "14             0.217299            0.068957            12          1.258033   \n",
       "4              0.217299            0.068957            12          1.258033   \n",
       "17             0.217401            0.069021            13          2.283083   \n",
       "7              0.217401            0.069021            13          2.283083   \n",
       "9              0.217481            0.069073            14          3.218291   \n",
       "13             0.217481            0.069073            14          1.081208   \n",
       "18             0.217481            0.069073            14          1.907712   \n",
       "8              0.217481            0.069073            14          1.907712   \n",
       "19             0.217481            0.069073            14          3.218291   \n",
       "3              0.217481            0.069073            14          1.081208   \n",
       "10             0.217677            0.069218            17          1.454068   \n",
       "11             0.217677            0.069218            17          1.739441   \n",
       "16             0.217677            0.069218            17          1.525829   \n",
       "1              0.217677            0.069218            17          1.739441   \n",
       "6              0.217677            0.069218            17          1.525829   \n",
       "0              0.217677            0.069218            17          1.454068   \n",
       "12             0.218018            0.069430            15          1.670328   \n",
       "2              0.218018            0.069430            15          1.670328   \n",
       "5              0.218105            0.069501            16          3.038426   \n",
       "15             0.218105            0.069501            16          3.038426   \n",
       "\n",
       "   max_features  \n",
       "14         sqrt  \n",
       "4          sqrt  \n",
       "17         sqrt  \n",
       "7          sqrt  \n",
       "9          log2  \n",
       "13         sqrt  \n",
       "18         log2  \n",
       "8          log2  \n",
       "19         log2  \n",
       "3          sqrt  \n",
       "10         sqrt  \n",
       "11         log2  \n",
       "16         log2  \n",
       "1          log2  \n",
       "6          log2  \n",
       "0          sqrt  \n",
       "12         sqrt  \n",
       "2          sqrt  \n",
       "5          log2  \n",
       "15         log2  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_1, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = ['mean_absolute_error', 'mean_squared_error'],\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae39beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20, 10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid: 100%|███████████████████████████████████████| 2/2 [00:05<00:00,  2.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>metric</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.218018</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.454...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.454068</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.739...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.739441</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 1.525...</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>17</td>\n",
       "      <td>1.525829</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 3.038...</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>16</td>\n",
       "      <td>3.038426</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 2.283...</td>\n",
       "      <td>0.220040</td>\n",
       "      <td>13</td>\n",
       "      <td>2.283083</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 1.670...</td>\n",
       "      <td>0.220173</td>\n",
       "      <td>15</td>\n",
       "      <td>1.670328</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.907...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>1.907712</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1.081...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>1.081208</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 3.218...</td>\n",
       "      <td>0.220478</td>\n",
       "      <td>14</td>\n",
       "      <td>3.218291</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 1.258...</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>12</td>\n",
       "      <td>1.258033</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lags                                             params  \\\n",
       "4         [1, 2, 3]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "7         [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "9         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "8         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "3         [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "6         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "0         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "1         [1, 2, 3]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "2         [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "5         [1, 2, 3]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "10  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.454...   \n",
       "11  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.739...   \n",
       "16  [1, 2, 3, 4, 5]  {'n_estimators': 17, 'min_samples_leaf': 1.525...   \n",
       "15  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 3.038...   \n",
       "17  [1, 2, 3, 4, 5]  {'n_estimators': 13, 'min_samples_leaf': 2.283...   \n",
       "12  [1, 2, 3, 4, 5]  {'n_estimators': 15, 'min_samples_leaf': 1.670...   \n",
       "18  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.907...   \n",
       "13  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 1.081...   \n",
       "19  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 3.218...   \n",
       "14  [1, 2, 3, 4, 5]  {'n_estimators': 12, 'min_samples_leaf': 1.258...   \n",
       "\n",
       "      metric  n_estimators  min_samples_leaf max_features  \n",
       "4   0.217299            12          1.258033         sqrt  \n",
       "7   0.217401            13          2.283083         sqrt  \n",
       "9   0.217481            14          3.218291         log2  \n",
       "8   0.217481            14          1.907712         log2  \n",
       "3   0.217481            14          1.081208         sqrt  \n",
       "6   0.217677            17          1.525829         log2  \n",
       "0   0.217677            17          1.454068         sqrt  \n",
       "1   0.217677            17          1.739441         log2  \n",
       "2   0.218018            15          1.670328         sqrt  \n",
       "5   0.218105            16          3.038426         log2  \n",
       "10  0.219529            17          1.454068         sqrt  \n",
       "11  0.219529            17          1.739441         log2  \n",
       "16  0.219529            17          1.525829         log2  \n",
       "15  0.219800            16          3.038426         log2  \n",
       "17  0.220040            13          2.283083         sqrt  \n",
       "12  0.220173            15          1.670328         sqrt  \n",
       "18  0.220478            14          1.907712         log2  \n",
       "13  0.220478            14          1.081208         sqrt  \n",
       "19  0.220478            14          3.218291         log2  \n",
       "14  0.220546            12          1.258033         sqrt  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameter and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'     : trial.suggest_int('n_estimators', 10, 20),\n",
    "                     'min_samples_leaf' : trial.suggest_float('min_samples_leaf', 1., 3.7, log=True),\n",
    "                     'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "                    } \n",
    "    return search_space\n",
    "\n",
    "results_2, frozen_trial = bayesian_search_forecaster(\n",
    "                            forecaster            = forecaster,\n",
    "                            y                     = data.loc[:end_val, 'y'],\n",
    "                            lags_grid             = lags_grid,\n",
    "                            search_space          = search_space,\n",
    "                            steps                 = 12,\n",
    "                            metric                = 'mean_absolute_error',\n",
    "                            refit                 = True,\n",
    "                            initial_train_size    = len(data.loc[:end_train]),\n",
    "                            fixed_train_size      = True,\n",
    "                            n_trials              = 10,\n",
    "                            random_state          = 123,\n",
    "                            return_best           = False,\n",
    "                            verbose               = False,\n",
    "                            engine                = 'optuna',\n",
    "                            kwargs_create_study   = {},\n",
    "                            kwargs_study_optimize = {}\n",
    "                        )\n",
    "\n",
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35dfae21",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results_1\u001b[39m.\u001b[39mlags \u001b[39m=\u001b[39m results_1\u001b[39m.\u001b[39;49mlags\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results_2\u001b[39m.\u001b[39mlags \u001b[39m=\u001b[39m results_2\u001b[39m.\u001b[39mlags\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m filtro \u001b[39m=\u001b[39m (results_1\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mvalues \u001b[39m==\u001b[39m results_2\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mvalues) \u001b[39mand\u001b[39;00m (results_1\u001b[39m.\u001b[39mlags \u001b[39m==\u001b[39m results_2\u001b[39m.\u001b[39mlags)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/series.py:4430\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4321\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4322\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4325\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4326\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4327\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4328\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4329\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4428\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4429\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4430\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1138\u001b[0m             values,\n\u001b[1;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1141\u001b[0m         )\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb Cell 9\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results_1\u001b[39m.\u001b[39mlags \u001b[39m=\u001b[39m results_1\u001b[39m.\u001b[39mlags\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results_2\u001b[39m.\u001b[39mlags \u001b[39m=\u001b[39m results_2\u001b[39m.\u001b[39mlags\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ximo/Documents/GitHub/skforecast/dev/multiple_metrics_bayesian_search.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m filtro \u001b[39m=\u001b[39m (results_1\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mvalues \u001b[39m==\u001b[39m results_2\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mvalues) \u001b[39mand\u001b[39;00m (results_1\u001b[39m.\u001b[39mlags \u001b[39m==\u001b[39m results_2\u001b[39m.\u001b[39mlags)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "results_1.lags = results_1.lags.apply(lambda x: x.tolist())\n",
    "results_2.lags = results_2.lags.apply(lambda x: x.tolist())\n",
    "filtro = (results_1.params.values == results_2.params.values) and (results_1.lags == results_2.lags)\n",
    "filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73a63ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2.lags.loc[14].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "784db74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1.mean_absolute_error.loc[filtro].values == results_2.metric.loc[filtro].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3e91dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'min_samples_leaf': 1.670328340553618, 'max_features': 'sqrt'}\n",
      "{'n_estimators': 15, 'min_samples_leaf': 1.670328340553618, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "print(results_1.params.loc[5])\n",
    "print(results_1.params.loc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16d396e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14    0.217299\n",
      "10    0.217677\n",
      "11    0.217677\n",
      "16    0.217677\n",
      "Name: mean_absolute_error, dtype: float64\n",
      "4     0.217299\n",
      "10    0.219529\n",
      "11    0.219529\n",
      "16    0.219529\n",
      "Name: metric, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(results_1.mean_absolute_error.loc[filtro])\n",
    "print(results_2.metric.loc[filtro])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1040de6fa7fac918a6f2fa3117abdc75aadd79ddb8896e3fabb1dd7d4a742299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
