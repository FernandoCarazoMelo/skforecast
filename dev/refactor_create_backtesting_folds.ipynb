{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.model_selection.model_selection import _get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc floor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mfloor(\u001b[39m100\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m6\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint32\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc floor"
     ]
    }
   ],
   "source": [
    "np.floor(100/6, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_backtesting_folds_2(\n",
    "    data: Union[pd.Series, pd.DataFrame],\n",
    "    window_size: int,\n",
    "    initial_train_size: Union[int, None],\n",
    "    test_size: int,\n",
    "    externally_fitted: bool=False,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    return_all_indexes: bool=False,\n",
    "    verbose: bool=True\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    This function is designed to work after passing the `check_backtesting_input` \n",
    "    function from `skforecast.utils`.\n",
    "\n",
    "    Provides train/test indices (position) to split time series data samples that\n",
    "    are observed at fixed time intervals, in train/test sets. In each split, test\n",
    "    indices must be higher than before.\n",
    "\n",
    "    Three arrays are returned for each fold with the position of train, test\n",
    "    including the gap, and test excluding the gap. The gap is the number of\n",
    "    samples to exclude from the end of each train set before the test set. The\n",
    "    test excluding the gap is the one that must be used to make evaluate the\n",
    "    model. The test including the gap is provided for convenience.\n",
    "\n",
    "    Returned indexes are not the indexes of the original time series, but the\n",
    "    positional indexes of the samples in the time series. For example, if the   \n",
    "    original time series is `y = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]`, the\n",
    "    returned indexes for the first fold if  `test_size = 4`, `gap = 1` and \n",
    "    `initial_train_size = 2` are: `[[0, 1], [2, 3, 4, 5], [3, 4, 5]]]`. This means\n",
    "    that the first fold is using the samples with positional indexes 0 and 1 in\n",
    "    the time series as training set, and the samples with positional indexes 2,\n",
    "    3, 4 and 5 as test set, but only the samples with positional indexes 3, 4 and\n",
    "    5 should be used to evaluate the model since `gap = 1`. The second fold would\n",
    "    be `[[0, 1, 2, 3], [4, 5, 6, 7], [5, 6, 7]]`, and so on.\n",
    "\n",
    "    Each fold also provides information as to whether the Forecaster needs to \n",
    "    be trained or not.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas Series, pandas DataFrame\n",
    "        Time series values.\n",
    "    window_size : int\n",
    "        Size of the window needed to create the predictors.\n",
    "    initial_train_size : int, None\n",
    "        Size of the training set in the first fold. If `None` or 0, the initial\n",
    "        fold does not include a training set.\n",
    "    test_size : int\n",
    "        Size of the test set in each fold.\n",
    "    externally_fitted : bool, default `False`\n",
    "        Flag indicating whether the forecaster is already trained. Only used when \n",
    "        `initial_train_size` is None and `refit` is False.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    return_all_indexes : bool, default `False`\n",
    "        If `True`, return all the indexes included in each fold. If `False`, return\n",
    "        only the first and last index of each partition in each fold.\n",
    "    verbose : bool, default `True`\n",
    "        Print information if the folds created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    folds : list\n",
    "        List containing the indices (position) of `y` for training, test including\n",
    "        the gap, test excluding the gap for each fold, and whether fir the Forecaster.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    idx = range(len(data))\n",
    "    folds = []\n",
    "    i = 0\n",
    "    last_fold_excluded = False\n",
    "\n",
    "    while initial_train_size + (i * test_size) + gap < len(data):\n",
    "\n",
    "        if refit:\n",
    "            # If fixed_train_size the train size doesn't increase but moves by \n",
    "            # `test_size` positions in each iteration. If False, the train size\n",
    "            # increases by `test_size` in each iteration.\n",
    "            train_idx_start = i * (test_size) if fixed_train_size else 0\n",
    "            train_idx_end = initial_train_size + i * (test_size)\n",
    "            test_idx_start = train_idx_end\n",
    "        else:\n",
    "            # The train size doesn't increase and doesn't move.\n",
    "            train_idx_start = 0\n",
    "            train_idx_end = initial_train_size\n",
    "            test_idx_start = initial_train_size + i * (test_size)\n",
    "            \n",
    "        last_window_start = test_idx_start - window_size \n",
    "        test_idx_end = test_idx_start + gap + test_size\n",
    "    \n",
    "        partitions = [\n",
    "            idx[train_idx_start : train_idx_end],\n",
    "            idx[last_window_start : test_idx_start],\n",
    "            idx[test_idx_start : test_idx_end],\n",
    "            idx[test_idx_start + gap : test_idx_end]\n",
    "        ]\n",
    "        folds.append(partitions)\n",
    "        i += 1\n",
    "\n",
    "    if not allow_incomplete_fold:\n",
    "        if len(folds[-1][2]) < test_size:\n",
    "            folds = folds[:-1]\n",
    "            last_fold_excluded = True\n",
    "\n",
    "    # Replace partitions inside folds with length 0 with None\n",
    "    folds = [[partition if len(partition) > 0 else None \n",
    "              for partition in fold] \n",
    "             for fold in folds]\n",
    "\n",
    "    # Create a flag to know whether to train the forecaster\n",
    "    if refit == 0:\n",
    "        refit = False\n",
    "        \n",
    "    if isinstance(refit, bool):\n",
    "        fit_forecaster = [refit]*len(folds)\n",
    "        fit_forecaster[0] = True\n",
    "    else:\n",
    "        fit_forecaster = [False]*len(folds)\n",
    "        for i in range(0, len(fit_forecaster), refit): \n",
    "            fit_forecaster[i] = True\n",
    "    \n",
    "    for i in range(len(folds)): \n",
    "        folds[i].append(fit_forecaster[i])\n",
    "        if fit_forecaster[i] is False:\n",
    "            folds[i][0] = folds[i-1][0]\n",
    "\n",
    "    # This is done to allow parallelization. The first Forecaster fit is \n",
    "    # outside the auxiliary function.\n",
    "    fit_forecaster[0] = False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Information of backtesting process\")\n",
    "        print(\"----------------------------------\")\n",
    "        if externally_fitted:\n",
    "            print(f\"An already trained forecaster is to be used. Window size: {window_size}\")\n",
    "        else:\n",
    "            print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(data) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {len(folds)}\")\n",
    "        print(f\"    Number of steps per fold: {test_size}\")\n",
    "        print(f\"    Number of steps to exclude from the end of each train set before test (gap): {gap}\")\n",
    "        if last_fold_excluded:\n",
    "            print(\"    Last fold has been excluded because it was incomplete.\")\n",
    "        if len(folds[-1][3]) < test_size:\n",
    "            print(f\"    Last fold only includes {len(folds[-1][3])} observations.\")\n",
    "        print(\"\")\n",
    "\n",
    "        for i, fold in enumerate(folds):\n",
    "            training_start    = data.index[fold[0][0]] if fold[0] is not None else None\n",
    "            training_end      = data.index[fold[0][-1]] if fold[0] is not None else None\n",
    "            training_length   = len(fold[0]) if fold[0] is not None else 0\n",
    "            validation_start  = data.index[fold[3][0]]\n",
    "            validation_end    = data.index[fold[3][-1]]\n",
    "            validation_length = len(fold[3])\n",
    "            print(f\"Fold: {i}\")\n",
    "            if not externally_fitted:\n",
    "                print(\n",
    "                    f\"    Training:   {training_start} -- {training_end}  (n={training_length})\"\n",
    "                )\n",
    "            print(\n",
    "                f\"    Validation: {validation_start} -- {validation_end}  (n={validation_length})\"\n",
    "            )\n",
    "        print(\"\")\n",
    "\n",
    "    if not return_all_indexes:\n",
    "        # +1 to prevent iloc pandas from deleting the last observation\n",
    "        folds = [\n",
    "            [[fold[0][0], fold[0][-1]+1], \n",
    "             [fold[1][0], fold[1][-1]+1], \n",
    "             [fold[2][0], fold[2][-1]+1],\n",
    "             [fold[3][0], fold[3][-1]+1],\n",
    "             fold[4]] \n",
    "            for fold in folds\n",
    "        ]\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "\n",
    "y = pd.Series(np.arange(100))\n",
    "y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')\n",
    "initial_train_size = 50\n",
    "gap = 5\n",
    "test_size = 7\n",
    "refit = False\n",
    "allow_incomplete_fold = False\n",
    "\n",
    "folds = _create_backtesting_folds_2(\n",
    "            data                  = y,\n",
    "            window_size           = 5,\n",
    "            initial_train_size    = initial_train_size,\n",
    "            test_size             = test_size,\n",
    "            externally_fitted     = False,\n",
    "            refit                 = 2,\n",
    "            fixed_train_size      = False,\n",
    "            gap                   = gap,\n",
    "            allow_incomplete_fold = allow_incomplete_fold,\n",
    "            return_all_indexes    = False,\n",
    "            verbose               = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 50], [45, 50], [50, 62], [55, 62], True],\n",
       " [[0, 50], [52, 57], [57, 69], [62, 69], False],\n",
       " [[0, 64], [59, 64], [64, 76], [69, 76], True],\n",
       " [[0, 64], [66, 71], [71, 83], [76, 83], False],\n",
       " [[0, 78], [73, 78], [78, 90], [83, 90], True],\n",
       " [[0, 78], [80, 85], [85, 97], [90, 97], False],\n",
       " [[0, 92], [87, 92], [92, 100], [97, 100], True]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "refit = 0\n",
    "\n",
    "if refit:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 91], [70, 82], [75, 82], 1, True, False, True, True, True],\n",
       " [[0, 91], [77, 89], [82, 89], 1, True, False, False, False, False],\n",
       " [[0, 91], [84, 96], [89, 96], 1, True, False, True, False, False],\n",
       " [[0, 91], [91, 100], [96, 100], 1, True, False, False, True, False]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refit = 4\n",
    "\n",
    "if isinstance(refit, bool):\n",
    "    fit_forecaster = [refit]*len(folds)\n",
    "else:\n",
    "    fit_forecaster = [False]*len(folds)\n",
    "    for i in range(0, len(fit_forecaster), refit): fit_forecaster[i] = True\n",
    "\n",
    "for i in range(len(folds)): \n",
    "    folds[i].append(fit_forecaster[i])\n",
    "    if fit_forecaster[i] is False:\n",
    "        folds[i][0] = folds[i-1][0]\n",
    "\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace partitions inside folds with length 0 with None\n",
    "folds[0].append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [False, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0] = True\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "n_boot = -1\n",
    "\n",
    "if not isinstance(n_boot, (bool, int, np.integer)) or n_boot < 0:\n",
    "    print(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _backtesting_forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster\n",
    "\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import out_sample_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.27 ms ± 74 µs per loop (mean ± std. dev. of 4 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 200 -r 4\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    refit = True,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    steps               = 4,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    n_jobs              = 1,\n",
    "                                    verbose             = False,\n",
    "                                    show_progress = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.29 ms ± 60.9 µs per loop (mean ± std. dev. of 4 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 200 -r 4\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    refit = True,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    steps               = 4,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    n_jobs              = 1,\n",
    "                                    verbose             = False,\n",
    "                                    show_progress = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytest import approx\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster\n",
    "\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import out_sample_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.696469\n",
       "1    0.286139\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.120629\n",
       "1    0.826341\n",
       "Name: exog, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregDirect(\n",
    "                     regressor = LinearRegression(), \n",
    "                     lags      = 3,\n",
    "                     steps     = 8\n",
    "                 )\n",
    "\n",
    "forecaster.fit(y=y.iloc[:30], exog=exog.iloc[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    0.582731\n",
       "31    0.449588\n",
       "32    0.595278\n",
       "33    0.650230\n",
       "34    0.523646\n",
       "35    0.468093\n",
       "36    0.487597\n",
       "37    0.471724\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(exog=exog.iloc[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013159000000000032"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.595890 - 0.582731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33    0.650230\n",
       "34    0.523646\n",
       "35    0.468093\n",
       "36    0.487597\n",
       "37    0.471724\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(exog=exog.iloc[30:], steps=[4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663389"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.650230 + 0.013159000000000032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
       "        0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
       "        0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
       "        0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
       "        0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
       "        0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
       "        0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
       "        0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
       "        0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
       "        0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453,\n",
       "        0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
       "        0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
       "        0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
       "        0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
       "        0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
       "        0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
       "        0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
       "        0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
       "        0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
       "        0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]),\n",
       " '2': array([0.51312815, 0.66662455, 0.10590849, 0.13089495, 0.32198061,\n",
       "        0.66156434, 0.84650623, 0.55325734, 0.85445249, 0.38483781,\n",
       "        0.3167879 , 0.35426468, 0.17108183, 0.82911263, 0.33867085,\n",
       "        0.55237008, 0.57855147, 0.52153306, 0.00268806, 0.98834542,\n",
       "        0.90534158, 0.20763586, 0.29248941, 0.52001015, 0.90191137,\n",
       "        0.98363088, 0.25754206, 0.56435904, 0.80696868, 0.39437005,\n",
       "        0.73107304, 0.16106901, 0.60069857, 0.86586446, 0.98352161,\n",
       "        0.07936579, 0.42834727, 0.20454286, 0.45063649, 0.54776357,\n",
       "        0.09332671, 0.29686078, 0.92758424, 0.56900373, 0.457412  ,\n",
       "        0.75352599, 0.74186215, 0.04857903, 0.7086974 , 0.83924335,\n",
       "        0.16593788, 0.78099794, 0.28653662, 0.30646975, 0.66526147,\n",
       "        0.11139217, 0.66487245, 0.88785679, 0.69631127, 0.44032788,\n",
       "        0.43821438, 0.7650961 , 0.565642  , 0.08490416, 0.58267109,\n",
       "        0.8148437 , 0.33706638, 0.92757658, 0.750717  , 0.57406383,\n",
       "        0.75164399, 0.07914896, 0.85938908, 0.82150411, 0.90987166,\n",
       "        0.1286312 , 0.08178009, 0.13841557, 0.39937871, 0.42430686,\n",
       "        0.56221838, 0.12224355, 0.2013995 , 0.81164435, 0.46798757,\n",
       "        0.80793821, 0.00742638, 0.55159273, 0.93193215, 0.58217546,\n",
       "        0.20609573, 0.71775756, 0.37898585, 0.66838395, 0.02931972,\n",
       "        0.63590036, 0.03219793, 0.74478066, 0.472913  , 0.12175436]),\n",
       " '3': array([0.54263593, 0.06677444, 0.65336487, 0.99608633, 0.76939734,\n",
       "        0.57377411, 0.10263526, 0.69983407, 0.66116787, 0.04909713,\n",
       "        0.7922993 , 0.51871659, 0.42586769, 0.78818717, 0.41156922,\n",
       "        0.48102628, 0.18162884, 0.3213189 , 0.845533  , 0.18690375,\n",
       "        0.41729106, 0.98903451, 0.23659981, 0.91683233, 0.91839747,\n",
       "        0.09129634, 0.46365272, 0.50221634, 0.31366895, 0.04733954,\n",
       "        0.24168564, 0.09552964, 0.23824991, 0.80779109, 0.89497829,\n",
       "        0.04322289, 0.30194684, 0.9805822 , 0.53950482, 0.62630936,\n",
       "        0.00554541, 0.48490944, 0.98832853, 0.37518553, 0.09703816,\n",
       "        0.46190876, 0.96300447, 0.34183061, 0.79892273, 0.79884633,\n",
       "        0.2082483 , 0.4433677 , 0.71560128, 0.41051979, 0.19100696,\n",
       "        0.96749431, 0.65075037, 0.86545985, 0.02524236, 0.26690581,\n",
       "        0.5020711 , 0.06744864, 0.99303326, 0.2364624 , 0.37429218,\n",
       "        0.21401191, 0.10544587, 0.23247979, 0.30061014, 0.63444227,\n",
       "        0.28123478, 0.36227676, 0.00594284, 0.36571913, 0.53388598,\n",
       "        0.16201584, 0.59743311, 0.29315247, 0.63205049, 0.02619661,\n",
       "        0.88759346, 0.01611863, 0.12695803, 0.77716246, 0.04589523,\n",
       "        0.71099869, 0.97104614, 0.87168293, 0.71016165, 0.95850974,\n",
       "        0.42981334, 0.87287891, 0.35595767, 0.92976365, 0.14877766,\n",
       "        0.94002901, 0.8327162 , 0.84605484, 0.12392301, 0.5964869 ])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "d = {'1': np.random.rand(100), '2': np.random.rand(100), '3': np.random.rand(100)}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28613933 0.19422296 0.51042234 0.42310646 0.70495883]\n",
      "[0.29248941 0.98363088 0.00268806 0.86586446 0.52153306]\n",
      "[0.89497829 0.01611863 0.46190876 0.35595767 0.09703816]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=123)\n",
    "sample_residuals = rng.choice(\n",
    "                        a       = d['1'],\n",
    "                        size    = 5,\n",
    "                        replace = True\n",
    "                    )\n",
    "print(sample_residuals)\n",
    "sample_residuals = rng.choice(\n",
    "                        a       = d['2'],\n",
    "                        size    = 5,\n",
    "                        replace = True\n",
    "                    )\n",
    "print(sample_residuals)\n",
    "sample_residuals = rng.choice(\n",
    "                        a       = d['3'],\n",
    "                        size    = 5,\n",
    "                        replace = True\n",
    "                    )\n",
    "print(sample_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66662455 0.750717   0.44032788 0.66156434 0.20609573]\n",
      "[0.06677444 0.30061014 0.26690581 0.57377411 0.42981334]\n"
     ]
    }
   ],
   "source": [
    "for step in ['2', '3']:\n",
    "    rng = np.random.default_rng(seed=123)\n",
    "    sample_residuals = rng.choice(\n",
    "                            a       = d[step],\n",
    "                            size    = 5,\n",
    "                            replace = True\n",
    "                        )\n",
    "    print(sample_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28613933 0.19422296 0.51042234 0.42310646 0.70495883]\n",
      "[0.66662455 0.750717   0.44032788 0.66156434 0.20609573]\n",
      "[0.06677444 0.30061014 0.26690581 0.57377411 0.42981334]\n"
     ]
    }
   ],
   "source": [
    "for step in ['1', '2', '3']:\n",
    "    rng = np.random.default_rng(seed=123)\n",
    "    sample_residuals = rng.choice(\n",
    "                            a       = d[step],\n",
    "                            size    = 5,\n",
    "                            replace = True\n",
    "                        )\n",
    "    print(sample_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_boot_0</th>\n",
       "      <th>pred_boot_1</th>\n",
       "      <th>pred_boot_2</th>\n",
       "      <th>pred_boot_3</th>\n",
       "      <th>pred_boot_4</th>\n",
       "      <th>pred_boot_5</th>\n",
       "      <th>pred_boot_6</th>\n",
       "      <th>pred_boot_7</th>\n",
       "      <th>pred_boot_8</th>\n",
       "      <th>pred_boot_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_boot_490</th>\n",
       "      <th>pred_boot_491</th>\n",
       "      <th>pred_boot_492</th>\n",
       "      <th>pred_boot_493</th>\n",
       "      <th>pred_boot_494</th>\n",
       "      <th>pred_boot_495</th>\n",
       "      <th>pred_boot_496</th>\n",
       "      <th>pred_boot_497</th>\n",
       "      <th>pred_boot_498</th>\n",
       "      <th>pred_boot_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.595890</td>\n",
       "      <td>0.319955</td>\n",
       "      <td>0.594976</td>\n",
       "      <td>0.719428</td>\n",
       "      <td>0.929964</td>\n",
       "      <td>0.505866</td>\n",
       "      <td>0.682543</td>\n",
       "      <td>1.074957</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>1.074957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505866</td>\n",
       "      <td>0.594976</td>\n",
       "      <td>0.594976</td>\n",
       "      <td>0.834912</td>\n",
       "      <td>0.682543</td>\n",
       "      <td>0.719428</td>\n",
       "      <td>0.337421</td>\n",
       "      <td>0.682543</td>\n",
       "      <td>0.693378</td>\n",
       "      <td>0.403944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.286934</td>\n",
       "      <td>0.286934</td>\n",
       "      <td>0.661122</td>\n",
       "      <td>0.458739</td>\n",
       "      <td>0.536715</td>\n",
       "      <td>0.060349</td>\n",
       "      <td>0.804013</td>\n",
       "      <td>0.578588</td>\n",
       "      <td>0.124023</td>\n",
       "      <td>0.286934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060349</td>\n",
       "      <td>0.536715</td>\n",
       "      <td>0.571531</td>\n",
       "      <td>0.629584</td>\n",
       "      <td>0.229138</td>\n",
       "      <td>0.522168</td>\n",
       "      <td>0.551815</td>\n",
       "      <td>0.571531</td>\n",
       "      <td>0.522168</td>\n",
       "      <td>0.522168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.917457</td>\n",
       "      <td>0.990094</td>\n",
       "      <td>0.672651</td>\n",
       "      <td>0.917457</td>\n",
       "      <td>0.618155</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.617088</td>\n",
       "      <td>0.439513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766426</td>\n",
       "      <td>0.423266</td>\n",
       "      <td>0.696094</td>\n",
       "      <td>0.439513</td>\n",
       "      <td>0.917457</td>\n",
       "      <td>0.181711</td>\n",
       "      <td>0.563551</td>\n",
       "      <td>0.181711</td>\n",
       "      <td>0.181711</td>\n",
       "      <td>0.688873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.591729</td>\n",
       "      <td>0.727680</td>\n",
       "      <td>0.735237</td>\n",
       "      <td>0.778007</td>\n",
       "      <td>0.521545</td>\n",
       "      <td>0.730467</td>\n",
       "      <td>0.725167</td>\n",
       "      <td>0.552930</td>\n",
       "      <td>0.392279</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591729</td>\n",
       "      <td>0.392279</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.248801</td>\n",
       "      <td>0.728662</td>\n",
       "      <td>0.565366</td>\n",
       "      <td>1.065039</td>\n",
       "      <td>0.565366</td>\n",
       "      <td>0.521545</td>\n",
       "      <td>0.464614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.440248</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.652858</td>\n",
       "      <td>0.444009</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>0.450979</td>\n",
       "      <td>0.923044</td>\n",
       "      <td>0.416877</td>\n",
       "      <td>0.440248</td>\n",
       "      <td>0.645430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>0.535159</td>\n",
       "      <td>0.450979</td>\n",
       "      <td>0.522948</td>\n",
       "      <td>0.416528</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>0.568009</td>\n",
       "      <td>0.450979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.398310</td>\n",
       "      <td>0.215374</td>\n",
       "      <td>0.402093</td>\n",
       "      <td>0.753951</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>0.885939</td>\n",
       "      <td>0.398310</td>\n",
       "      <td>0.402093</td>\n",
       "      <td>0.488850</td>\n",
       "      <td>0.398310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426543</td>\n",
       "      <td>0.591517</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>0.478034</td>\n",
       "      <td>0.478034</td>\n",
       "      <td>0.885939</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.398310</td>\n",
       "      <td>0.885939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.831451</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.299214</td>\n",
       "      <td>0.522564</td>\n",
       "      <td>0.280663</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863003</td>\n",
       "      <td>0.511131</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.421932</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.357115</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.644121</td>\n",
       "      <td>0.280663</td>\n",
       "      <td>0.587898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.548837</td>\n",
       "      <td>0.675221</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>0.653531</td>\n",
       "      <td>0.374671</td>\n",
       "      <td>0.268488</td>\n",
       "      <td>0.351567</td>\n",
       "      <td>0.675221</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746976</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.675221</td>\n",
       "      <td>0.543662</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.351567</td>\n",
       "      <td>0.263568</td>\n",
       "      <td>0.367503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_boot_0  pred_boot_1  pred_boot_2  pred_boot_3  pred_boot_4  \\\n",
       "30     0.595890     0.319955     0.594976     0.719428     0.929964   \n",
       "31     0.286934     0.286934     0.661122     0.458739     0.536715   \n",
       "32     0.688873     0.722722     0.917457     0.990094     0.672651   \n",
       "33     0.591729     0.727680     0.735237     0.778007     0.521545   \n",
       "34     0.440248     0.239002     0.652858     0.444009     0.654075   \n",
       "35     0.398310     0.215374     0.402093     0.753951     0.300307   \n",
       "36     0.831451     0.513211     0.299214     0.522564     0.280663   \n",
       "37     0.145334     0.548837     0.675221     0.710396     0.653531   \n",
       "\n",
       "    pred_boot_5  pred_boot_6  pred_boot_7  pred_boot_8  pred_boot_9  ...  \\\n",
       "30     0.505866     0.682543     1.074957     0.337421     1.074957  ...   \n",
       "31     0.060349     0.804013     0.578588     0.124023     0.286934  ...   \n",
       "32     0.917457     0.618155     0.722722     0.617088     0.439513  ...   \n",
       "33     0.730467     0.725167     0.552930     0.392279     0.997500  ...   \n",
       "34     0.450979     0.923044     0.416877     0.440248     0.645430  ...   \n",
       "35     0.885939     0.398310     0.402093     0.488850     0.398310  ...   \n",
       "36     0.513211     0.750249     0.513211     0.587898     0.240795  ...   \n",
       "37     0.374671     0.268488     0.351567     0.675221     0.145334  ...   \n",
       "\n",
       "    pred_boot_490  pred_boot_491  pred_boot_492  pred_boot_493  pred_boot_494  \\\n",
       "30       0.505866       0.594976       0.594976       0.834912       0.682543   \n",
       "31       0.060349       0.536715       0.571531       0.629584       0.229138   \n",
       "32       0.766426       0.423266       0.696094       0.439513       0.917457   \n",
       "33       0.591729       0.392279       0.997500       0.248801       0.728662   \n",
       "34       0.239002       0.194533       0.654075       0.535159       0.450979   \n",
       "35       0.426543       0.591517       0.644463       0.300307       0.478034   \n",
       "36       0.863003       0.511131       0.240795       0.421932       0.513211   \n",
       "37       0.746976       0.263568       0.145334       0.675221       0.543662   \n",
       "\n",
       "    pred_boot_495  pred_boot_496  pred_boot_497  pred_boot_498  pred_boot_499  \n",
       "30       0.719428       0.337421       0.682543       0.693378       0.403944  \n",
       "31       0.522168       0.551815       0.571531       0.522168       0.522168  \n",
       "32       0.181711       0.563551       0.181711       0.181711       0.688873  \n",
       "33       0.565366       1.065039       0.565366       0.521545       0.464614  \n",
       "34       0.522948       0.416528       0.654075       0.568009       0.450979  \n",
       "35       0.478034       0.885939       0.644463       0.398310       0.885939  \n",
       "36       0.357115       0.587898       0.644121       0.280663       0.587898  \n",
       "37       0.710396       0.145334       0.351567       0.263568       0.367503  \n",
       "\n",
       "[8 rows x 500 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict_bootstrapping(exog=exog.iloc[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_boot_0</th>\n",
       "      <th>pred_boot_1</th>\n",
       "      <th>pred_boot_2</th>\n",
       "      <th>pred_boot_3</th>\n",
       "      <th>pred_boot_4</th>\n",
       "      <th>pred_boot_5</th>\n",
       "      <th>pred_boot_6</th>\n",
       "      <th>pred_boot_7</th>\n",
       "      <th>pred_boot_8</th>\n",
       "      <th>pred_boot_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_boot_490</th>\n",
       "      <th>pred_boot_491</th>\n",
       "      <th>pred_boot_492</th>\n",
       "      <th>pred_boot_493</th>\n",
       "      <th>pred_boot_494</th>\n",
       "      <th>pred_boot_495</th>\n",
       "      <th>pred_boot_496</th>\n",
       "      <th>pred_boot_497</th>\n",
       "      <th>pred_boot_498</th>\n",
       "      <th>pred_boot_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.065039</td>\n",
       "      <td>0.565366</td>\n",
       "      <td>0.271832</td>\n",
       "      <td>0.730467</td>\n",
       "      <td>0.778007</td>\n",
       "      <td>0.536698</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.591729</td>\n",
       "      <td>0.735237</td>\n",
       "      <td>0.591729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536698</td>\n",
       "      <td>0.271832</td>\n",
       "      <td>0.271832</td>\n",
       "      <td>0.552930</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.730467</td>\n",
       "      <td>0.735237</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.521545</td>\n",
       "      <td>0.248801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.416877</td>\n",
       "      <td>0.652858</td>\n",
       "      <td>0.450979</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>0.522948</td>\n",
       "      <td>0.568009</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.450979</td>\n",
       "      <td>0.535159</td>\n",
       "      <td>0.473526</td>\n",
       "      <td>0.645430</td>\n",
       "      <td>0.923044</td>\n",
       "      <td>0.444009</td>\n",
       "      <td>0.535159</td>\n",
       "      <td>0.923044</td>\n",
       "      <td>0.923044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.501507</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>0.591517</td>\n",
       "      <td>0.332730</td>\n",
       "      <td>0.406936</td>\n",
       "      <td>0.591517</td>\n",
       "      <td>0.644463</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>0.753951</td>\n",
       "      <td>0.645406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488850</td>\n",
       "      <td>0.398310</td>\n",
       "      <td>0.426543</td>\n",
       "      <td>0.645406</td>\n",
       "      <td>0.591517</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.402093</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.501507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.466250</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.831451</td>\n",
       "      <td>0.280663</td>\n",
       "      <td>0.421932</td>\n",
       "      <td>0.357115</td>\n",
       "      <td>0.528976</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.511131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466250</td>\n",
       "      <td>0.513211</td>\n",
       "      <td>0.511131</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>0.369764</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>0.421932</td>\n",
       "      <td>0.863003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.351567</td>\n",
       "      <td>0.543148</td>\n",
       "      <td>0.374671</td>\n",
       "      <td>0.017550</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.807425</td>\n",
       "      <td>0.548837</td>\n",
       "      <td>0.376153</td>\n",
       "      <td>0.351567</td>\n",
       "      <td>0.746976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543148</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.675221</td>\n",
       "      <td>0.807425</td>\n",
       "      <td>0.268488</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.464328</td>\n",
       "      <td>0.807425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_boot_0  pred_boot_1  pred_boot_2  pred_boot_3  pred_boot_4  \\\n",
       "33     1.065039     0.565366     0.271832     0.730467     0.778007   \n",
       "34     0.194533     0.194533     0.416877     0.652858     0.450979   \n",
       "35     0.501507     0.300307     0.591517     0.332730     0.406936   \n",
       "36     0.466250     0.335404     0.831451     0.280663     0.421932   \n",
       "37     0.351567     0.543148     0.374671     0.017550     0.145334   \n",
       "\n",
       "    pred_boot_5  pred_boot_6  pred_boot_7  pred_boot_8  pred_boot_9  ...  \\\n",
       "33     0.536698     0.997500     0.591729     0.735237     0.591729  ...   \n",
       "34     0.239002     0.654075     0.522948     0.568009     0.194533  ...   \n",
       "35     0.591517     0.644463     0.300307     0.753951     0.645406  ...   \n",
       "36     0.357115     0.528976     0.121076     0.513211     0.511131  ...   \n",
       "37     0.807425     0.548837     0.376153     0.351567     0.746976  ...   \n",
       "\n",
       "    pred_boot_490  pred_boot_491  pred_boot_492  pred_boot_493  pred_boot_494  \\\n",
       "33       0.536698       0.271832       0.271832       0.552930       0.997500   \n",
       "34       0.239002       0.450979       0.535159       0.473526       0.645430   \n",
       "35       0.488850       0.398310       0.426543       0.645406       0.591517   \n",
       "36       0.466250       0.513211       0.511131       0.240795       0.587898   \n",
       "37       0.543148       0.586538       0.145334       0.675221       0.807425   \n",
       "\n",
       "    pred_boot_495  pred_boot_496  pred_boot_497  pred_boot_498  pred_boot_499  \n",
       "33       0.730467       0.735237       0.997500       0.521545       0.248801  \n",
       "34       0.923044       0.444009       0.535159       0.923044       0.923044  \n",
       "35       0.124407       0.402093       0.124407       0.124407       0.501507  \n",
       "36       0.750249       0.369764       0.750249       0.421932       0.863003  \n",
       "37       0.268488       0.710396       0.145334       0.464328       0.807425  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict_bootstrapping(steps=[4,5,6,7,8], exog=exog.iloc[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`exog` must have at least as many values as the distance to the maximum step predicted, 5.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forecaster\u001b[39m.\u001b[39;49mpredict(steps\u001b[39m=\u001b[39;49m[\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m], exog\u001b[39m=\u001b[39;49mexog\u001b[39m.\u001b[39;49miloc[\u001b[39m22\u001b[39;49m:\u001b[39m25\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregDirect\\ForecasterAutoregDirect.py:711\u001b[0m, in \u001b[0;36mForecasterAutoregDirect.predict\u001b[1;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m last_window \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     last_window \u001b[39m=\u001b[39m copy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_window)\n\u001b[1;32m--> 711\u001b[0m check_predict_input(\n\u001b[0;32m    712\u001b[0m     forecaster_name  \u001b[39m=\u001b[39;49m \u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    713\u001b[0m     steps            \u001b[39m=\u001b[39;49m steps,\n\u001b[0;32m    714\u001b[0m     fitted           \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitted,\n\u001b[0;32m    715\u001b[0m     included_exog    \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mincluded_exog,\n\u001b[0;32m    716\u001b[0m     index_type       \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_type,\n\u001b[0;32m    717\u001b[0m     index_freq       \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_freq,\n\u001b[0;32m    718\u001b[0m     window_size      \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow_size,\n\u001b[0;32m    719\u001b[0m     last_window      \u001b[39m=\u001b[39;49m last_window,\n\u001b[0;32m    720\u001b[0m     last_window_exog \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    721\u001b[0m     exog             \u001b[39m=\u001b[39;49m exog,\n\u001b[0;32m    722\u001b[0m     exog_type        \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexog_type,\n\u001b[0;32m    723\u001b[0m     exog_col_names   \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexog_col_names,\n\u001b[0;32m    724\u001b[0m     interval         \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    725\u001b[0m     alpha            \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    726\u001b[0m     max_steps        \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msteps,\n\u001b[0;32m    727\u001b[0m     levels           \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    728\u001b[0m     series_col_names \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    729\u001b[0m ) \n\u001b[0;32m    731\u001b[0m \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exog, pd\u001b[39m.\u001b[39mDataFrame):\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:646\u001b[0m, in \u001b[0;36mcheck_predict_input\u001b[1;34m(forecaster_name, steps, fitted, included_exog, index_type, index_freq, window_size, last_window, last_window_exog, exog, exog_type, exog_col_names, interval, alpha, max_steps, levels, series_col_names)\u001b[0m\n\u001b[0;32m    644\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(steps) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(steps, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m steps\n\u001b[0;32m    645\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(exog) \u001b[39m<\u001b[39m last_step:\n\u001b[1;32m--> 646\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    647\u001b[0m         (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`exog` must have at least as many values as the distance to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe maximum step predicted, \u001b[39m\u001b[39m{\u001b[39;00mlast_step\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    649\u001b[0m     )\n\u001b[0;32m    651\u001b[0m \u001b[39m# Check all columns are in the pandas DataFrame\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exog, pd\u001b[39m.\u001b[39mDataFrame):\n",
      "\u001b[1;31mValueError\u001b[0m: `exog` must have at least as many values as the distance to the maximum step predicted, 5."
     ]
    }
   ],
   "source": [
    "forecaster.predict(steps=[3,4,5], exog=exog.iloc[22:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregDirect(\n",
    "                    regressor = LinearRegression(), \n",
    "                    lags      = 3,\n",
    "                    steps     = 8\n",
    "                )\n",
    "\n",
    "n_backtest = 20\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    y                     = y,\n",
    "                                    exog                  = exog,\n",
    "                                    refit                 = False,\n",
    "                                    initial_train_size    = len(y_train),\n",
    "                                    gap                   = 3,\n",
    "                                    allow_incomplete_fold = True,\n",
    "                                    steps                 = 5,\n",
    "                                    metric                = 'mean_squared_error',\n",
    "                                    interval              = [5, 95],\n",
    "                                    n_boot                = 500,\n",
    "                                    random_state          = 123,\n",
    "                                    in_sample_residuals   = True,\n",
    "                                    verbose               = False,\n",
    "                                    show_progress=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.650230</td>\n",
       "      <td>0.271832</td>\n",
       "      <td>1.065039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.523646</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.882655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.468093</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.753951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.487597</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.863003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.145334</td>\n",
       "      <td>0.807425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.575858</td>\n",
       "      <td>0.197460</td>\n",
       "      <td>0.990668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.535929</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.894938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.489951</td>\n",
       "      <td>0.146265</td>\n",
       "      <td>0.775809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.452713</td>\n",
       "      <td>0.205911</td>\n",
       "      <td>0.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.495194</td>\n",
       "      <td>0.168803</td>\n",
       "      <td>0.830894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.271678</td>\n",
       "      <td>-0.106720</td>\n",
       "      <td>0.686487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.278138</td>\n",
       "      <td>-0.050975</td>\n",
       "      <td>0.637146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.315694</td>\n",
       "      <td>-0.027992</td>\n",
       "      <td>0.601552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.398322</td>\n",
       "      <td>0.151521</td>\n",
       "      <td>0.773728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.348227</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.683927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.620987</td>\n",
       "      <td>0.242588</td>\n",
       "      <td>1.035796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.471908</td>\n",
       "      <td>0.142794</td>\n",
       "      <td>0.830916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred  lower_bound  upper_bound\n",
       "33  0.650230     0.271832     1.065039\n",
       "34  0.523646     0.194533     0.882655\n",
       "35  0.468093     0.124407     0.753951\n",
       "36  0.487597     0.240795     0.863003\n",
       "37  0.471724     0.145334     0.807425\n",
       "38  0.575858     0.197460     0.990668\n",
       "39  0.535929     0.206816     0.894938\n",
       "40  0.489951     0.146265     0.775809\n",
       "41  0.452713     0.205911     0.828119\n",
       "42  0.495194     0.168803     0.830894\n",
       "43  0.271678    -0.106720     0.686487\n",
       "44  0.278138    -0.050975     0.637146\n",
       "45  0.315694    -0.027992     0.601552\n",
       "46  0.398322     0.151521     0.773728\n",
       "47  0.348227     0.021836     0.683927\n",
       "48  0.620987     0.242588     1.035796\n",
       "49  0.471908     0.142794     0.830916"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.582731</td>\n",
       "      <td>0.274546</td>\n",
       "      <td>0.929964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.449588</td>\n",
       "      <td>0.124023</td>\n",
       "      <td>0.804013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.595278</td>\n",
       "      <td>0.181711</td>\n",
       "      <td>0.990094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.650230</td>\n",
       "      <td>0.248801</td>\n",
       "      <td>1.065039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.523646</td>\n",
       "      <td>0.194533</td>\n",
       "      <td>0.923044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.468093</td>\n",
       "      <td>0.124407</td>\n",
       "      <td>0.885939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.487597</td>\n",
       "      <td>0.240795</td>\n",
       "      <td>0.863003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.138944</td>\n",
       "      <td>0.746976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.411027</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>0.758259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.567017</td>\n",
       "      <td>0.241452</td>\n",
       "      <td>0.921442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.610505</td>\n",
       "      <td>0.196939</td>\n",
       "      <td>1.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.575858</td>\n",
       "      <td>0.174429</td>\n",
       "      <td>0.990668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.535929</td>\n",
       "      <td>0.206816</td>\n",
       "      <td>0.935327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.489951</td>\n",
       "      <td>0.146265</td>\n",
       "      <td>0.907798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.452713</td>\n",
       "      <td>0.205911</td>\n",
       "      <td>0.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.495194</td>\n",
       "      <td>0.162414</td>\n",
       "      <td>0.770445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.512586</td>\n",
       "      <td>0.204401</td>\n",
       "      <td>0.859819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.589528</td>\n",
       "      <td>0.263963</td>\n",
       "      <td>0.943953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.489534</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.884351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.271678</td>\n",
       "      <td>-0.129751</td>\n",
       "      <td>0.686487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.278138</td>\n",
       "      <td>-0.050975</td>\n",
       "      <td>0.677536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.315694</td>\n",
       "      <td>-0.027992</td>\n",
       "      <td>0.733541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.398322</td>\n",
       "      <td>0.151521</td>\n",
       "      <td>0.773728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.348227</td>\n",
       "      <td>0.015447</td>\n",
       "      <td>0.623478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.588244</td>\n",
       "      <td>0.280059</td>\n",
       "      <td>0.935477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.498263</td>\n",
       "      <td>0.172698</td>\n",
       "      <td>0.852687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.646064</td>\n",
       "      <td>0.232497</td>\n",
       "      <td>1.040881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.620987</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>1.035796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.471908</td>\n",
       "      <td>0.142794</td>\n",
       "      <td>0.871305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred  lower_bound  upper_bound\n",
       "30  0.582731     0.274546     0.929964\n",
       "31  0.449588     0.124023     0.804013\n",
       "32  0.595278     0.181711     0.990094\n",
       "33  0.650230     0.248801     1.065039\n",
       "34  0.523646     0.194533     0.923044\n",
       "35  0.468093     0.124407     0.885939\n",
       "36  0.487597     0.240795     0.863003\n",
       "37  0.471724     0.138944     0.746976\n",
       "35  0.411027     0.102842     0.758259\n",
       "36  0.567017     0.241452     0.921442\n",
       "37  0.610505     0.196939     1.005322\n",
       "38  0.575858     0.174429     0.990668\n",
       "39  0.535929     0.206816     0.935327\n",
       "40  0.489951     0.146265     0.907798\n",
       "41  0.452713     0.205911     0.828119\n",
       "42  0.495194     0.162414     0.770445\n",
       "40  0.512586     0.204401     0.859819\n",
       "41  0.589528     0.263963     0.943953\n",
       "42  0.489534     0.075968     0.884351\n",
       "43  0.271678    -0.129751     0.686487\n",
       "44  0.278138    -0.050975     0.677536\n",
       "45  0.315694    -0.027992     0.733541\n",
       "46  0.398322     0.151521     0.773728\n",
       "47  0.348227     0.015447     0.623478\n",
       "45  0.588244     0.280059     0.935477\n",
       "46  0.498263     0.172698     0.852687\n",
       "47  0.646064     0.232497     1.040881\n",
       "48  0.620987     0.219558     1.035796\n",
       "49  0.471908     0.142794     0.871305"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20387a1f2e645b7af8394c563bafca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\model_selection\\model_selection.py:525: LongTrainingWarning: The forecaster will be fit 72.0 times (9.0 folds * 8 regressors). This can take substantial amounts of time. If not feasible, try with `refit = False`.\n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregDirect(\n",
    "                     regressor = Ridge(random_state=123), \n",
    "                     lags      = 3,\n",
    "                     steps     = 8\n",
    "                 )\n",
    "\n",
    "n_backtest = 35\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = backtesting_forecaster(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    y                     = y,\n",
    "                                    exog                  = exog,\n",
    "                                    refit                 = 2,\n",
    "                                    initial_train_size    = len(y_train),\n",
    "                                    fixed_train_size      = False,\n",
    "                                    gap                   = 0,\n",
    "                                    allow_incomplete_fold = True,\n",
    "                                    steps                 = 2,\n",
    "                                    metric                = 'mean_squared_error',\n",
    "                                    interval              = [5, 95],\n",
    "                                    n_boot                = 500,\n",
    "                                    random_state          = 123,\n",
    "                                    in_sample_residuals   = True,\n",
    "                                    verbose               = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06099110404144631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55616986, 0.15288789, 0.89198752],\n",
       "       [0.48751797, 0.14866438, 0.83169303],\n",
       "       [0.57764391, 0.17436194, 0.91346157],\n",
       "       [0.51298667, 0.17413308, 0.85716173],\n",
       "       [0.47430051, 0.0796644 , 0.82587748],\n",
       "       [0.49192271, 0.14609696, 0.95959395],\n",
       "       [0.52213783, 0.12750172, 0.8737148 ],\n",
       "       [0.54492575, 0.1991    , 1.012597  ],\n",
       "       [0.52501537, 0.13641764, 0.86685356],\n",
       "       [0.4680474 , 0.08515461, 0.81792677],\n",
       "       [0.51059498, 0.12199725, 0.85243317],\n",
       "       [0.53067132, 0.14777853, 0.88055069],\n",
       "       [0.4430938 , 0.0509291 , 0.69854202],\n",
       "       [0.49911716, 0.1231365 , 0.8711497 ],\n",
       "       [0.44546347, 0.05329877, 0.70091169],\n",
       "       [0.46530749, 0.08932683, 0.83734003],\n",
       "       [0.46901878, 0.08173407, 0.82098555],\n",
       "       [0.55371362, 0.14618224, 0.98199137],\n",
       "       [0.60759064, 0.22030593, 0.9595574 ],\n",
       "       [0.50415336, 0.09662198, 0.93243111]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_with_index \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m y_with_index\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mdate_range(start\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2022-01-01\u001b[39m\u001b[39m'\u001b[39m, periods\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m exog_with_index \u001b[39m=\u001b[39m exog\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y_with_index = y.copy()\n",
    "y_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "exog_with_index = exog.copy()\n",
    "exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=Ridge(random_state=123), lags=3)\n",
    "\n",
    "metric, backtest_predictions = backtesting_forecaster(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    y                     = y_with_index,\n",
    "                                    exog                  = exog_with_index,\n",
    "                                    refit                 = 3,\n",
    "                                    initial_train_size    = len(y_with_index) - 20,\n",
    "                                    fixed_train_size      = True,\n",
    "                                    gap                   = 3,\n",
    "                                    allow_incomplete_fold = False,\n",
    "                                    steps                 = 4,\n",
    "                                    metric                = 'mean_squared_error',\n",
    "                                    interval              = [5, 95],\n",
    "                                    n_boot                = 500,\n",
    "                                    random_state          = 123,\n",
    "                                    in_sample_residuals   = True,\n",
    "                                    verbose               = True,\n",
    "                                    n_jobs                = 1\n",
    "                                )\n",
    "backtest_predictions = backtest_predictions.asfreq('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060991643719298785"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y=y_with_index.iloc[:30], exog=exog_with_index[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-03    0.518786\n",
       "2022-02-04    0.492698\n",
       "2022-02-05    0.493804\n",
       "2022-02-06    0.514675\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, exog=exog_with_index.iloc[30:37]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-07    0.526900\n",
       "2022-02-08    0.517320\n",
       "2022-02-09    0.512903\n",
       "2022-02-10    0.503343\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, last_window=y_with_index.iloc[:34], \n",
    "                   exog=exog_with_index.iloc[34:42]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-11    0.501715\n",
       "2022-02-12    0.509469\n",
       "2022-02-13    0.502004\n",
       "2022-02-14    0.504360\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, last_window=y_with_index.iloc[:38], \n",
    "                   exog=exog_with_index.iloc[38:45]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-15    0.453419\n",
       "2022-02-16    0.526217\n",
       "2022-02-17    0.504778\n",
       "2022-02-18    0.522353\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.fit(y=y_with_index.iloc[12:42], exog=exog_with_index[12:42])\n",
    "forecaster.predict(7, exog=exog_with_index.iloc[42:49]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>0.518786</td>\n",
       "      <td>0.173240</td>\n",
       "      <td>0.877714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>0.492698</td>\n",
       "      <td>0.152233</td>\n",
       "      <td>0.868473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-05</th>\n",
       "      <td>0.493804</td>\n",
       "      <td>0.140035</td>\n",
       "      <td>0.812267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-06</th>\n",
       "      <td>0.514675</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.915069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>0.526900</td>\n",
       "      <td>0.181354</td>\n",
       "      <td>0.885829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>0.517320</td>\n",
       "      <td>0.176855</td>\n",
       "      <td>0.893095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>0.512903</td>\n",
       "      <td>0.159134</td>\n",
       "      <td>0.831365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-10</th>\n",
       "      <td>0.503343</td>\n",
       "      <td>0.170928</td>\n",
       "      <td>0.903737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>0.501715</td>\n",
       "      <td>0.156169</td>\n",
       "      <td>0.860643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12</th>\n",
       "      <td>0.509469</td>\n",
       "      <td>0.169004</td>\n",
       "      <td>0.885245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-13</th>\n",
       "      <td>0.502004</td>\n",
       "      <td>0.148234</td>\n",
       "      <td>0.820466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>0.504360</td>\n",
       "      <td>0.171945</td>\n",
       "      <td>0.904754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-15</th>\n",
       "      <td>0.453419</td>\n",
       "      <td>0.093209</td>\n",
       "      <td>0.835611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16</th>\n",
       "      <td>0.526217</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>0.911330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17</th>\n",
       "      <td>0.504778</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.887501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-18</th>\n",
       "      <td>0.522353</td>\n",
       "      <td>0.170076</td>\n",
       "      <td>0.911283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  lower_bound  upper_bound\n",
       "2022-02-03  0.518786     0.173240     0.877714\n",
       "2022-02-04  0.492698     0.152233     0.868473\n",
       "2022-02-05  0.493804     0.140035     0.812267\n",
       "2022-02-06  0.514675     0.182259     0.915069\n",
       "2022-02-07  0.526900     0.181354     0.885829\n",
       "2022-02-08  0.517320     0.176855     0.893095\n",
       "2022-02-09  0.512903     0.159134     0.831365\n",
       "2022-02-10  0.503343     0.170928     0.903737\n",
       "2022-02-11  0.501715     0.156169     0.860643\n",
       "2022-02-12  0.509469     0.169004     0.885245\n",
       "2022-02-13  0.502004     0.148234     0.820466\n",
       "2022-02-14  0.504360     0.171945     0.904754\n",
       "2022-02-15  0.453419     0.093209     0.835611\n",
       "2022-02-16  0.526217     0.173060     0.911330\n",
       "2022-02-17  0.504778     0.106900     0.887501\n",
       "2022-02-18  0.522353     0.170076     0.911283"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51878642, 0.17324039, 0.87771447],\n",
       "       [0.49269791, 0.15223278, 0.86847335],\n",
       "       [0.49380441, 0.14003517, 0.81226679],\n",
       "       [0.51467463, 0.18225936, 0.91506854],\n",
       "       [0.52690045, 0.18135443, 0.8858285 ],\n",
       "       [0.51731996, 0.17685482, 0.8930954 ],\n",
       "       [0.51290311, 0.15913388, 0.83136549],\n",
       "       [0.50334306, 0.17092779, 0.90373697],\n",
       "       [0.50171526, 0.15616923, 0.86064331],\n",
       "       [0.50946908, 0.16900395, 0.88524452],\n",
       "       [0.50200357, 0.14823433, 0.82046595],\n",
       "       [0.50436041, 0.17194514, 0.90475432],\n",
       "       [0.4534189 , 0.09320851, 0.83561058],\n",
       "       [0.52621695, 0.17305963, 0.91133042],\n",
       "       [0.50477802, 0.10690002, 0.88750077],\n",
       "       [0.52235258, 0.1700762 , 0.91128311]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multivariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 20\n",
      "Number of observations used for backtesting: 30\n",
      "    Number of folds: 6\n",
      "    Number of steps per fold: 4\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 3\n",
      "    Last fold has been excluded because it was incomplete.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-20 00:00:00  (n=20)\n",
      "    Validation: 2022-01-24 00:00:00 -- 2022-01-27 00:00:00  (n=4)\n",
      "Fold: 1\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-20 00:00:00  (n=20)\n",
      "    Validation: 2022-01-28 00:00:00 -- 2022-01-31 00:00:00  (n=4)\n",
      "Fold: 2\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-20 00:00:00  (n=20)\n",
      "    Validation: 2022-02-01 00:00:00 -- 2022-02-04 00:00:00  (n=4)\n",
      "Fold: 3\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-02-01 00:00:00  (n=32)\n",
      "    Validation: 2022-02-05 00:00:00 -- 2022-02-08 00:00:00  (n=4)\n",
      "Fold: 4\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-02-01 00:00:00  (n=32)\n",
      "    Validation: 2022-02-09 00:00:00 -- 2022-02-12 00:00:00  (n=4)\n",
      "Fold: 5\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-02-01 00:00:00  (n=32)\n",
      "    Validation: 2022-02-13 00:00:00 -- 2022-02-16 00:00:00  (n=4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6740f3493d45a687e12efeb9bec571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_with_index = series.copy()\n",
    "series_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "exog_with_index = series['l1'].rename('exog_1').copy()\n",
    "exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor = Ridge(random_state=123),\n",
    "                    level     = 'l1',\n",
    "                    lags      = 2,\n",
    "                    steps     = 7\n",
    "                )\n",
    "\n",
    "refit = 3\n",
    "n_validation = 30\n",
    "steps = 4\n",
    "gap = 3\n",
    "\n",
    "metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "                                            forecaster            = forecaster,\n",
    "                                            series                = series_with_index,\n",
    "                                            steps                 = steps,\n",
    "                                            levels                = 'l1',\n",
    "                                            metric                = 'mean_absolute_error',\n",
    "                                            initial_train_size    = len(series) - n_validation,\n",
    "                                            gap                   = gap,\n",
    "                                            allow_incomplete_fold = False,\n",
    "                                            refit                 = refit,\n",
    "                                            fixed_train_size      = False,\n",
    "                                            exog                  = exog_with_index,\n",
    "                                            interval              = [5, 95],\n",
    "                                            n_boot                = 100,\n",
    "                                            random_state          = 123,\n",
    "                                            in_sample_residuals   = True,\n",
    "                                            verbose               = True\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['l1', 0.10066454067329249]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_levels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(backtest_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import norm\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytest import approx\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "\n",
    "# Fixtures\n",
    "# from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import series\n",
    "# from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import exog\n",
    "# from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import exog_predict\n",
    "\n",
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "\n",
    "transformer_exog = ColumnTransformer(\n",
    "                       [('scale', StandardScaler(), ['exog_1']),\n",
    "                        ('onehot', OneHotEncoder(), ['exog_2'])],\n",
    "                       remainder = 'passthrough',\n",
    "                       verbose_feature_names_out = False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae178667a411478e9bb89c5f4d0dd5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    series_with_index = series.copy()\n",
    "    series_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "    exog_with_index = series['l1'].rename('exog_1').copy()\n",
    "    exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "\n",
    "    forecaster = ForecasterAutoregMultiVariate(\n",
    "                     regressor = Ridge(random_state=123),\n",
    "                     level     = 'l1',\n",
    "                     lags      = 2,\n",
    "                     steps     = 7\n",
    "                 )\n",
    "\n",
    "    refit = 3\n",
    "    n_validation = 30\n",
    "    steps = 4\n",
    "    gap = 3\n",
    "\n",
    "    metrics_levels, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "                                               forecaster            = forecaster,\n",
    "                                               series                = series_with_index,\n",
    "                                               steps                 = steps,\n",
    "                                               levels                = ['l1'],\n",
    "                                               metric                = 'mean_absolute_error',\n",
    "                                               initial_train_size    = len(series_with_index) - n_validation,\n",
    "                                               gap                   = gap,\n",
    "                                               allow_incomplete_fold = False,\n",
    "                                               refit                 = refit,\n",
    "                                               fixed_train_size      = False,\n",
    "                                               exog                  = exog_with_index,\n",
    "                                               interval              = [5, 95],\n",
    "                                               n_boot                = 100,\n",
    "                                               random_state          = 123,\n",
    "                                               in_sample_residuals   = True,\n",
    "                                               verbose               = False\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['l1', 0.10066454067329249]], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_levels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53203113, 0.27318916, 0.69931226],\n",
       "       [0.62129188, 0.46220068, 0.85870486],\n",
       "       [0.40145922, 0.17189084, 0.59797159],\n",
       "       [0.38821275, 0.17098498, 0.61456487],\n",
       "       [0.37636995, 0.11752798, 0.54365108],\n",
       "       [0.36599243, 0.20690123, 0.60340541],\n",
       "       [0.47654862, 0.24698023, 0.67306099],\n",
       "       [0.33725755, 0.12002978, 0.56360967],\n",
       "       [0.46122163, 0.20237966, 0.62850276],\n",
       "       [0.47541934, 0.31632814, 0.71283232],\n",
       "       [0.50601999, 0.27645161, 0.70253236],\n",
       "       [0.39293452, 0.17570675, 0.61928664],\n",
       "       [0.43793405, 0.27695885, 0.5990429 ],\n",
       "       [0.52600886, 0.38167775, 0.72224797],\n",
       "       [0.70882239, 0.55319058, 0.83377003],\n",
       "       [0.70063755, 0.51962777, 0.85415566],\n",
       "       [0.48631217, 0.32533698, 0.64742102],\n",
       "       [0.52248417, 0.37815306, 0.71872328],\n",
       "       [0.30010035, 0.14446853, 0.42504798],\n",
       "       [0.43342987, 0.25242008, 0.58694797],\n",
       "       [0.42479569, 0.2638205 , 0.58590454],\n",
       "       [0.68566159, 0.54133048, 0.8819007 ],\n",
       "       [0.34632377, 0.19069195, 0.4712714 ],\n",
       "       [0.44695116, 0.26594138, 0.60046927]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
