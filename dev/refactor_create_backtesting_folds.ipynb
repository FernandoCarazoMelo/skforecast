{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "from skforecast.model_selection.model_selection import _get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_backtesting_folds_2(\n",
    "    data: Union[pd.Series, pd.DataFrame],\n",
    "    window_size: int,\n",
    "    initial_train_size: Union[int, None],\n",
    "    test_size: int,\n",
    "    externally_fitted: bool=False,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    return_all_indexes: bool=False,\n",
    "    verbose: bool=True\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    This function is designed to work after passing the `check_backtesting_input` \n",
    "    function from `skforecast.utils`.\n",
    "\n",
    "    Provides train/test indices (position) to split time series data samples that\n",
    "    are observed at fixed time intervals, in train/test sets. In each split, test\n",
    "    indices must be higher than before.\n",
    "\n",
    "    Three arrays are returned for each fold with the position of train, test\n",
    "    including the gap, and test excluding the gap. The gap is the number of\n",
    "    samples to exclude from the end of each train set before the test set. The\n",
    "    test excluding the gap is the one that must be used to make evaluate the\n",
    "    model. The test including the gap is provided for convenience.\n",
    "\n",
    "    Returned indexes are not the indexes of the original time series, but the\n",
    "    positional indexes of the samples in the time series. For example, if the   \n",
    "    original time series is `y = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]`, the\n",
    "    returned indexes for the first fold if  `test_size = 4`, `gap = 1` and \n",
    "    `initial_train_size = 2` are: `[[0, 1], [2, 3, 4, 5], [3, 4, 5]]]`. This means\n",
    "    that the first fold is using the samples with positional indexes 0 and 1 in\n",
    "    the time series as training set, and the samples with positional indexes 2,\n",
    "    3, 4 and 5 as test set, but only the samples with positional indexes 3, 4 and\n",
    "    5 should be used to evaluate the model since `gap = 1`. The second fold would\n",
    "    be `[[0, 1, 2, 3], [4, 5, 6, 7], [5, 6, 7]]`, and so on.\n",
    "\n",
    "    Each fold also provides information as to whether the Forecaster needs to \n",
    "    be trained or not.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas Series, pandas DataFrame\n",
    "        Time series values.\n",
    "    window_size : int\n",
    "        Size of the window needed to create the predictors.\n",
    "    initial_train_size : int, None\n",
    "        Size of the training set in the first fold. If `None` or 0, the initial\n",
    "        fold does not include a training set.\n",
    "    test_size : int\n",
    "        Size of the test set in each fold.\n",
    "    externally_fitted : bool, default `False`\n",
    "        Flag indicating whether the forecaster is already trained. Only used when \n",
    "        `initial_train_size` is None and `refit` is False.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    return_all_indexes : bool, default `False`\n",
    "        If `True`, return all the indexes included in each fold. If `False`, return\n",
    "        only the first and last index of each partition in each fold.\n",
    "    verbose : bool, default `True`\n",
    "        Print information if the folds created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    folds : list\n",
    "        List containing the indices (position) of `y` for training, test including\n",
    "        the gap, test excluding the gap for each fold, and whether fir the Forecaster.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    idx = range(len(data))\n",
    "    folds = []\n",
    "    i = 0\n",
    "    last_fold_excluded = False\n",
    "\n",
    "    while initial_train_size + (i * test_size) + gap < len(data):\n",
    "\n",
    "        if refit:\n",
    "            # If fixed_train_size the train size doesn't increase but moves by \n",
    "            # `test_size` positions in each iteration. If False, the train size\n",
    "            # increases by `test_size` in each iteration.\n",
    "            train_idx_start = i * (test_size) if fixed_train_size else 0\n",
    "            train_idx_end = initial_train_size + i * (test_size)\n",
    "            test_idx_start = train_idx_end\n",
    "        else:\n",
    "            # The train size doesn't increase and doesn't move.\n",
    "            train_idx_start = 0\n",
    "            train_idx_end = initial_train_size\n",
    "            test_idx_start = initial_train_size + i * (test_size)\n",
    "            \n",
    "        last_window_start = test_idx_start - window_size \n",
    "        test_idx_end = test_idx_start + gap + test_size\n",
    "    \n",
    "        partitions = [\n",
    "            idx[train_idx_start : train_idx_end],\n",
    "            idx[last_window_start : test_idx_start],\n",
    "            idx[test_idx_start : test_idx_end],\n",
    "            idx[test_idx_start + gap : test_idx_end]\n",
    "        ]\n",
    "        folds.append(partitions)\n",
    "        i += 1\n",
    "\n",
    "    if not allow_incomplete_fold:\n",
    "        if len(folds[-1][2]) < test_size:\n",
    "            folds = folds[:-1]\n",
    "            last_fold_excluded = True\n",
    "\n",
    "    # Replace partitions inside folds with length 0 with None\n",
    "    folds = [[partition if len(partition) > 0 else None \n",
    "              for partition in fold] \n",
    "             for fold in folds]\n",
    "\n",
    "    # Create a flag to know whether to train the forecaster\n",
    "    if refit == 0:\n",
    "        refit = False\n",
    "        \n",
    "    if isinstance(refit, bool):\n",
    "        fit_forecaster = [refit]*len(folds)\n",
    "        fit_forecaster[0] = True\n",
    "    else:\n",
    "        fit_forecaster = [False]*len(folds)\n",
    "        for i in range(0, len(fit_forecaster), refit): \n",
    "            fit_forecaster[i] = True\n",
    "    \n",
    "    for i in range(len(folds)): \n",
    "        folds[i].append(fit_forecaster[i])\n",
    "        if fit_forecaster[i] is False:\n",
    "            folds[i][0] = folds[i-1][0]\n",
    "\n",
    "    # This is done to allow parallelization. The first Forecaster fit is \n",
    "    # outside the auxiliary function.\n",
    "    fit_forecaster[0] = False\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Information of backtesting process\")\n",
    "        print(\"----------------------------------\")\n",
    "        if externally_fitted:\n",
    "            print(f\"An already trained forecaster is to be used. Window size: {window_size}\")\n",
    "        else:\n",
    "            print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(data) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {len(folds)}\")\n",
    "        print(f\"    Number of steps per fold: {test_size}\")\n",
    "        print(f\"    Number of steps to exclude from the end of each train set before test (gap): {gap}\")\n",
    "        if last_fold_excluded:\n",
    "            print(\"    Last fold has been excluded because it was incomplete.\")\n",
    "        if len(folds[-1][3]) < test_size:\n",
    "            print(f\"    Last fold only includes {len(folds[-1][3])} observations.\")\n",
    "        print(\"\")\n",
    "\n",
    "        for i, fold in enumerate(folds):\n",
    "            training_start    = data.index[fold[0][0]] if fold[0] is not None else None\n",
    "            training_end      = data.index[fold[0][-1]] if fold[0] is not None else None\n",
    "            training_length   = len(fold[0]) if fold[0] is not None else 0\n",
    "            validation_start  = data.index[fold[3][0]]\n",
    "            validation_end    = data.index[fold[3][-1]]\n",
    "            validation_length = len(fold[3])\n",
    "            print(f\"Fold: {i}\")\n",
    "            if not externally_fitted:\n",
    "                print(\n",
    "                    f\"    Training:   {training_start} -- {training_end}  (n={training_length})\"\n",
    "                )\n",
    "            print(\n",
    "                f\"    Validation: {validation_start} -- {validation_end}  (n={validation_length})\"\n",
    "            )\n",
    "        print(\"\")\n",
    "\n",
    "    if not return_all_indexes:\n",
    "        # +1 to prevent iloc pandas from deleting the last observation\n",
    "        folds = [\n",
    "            [[fold[0][0], fold[0][-1]+1], \n",
    "             [fold[1][0], fold[1][-1]+1], \n",
    "             [fold[2][0], fold[2][-1]+1],\n",
    "             [fold[3][0], fold[3][-1]+1],\n",
    "             fold[4]] \n",
    "            for fold in folds\n",
    "        ]\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection.model_selection import _create_backtesting_folds\n",
    "\n",
    "y = pd.Series(np.arange(100))\n",
    "y.index = pd.date_range(start='2022-01-01', periods=100, freq='D')\n",
    "initial_train_size = 50\n",
    "gap = 5\n",
    "test_size = 7\n",
    "refit = False\n",
    "allow_incomplete_fold = False\n",
    "\n",
    "folds = _create_backtesting_folds_2(\n",
    "            data                  = y,\n",
    "            window_size           = 5,\n",
    "            initial_train_size    = initial_train_size,\n",
    "            test_size             = test_size,\n",
    "            externally_fitted     = False,\n",
    "            refit                 = 2,\n",
    "            fixed_train_size      = False,\n",
    "            gap                   = gap,\n",
    "            allow_incomplete_fold = allow_incomplete_fold,\n",
    "            return_all_indexes    = False,\n",
    "            verbose               = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 50], [45, 50], [50, 62], [55, 62], True],\n",
       " [[0, 50], [52, 57], [57, 69], [62, 69], False],\n",
       " [[0, 64], [59, 64], [64, 76], [69, 76], True],\n",
       " [[0, 64], [66, 71], [71, 83], [76, 83], False],\n",
       " [[0, 78], [73, 78], [78, 90], [83, 90], True],\n",
       " [[0, 78], [80, 85], [85, 97], [90, 97], False],\n",
       " [[0, 92], [87, 92], [92, 100], [97, 100], True]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "refit = 0\n",
    "\n",
    "if refit:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 91], [70, 82], [75, 82], 1, True, False, True, True, True],\n",
       " [[0, 91], [77, 89], [82, 89], 1, True, False, False, False, False],\n",
       " [[0, 91], [84, 96], [89, 96], 1, True, False, True, False, False],\n",
       " [[0, 91], [91, 100], [96, 100], 1, True, False, False, True, False]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refit = 4\n",
    "\n",
    "if isinstance(refit, bool):\n",
    "    fit_forecaster = [refit]*len(folds)\n",
    "else:\n",
    "    fit_forecaster = [False]*len(folds)\n",
    "    for i in range(0, len(fit_forecaster), refit): fit_forecaster[i] = True\n",
    "\n",
    "for i in range(len(folds)): \n",
    "    folds[i].append(fit_forecaster[i])\n",
    "    if fit_forecaster[i] is False:\n",
    "        folds[i][0] = folds[i-1][0]\n",
    "\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace partitions inside folds with length 0 with None\n",
    "folds[0].append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [False, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0] = True\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "n_boot = -1\n",
    "\n",
    "if not isinstance(n_boot, (bool, int, np.integer)) or n_boot < 0:\n",
    "    print(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _backtesting_forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster\n",
    "\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import out_sample_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.27 ms ± 74 µs per loop (mean ± std. dev. of 4 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 200 -r 4\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    refit = True,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    steps               = 4,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    n_jobs              = 1,\n",
    "                                    verbose             = False,\n",
    "                                    show_progress = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.29 ms ± 60.9 µs per loop (mean ± std. dev. of 4 runs, 200 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 200 -r 4\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster(\n",
    "                                    forecaster          = forecaster,\n",
    "                                    y                   = y,\n",
    "                                    exog                = None,\n",
    "                                    refit = True,\n",
    "                                    initial_train_size  = len(y_train),\n",
    "                                    steps               = 4,\n",
    "                                    metric              = 'mean_squared_error',\n",
    "                                    interval            = None,\n",
    "                                    n_boot              = 500,\n",
    "                                    random_state        = 123,\n",
    "                                    in_sample_residuals = True,\n",
    "                                    n_jobs              = 1,\n",
    "                                    verbose             = False,\n",
    "                                    show_progress = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytest import approx\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection.model_selection import backtesting_forecaster\n",
    "\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import y\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import exog\n",
    "from skforecast.model_selection.tests.fixtures_model_selection import out_sample_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae9da47ba954ac5813da26deebe7b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregDirect(\n",
    "                     regressor = Ridge(random_state=123), \n",
    "                     lags      = 3,\n",
    "                     steps     = 8\n",
    "                 )\n",
    "\n",
    "n_backtest = 20\n",
    "y_train = y[:-n_backtest]\n",
    "\n",
    "metric, backtest_predictions = backtesting_forecaster(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    y                     = y,\n",
    "                                    exog                  = exog,\n",
    "                                    refit                 = 2,\n",
    "                                    initial_train_size    = len(y_train),\n",
    "                                    fixed_train_size      = False,\n",
    "                                    gap                   = 0,\n",
    "                                    allow_incomplete_fold = True,\n",
    "                                    steps                 = 2,\n",
    "                                    metric                = 'mean_squared_error',\n",
    "                                    interval              = [5, 95],\n",
    "                                    n_boot                = 500,\n",
    "                                    random_state          = 123,\n",
    "                                    in_sample_residuals   = True,\n",
    "                                    verbose               = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06099110404144631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55616986, 0.15288789, 0.89198752],\n",
       "       [0.48751797, 0.14866438, 0.83169303],\n",
       "       [0.57764391, 0.17436194, 0.91346157],\n",
       "       [0.51298667, 0.17413308, 0.85716173],\n",
       "       [0.47430051, 0.0796644 , 0.82587748],\n",
       "       [0.49192271, 0.14609696, 0.95959395],\n",
       "       [0.52213783, 0.12750172, 0.8737148 ],\n",
       "       [0.54492575, 0.1991    , 1.012597  ],\n",
       "       [0.52501537, 0.13641764, 0.86685356],\n",
       "       [0.4680474 , 0.08515461, 0.81792677],\n",
       "       [0.51059498, 0.12199725, 0.85243317],\n",
       "       [0.53067132, 0.14777853, 0.88055069],\n",
       "       [0.4430938 , 0.0509291 , 0.69854202],\n",
       "       [0.49911716, 0.1231365 , 0.8711497 ],\n",
       "       [0.44546347, 0.05329877, 0.70091169],\n",
       "       [0.46530749, 0.08932683, 0.83734003],\n",
       "       [0.46901878, 0.08173407, 0.82098555],\n",
       "       [0.55371362, 0.14618224, 0.98199137],\n",
       "       [0.60759064, 0.22030593, 0.9595574 ],\n",
       "       [0.50415336, 0.09662198, 0.93243111]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 30\n",
      "Number of observations used for backtesting: 20\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 4\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 3\n",
      "    Last fold has been excluded because it was incomplete.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-30 00:00:00  (n=30)\n",
      "    Validation: 2022-02-03 00:00:00 -- 2022-02-06 00:00:00  (n=4)\n",
      "Fold: 1\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-30 00:00:00  (n=30)\n",
      "    Validation: 2022-02-07 00:00:00 -- 2022-02-10 00:00:00  (n=4)\n",
      "Fold: 2\n",
      "    Training:   2022-01-01 00:00:00 -- 2022-01-30 00:00:00  (n=30)\n",
      "    Validation: 2022-02-11 00:00:00 -- 2022-02-14 00:00:00  (n=4)\n",
      "Fold: 3\n",
      "    Training:   2022-01-13 00:00:00 -- 2022-02-11 00:00:00  (n=30)\n",
      "    Validation: 2022-02-15 00:00:00 -- 2022-02-18 00:00:00  (n=4)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6766c4d44caa477a8436604126806389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_with_index = y.copy()\n",
    "y_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "exog_with_index = exog.copy()\n",
    "exog_with_index.index = pd.date_range(start='2022-01-01', periods=50, freq='D')\n",
    "\n",
    "forecaster = ForecasterAutoreg(regressor=Ridge(random_state=123), lags=3)\n",
    "\n",
    "metric, backtest_predictions = backtesting_forecaster(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    y                     = y_with_index,\n",
    "                                    exog                  = exog_with_index,\n",
    "                                    refit                 = 3,\n",
    "                                    initial_train_size    = len(y_with_index) - 20,\n",
    "                                    fixed_train_size      = True,\n",
    "                                    gap                   = 3,\n",
    "                                    allow_incomplete_fold = False,\n",
    "                                    steps                 = 4,\n",
    "                                    metric                = 'mean_squared_error',\n",
    "                                    interval              = [5, 95],\n",
    "                                    n_boot                = 500,\n",
    "                                    random_state          = 123,\n",
    "                                    in_sample_residuals   = True,\n",
    "                                    verbose               = True,\n",
    "                                    n_jobs                = 1\n",
    "                                )\n",
    "backtest_predictions = backtest_predictions.asfreq('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060991643719298785"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y=y_with_index.iloc[:30], exog=exog_with_index[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-03    0.518786\n",
       "2022-02-04    0.492698\n",
       "2022-02-05    0.493804\n",
       "2022-02-06    0.514675\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, exog=exog_with_index.iloc[30:37]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-07    0.526900\n",
       "2022-02-08    0.517320\n",
       "2022-02-09    0.512903\n",
       "2022-02-10    0.503343\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, last_window=y_with_index.iloc[:34], \n",
    "                   exog=exog_with_index.iloc[34:42]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-11    0.501715\n",
       "2022-02-12    0.509469\n",
       "2022-02-13    0.502004\n",
       "2022-02-14    0.504360\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(7, last_window=y_with_index.iloc[:38], \n",
    "                   exog=exog_with_index.iloc[38:45]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-02-15    0.453419\n",
       "2022-02-16    0.526217\n",
       "2022-02-17    0.504778\n",
       "2022-02-18    0.522353\n",
       "Freq: D, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.fit(y=y_with_index.iloc[12:42], exog=exog_with_index[12:42])\n",
    "forecaster.predict(7, exog=exog_with_index.iloc[42:49]).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-03</th>\n",
       "      <td>0.518786</td>\n",
       "      <td>0.173240</td>\n",
       "      <td>0.877714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-04</th>\n",
       "      <td>0.492698</td>\n",
       "      <td>0.152233</td>\n",
       "      <td>0.868473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-05</th>\n",
       "      <td>0.493804</td>\n",
       "      <td>0.140035</td>\n",
       "      <td>0.812267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-06</th>\n",
       "      <td>0.514675</td>\n",
       "      <td>0.182259</td>\n",
       "      <td>0.915069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-07</th>\n",
       "      <td>0.526900</td>\n",
       "      <td>0.181354</td>\n",
       "      <td>0.885829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-08</th>\n",
       "      <td>0.517320</td>\n",
       "      <td>0.176855</td>\n",
       "      <td>0.893095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-09</th>\n",
       "      <td>0.512903</td>\n",
       "      <td>0.159134</td>\n",
       "      <td>0.831365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-10</th>\n",
       "      <td>0.503343</td>\n",
       "      <td>0.170928</td>\n",
       "      <td>0.903737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-11</th>\n",
       "      <td>0.501715</td>\n",
       "      <td>0.156169</td>\n",
       "      <td>0.860643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-12</th>\n",
       "      <td>0.509469</td>\n",
       "      <td>0.169004</td>\n",
       "      <td>0.885245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-13</th>\n",
       "      <td>0.502004</td>\n",
       "      <td>0.148234</td>\n",
       "      <td>0.820466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14</th>\n",
       "      <td>0.504360</td>\n",
       "      <td>0.171945</td>\n",
       "      <td>0.904754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-15</th>\n",
       "      <td>0.453419</td>\n",
       "      <td>0.093209</td>\n",
       "      <td>0.835611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16</th>\n",
       "      <td>0.526217</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>0.911330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17</th>\n",
       "      <td>0.504778</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.887501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-18</th>\n",
       "      <td>0.522353</td>\n",
       "      <td>0.170076</td>\n",
       "      <td>0.911283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  lower_bound  upper_bound\n",
       "2022-02-03  0.518786     0.173240     0.877714\n",
       "2022-02-04  0.492698     0.152233     0.868473\n",
       "2022-02-05  0.493804     0.140035     0.812267\n",
       "2022-02-06  0.514675     0.182259     0.915069\n",
       "2022-02-07  0.526900     0.181354     0.885829\n",
       "2022-02-08  0.517320     0.176855     0.893095\n",
       "2022-02-09  0.512903     0.159134     0.831365\n",
       "2022-02-10  0.503343     0.170928     0.903737\n",
       "2022-02-11  0.501715     0.156169     0.860643\n",
       "2022-02-12  0.509469     0.169004     0.885245\n",
       "2022-02-13  0.502004     0.148234     0.820466\n",
       "2022-02-14  0.504360     0.171945     0.904754\n",
       "2022-02-15  0.453419     0.093209     0.835611\n",
       "2022-02-16  0.526217     0.173060     0.911330\n",
       "2022-02-17  0.504778     0.106900     0.887501\n",
       "2022-02-18  0.522353     0.170076     0.911283"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51878642, 0.17324039, 0.87771447],\n",
       "       [0.49269791, 0.15223278, 0.86847335],\n",
       "       [0.49380441, 0.14003517, 0.81226679],\n",
       "       [0.51467463, 0.18225936, 0.91506854],\n",
       "       [0.52690045, 0.18135443, 0.8858285 ],\n",
       "       [0.51731996, 0.17685482, 0.8930954 ],\n",
       "       [0.51290311, 0.15913388, 0.83136549],\n",
       "       [0.50334306, 0.17092779, 0.90373697],\n",
       "       [0.50171526, 0.15616923, 0.86064331],\n",
       "       [0.50946908, 0.16900395, 0.88524452],\n",
       "       [0.50200357, 0.14823433, 0.82046595],\n",
       "       [0.50436041, 0.17194514, 0.90475432],\n",
       "       [0.4534189 , 0.09320851, 0.83561058],\n",
       "       [0.52621695, 0.17305963, 0.91133042],\n",
       "       [0.50477802, 0.10690002, 0.88750077],\n",
       "       [0.52235258, 0.1700762 , 0.91128311]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_predictions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
