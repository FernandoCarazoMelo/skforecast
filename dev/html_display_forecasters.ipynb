{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skforecast.datasets import load_demo_dataset\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 1991-07-01 00:00:00 --- 2005-06-01 00:00:00  (n=168)\n",
      "Test dates  : 2005-07-01 00:00:00 --- 2008-06-01 00:00:00  (n=36)\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = load_demo_dataset()\n",
    "data.head(5)\n",
    "exog = pd.DataFrame(index=data.index)\n",
    "for i in range(1, 55):\n",
    "    exog[f'exog_{i}'] = np.random.normal(size=len(data))\n",
    "    \n",
    "# Data partition train-test\n",
    "# ==============================================================================\n",
    "end_train = '2005-06-01 23:59:00'\n",
    "print(\n",
    "    f\"Train dates : {data.index.min()} --- {data.loc[:end_train].index.max()}  \" \n",
    "    f\"(n={len(data.loc[:end_train])})\")\n",
    "print(\n",
    "    f\"Test dates  : {data.loc[end_train:].index.min()} --- {data.index.max()}  \"\n",
    "    f\"(n={len(data.loc[end_train:])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .container {\n",
       "                font-family: 'Arial', sans-serif;\n",
       "                font-size: 0.9em;\n",
       "                color: #333;\n",
       "                border: 1px solid #ddd;\n",
       "                background-color: #fafafa;\n",
       "                padding: 5px 15px;\n",
       "                border-radius: 8px;\n",
       "                max-width: 600px;\n",
       "                #margin: auto;\n",
       "            }\n",
       "            .container h2 {\n",
       "                font-size: 1.2em;\n",
       "                color: #222;\n",
       "                border-bottom: 2px solid #ddd;\n",
       "                padding-bottom: 5px;\n",
       "                margin-bottom: 15px;\n",
       "            }\n",
       "            .container details {\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container summary {\n",
       "                font-weight: bold;\n",
       "                font-size: 1.1em;\n",
       "                cursor: pointer;\n",
       "                margin-bottom: 5px;\n",
       "                background-color: #f0f0f0;\n",
       "                padding: 5px;\n",
       "                border-radius: 5px;\n",
       "            }\n",
       "            .container summary:hover {\n",
       "            background-color: #e0e0e0;\n",
       "            }\n",
       "            .container ul {\n",
       "                font-family: 'Courier New', monospace;\n",
       "                list-style-type: none;\n",
       "                padding-left: 20px;\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container li {\n",
       "                margin: 5px 0;\n",
       "                font-family: 'Courier New', monospace;\n",
       "            }\n",
       "            .container li strong {\n",
       "                font-weight: bold;\n",
       "                color: #444;\n",
       "            }\n",
       "            .container li::before {\n",
       "                content: \"- \";\n",
       "                color: #666;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <div class=\"container\">\n",
       "            <h2>ForecasterAutoreg</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LGBMRegressor(random_state=123, verbose=-1)</li>\n",
       "                    <li><strong>Lags:</strong> [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]</li>\n",
       "                    <li><strong>Window size:</strong> 15</li>\n",
       "                    <li><strong>Exogenous included:</strong> True</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2024-08-15 22:13:37</li>\n",
       "                    <li><strong>Last fit date:</strong> 2024-08-15 22:13:37</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.13.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.12.4</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                 ['exog_1', 'exog_2', 'exog_3', 'exog_4', 'exog_5', 'exog_6', 'exog_7', 'exog_8', 'exog_9', 'exog_10', 'exog_11', 'exog_12', 'exog_13', 'exog_14', 'exog_15', 'exog_16', 'exog_17', 'exog_18', 'exog_19', 'exog_20', 'exog_21', 'exog_22', 'exog_23', 'exog_24', 'exog_25', 'exog_26', 'exog_27', 'exog_28', 'exog_29', 'exog_30', 'exog_31', 'exog_32', 'exog_33', 'exog_34', 'exog_35', 'exog_36', 'exog_37', 'exog_38', 'exog_39', 'exog_40', 'exog_41', 'exog_42', 'exog_43', 'exog_44', 'exog_45', 'exog_46', 'exog_47', 'exog_48', 'exog_49', 'exog_50', 'exog_51', 'exog_52', 'exog_53', 'exog_54']\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                 <li><strong>Transformer for y:</strong> StandardScaler()</li>\n",
       "                 <li><strong>Transformer for exog:</strong> StandardScaler()</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Training range:</strong> [Timestamp('1991-07-01 00:00:00'), Timestamp('2005-06-01 00:00:00')]</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> MS</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] \n",
       "Window size: 15 \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9, exog_10,\n",
       "    exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17, exog_18,\n",
       "    exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, exog_25, exog_26,\n",
       "    exog_27, exog_28, exog_29, exog_30, exog_31, exog_32, exog_33, exog_34,\n",
       "    exog_35, exog_36, exog_37, exog_38, exog_39, exog_40, exog_41, exog_42,\n",
       "    exog_43, exog_44, exog_45, exog_46, exog_47, exog_48, exog_49, exog_50, ... \n",
       "Transformer for y: StandardScaler() \n",
       "Transformer for exog: StandardScaler() \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2005-06-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-15 22:13:37 \n",
       "Last fit date: 2024-08-15 22:13:37 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForecasterAutoreg\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 15,\n",
    "                 transformer_y=StandardScaler(),\n",
    "                 transformer_exog=StandardScaler()\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data.loc[:end_train], exog=exog.loc[:end_train])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= \n",
      "ForecasterAutoreg \n",
      "================= \n",
      "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
      "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] \n",
      "Window size: 15 \n",
      "Exogenous included: True \n",
      "Exogenous names: \n",
      "    exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9, exog_10,\n",
      "    exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17, exog_18,\n",
      "    exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, exog_25, exog_26,\n",
      "    exog_27, exog_28, exog_29, exog_30, exog_31, exog_32, exog_33, exog_34,\n",
      "    exog_35, exog_36, exog_37, exog_38, exog_39, exog_40, exog_41, exog_42,\n",
      "    exog_43, exog_44, exog_45, exog_46, exog_47, exog_48, exog_49, exog_50, ... \n",
      "Transformer for y: StandardScaler() \n",
      "Transformer for exog: StandardScaler() \n",
      "Weight function included: False \n",
      "Differentiation order: None \n",
      "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2005-06-01 00:00:00')] \n",
      "Training index type: DatetimeIndex \n",
      "Training index frequency: MS \n",
      "Regressor parameters: \n",
      "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
      "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1,\n",
      "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
      "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
      "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
      "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
      "fit_kwargs: {} \n",
      "Creation date: 2024-08-15 22:13:37 \n",
      "Last fit date: 2024-08-15 22:13:37 \n",
      "Skforecast version: 0.13.0 \n",
      "Python version: 3.12.4 \n",
      "Forecaster id: None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(forecaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================= \n",
       "ForecasterAutoregDirect \n",
       "======================= \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] \n",
       "Window size: 15 \n",
       "Maximum steps to predict: 3 \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9, exog_10,\n",
       "    exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17, exog_18,\n",
       "    exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, exog_25, exog_26,\n",
       "    exog_27, exog_28, exog_29, exog_30, exog_31, exog_32, exog_33, exog_34,\n",
       "    exog_35, exog_36, exog_37, exog_38, exog_39, exog_40, exog_41, exog_42,\n",
       "    exog_43, exog_44, exog_45, exog_46, exog_47, exog_48, exog_49, exog_50, ... \n",
       "Transformer for y: StandardScaler() \n",
       "Transformer for exog: StandardScaler() \n",
       "Weight function included: False \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2005-06-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-15 22:13:37 \n",
       "Last fit date: 2024-08-15 22:13:37 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ForecasterAutoregDirect\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 15,\n",
    "                 steps     = 3,\n",
    "                 transformer_y=StandardScaler(),\n",
    "                 transformer_exog=StandardScaler()\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data.loc[:end_train], exog=exog.loc[:end_train])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "\n",
    "\n",
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "\n",
    "for i in range(3, 80):\n",
    "    data[f'item_{i}'] = data['item_1']\n",
    "\n",
    "exog = data.copy()\n",
    "exog.columns = [f'exog_{i}' for i in range(exog.shape[1])]\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/varios/skforecast/skforecast/utils/utils.py:255: IgnoredArgumentWarning: {'item_53', 'item_49', 'item_19', 'item_79', 'item_71', 'item_11', 'item_12', 'item_14', 'item_28', 'item_25', 'item_56', 'item_62', 'item_30', 'item_36', 'item_66', 'item_3', 'item_29', 'item_44', 'item_9', 'item_46', 'item_51', 'item_20', 'item_43', 'item_41', 'item_50', 'item_68', 'item_24', 'item_58', 'item_74', 'item_7', 'item_13', 'item_39', 'item_63', 'item_34', 'item_42', 'item_8', 'item_59', 'item_67', 'item_10', 'item_17', 'item_38', 'item_65', 'item_26', 'item_69', 'item_76', 'item_33', 'item_32', 'item_6', 'item_31', 'item_48', 'item_47', 'item_40', 'item_18', 'item_77', 'item_61', 'item_45', 'item_21', 'item_16', 'item_57', 'item_60', 'item_64', 'item_4', 'item_37', 'item_78', 'item_70', 'item_73', 'item_72', 'item_75', 'item_35', 'item_22', 'item_23', 'item_27', 'item_5', 'item_55', 'item_15', 'item_54', 'item_52'} not present in `transformer_series`. No transformation is applied to these series. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=IgnoredArgumentWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24] \n",
       "Window size: 24 \n",
       "Series levels (names): \n",
       "    item_1, item_2, item_3, item_4, item_5, item_6, item_7, item_8, item_9, item_10,\n",
       "    item_11, item_12, item_13, item_14, item_15, item_16, item_17, item_18,\n",
       "    item_19, item_20, item_21, item_22, item_23, item_24, item_25, item_26,\n",
       "    item_27, item_28, item_29, item_30, item_31, item_32, item_33, item_34,\n",
       "    item_35, item_36, item_37, item_38, item_39, item_40, item_41, item_42,\n",
       "    item_43, item_44, item_45, item_46, item_47, item_48, item_49, item_50, ... \n",
       "Series encoding: ordinal \n",
       "Series weights: None \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_0, exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9,\n",
       "    exog_10, exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17,\n",
       "    exog_18, exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, exog_25,\n",
       "    exog_26, exog_27, exog_28, exog_29, exog_30, exog_31, exog_32, exog_33,\n",
       "    exog_34, exog_35, exog_36, exog_37, exog_38, exog_39, exog_40, exog_41,\n",
       "    exog_42, exog_43, exog_44, exog_45, exog_46, exog_47, exog_48, exog_49, ... \n",
       "Transformer for series: \n",
       "    'item_1': StandardScaler()\n",
       "    'item_2': MinMaxScaler()\n",
       "    '_unknown_level': MinMaxScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: \n",
       "    'item_1': ['2012-01-01', '2014-07-15']\n",
       "    'item_2': ['2012-01-01', '2014-07-15']\n",
       "    'item_3': ['2012-01-01', '2014-07-15']\n",
       "    'item_4': ['2012-01-01', '2014-07-15']\n",
       "    'item_5': ['2012-01-01', '2014-07-15']\n",
       "    'item_6': ['2012-01-01', '2014-07-15']\n",
       "    'item_7': ['2012-01-01', '2014-07-15']\n",
       "    'item_8': ['2012-01-01', '2014-07-15']\n",
       "    'item_9': ['2012-01-01', '2014-07-15']\n",
       "    'item_10': ['2012-01-01', '2014-07-15']\n",
       "    ... \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-15 22:13:37 \n",
       "Last fit date: 2024-08-15 22:13:40 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 24,\n",
    "                 encoding           = 'ordinal',\n",
    "                 transformer_series = {'item_1': StandardScaler(), 'item_2': MinMaxScaler(), '_unknown_level': MinMaxScaler()},\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index, :])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================== \n",
       "ForecasterAutoregMultiSeriesCustom \n",
       "================================== \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Predictors created with function: <lambda> \n",
       "Window size: 24 \n",
       "Series levels (names): \n",
       "    item_1, item_2, item_3, item_4, item_5, item_6, item_7, item_8, item_9, item_10,\n",
       "    item_11, item_12, item_13, item_14, item_15, item_16, item_17, item_18,\n",
       "    item_19, item_20, item_21, item_22, item_23, item_24, item_25, item_26,\n",
       "    item_27, item_28, item_29, item_30, item_31, item_32, item_33, item_34,\n",
       "    item_35, item_36, item_37, item_38, item_39, item_40, item_41, item_42,\n",
       "    item_43, item_44, item_45, item_46, item_47, item_48, item_49, item_50, ... \n",
       "Series encoding: ordinal \n",
       "Series weights: None \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_0, exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9,\n",
       "    exog_10, exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17,\n",
       "    exog_18, exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, exog_25,\n",
       "    exog_26, exog_27, exog_28, exog_29, exog_30, exog_31, exog_32, exog_33,\n",
       "    exog_34, exog_35, exog_36, exog_37, exog_38, exog_39, exog_40, exog_41,\n",
       "    exog_42, exog_43, exog_44, exog_45, exog_46, exog_47, exog_48, exog_49, ... \n",
       "Transformer for series: None \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: \n",
       "    'item_1': ['2012-01-01', '2014-07-15']\n",
       "    'item_2': ['2012-01-01', '2014-07-15']\n",
       "    'item_3': ['2012-01-01', '2014-07-15']\n",
       "    'item_4': ['2012-01-01', '2014-07-15']\n",
       "    'item_5': ['2012-01-01', '2014-07-15']\n",
       "    'item_6': ['2012-01-01', '2014-07-15']\n",
       "    'item_7': ['2012-01-01', '2014-07-15']\n",
       "    'item_8': ['2012-01-01', '2014-07-15']\n",
       "    'item_9': ['2012-01-01', '2014-07-15']\n",
       "    'item_10': ['2012-01-01', '2014-07-15']\n",
       "    ... \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-15 22:13:40 \n",
       "Last fit date: 2024-08-15 22:13:42 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ForecasterAutoregMultiSeriesCustom\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeriesCustom(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 window_size        = 24,\n",
    "                 fun_predictors     = lambda y: np.array([1,2,3]),\n",
    "                 encoding           = 'ordinal',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index, :])\n",
    "forecaster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
