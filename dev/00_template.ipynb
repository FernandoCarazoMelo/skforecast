{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df 1000 series\n",
    "np.random.seed(1)\n",
    "n_series = 100\n",
    "n = 100\n",
    "index = pd.date_range(start='01-01-2010', periods=n, freq='D')\n",
    "columns = ['series_' + str(i) for i in range(n_series)]\n",
    "data = np.random.normal(loc=0, scale=1, size=(n, n_series))\n",
    "df = pd.DataFrame(data, index=index, columns=columns)\n",
    "\n",
    "columns_exog = ['exog_' + str(i) for i in range(n_series)]\n",
    "data_exog = np.random.normal(loc=0, scale=1, size=(n, n_series))\n",
    "df_exog = pd.DataFrame(data_exog, index=index, columns=columns_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed {\n",
       "                font-family: 'Arial', sans-serif;\n",
       "                font-size: 0.9em;\n",
       "                color: #333;\n",
       "                border: 1px solid #ddd;\n",
       "                background-color: #f9f1e2;\n",
       "                padding: 5px 15px;\n",
       "                border-radius: 8px;\n",
       "                max-width: 600px;\n",
       "                #margin: auto;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed h2 {\n",
       "                font-size: 1.5em;\n",
       "                color: #222;\n",
       "                border-bottom: 2px solid #ddd;\n",
       "                padding-bottom: 5px;\n",
       "                margin-bottom: 15px;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed details {\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed summary {\n",
       "                font-weight: bold;\n",
       "                font-size: 1.1em;\n",
       "                cursor: pointer;\n",
       "                margin-bottom: 5px;\n",
       "                background-color: #fae3b3;\n",
       "                padding: 5px;\n",
       "                border-radius: 5px;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed summary:hover {\n",
       "                background-color: #e0e0e0;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed ul {\n",
       "                font-family: 'Courier New', monospace;\n",
       "                list-style-type: none;\n",
       "                padding-left: 20px;\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed li {\n",
       "                margin: 5px 0;\n",
       "                font-family: 'Courier New', monospace;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed li strong {\n",
       "                font-weight: bold;\n",
       "                color: #444;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed li::before {\n",
       "                content: \"- \";\n",
       "                color: #666;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed a {\n",
       "                color: #001633;\n",
       "                text-decoration: none;\n",
       "            }\n",
       "            .container-2f3fa4c87038463db7c1070eb291bbed a:hover {\n",
       "                color: #359ccb; \n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <div class=\"container-2f3fa4c87038463db7c1070eb291bbed\">\n",
       "            <h2>ForecasterAutoregMultiSeries</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LinearRegression()</li>\n",
       "                    <li><strong>Lags:</strong> [1 2 3 4 5]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 5</li>\n",
       "                    <li><strong>Series encoding:</strong> ordinal</li>\n",
       "                    <li><strong>Exogenous included:</strong> False</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Series weights:</strong> None</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2024-10-16 16:57:04</li>\n",
       "                    <li><strong>Last fit date:</strong> None</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.14.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.12.4</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    None\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for series:</strong> StandardScaler()</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Series names (levels):</strong> None</li>\n",
       "                    <li><strong>Training range:</strong> None</li>\n",
       "                    <li><strong>Training index type:</strong> Not fitted</li>\n",
       "                    <li><strong>Training index frequency:</strong> Not fitted</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.14.0/api/forecastermultiseries#forecasterautoregmultiseries.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.14.0/user_guides/independent-multi-time-series-forecasting.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LinearRegression() \n",
       "Lags: [1 2 3 4 5] \n",
       "Window features: None \n",
       "Window size: 5 \n",
       "Series encoding: ordinal \n",
       "Series names (levels): None \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for series: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Series weights: None \n",
       "Differentiation order: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: \n",
       "    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-10-16 16:57:04 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.14.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_series = {col: StandardScaler() for col in columns}\n",
    "transformer_series['_unknown_level'] = StandardScaler()\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor = LinearRegression(),\n",
    "                    lags = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                )\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ForecasterAutoregMultiSeries.__repr__ of ============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LinearRegression() \n",
       "Lags: [1 2 3 4 5] \n",
       "Window features: None \n",
       "Window size: 5 \n",
       "Series encoding: ordinal \n",
       "Series names (levels): None \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for series: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Series weights: None \n",
       "Differentiation order: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: \n",
       "    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-10-16 16:57:04 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.14.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None \n",
       ">"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.__repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e {\n",
       "                font-family: 'Arial', sans-serif;\n",
       "                font-size: 0.9em;\n",
       "                color: #333;\n",
       "                border: 1px solid #ddd;\n",
       "                background-color: #f0f8ff;\n",
       "                padding: 5px 15px;\n",
       "                border-radius: 8px;\n",
       "                max-width: 600px;\n",
       "                #margin: auto;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e h2 {\n",
       "                font-size: 1.5em;\n",
       "                color: #222;\n",
       "                border-bottom: 2px solid #ddd;\n",
       "                padding-bottom: 5px;\n",
       "                margin-bottom: 15px;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e details {\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e summary {\n",
       "                font-weight: bold;\n",
       "                font-size: 1.1em;\n",
       "                cursor: pointer;\n",
       "                margin-bottom: 5px;\n",
       "                background-color: #b3dbfd;\n",
       "                padding: 5px;\n",
       "                border-radius: 5px;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e summary:hover {\n",
       "                background-color: #e0e0e0;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e ul {\n",
       "                font-family: 'Courier New', monospace;\n",
       "                list-style-type: none;\n",
       "                padding-left: 20px;\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e li {\n",
       "                margin: 5px 0;\n",
       "                font-family: 'Courier New', monospace;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e li strong {\n",
       "                font-weight: bold;\n",
       "                color: #444;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e li::before {\n",
       "                content: \"- \";\n",
       "                color: #666;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e a {\n",
       "                color: #001633;\n",
       "                text-decoration: none;\n",
       "            }\n",
       "            .container-eb28cc544a1c479abc4821b62ce3386e a:hover {\n",
       "                color: #359ccb; \n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <div class=\"container-eb28cc544a1c479abc4821b62ce3386e\">\n",
       "            <h2>ForecasterAutoregMultiSeries</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LinearRegression()</li>\n",
       "                    <li><strong>Lags:</strong> [1 2 3 4 5]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 5</li>\n",
       "                    <li><strong>Series encoding:</strong> ordinal</li>\n",
       "                    <li><strong>Exogenous included:</strong> True</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Series weights:</strong> None</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2024-10-16 16:57:04</li>\n",
       "                    <li><strong>Last fit date:</strong> 2024-10-16 16:57:05</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.14.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.12.4</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    exog_0, exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9, exog_10, exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17, exog_18, exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, ..., exog_75, exog_76, exog_77, exog_78, exog_79, exog_80, exog_81, exog_82, exog_83, exog_84, exog_85, exog_86, exog_87, exog_88, exog_89, exog_90, exog_91, exog_92, exog_93, exog_94, exog_95, exog_96, exog_97, exog_98, exog_99\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for series:</strong> StandardScaler()</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Series names (levels):</strong> series_0, series_1, series_2, series_3, series_4, series_5, series_6, series_7, series_8, series_9, series_10, series_11, series_12, series_13, series_14, series_15, series_16, series_17, series_18, series_19, series_20, series_21, series_22, series_23, series_24, ..., series_75, series_76, series_77, series_78, series_79, series_80, series_81, series_82, series_83, series_84, series_85, series_86, series_87, series_88, series_89, series_90, series_91, series_92, series_93, series_94, series_95, series_96, series_97, series_98, series_99</li>\n",
       "                    <li><strong>Training range:</strong> 'series_0': ['2010-01-01', '2010-04-10'], 'series_1': ['2010-01-01', '2010-04-10'], 'series_2': ['2010-01-01', '2010-04-10'], 'series_3': ['2010-01-01', '2010-04-10'], 'series_4': ['2010-01-01', '2010-04-10'], ..., 'series_95': ['2010-01-01', '2010-04-10'], 'series_96': ['2010-01-01', '2010-04-10'], 'series_97': ['2010-01-01', '2010-04-10'], 'series_98': ['2010-01-01', '2010-04-10'], 'series_99': ['2010-01-01', '2010-04-10']</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> D</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.14.0/api/forecastermultiseries#forecasterautoregmultiseries.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.14.0/user_guides/independent-multi-time-series-forecasting.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LinearRegression() \n",
       "Lags: [1 2 3 4 5] \n",
       "Window features: None \n",
       "Window size: 5 \n",
       "Series encoding: ordinal \n",
       "Series names (levels): \n",
       "    series_0, series_1, series_2, series_3, series_4, series_5, series_6, series_7,\n",
       "    series_8, series_9, series_10, series_11, series_12, series_13, series_14,\n",
       "    series_15, series_16, series_17, series_18, series_19, series_20, series_21,\n",
       "    series_22, series_23, series_24, ..., series_75, series_76, series_77,\n",
       "    series_78, series_79, series_80, series_81, series_82, series_83, series_84,\n",
       "    series_85, series_86, series_87, series_88, series_89, series_90, series_91,\n",
       "    series_92, series_93, series_94, series_95, series_96, series_97, series_98,\n",
       "    series_99 \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_0, exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9,\n",
       "    exog_10, exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17,\n",
       "    exog_18, exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, ..., exog_75,\n",
       "    exog_76, exog_77, exog_78, exog_79, exog_80, exog_81, exog_82, exog_83,\n",
       "    exog_84, exog_85, exog_86, exog_87, exog_88, exog_89, exog_90, exog_91,\n",
       "    exog_92, exog_93, exog_94, exog_95, exog_96, exog_97, exog_98, exog_99 \n",
       "Transformer for series: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Series weights: None \n",
       "Differentiation order: None \n",
       "Training range: \n",
       "    'series_0': ['2010-01-01', '2010-04-10'], 'series_1': ['2010-01-01',\n",
       "    '2010-04-10'], 'series_2': ['2010-01-01', '2010-04-10'], 'series_3':\n",
       "    ['2010-01-01', '2010-04-10'], 'series_4': ['2010-01-01', '2010-04-10'], ...,\n",
       "    'series_95': ['2010-01-01', '2010-04-10'], 'series_96': ['2010-01-01',\n",
       "    '2010-04-10'], 'series_97': ['2010-01-01', '2010-04-10'], 'series_98':\n",
       "    ['2010-01-01', '2010-04-10'], 'series_99': ['2010-01-01', '2010-04-10'] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: \n",
       "    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-10-16 16:57:04 \n",
       "Last fit date: 2024-10-16 16:57:05 \n",
       "Skforecast version: 0.14.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.fit(series=df, exog=df_exog)\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ForecasterAutoregMultiSeries.__repr__ of ============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LinearRegression() \n",
       "Lags: [1 2 3 4 5] \n",
       "Window features: None \n",
       "Window size: 5 \n",
       "Series encoding: ordinal \n",
       "Series names (levels): \n",
       "    series_0, series_1, series_2, series_3, series_4, series_5, series_6, series_7,\n",
       "    series_8, series_9, series_10, series_11, series_12, series_13, series_14,\n",
       "    series_15, series_16, series_17, series_18, series_19, series_20, series_21,\n",
       "    series_22, series_23, series_24, ..., series_75, series_76, series_77,\n",
       "    series_78, series_79, series_80, series_81, series_82, series_83, series_84,\n",
       "    series_85, series_86, series_87, series_88, series_89, series_90, series_91,\n",
       "    series_92, series_93, series_94, series_95, series_96, series_97, series_98,\n",
       "    series_99 \n",
       "Exogenous included: True \n",
       "Exogenous names: \n",
       "    exog_0, exog_1, exog_2, exog_3, exog_4, exog_5, exog_6, exog_7, exog_8, exog_9,\n",
       "    exog_10, exog_11, exog_12, exog_13, exog_14, exog_15, exog_16, exog_17,\n",
       "    exog_18, exog_19, exog_20, exog_21, exog_22, exog_23, exog_24, ..., exog_75,\n",
       "    exog_76, exog_77, exog_78, exog_79, exog_80, exog_81, exog_82, exog_83,\n",
       "    exog_84, exog_85, exog_86, exog_87, exog_88, exog_89, exog_90, exog_91,\n",
       "    exog_92, exog_93, exog_94, exog_95, exog_96, exog_97, exog_98, exog_99 \n",
       "Transformer for series: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Series weights: None \n",
       "Differentiation order: None \n",
       "Training range: \n",
       "    'series_0': ['2010-01-01', '2010-04-10'], 'series_1': ['2010-01-01',\n",
       "    '2010-04-10'], 'series_2': ['2010-01-01', '2010-04-10'], 'series_3':\n",
       "    ['2010-01-01', '2010-04-10'], 'series_4': ['2010-01-01', '2010-04-10'], ...,\n",
       "    'series_95': ['2010-01-01', '2010-04-10'], 'series_96': ['2010-01-01',\n",
       "    '2010-04-10'], 'series_97': ['2010-01-01', '2010-04-10'], 'series_98':\n",
       "    ['2010-01-01', '2010-04-10'], 'series_99': ['2010-01-01', '2010-04-10'] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: \n",
       "    {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-10-16 16:57:04 \n",
       "Last fit date: 2024-10-16 16:57:05 \n",
       "Skforecast version: 0.14.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None \n",
       ">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.__repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(trab=None):\n",
    "    b = 1\n",
    "    return trab, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, b = aaa()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': ['l1_lag_1', 'l1_lag_2', 'l1_lag_3', 'l1_lag_4', 'l1_lag_5']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "\n",
    "lags={'l1': 5}\n",
    "expected = {'l1': None, 'l2': np.array([1, 2, 3, 4, 5])}\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "    LinearRegression(), level='l1', lags=lags, steps=2\n",
    ")\n",
    "forecaster.lags_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': array([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m forecaster\u001b[38;5;241m.\u001b[39mlags_names[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_array_almost_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlags\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m forecaster\u001b[38;5;241m.\u001b[39mlags_names[k] \u001b[38;5;241m==\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, lags[k] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py12\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py12\\Lib\\site-packages\\numpy\\_utils\\__init__.py:85\u001b[0m, in \u001b[0;36m_rename_parameter.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m     84\u001b[0m         kwargs[new_name] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old_name)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py12\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py12\\Lib\\site-packages\\numpy\\testing\\_private\\utils.py:1130\u001b[0m, in \u001b[0;36massert_array_almost_equal.<locals>.compare\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1128\u001b[0m dtype \u001b[38;5;241m=\u001b[39m result_type(y, \u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m   1129\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(y, dtype)\n\u001b[1;32m-> 1130\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issubdtype(z\u001b[38;5;241m.\u001b[39mdtype, number):\n\u001b[0;32m   1133\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)  \u001b[38;5;66;03m# handle object arrays\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for k in forecaster.lags:\n",
    "    if lags[k] is None:\n",
    "        assert forecaster.lags[k] is None\n",
    "        assert forecaster.lags_names[k] is None\n",
    "    else:\n",
    "        np.testing.assert_array_almost_equal(forecaster.lags[k], expected[k])\n",
    "        assert forecaster.lags_names[k] == [f'lag_{i}' for i in range(1, lags[k] + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_create_lags = {'col1': 5, 'col2': None}\n",
    "\n",
    "cols_to_create_lags.get('col3', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1': 'both', 'l2': 'X'}\n"
     ]
    }
   ],
   "source": [
    "series = pd.DataFrame({'l1': pd.Series(np.arange(10)), \n",
    "                        'l2': pd.Series(np.arange(100, 110))})\n",
    "exog = None\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1',\n",
    "                                            lags={'l1': 3, 'l2': 3}, \n",
    "                                            steps=2, transformer_series=None)\n",
    "results = forecaster._create_train_X_y(series=series, exog=exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[3., 4., 5., 6., 7., 8., 9.]])[1 - 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.0\n",
       "1    4.0\n",
       "2    5.0\n",
       "3    6.0\n",
       "4    7.0\n",
       "5    8.0\n",
       "6    9.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.array([[3., 4., 5., 6., 7., 8., 9.]])[1 - 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[10], [20], [30], [40], [50]])[1] + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 7.],\n",
       "       [7., 8.],\n",
       "       [8., 9.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[6., 7., 8.],\n",
    "                  [7., 8., 9.]]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[4., 3., 2., 1., 0.],\n",
      "       [5., 4., 3., 2., 1.],\n",
      "       [6., 5., 4., 3., 2.],\n",
      "       [7., 6., 5., 4., 3.]]), array([[54., 53., 52., 51., 50.],\n",
      "       [55., 54., 53., 52., 51.],\n",
      "       [56., 55., 54., 53., 52.],\n",
      "       [57., 56., 55., 54., 53.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:553: DataTypeWarning: `exog` may contain only `int`, `float` or `category` dtypes. Most machine learning models do not allow other types of values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=ValueTypesExogWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   l1_lag_1  l1_lag_2  l1_lag_3  l1_lag_4  l1_lag_5  l2_lag_1  l2_lag_2  \\\n",
       " 6       4.0       3.0       2.0       1.0       0.0      54.0      53.0   \n",
       " 7       5.0       4.0       3.0       2.0       1.0      55.0      54.0   \n",
       " 8       6.0       5.0       4.0       3.0       2.0      56.0      55.0   \n",
       " 9       7.0       6.0       5.0       4.0       3.0      57.0      56.0   \n",
       " \n",
       "    l2_lag_3  l2_lag_4  l2_lag_5 exog_step_1 exog_step_2  \n",
       " 6      52.0      51.0      50.0      string      string  \n",
       " 7      53.0      52.0      51.0      string      string  \n",
       " 8      54.0      53.0      52.0      string      string  \n",
       " 9      55.0      54.0      53.0      string      string  ,\n",
       " {1: 5    5.0\n",
       "  6    6.0\n",
       "  7    7.0\n",
       "  8    8.0\n",
       "  Name: l1_step_1, dtype: float64,\n",
       "  2: 6    6.0\n",
       "  7    7.0\n",
       "  8    8.0\n",
       "  9    9.0\n",
       "  Name: l1_step_2, dtype: float64},\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " ['exog'],\n",
       " None,\n",
       " ['exog'],\n",
       " ['l1_lag_1',\n",
       "  'l1_lag_2',\n",
       "  'l1_lag_3',\n",
       "  'l1_lag_4',\n",
       "  'l1_lag_5',\n",
       "  'l2_lag_1',\n",
       "  'l2_lag_2',\n",
       "  'l2_lag_3',\n",
       "  'l2_lag_4',\n",
       "  'l2_lag_5',\n",
       "  'exog_step_1',\n",
       "  'exog_step_2'],\n",
       " {'exog': dtype('O')})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.DataFrame({'l1': pd.Series(np.arange(10), dtype=float), \n",
    "                           'l2': pd.Series(np.arange(50, 60), dtype=float)})\n",
    "exog = pd.Series(['string'] * 10, name='exog', dtype=str)\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(LinearRegression(), level='l1',\n",
    "                                            lags=5, steps=2, transformer_series=None)\n",
    "forecaster._create_train_X_y(series=series, exog=exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skforecast.exceptions import MissingValuesWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skforecast.preprocessing import TimeSeriesDifferentiator\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import data  # to test results when using differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data.to_numpy(copy=True)\n",
    "diferenciator = TimeSeriesDifferentiator(order=1)\n",
    "data_diff = diferenciator.fit_transform(arr)\n",
    "\n",
    "series = pd.DataFrame(\n",
    "    {'l1': arr,\n",
    "        'l2': arr},\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "series_diff = pd.DataFrame(\n",
    "    \n",
    "    {'l1': data_diff,\n",
    "        'l2': data_diff},\n",
    "    index=data.index\n",
    ").dropna()\n",
    "\n",
    "# Simulated exogenous variable\n",
    "rng = np.random.default_rng(9876)\n",
    "exog = pd.Series(\n",
    "    rng.normal(loc=0, scale=1, size=len(data)), index=data.index, name='exog'\n",
    ")\n",
    "exog_diff = exog.iloc[1:]\n",
    "end_train = '2003-03-01 23:59:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster_1 = ForecasterAutoregMultiVariate(\n",
    "    LinearRegression(), level='l1', steps=3, lags=5, transformer_series=None\n",
    ")\n",
    "forecaster_2 = ForecasterAutoregMultiVariate(\n",
    "    LinearRegression(), level='l1', steps=3, lags=5, transformer_series=None, differentiation=1\n",
    ")\n",
    "\n",
    "if False:\n",
    "    forecaster_2.fit(series=series.loc[:end_train], exog=exog.loc[:end_train])\n",
    "\n",
    "output_1 = forecaster_1._create_train_X_y(\n",
    "                series = series_diff.loc[:end_train],\n",
    "                exog   = exog_diff.loc[:end_train]\n",
    "            )\n",
    "\n",
    "output_2 = forecaster_2._create_train_X_y(\n",
    "                series = series.loc[:end_train],\n",
    "                exog   = exog.loc[:end_train]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_lag_1</th>\n",
       "      <th>l1_lag_2</th>\n",
       "      <th>l1_lag_3</th>\n",
       "      <th>l1_lag_4</th>\n",
       "      <th>l1_lag_5</th>\n",
       "      <th>l2_lag_1</th>\n",
       "      <th>l2_lag_2</th>\n",
       "      <th>l2_lag_3</th>\n",
       "      <th>l2_lag_4</th>\n",
       "      <th>l2_lag_5</th>\n",
       "      <th>exog_step_1</th>\n",
       "      <th>exog_step_2</th>\n",
       "      <th>exog_step_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-03-01</th>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>-0.018889</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>-0.018889</td>\n",
       "      <td>-0.337261</td>\n",
       "      <td>0.303042</td>\n",
       "      <td>1.569935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-04-01</th>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.303042</td>\n",
       "      <td>1.569935</td>\n",
       "      <td>0.175040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-05-01</th>\n",
       "      <td>-0.313899</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>-0.313899</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>1.569935</td>\n",
       "      <td>0.175040</td>\n",
       "      <td>-0.403905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            l1_lag_1  l1_lag_2  l1_lag_3  l1_lag_4  l1_lag_5  l2_lag_1  \\\n",
       "1992-03-01  0.110283  0.019826  0.070384  0.041253 -0.018889  0.110283   \n",
       "1992-04-01  0.067467  0.110283  0.019826  0.070384  0.041253  0.067467   \n",
       "1992-05-01 -0.313899  0.067467  0.110283  0.019826  0.070384 -0.313899   \n",
       "\n",
       "            l2_lag_2  l2_lag_3  l2_lag_4  l2_lag_5  exog_step_1  exog_step_2  \\\n",
       "1992-03-01  0.019826  0.070384  0.041253 -0.018889    -0.337261     0.303042   \n",
       "1992-04-01  0.110283  0.019826  0.070384  0.041253     0.303042     1.569935   \n",
       "1992-05-01  0.067467  0.110283  0.019826  0.070384     1.569935     0.175040   \n",
       "\n",
       "            exog_step_3  \n",
       "1992-03-01     1.569935  \n",
       "1992-04-01     0.175040  \n",
       "1992-05-01    -0.403905  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_lag_1</th>\n",
       "      <th>l1_lag_2</th>\n",
       "      <th>l1_lag_3</th>\n",
       "      <th>l1_lag_4</th>\n",
       "      <th>l1_lag_5</th>\n",
       "      <th>l2_lag_1</th>\n",
       "      <th>l2_lag_2</th>\n",
       "      <th>l2_lag_3</th>\n",
       "      <th>l2_lag_4</th>\n",
       "      <th>l2_lag_5</th>\n",
       "      <th>exog_step_1</th>\n",
       "      <th>exog_step_2</th>\n",
       "      <th>exog_step_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-03-01</th>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>-0.018889</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>-0.018889</td>\n",
       "      <td>-0.337261</td>\n",
       "      <td>0.303042</td>\n",
       "      <td>1.569935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-04-01</th>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.303042</td>\n",
       "      <td>1.569935</td>\n",
       "      <td>0.175040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-05-01</th>\n",
       "      <td>-0.313899</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>-0.313899</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.070384</td>\n",
       "      <td>1.569935</td>\n",
       "      <td>0.175040</td>\n",
       "      <td>-0.403905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            l1_lag_1  l1_lag_2  l1_lag_3  l1_lag_4  l1_lag_5  l2_lag_1  \\\n",
       "1992-03-01  0.110283  0.019826  0.070384  0.041253 -0.018889  0.110283   \n",
       "1992-04-01  0.067467  0.110283  0.019826  0.070384  0.041253  0.067467   \n",
       "1992-05-01 -0.313899  0.067467  0.110283  0.019826  0.070384 -0.313899   \n",
       "\n",
       "            l2_lag_2  l2_lag_3  l2_lag_4  l2_lag_5  exog_step_1  exog_step_2  \\\n",
       "1992-03-01  0.019826  0.070384  0.041253 -0.018889    -0.337261     0.303042   \n",
       "1992-04-01  0.110283  0.019826  0.070384  0.041253     0.303042     1.569935   \n",
       "1992-05-01  0.067467  0.110283  0.019826  0.070384     1.569935     0.175040   \n",
       "\n",
       "            exog_step_3  \n",
       "1992-03-01     1.569935  \n",
       "1992-04-01     0.175040  \n",
       "1992-05-01    -0.403905  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992-01-01    0.067467\n",
       "1992-02-01   -0.313899\n",
       "1992-03-01    0.025128\n",
       "Freq: MS, Name: l1_step_1, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1[1][1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992-01-01    0.067467\n",
       "1992-02-01   -0.313899\n",
       "1992-03-01    0.025128\n",
       "Freq: MS, Name: l1_step_1, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2[1][1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(output_1[0], output_2[0])\n",
    "assert output_1[1].keys() == output_2[1].keys()\n",
    "for key in output_1[1]: \n",
    "    pd.testing.assert_series_equal(output_1[1][key], output_2[1][key]) \n",
    "assert output_1[2] == output_2[2]\n",
    "assert output_1[3] == output_2[3]\n",
    "assert output_1[4] == output_2[4]\n",
    "assert output_1[5] == output_2[5]\n",
    "assert output_1[6] == output_2[6]\n",
    "assert output_1[7] == output_2[7]\n",
    "for k in output_1[8].keys():\n",
    "    assert output_1[8][k] == output_2[8][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py12\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:263: UserWarning: Feature 0 is constant and will be replaced with 0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "\n",
    "y_datetime = pd.Series(\n",
    "    np.arange(15), index=pd.date_range('2000-01-01', periods=15, freq='D'),\n",
    "    name='y', dtype=float\n",
    ")\n",
    "exog_datetime = pd.Series(\n",
    "    np.arange(100, 115), index=pd.date_range('2000-01-01', periods=15, freq='D'),\n",
    "    name='exog', dtype=float\n",
    ")\n",
    "rolling = RollingFeatures(stats=['mean', 'median'], window_sizes=[5, 5])\n",
    "rolling_2 = RollingFeatures(stats='sum', window_sizes=[6])\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    LinearRegression(), lags=5, window_features=[rolling, rolling_2],\n",
    "    differentiation=1\n",
    ")\n",
    "forecaster.fit(y=y_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.07503713, -0.48984868, -0.01463081,  0.10597971, -0.01018012,\n",
       "           0.02377842,  0.09883014,  0.01630394,  0.17596768, -0.00584249,\n",
       "           0.09807633,  0.04869748,  0.07558021, -0.56028323,  0.14355438,\n",
       "           1.16172882]]),\n",
       "  array([[ 0.07503713, -0.48984868, -0.01463081,  0.10597971, -0.01018012,\n",
       "           0.02377842,  0.09883014,  0.01630394,  0.17596768, -0.00584249,\n",
       "           0.09807633,  0.04869748,  0.07558021, -0.56028323,  0.14355438,\n",
       "           0.29468848]]),\n",
       "  array([[ 0.07503713, -0.48984868, -0.01463081,  0.10597971, -0.01018012,\n",
       "           0.02377842,  0.09883014,  0.01630394,  0.17596768, -0.00584249,\n",
       "           0.09807633,  0.04869748,  0.07558021, -0.56028323,  0.14355438,\n",
       "          -0.4399757 ]]),\n",
       "  array([[ 0.07503713, -0.48984868, -0.01463081,  0.10597971, -0.01018012,\n",
       "           0.02377842,  0.09883014,  0.01630394,  0.17596768, -0.00584249,\n",
       "           0.09807633,  0.04869748,  0.07558021, -0.56028323,  0.14355438,\n",
       "           1.25008389]]),\n",
       "  array([[ 0.07503713, -0.48984868, -0.01463081,  0.10597971, -0.01018012,\n",
       "           0.02377842,  0.09883014,  0.01630394,  0.17596768, -0.00584249,\n",
       "           0.09807633,  0.04869748,  0.07558021, -0.56028323,  0.14355438,\n",
       "           1.37496887]])],\n",
       " ['lag_1',\n",
       "  'lag_2',\n",
       "  'lag_3',\n",
       "  'lag_4',\n",
       "  'lag_5',\n",
       "  'lag_6',\n",
       "  'lag_7',\n",
       "  'lag_8',\n",
       "  'lag_9',\n",
       "  'lag_10',\n",
       "  'lag_11',\n",
       "  'lag_12',\n",
       "  'lag_13',\n",
       "  'lag_14',\n",
       "  'lag_15',\n",
       "  'exog'],\n",
       " [1, 2, 3, 4, 5],\n",
       " DatetimeIndex(['2003-04-01', '2003-05-01', '2003-06-01', '2003-07-01',\n",
       "                '2003-08-01'],\n",
       "               dtype='datetime64[ns]', freq='MS'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.ForecasterAutoregDirect.tests.fixtures_ForecasterAutoregDirect import data  # to test results when using differentiation\n",
    "\n",
    "end_train = '2003-03-01 23:59:00'\n",
    "\n",
    "# Simulated exogenous variable\n",
    "rng = np.random.default_rng(9876)\n",
    "exog = pd.Series(\n",
    "    rng.normal(loc=0, scale=1, size=len(data)), index=data.index, name='exog'\n",
    ")\n",
    "steps = len(data.loc[end_train:])\n",
    "\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                    regressor       = LinearRegression(),\n",
    "                    steps           = 5,\n",
    "                    lags            = 15,\n",
    "                    differentiation = 1\n",
    "            )\n",
    "forecaster.fit(y=data.loc[:end_train], exog=exog.loc[:end_train])\n",
    "results = forecaster._create_predict_inputs(exog=exog.loc[end_train:])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "lags_ = {'l1': None, 'l2': None}\n",
    "\n",
    "n_lags = len(list(\n",
    "    chain(*[v for v in lags_.values() if v is not None])\n",
    "))\n",
    "n_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "type(pd.to_datetime('2020-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import series\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import exog\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import exog_predict\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_train = '2003-03-01 23:59:00'\n",
    "arr = data.to_numpy(copy=True)\n",
    "series = pd.DataFrame(\n",
    "    {'l1': arr,\n",
    "        'l2': arr},\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# Simulated exogenous variable\n",
    "rng = np.random.default_rng(9876)\n",
    "exog = pd.Series(\n",
    "    rng.normal(loc=0, scale=1, size=len(data)), index=data.index, name='exog'\n",
    ")\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor       = LinearRegression(),\n",
    "                    level           = 'l1',\n",
    "                    steps           = 5,\n",
    "                    lags            = 15,\n",
    "                    differentiation = 1,\n",
    "                    transformer_series = StandardScaler()\n",
    "            )\n",
    "forecaster.fit(series=series.loc[:end_train], exog=exog.loc[:end_train])\n",
    "results = forecaster._create_predict_inputs(exog=exog.loc[end_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least one of the arguments `lags` or `window_features` must be different from None. This is required to create the predictors used in training the forecaster.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m \u001b[43mForecasterAutoregMultiVariate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlags\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdifferentiation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtransformer_series\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiVariate\\ForecasterAutoregMultiVariate.py:352\u001b[0m, in \u001b[0;36mForecasterAutoregMultiVariate.__init__\u001b[1;34m(self, regressor, level, steps, lags, window_features, transformer_series, transformer_exog, weight_func, differentiation, fit_kwargs, n_jobs, forecaster_id)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_features_names, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size_window_features \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    349\u001b[0m     initialize_window_features(window_features)\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_lag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    353\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of the arguments `lags` or `window_features` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be different from None. This is required to create the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictors used in training the forecaster.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    359\u001b[0m     [ws \u001b[38;5;28;01mfor\u001b[39;00m ws \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_lag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size_window_features] \n\u001b[0;32m    360\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m ws \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_features_class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one of the arguments `lags` or `window_features` must be different from None. This is required to create the predictors used in training the forecaster."
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor       = LinearRegression(),\n",
    "                    level           = 'l1',\n",
    "                    steps           = 5,\n",
    "                    lags            = {'l1': None, 'l2': None},\n",
    "                    differentiation = 1,\n",
    "                    transformer_series = StandardScaler()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'l1': None, 'l2': np.array([1])}\n",
    "\n",
    "all(value is None for value in my_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "np.random.seed(random_state)\n",
    "\n",
    "n_size = 100\n",
    "residuals = {\n",
    "    1: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    2: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    3: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    4: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    5: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "}\n",
    "# residuals = {\n",
    "#     1: np.array([10] * n_size),\n",
    "#     2: np.array([20] * n_size),\n",
    "#     3: np.array([30] * n_size),\n",
    "#     4: np.array([40] * n_size),\n",
    "#     5: np.array([50] * n_size)\n",
    "# }\n",
    "\n",
    "steps = np.arange(1, 6)\n",
    "\n",
    "n_boot = 150\n",
    "predictions = np.random.normal(loc=0, scale=1, size=len(steps))\n",
    "boot_predictions = np.tile(predictions, (n_boot, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=random_state)\n",
    "for i, step in enumerate(steps):\n",
    "    sampled_residuals = residuals[step][\n",
    "        rng.integers(low=0, high=len(residuals[step]), size=n_boot)\n",
    "    ]\n",
    "    boot_predictions[i, :] = boot_predictions[i, :] + sampled_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 123\n",
    "np.random.seed(random_state)\n",
    "\n",
    "n_size = 100\n",
    "residuals = {\n",
    "    1: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    2: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    3: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    4: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "    5: np.random.normal(loc=0, scale=1, size=n_size),\n",
    "}\n",
    "# residuals = {\n",
    "#     1: np.array([10] * n_size),\n",
    "#     2: np.array([20] * n_size),\n",
    "#     3: np.array([30] * n_size),\n",
    "#     4: np.array([40] * n_size),\n",
    "#     5: np.array([50] * n_size)\n",
    "# }\n",
    "\n",
    "steps = np.arange(1, 6)\n",
    "\n",
    "n_boot = 150\n",
    "predictions = np.random.normal(loc=0, scale=1, size=len(steps))\n",
    "boot_predictions = np.tile(predictions, (n_boot, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1_lag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1_lag_2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1_lag_3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1_roll_mean_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1_roll_sum_5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2_lag_1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2_lag_2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2_lag_3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2_roll_mean_3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2_roll_sum_5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exog_1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "0         l1_lag_1           0\n",
       "1         l1_lag_2          18\n",
       "2         l1_lag_3          11\n",
       "3   l1_roll_mean_3           0\n",
       "4    l1_roll_sum_5          19\n",
       "5         l2_lag_1          12\n",
       "6         l2_lag_2           9\n",
       "7         l2_lag_3           8\n",
       "8   l2_roll_mean_3           7\n",
       "9    l2_roll_sum_5           3\n",
       "10          exog_1          13"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import series as series_2\n",
    "from skforecast.ForecasterAutoregMultiVariate.tests.fixtures_ForecasterAutoregMultiVariate import exog as exog_2\n",
    "\n",
    "rolling = RollingFeatures(stats=['mean', 'sum'], window_sizes=[3, 5])\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor       = LGBMRegressor(verbose=-1, random_state=123),\n",
    "                    level           = 'l1',\n",
    "                    steps           = 2,\n",
    "                    lags            = 3,\n",
    "                    window_features = rolling\n",
    "                )\n",
    "forecaster.fit(series=series_2, exog=exog_2['exog_1'])\n",
    "results = forecaster.get_feature_importances(step=2, sort_importance=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_lag_1',\n",
       " 'l1_lag_2',\n",
       " 'l1_lag_3',\n",
       " 'l1_roll_mean_3',\n",
       " 'l1_roll_sum_5',\n",
       " 'l2_lag_1',\n",
       " 'l2_lag_2',\n",
       " 'l2_lag_3',\n",
       " 'l2_roll_mean_3',\n",
       " 'l2_roll_sum_5',\n",
       " 'exog_1']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 18, 11,  0, 19, 12,  9,  8,  7,  3, 13], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['importance'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
