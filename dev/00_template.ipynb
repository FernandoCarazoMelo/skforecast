{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.preprocessing import TimeSeriesDifferentiator\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "\n",
    "from skforecast.ForecasterAutoreg.tests.fixtures_ForecasterAutoreg import data  # to test results when using differentiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog_predict\n",
    "\n",
    "series_dict = joblib.load(r'C:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\tests\\fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load(r'C:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\tests\\fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}\n",
    "\n",
    "series_2 = pd.DataFrame({'1': pd.Series(np.arange(start=0, stop=50, dtype=float)), \n",
    "                         '2': pd.Series(np.arange(start=50, stop=100, dtype=float))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98327068, -0.88248605, -0.79842631, -0.79277912, -0.77768307,\n",
       "         0.00821644,  1.42962482,         nan,         nan],\n",
       "       [-0.12514786, -0.98327068, -0.88248605, -0.79842631, -0.79277912,\n",
       "         1.11220226,  0.89634375,         nan,         nan],\n",
       "       [-0.12514786, -0.12514786, -0.98327068, -0.88248605, -0.79842631,\n",
       "         1.38486425, -0.30192795,         nan,         nan],\n",
       "       [-0.07645311, -0.12514786, -0.12514786, -0.98327068, -0.88248605,\n",
       "         0.62088235, -1.26286725,         nan,         nan],\n",
       "       [-0.07645311, -0.07645311, -0.12514786, -0.12514786, -0.98327068,\n",
       "        -0.60444947, -1.26286725,         nan,         nan]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor          = LGBMRegressor(\n",
    "        n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "    ),\n",
    "    lags               = 5,\n",
    "    encoding           = None,\n",
    "    dropna_from_series = False,\n",
    "    transformer_series = StandardScaler(),\n",
    "    transformer_exog   = StandardScaler()\n",
    ")\n",
    "forecaster.fit(\n",
    "    series=series_dict_train, exog=exog_dict_train, suppress_warnings=True\n",
    ")\n",
    "levels = ['id_1000', 'id_1001', 'id_1003', 'id_1004', 'id_1005']\n",
    "last_window = pd.DataFrame(\n",
    "    {k: v for k, v in forecaster.last_window_.items() if k in levels}\n",
    ")\n",
    "last_window['id_1005'] = last_window['id_1004']\n",
    "exog_dict_test_2 = exog_dict_test.copy()\n",
    "exog_dict_test_2['id_1005'] = exog_dict_test_2['id_1004']\n",
    "results = forecaster.create_predict_X(\n",
    "    steps=5, levels=levels, last_window=last_window, exog=exog_dict_test_2, suppress_warnings=True\n",
    ")\n",
    "results['id_1000'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22899343,  1.65819658,  2.4318926 ,  2.56743042,  2.38367241,\n",
       "         0.00821644,  1.42962482,  1.11141113, -0.87943526],\n",
       "       [ 0.12663112,  1.22899343,  1.65819658,  2.4318926 ,  2.56743042,\n",
       "         1.11220226,  0.89634375,  1.1327558 ,  0.0058948 ],\n",
       "       [ 0.01290134,  0.12663112,  1.22899343,  1.65819658,  2.4318926 ,\n",
       "         1.38486425, -0.30192795,  1.1775869 , -0.3532584 ],\n",
       "       [ 0.01290134,  0.01290134,  0.12663112,  1.22899343,  1.65819658,\n",
       "         0.62088235, -1.26286725,  1.0428337 ,  0.84287284],\n",
       "       [ 0.01290134,  0.01290134,  0.01290134,  0.12663112,  1.22899343,\n",
       "        -0.60444947, -1.26286725,  1.00599776, -0.62314633]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['id_1005'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>roll_mean_5</th>\n",
       "      <th>roll_median_5</th>\n",
       "      <th>roll_sum_6</th>\n",
       "      <th>exog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-04-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>1.161729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>0.294688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-06-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>-0.439976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-07-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>1.250084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-08-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>1.374969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-01</th>\n",
       "      <td>2.043333</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>2.261869</td>\n",
       "      <td>2.366796</td>\n",
       "      <td>13.686322</td>\n",
       "      <td>-0.416732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lag_1     lag_5  roll_mean_5  roll_median_5  roll_sum_6  \\\n",
       "2003-04-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "2003-05-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "2003-06-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "2003-07-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "2003-08-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "2003-09-01  2.043333  2.366796     2.261869       2.366796   13.686322   \n",
       "\n",
       "                exog  \n",
       "2003-04-01  1.161729  \n",
       "2003-05-01  0.294688  \n",
       "2003-06-01 -0.439976  \n",
       "2003-07-01  1.250084  \n",
       "2003-08-01  1.374969  \n",
       "2003-09-01 -0.416732  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_train = '2003-03-01 23:59:00'\n",
    "\n",
    "# Simulated exogenous variable\n",
    "rng = np.random.default_rng(9876)\n",
    "exog = pd.Series(\n",
    "    rng.normal(loc=0, scale=1, size=len(data)), index=data.index, name='exog'\n",
    ")\n",
    "rolling = RollingFeatures(stats=['mean', 'median'], window_sizes=[5, 5])\n",
    "rolling_2 = RollingFeatures(stats='sum', window_sizes=[6])\n",
    "\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                    regressor        = LinearRegression(),\n",
    "                    lags             = [1, 5],\n",
    "                    window_features  = [rolling, rolling_2],\n",
    "                    steps            = 6,\n",
    "                    transformer_y    = None,\n",
    "                    transformer_exog = None,\n",
    "                    differentiation  = None\n",
    "                )\n",
    "forecaster.fit(y=data.loc[:end_train], exog=exog.loc[:end_train])\n",
    "X_predict = forecaster.create_predict_X(exog=exog.loc[end_train:])\n",
    "X_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.19238587]\n",
      "[2.23555505]\n",
      "[2.25654547]\n",
      "[2.34763646]\n",
      "[2.31040474]\n",
      "[2.43900132]\n"
     ]
    }
   ],
   "source": [
    "for i, step in enumerate(range(1, forecaster.steps + 1)):\n",
    "    print(forecaster.regressors_[step].predict(X_predict.iloc[[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.23555505])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.predict(steps=[2], exog=exog.loc[end_train:]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skforecast.model_selection._split import BaseFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_params = {\n",
    "    \"steps\": 5,\n",
    "    \"initial_train_size\": 100,\n",
    "    \"window_size\": 10,\n",
    "    \"differentiation\": None,\n",
    "    \"refit\": True,\n",
    "    \"fixed_train_size\": True,\n",
    "    \"gap\": 0,\n",
    "    \"skip_folds\": None,\n",
    "    \"allow_incomplete_fold\": True,\n",
    "    \"return_all_indexes\": False,\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = BaseFold()\n",
    "params = dict(valid_params)\n",
    "params[\"initial_train_size\"] = \"invalid\"\n",
    "msg = (\n",
    "    f\"`initial_train_size` must be an integer greater than 0 or None. \"\n",
    "    f\"Got {params[\"initial_train_size\"]}.\"\n",
    ")\n",
    "with pytest.raises(ValueError, match=msg):\n",
    "    cv._validate_params(cv_name=\"TimeSeriesFold\", **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params is valid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': 5,\n",
       " 'initial_train_size': 'invalid',\n",
       " 'window_size': 10,\n",
       " 'differentiation': None,\n",
       " 'refit': True,\n",
       " 'fixed_train_size': True,\n",
       " 'gap': 0,\n",
       " 'skip_folds': None,\n",
       " 'allow_incomplete_fold': True,\n",
       " 'return_all_indexes': False,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
