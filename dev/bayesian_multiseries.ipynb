{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "import sklearn.pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_log_error,\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "from skforecast.utils import select_n_jobs_backtesting\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(name)-10s %(levelname)-5s %(message)s', \n",
    "    level  = logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "url = (\n",
    "       'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/'\n",
    "       'data/simulated_items_sales.csv'\n",
    ")\n",
    "data = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _initialize_levels_model_selection_multiseries\n",
    "\n",
    "\n",
    "def bayesian_search_forecaster(\n",
    "    forecaster,\n",
    "    series: pd.DataFrame,\n",
    "    search_space: Callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    levels: Optional[Union[str, list]]=None,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    n_jobs: Optional[Union[int, str]]='auto',\n",
    "    verbose: bool=True,\n",
    "    show_progress: bool=True,\n",
    "    engine: str='optuna',\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using multi-series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate\n",
    "        Forecaster model.\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    search_space : Callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        - If `string`: {'mean_squared_error', 'mean_absolute_error',\n",
    "        'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "        - If `Callable`: Function with arguments y_true, y_pred that returns \n",
    "        a float.\n",
    "        - If `list`: List containing multiple strings and/or Callables.\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    levels : str, list, default `None`\n",
    "        level (`str`) or levels (`list`) at which the forecaster is optimized. \n",
    "        If `None`, all levels are taken into account. The resulting metric will be\n",
    "        the average of the optimization of all levels.\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "    n_jobs : int, 'auto', default `'auto'`\n",
    "        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n",
    "        set to the number of cores. If 'auto', `n_jobs` is set using the function\n",
    "        skforecast.utils.select_n_jobs_backtesting.\n",
    "        **New in version 0.9.0**\n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar.\n",
    "    engine : str, default `'optuna'`\n",
    "        Bayesian optimization runs through the optuna library.\n",
    "    kwargs_create_study : dict, default `{'direction': 'minimize', 'sampler': TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "        - column levels: levels configuration for each iteration.\n",
    "        - column lags: lags configuration for each iteration.\n",
    "        - column params: parameters configuration for each iteration.\n",
    "        - column metric: metric value estimated for each iteration. The resulting \n",
    "        metric will be the average of the optimization of all levels.\n",
    "        - additional n columns with param = value.\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if return_best and exog is not None and (len(exog) != len(series)):\n",
    "        raise ValueError(\n",
    "            (f\"`exog` must have same number of samples as `series`. \"\n",
    "             f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "        )\n",
    "\n",
    "    if engine not in ['optuna']:\n",
    "        raise ValueError(\n",
    "            f\"`engine` only allows 'optuna', got {engine}.\"\n",
    "        )\n",
    "\n",
    "    results, results_opt_best = _bayesian_search_optuna_multiseries(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    series                = series,\n",
    "                                    exog                  = exog,\n",
    "                                    levels                = levels, \n",
    "                                    lags_grid             = lags_grid,\n",
    "                                    search_space          = search_space,\n",
    "                                    steps                 = steps,\n",
    "                                    metric                = metric,\n",
    "                                    refit                 = refit,\n",
    "                                    initial_train_size    = initial_train_size,\n",
    "                                    fixed_train_size      = fixed_train_size,\n",
    "                                    gap                   = gap,\n",
    "                                    allow_incomplete_fold = allow_incomplete_fold,\n",
    "                                    n_trials              = n_trials,\n",
    "                                    random_state          = random_state,\n",
    "                                    return_best           = return_best,\n",
    "                                    n_jobs                = n_jobs,\n",
    "                                    verbose               = verbose,\n",
    "                                    show_progress         = show_progress,\n",
    "                                    kwargs_create_study   = kwargs_create_study,\n",
    "                                    kwargs_study_optimize = kwargs_study_optimize\n",
    "                                )\n",
    "\n",
    "    return results, results_opt_best\n",
    "\n",
    "\n",
    "def _bayesian_search_optuna_multiseries(\n",
    "    forecaster,\n",
    "    series: pd.DataFrame,\n",
    "    search_space: Callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    levels: Optional[Union[str, list]]=None,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    n_jobs: Optional[Union[int, str]]='auto',\n",
    "    verbose: bool=True,\n",
    "    show_progress: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using multi-series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate\n",
    "        Forecaster model.\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    search_space : Callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        - If `string`: {'mean_squared_error', 'mean_absolute_error',\n",
    "        'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "        - If `Callable`: Function with arguments y_true, y_pred that returns \n",
    "        a float.\n",
    "        - If `list`: List containing multiple strings and/or Callables.\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    levels : str, list, default `None`\n",
    "        level (`str`) or levels (`list`) at which the forecaster is optimized. \n",
    "        If `None`, all levels are taken into account. The resulting metric will be\n",
    "        the average of the optimization of all levels.\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "    n_jobs : int, 'auto', default `'auto'`\n",
    "        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n",
    "        set to the number of cores. If 'auto', `n_jobs` is set using the function\n",
    "        skforecast.utils.select_n_jobs_backtesting.\n",
    "        **New in version 0.9.0**\n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar.\n",
    "    kwargs_create_study : dict, default `{'direction': 'minimize', 'sampler': TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "        - column levels: levels configuration for each iteration.\n",
    "        - column lags: lags configuration for each iteration.\n",
    "        - column params: parameters configuration for each iteration.\n",
    "        - column metric: metric value estimated for each iteration. The resulting \n",
    "        metric will be the average of the optimization of all levels.\n",
    "        - additional n columns with param = value.\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    levels = _initialize_levels_model_selection_multiseries(\n",
    "                 forecaster = forecaster,\n",
    "                 series     = series,\n",
    "                 levels     = levels\n",
    "             )\n",
    "\n",
    "    if type(forecaster).__name__ == 'ForecasterAutoregMultiSeriesCustom':\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                \"`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregMultiSeriesCustom`.\",\n",
    "                IgnoredArgumentWarning\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric = [metric] \n",
    "    metric_dict = {(m if isinstance(m, str) else m.__name__): [] \n",
    "                   for m in metric}\n",
    "    \n",
    "    if len(metric_dict) != len(metric):\n",
    "        raise ValueError(\n",
    "            \"When `metric` is a `list`, each metric name must be unique.\"\n",
    "        )\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        search_space          = search_space,\n",
    "        forecaster            = forecaster,\n",
    "        series                = series,\n",
    "        exog                  = exog,\n",
    "        steps                 = steps,\n",
    "        levels                = levels,\n",
    "        metric                = metric,\n",
    "        initial_train_size    = initial_train_size,\n",
    "        fixed_train_size      = fixed_train_size,\n",
    "        gap                   = gap,\n",
    "        allow_incomplete_fold = allow_incomplete_fold,\n",
    "        refit                 = refit,\n",
    "        n_jobs                = n_jobs,\n",
    "        verbose               = verbose\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(search_space(trial))\n",
    "        \n",
    "        metrics_levels = backtesting_forecaster_multiseries(\n",
    "                             forecaster            = forecaster,\n",
    "                             series                = series,\n",
    "                             exog                  = exog,\n",
    "                             steps                 = steps,\n",
    "                             levels                = levels,\n",
    "                             metric                = metric,\n",
    "                             initial_train_size    = initial_train_size,\n",
    "                             fixed_train_size      = fixed_train_size,\n",
    "                             gap                   = gap,\n",
    "                             allow_incomplete_fold = allow_incomplete_fold,\n",
    "                             refit                 = refit,\n",
    "                             n_jobs                = n_jobs,\n",
    "                             verbose               = verbose,\n",
    "                             show_progress         = False\n",
    "                         )[0]\n",
    "        # Store metrics in the variable metric_values defined outside _objective.\n",
    "        nonlocal metric_values\n",
    "        metric_values.append(metrics_levels)\n",
    "\n",
    "        return metrics_levels.iloc[:, 1].mean()\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)},\n",
    "         {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    if show_progress:\n",
    "        lags_grid = tqdm(lags_grid, desc='lags grid', position=0)\n",
    "\n",
    "    for lags in lags_grid:\n",
    "        metric_values = [] # This variable will be modified inside _objective function. \n",
    "        # It is a trick to extract multiple values from _objective function since\n",
    "        # only the optimized value can be returned.\n",
    "\n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)\n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise ValueError(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "        \n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "\n",
    "            m_values = metric_values[i]\n",
    "            for m in metric:\n",
    "                m_name = m if isinstance(m, str) else m.__name__\n",
    "                metric_dict[m_name].append(m_values[m_name].mean())\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "                  'levels': [levels]*len(lags_list),\n",
    "                  'lags'  : lags_list,\n",
    "                  'params': params_list,\n",
    "                  **metric_dict\n",
    "              })\n",
    "\n",
    "    results = results.sort_values(by=list(metric_dict.keys())[0], ascending=True)\n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results[list(metric_dict.keys())[0]].iloc[0]\n",
    "        \n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(best_params)\n",
    "        forecaster.fit(series=series, exog=exog, store_in_sample_residuals=True)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, \"\n",
    "            f\"and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "            f\"  Levels: {results['levels'].iloc[0]}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.603060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341\n",
       "2  0.226851  0.603060"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "\n",
    "series.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b099852d9d1b491a9150022344095d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 0.149...</td>\n",
       "      <td>0.209610</td>\n",
       "      <td>12</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 0.246...</td>\n",
       "      <td>0.209730</td>\n",
       "      <td>15</td>\n",
       "      <td>0.246671</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.210...</td>\n",
       "      <td>0.211587</td>\n",
       "      <td>17</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.193...</td>\n",
       "      <td>0.212235</td>\n",
       "      <td>17</td>\n",
       "      <td>0.193259</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.311...</td>\n",
       "      <td>0.212961</td>\n",
       "      <td>14</td>\n",
       "      <td>0.311663</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.114...</td>\n",
       "      <td>0.213406</td>\n",
       "      <td>14</td>\n",
       "      <td>0.114730</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.264...</td>\n",
       "      <td>0.214647</td>\n",
       "      <td>17</td>\n",
       "      <td>0.264915</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 0.246...</td>\n",
       "      <td>0.215478</td>\n",
       "      <td>15</td>\n",
       "      <td>0.246671</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.782...</td>\n",
       "      <td>0.215708</td>\n",
       "      <td>14</td>\n",
       "      <td>0.782329</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 0.427...</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>13</td>\n",
       "      <td>0.427539</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 0.707...</td>\n",
       "      <td>0.216166</td>\n",
       "      <td>16</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 0.707...</td>\n",
       "      <td>0.216349</td>\n",
       "      <td>16</td>\n",
       "      <td>0.707020</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.782...</td>\n",
       "      <td>0.216538</td>\n",
       "      <td>14</td>\n",
       "      <td>0.782329</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 0.427...</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>13</td>\n",
       "      <td>0.427539</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.264...</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>17</td>\n",
       "      <td>0.264915</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.193...</td>\n",
       "      <td>0.217065</td>\n",
       "      <td>17</td>\n",
       "      <td>0.193259</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 17, 'min_samples_leaf': 0.210...</td>\n",
       "      <td>0.217322</td>\n",
       "      <td>17</td>\n",
       "      <td>0.210358</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.311...</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>14</td>\n",
       "      <td>0.311663</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 0.149...</td>\n",
       "      <td>0.219903</td>\n",
       "      <td>12</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[l1, l2]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 0.114...</td>\n",
       "      <td>0.224938</td>\n",
       "      <td>14</td>\n",
       "      <td>0.114730</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      levels          lags                                             params  \\\n",
       "4   [l1, l2]        [1, 2]  {'n_estimators': 12, 'min_samples_leaf': 0.149...   \n",
       "2   [l1, l2]        [1, 2]  {'n_estimators': 15, 'min_samples_leaf': 0.246...   \n",
       "6   [l1, l2]        [1, 2]  {'n_estimators': 17, 'min_samples_leaf': 0.210...   \n",
       "0   [l1, l2]        [1, 2]  {'n_estimators': 17, 'min_samples_leaf': 0.193...   \n",
       "8   [l1, l2]        [1, 2]  {'n_estimators': 14, 'min_samples_leaf': 0.311...   \n",
       "3   [l1, l2]        [1, 2]  {'n_estimators': 14, 'min_samples_leaf': 0.114...   \n",
       "1   [l1, l2]        [1, 2]  {'n_estimators': 17, 'min_samples_leaf': 0.264...   \n",
       "12  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 15, 'min_samples_leaf': 0.246...   \n",
       "19  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 14, 'min_samples_leaf': 0.782...   \n",
       "17  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 13, 'min_samples_leaf': 0.427...   \n",
       "15  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 16, 'min_samples_leaf': 0.707...   \n",
       "5   [l1, l2]        [1, 2]  {'n_estimators': 16, 'min_samples_leaf': 0.707...   \n",
       "9   [l1, l2]        [1, 2]  {'n_estimators': 14, 'min_samples_leaf': 0.782...   \n",
       "7   [l1, l2]        [1, 2]  {'n_estimators': 13, 'min_samples_leaf': 0.427...   \n",
       "11  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 17, 'min_samples_leaf': 0.264...   \n",
       "10  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 17, 'min_samples_leaf': 0.193...   \n",
       "16  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 17, 'min_samples_leaf': 0.210...   \n",
       "18  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 14, 'min_samples_leaf': 0.311...   \n",
       "14  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 12, 'min_samples_leaf': 0.149...   \n",
       "13  [l1, l2]  [1, 2, 3, 4]  {'n_estimators': 14, 'min_samples_leaf': 0.114...   \n",
       "\n",
       "    mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "4              0.209610            12          0.149779         sqrt  \n",
       "2              0.209730            15          0.246671         sqrt  \n",
       "6              0.211587            17          0.210358         log2  \n",
       "0              0.212235            17          0.193259         sqrt  \n",
       "8              0.212961            14          0.311663         log2  \n",
       "3              0.213406            14          0.114730         sqrt  \n",
       "1              0.214647            17          0.264915         log2  \n",
       "12             0.215478            15          0.246671         sqrt  \n",
       "19             0.215708            14          0.782329         log2  \n",
       "17             0.215743            13          0.427539         sqrt  \n",
       "15             0.216166            16          0.707020         log2  \n",
       "5              0.216349            16          0.707020         log2  \n",
       "9              0.216538            14          0.782329         log2  \n",
       "7              0.216657            13          0.427539         sqrt  \n",
       "11             0.216847            17          0.264915         log2  \n",
       "10             0.217065            17          0.193259         sqrt  \n",
       "16             0.217322            17          0.210358         log2  \n",
       "18             0.218391            14          0.311663         log2  \n",
       "14             0.219903            12          0.149779         sqrt  \n",
       "13             0.224938            14          0.114730         sqrt  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor = RandomForestRegressor(random_state=123),\n",
    "                    lags      = 2 # Placeholder, the value will be overwritten\n",
    "                 )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "lags_grid = [2, 4]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "                        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 1., log=True),\n",
    "                        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])}\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results = _bayesian_search_optuna_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                lags_grid          = lags_grid,\n",
    "                search_space       = search_space,\n",
    "                steps              = steps,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = True,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                fixed_train_size   = True,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False\n",
    "            )[0]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in results['lags'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'n_estimators': 12, 'min_samples_leaf': 0.14977928606210794, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 15, 'min_samples_leaf': 0.2466706727024324, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.21035794225904136, 'max_features': 'log2'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.19325882509735576, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.3116628929828935, 'max_features': 'log2'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.1147302385573586, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.2649149454284987, 'max_features': 'log2'},\n",
       "       {'n_estimators': 15, 'min_samples_leaf': 0.2466706727024324, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.782328520465639, 'max_features': 'log2'},\n",
       "       {'n_estimators': 13, 'min_samples_leaf': 0.42753938073418213, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 16, 'min_samples_leaf': 0.707020154488976, 'max_features': 'log2'},\n",
       "       {'n_estimators': 16, 'min_samples_leaf': 0.707020154488976, 'max_features': 'log2'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.782328520465639, 'max_features': 'log2'},\n",
       "       {'n_estimators': 13, 'min_samples_leaf': 0.42753938073418213, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.2649149454284987, 'max_features': 'log2'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.19325882509735576, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 17, 'min_samples_leaf': 0.21035794225904136, 'max_features': 'log2'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.3116628929828935, 'max_features': 'log2'},\n",
       "       {'n_estimators': 12, 'min_samples_leaf': 0.14977928606210794, 'max_features': 'sqrt'},\n",
       "       {'n_estimators': 14, 'min_samples_leaf': 0.1147302385573586, 'max_features': 'sqrt'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['params'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20961049, 0.20973005, 0.21158737, 0.21223533, 0.21296057,\n",
       "       0.21340636, 0.21464693, 0.2154781 , 0.21570766, 0.2157434 ,\n",
       "       0.21616556, 0.21634926, 0.2165384 , 0.21665671, 0.21684708,\n",
       "       0.21706527, 0.21732157, 0.21839139, 0.21990283, 0.22493842])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mean_absolute_error'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 17, 17, 14, 14, 17, 15, 14, 13, 16, 16, 14, 13, 17, 17, 17,\n",
       "       14, 12, 14], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['n_estimators'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14977929, 0.24667067, 0.21035794, 0.19325883, 0.31166289,\n",
       "       0.11473024, 0.26491495, 0.24667067, 0.78232852, 0.42753938,\n",
       "       0.70702015, 0.70702015, 0.78232852, 0.42753938, 0.26491495,\n",
       "       0.19325883, 0.21035794, 0.31166289, 0.14977929, 0.11473024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['min_samples_leaf'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sqrt', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "       'log2', 'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "       'log2', 'log2', 'sqrt', 'sqrt'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['max_features'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([4, 2, 6, 0, 8, 3, 1, 12, 19, 17, 15, 5, 9, 7, 11, 10, 16, 18, 14, 13], dtype='int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d20eed54a5b4c77ade856475510dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor = RandomForestRegressor(random_state=123),\n",
    "                    lags      = 2 # Placeholder, the value will be overwritten\n",
    "                 )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "lags_grid = [2, 4]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "                        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 1., log=True),\n",
    "                        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])}\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "results = _bayesian_search_optuna_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                lags_grid          = lags_grid,\n",
    "                search_space       = search_space,\n",
    "                steps              = steps,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = True,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                fixed_train_size   = True,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False\n",
    "            )[0]\n",
    "\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': [['l1', 'l2']]*2*10,\n",
    "    'lags'  :[[1, 2], [1, 2], [1, 2], [1, 2], [1, 2],\n",
    "                [1, 2], [1, 2], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4],\n",
    "                [1, 2, 3, 4], [1, 2], [1, 2], [1, 2], [1, 2, 3, 4],\n",
    "                [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],\n",
    "    'params':[{'n_estimators': 12, 'min_samples_leaf': 0.14977928606210794, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 15, 'min_samples_leaf': 0.2466706727024324, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.21035794225904136, 'max_features': 'log2'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.19325882509735576, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.3116628929828935, 'max_features': 'log2'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.1147302385573586, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.2649149454284987, 'max_features': 'log2'},\n",
    "                {'n_estimators': 15, 'min_samples_leaf': 0.2466706727024324, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.782328520465639, 'max_features': 'log2'},\n",
    "                {'n_estimators': 13, 'min_samples_leaf': 0.42753938073418213, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 16, 'min_samples_leaf': 0.707020154488976, 'max_features': 'log2'},\n",
    "                {'n_estimators': 16, 'min_samples_leaf': 0.707020154488976, 'max_features': 'log2'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.782328520465639, 'max_features': 'log2'},\n",
    "                {'n_estimators': 13, 'min_samples_leaf': 0.42753938073418213, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.2649149454284987, 'max_features': 'log2'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.19325882509735576, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 17, 'min_samples_leaf': 0.21035794225904136, 'max_features': 'log2'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.3116628929828935, 'max_features': 'log2'},\n",
    "                {'n_estimators': 12, 'min_samples_leaf': 0.14977928606210794, 'max_features': 'sqrt'},\n",
    "                {'n_estimators': 14, 'min_samples_leaf': 0.1147302385573586, 'max_features': 'sqrt'}],\n",
    "    'mean_absolute_error':np.array([0.20961049, 0.20973005, 0.21158737, 0.21223533, 0.21296057,\n",
    "                                    0.21340636, 0.21464693, 0.2154781 , 0.21570766, 0.2157434 ,\n",
    "                                    0.21616556, 0.21634926, 0.2165384 , 0.21665671, 0.21684708,\n",
    "                                    0.21706527, 0.21732157, 0.21839139, 0.21990283, 0.22493842]),                                                               \n",
    "    'n_estimators' :np.array([12, 15, 17, 17, 14, 14, 17, 15, 14, 13, 16, 16, 14, 13, 17, 17, 17, 14, 12, 14]),\n",
    "    'min_samples_leaf' :np.array([0.14977929, 0.24667067, 0.21035794, 0.19325883, 0.31166289,\n",
    "                                    0.11473024, 0.26491495, 0.24667067, 0.78232852, 0.42753938,\n",
    "                                    0.70702015, 0.70702015, 0.78232852, 0.42753938, 0.26491495,\n",
    "                                    0.19325883, 0.21035794, 0.31166289, 0.14977929, 0.11473024]),\n",
    "    'max_features' :['sqrt', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt',\n",
    "                        'log2', 'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
    "                        'log2', 'log2', 'sqrt', 'sqrt']\n",
    "    },\n",
    "    index=pd.Index([4, 2, 6, 0, 8, 3, 1, 12, 19, 17, 15, 5, 9, 7, 11, 10, 16, 18, 14, 13], dtype=\"int64\")\n",
    ").sort_values(by='mean_absolute_error', ascending=True)\n",
    "\n",
    "pd.testing.assert_frame_equal(results, expected_results, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                lags      = 4\n",
    "             )\n",
    "\n",
    "steps              = 3\n",
    "metric             = 'mean_absolute_error'\n",
    "levels             = ['l1']\n",
    "n_validation       = 12\n",
    "initial_train_size = len(series) - n_validation\n",
    "fixed_train_size   = True\n",
    "refit              = True\n",
    "verbose            = False\n",
    "show_progress      = False\n",
    "\n",
    "n_trials = 10\n",
    "random_state = 123\n",
    "\n",
    "def objective(\n",
    "    trial,\n",
    "    forecaster         = forecaster,\n",
    "    series             = series,\n",
    "    levels             = levels,\n",
    "    steps              = steps,\n",
    "    metric             = metric,\n",
    "    initial_train_size = initial_train_size,\n",
    "    fixed_train_size   = fixed_train_size,\n",
    "    refit              = refit,\n",
    "    verbose            = verbose,\n",
    "    show_progress      = show_progress\n",
    ") -> float:\n",
    "    \n",
    "    alpha = trial.suggest_float('alpha', 1e-2, 1.0)\n",
    "    \n",
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor = Ridge(random_state=random_state, \n",
    "                                        alpha=alpha),\n",
    "                    lags      = 4\n",
    "                    )\n",
    "\n",
    "    metrics_levels, _ = backtesting_forecaster_multiseries(\n",
    "                            forecaster         = forecaster,\n",
    "                            series             = series,\n",
    "                            levels             = levels,\n",
    "                            steps              = steps,\n",
    "                            metric             = metric,\n",
    "                            initial_train_size = initial_train_size,\n",
    "                            fixed_train_size   = fixed_train_size,\n",
    "                            refit              = refit,\n",
    "                            verbose            = verbose,\n",
    "                            show_progress      = show_progress     \n",
    "                        )\n",
    "\n",
    "    return abs(metrics_levels.iloc[:, 1].mean())\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", \n",
    "                            sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "lags_grid = [2, 4]\n",
    "def search_space(trial):\n",
    "    search_space  = {'alpha': trial.suggest_float('alpha', 1e-2, 1.0)}\n",
    "\n",
    "    return search_space\n",
    "\n",
    "return_best  = False\n",
    "\n",
    "_, results_opt_best = _bayesian_search_optuna_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = series,\n",
    "                        levels             = levels, \n",
    "                        lags_grid          = lags_grid,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        metric             = metric,\n",
    "                        refit              = refit,\n",
    "                        initial_train_size = initial_train_size,\n",
    "                        fixed_train_size   = fixed_train_size,\n",
    "                        n_trials           = n_trials,\n",
    "                        return_best        = return_best,\n",
    "                        verbose            = verbose,\n",
    "                        show_progress      = show_progress\n",
    "                    )\n",
    "\n",
    "assert best_trial.number == results_opt_best.number\n",
    "assert best_trial.values == results_opt_best.values\n",
    "assert best_trial.params == results_opt_best.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.215850</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.215857</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.215871</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.215874</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.215890</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.215908</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.215911</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.216304</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.216306</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.216310</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.216312</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.216319</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.216329</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels          lags                          params  mean_absolute_error  \\\n",
       "12   [l1]  [1, 2, 3, 4]   {'alpha': 0.2345829390285611}             0.215850   \n",
       "11   [l1]  [1, 2, 3, 4]  {'alpha': 0.29327794160087567}             0.215857   \n",
       "19   [l1]  [1, 2, 3, 4]    {'alpha': 0.398196343012209}             0.215871   \n",
       "15   [l1]  [1, 2, 3, 4]  {'alpha': 0.42887539552321635}             0.215874   \n",
       "18   [l1]  [1, 2, 3, 4]  {'alpha': 0.48612258246951734}             0.215882   \n",
       "13   [l1]  [1, 2, 3, 4]   {'alpha': 0.5558016213920624}             0.215890   \n",
       "17   [l1]  [1, 2, 3, 4]   {'alpha': 0.6879814411990146}             0.215907   \n",
       "10   [l1]  [1, 2, 3, 4]   {'alpha': 0.6995044937418831}             0.215908   \n",
       "14   [l1]  [1, 2, 3, 4]   {'alpha': 0.7222742800877074}             0.215911   \n",
       "16   [l1]  [1, 2, 3, 4]   {'alpha': 0.9809565564007693}             0.215942   \n",
       "2    [l1]        [1, 2]   {'alpha': 0.2345829390285611}             0.216304   \n",
       "1    [l1]        [1, 2]  {'alpha': 0.29327794160087567}             0.216306   \n",
       "9    [l1]        [1, 2]    {'alpha': 0.398196343012209}             0.216309   \n",
       "5    [l1]        [1, 2]  {'alpha': 0.42887539552321635}             0.216310   \n",
       "8    [l1]        [1, 2]  {'alpha': 0.48612258246951734}             0.216312   \n",
       "3    [l1]        [1, 2]   {'alpha': 0.5558016213920624}             0.216315   \n",
       "7    [l1]        [1, 2]   {'alpha': 0.6879814411990146}             0.216319   \n",
       "0    [l1]        [1, 2]   {'alpha': 0.6995044937418831}             0.216320   \n",
       "4    [l1]        [1, 2]   {'alpha': 0.7222742800877074}             0.216320   \n",
       "6    [l1]        [1, 2]   {'alpha': 0.9809565564007693}             0.216329   \n",
       "\n",
       "       alpha  \n",
       "12  0.234583  \n",
       "11  0.293278  \n",
       "19  0.398196  \n",
       "15  0.428875  \n",
       "18  0.486123  \n",
       "13  0.555802  \n",
       "17  0.687981  \n",
       "10  0.699504  \n",
       "14  0.722274  \n",
       "16  0.980957  \n",
       "2   0.234583  \n",
       "1   0.293278  \n",
       "9   0.398196  \n",
       "5   0.428875  \n",
       "8   0.486123  \n",
       "3   0.555802  \n",
       "7   0.687981  \n",
       "0   0.699504  \n",
       "4   0.722274  \n",
       "6   0.980957  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in _['lags'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693},\n",
       "       {'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['params'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21584992, 0.21585737, 0.2158706 , 0.21587445, 0.2158816 ,\n",
       "       0.21589025, 0.21590653, 0.21590794, 0.21591073, 0.21594197,\n",
       "       0.2163035 , 0.21630557, 0.21630925, 0.21631032, 0.21631231,\n",
       "       0.21631472, 0.21631927, 0.21631967, 0.21632045, 0.21632921])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['mean_absolute_error'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656,\n",
       "       0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['alpha'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([12, 11, 19, 15, 18, 13, 17, 10, 14, 16, 2, 1, 9, 5, 8, 3, 7, 0, 4, 6], dtype='int64')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
