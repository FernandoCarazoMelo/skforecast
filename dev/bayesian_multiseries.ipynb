{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "import sklearn.pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_log_error,\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "from skforecast.utils import select_n_jobs_backtesting\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(name)-10s %(levelname)-5s %(message)s', \n",
    "    level  = logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "url = (\n",
    "       'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/'\n",
    "       'data/simulated_items_sales.csv'\n",
    ")\n",
    "data = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _initialize_levels_model_selection_multiseries\n",
    "\n",
    "\n",
    "def bayesian_search_forecaster_dev(\n",
    "    forecaster,\n",
    "    series: pd.DataFrame,\n",
    "    search_space: Callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    levels: Optional[Union[str, list]]=None,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    n_jobs: Optional[Union[int, str]]='auto',\n",
    "    verbose: bool=True,\n",
    "    show_progress: bool=True,\n",
    "    engine: str='optuna',\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using multi-series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate\n",
    "        Forecaster model.\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    search_space : Callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        - If `string`: {'mean_squared_error', 'mean_absolute_error',\n",
    "        'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "        - If `Callable`: Function with arguments y_true, y_pred that returns \n",
    "        a float.\n",
    "        - If `list`: List containing multiple strings and/or Callables.\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    levels : str, list, default `None`\n",
    "        level (`str`) or levels (`list`) at which the forecaster is optimized. \n",
    "        If `None`, all levels are taken into account. The resulting metric will be\n",
    "        the average of the optimization of all levels.\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "    n_jobs : int, 'auto', default `'auto'`\n",
    "        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n",
    "        set to the number of cores. If 'auto', `n_jobs` is set using the function\n",
    "        skforecast.utils.select_n_jobs_backtesting.\n",
    "        **New in version 0.9.0**\n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar.\n",
    "    engine : str, default `'optuna'`\n",
    "        Bayesian optimization runs through the optuna library.\n",
    "    kwargs_create_study : dict, default `{'direction': 'minimize', 'sampler': TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "        - column levels: levels configuration for each iteration.\n",
    "        - column lags: lags configuration for each iteration.\n",
    "        - column params: parameters configuration for each iteration.\n",
    "        - column metric: metric value estimated for each iteration. The resulting \n",
    "        metric will be the average of the optimization of all levels.\n",
    "        - additional n columns with param = value.\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if return_best and exog is not None and (len(exog) != len(series)):\n",
    "        raise ValueError(\n",
    "            (f\"`exog` must have same number of samples as `series`. \"\n",
    "             f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "        )\n",
    "\n",
    "    if engine not in ['optuna']:\n",
    "        raise ValueError(\n",
    "            f\"`engine` only allows 'optuna', got {engine}.\"\n",
    "        )\n",
    "\n",
    "    results, results_opt_best = _bayesian_search_optuna_multiseries(\n",
    "                                    forecaster            = forecaster,\n",
    "                                    series                = series,\n",
    "                                    exog                  = exog,\n",
    "                                    levels                = levels, \n",
    "                                    lags_grid             = lags_grid,\n",
    "                                    search_space          = search_space,\n",
    "                                    steps                 = steps,\n",
    "                                    metric                = metric,\n",
    "                                    refit                 = refit,\n",
    "                                    initial_train_size    = initial_train_size,\n",
    "                                    fixed_train_size      = fixed_train_size,\n",
    "                                    gap                   = gap,\n",
    "                                    allow_incomplete_fold = allow_incomplete_fold,\n",
    "                                    n_trials              = n_trials,\n",
    "                                    random_state          = random_state,\n",
    "                                    return_best           = return_best,\n",
    "                                    n_jobs                = n_jobs,\n",
    "                                    verbose               = verbose,\n",
    "                                    show_progress         = show_progress,\n",
    "                                    kwargs_create_study   = kwargs_create_study,\n",
    "                                    kwargs_study_optimize = kwargs_study_optimize\n",
    "                                )\n",
    "\n",
    "    return results, results_opt_best\n",
    "\n",
    "\n",
    "def _bayesian_search_optuna_multiseries_dev(\n",
    "    forecaster,\n",
    "    series: pd.DataFrame,\n",
    "    search_space: Callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    levels: Optional[Union[str, list]]=None,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    n_jobs: Optional[Union[int, str]]='auto',\n",
    "    verbose: bool=True,\n",
    "    show_progress: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    Bayesian optimization for a Forecaster object using multi-series backtesting \n",
    "    and optuna library.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoregMultiSeries, ForecasterAutoregMultiSeriesCustom, ForecasterAutoregMultiVariate\n",
    "        Forecaster model.\n",
    "    series : pandas DataFrame\n",
    "        Training time series.\n",
    "    search_space : Callable\n",
    "        Function with argument `trial` which returns a dictionary with parameters names \n",
    "        (`str`) as keys and Trial object from optuna (trial.suggest_float, \n",
    "        trial.suggest_int, trial.suggest_categorical) as values.\n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "    metric : str, Callable, list\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        - If `string`: {'mean_squared_error', 'mean_absolute_error',\n",
    "        'mean_absolute_percentage_error', 'mean_squared_log_error'}\n",
    "        - If `Callable`: Function with arguments y_true, y_pred that returns \n",
    "        a float.\n",
    "        - If `list`: List containing multiple strings and/or Callables.\n",
    "    initial_train_size : int \n",
    "        Number of samples in the initial train split.\n",
    "    fixed_train_size : bool, default `True`\n",
    "        If True, train size doesn't increase but moves by `steps` in each iteration.\n",
    "    gap : int, default `0`\n",
    "        Number of samples to be excluded after the end of each training set and \n",
    "        before the test set.\n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Last fold is allowed to have a smaller number of samples than the \n",
    "        `test_size`. If `False`, the last fold is excluded.\n",
    "    levels : str, list, default `None`\n",
    "        level (`str`) or levels (`list`) at which the forecaster is optimized. \n",
    "        If `None`, all levels are taken into account. The resulting metric will be\n",
    "        the average of the optimization of all levels.\n",
    "    exog : pandas Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "    lags_grid : list of int, lists, numpy ndarray or range, default `None`\n",
    "        Lists of `lags` to try. Only used if forecaster is an instance of \n",
    "        `ForecasterAutoregMultiSeries` or `ForecasterAutoregMultiVariate`.\n",
    "    refit : bool, int, default `False`\n",
    "        Whether to re-fit the forecaster in each iteration. If `refit` is an integer, \n",
    "        the Forecaster will be trained every that number of iterations.\n",
    "    n_trials : int, default `10`\n",
    "        Number of parameter settings that are sampled in each lag configuration.\n",
    "    random_state : int, default `123`\n",
    "        Sets a seed to the sampling for reproducible output.\n",
    "    return_best : bool, default `True`\n",
    "        Refit the `forecaster` using the best found parameters on the whole data.\n",
    "    n_jobs : int, 'auto', default `'auto'`\n",
    "        The number of jobs to run in parallel. If `-1`, then the number of jobs is \n",
    "        set to the number of cores. If 'auto', `n_jobs` is set using the function\n",
    "        skforecast.utils.select_n_jobs_backtesting.\n",
    "        **New in version 0.9.0**\n",
    "    verbose : bool, default `True`\n",
    "        Print number of folds used for cv or backtesting.\n",
    "    show_progress: bool, default `True`\n",
    "        Whether to show a progress bar.\n",
    "    kwargs_create_study : dict, default `{'direction': 'minimize', 'sampler': TPESampler(seed=123)}`\n",
    "        Keyword arguments (key, value mappings) to pass to optuna.create_study.\n",
    "    kwargs_study_optimize : dict, default `{}`\n",
    "        Other keyword arguments (key, value mappings) to pass to study.optimize().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : pandas DataFrame\n",
    "        Results for each combination of parameters.\n",
    "        - column levels: levels configuration for each iteration.\n",
    "        - column lags: lags configuration for each iteration.\n",
    "        - column params: parameters configuration for each iteration.\n",
    "        - column metric: metric value estimated for each iteration. The resulting \n",
    "        metric will be the average of the optimization of all levels.\n",
    "        - additional n columns with param = value.\n",
    "    results_opt_best : optuna object\n",
    "        The best optimization result returned as a FrozenTrial optuna object.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    levels = _initialize_levels_model_selection_multiseries(\n",
    "                 forecaster = forecaster,\n",
    "                 series     = series,\n",
    "                 levels     = levels\n",
    "             )\n",
    "\n",
    "    if type(forecaster).__name__ == 'ForecasterAutoregMultiSeriesCustom':\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                \"`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregMultiSeriesCustom`.\",\n",
    "                IgnoredArgumentWarning\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric = [metric] \n",
    "    metric_dict = {(m if isinstance(m, str) else m.__name__): [] \n",
    "                   for m in metric}\n",
    "    \n",
    "    if len(metric_dict) != len(metric):\n",
    "        raise ValueError(\n",
    "            \"When `metric` is a `list`, each metric name must be unique.\"\n",
    "        )\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        search_space          = search_space,\n",
    "        forecaster            = forecaster,\n",
    "        series                = series,\n",
    "        exog                  = exog,\n",
    "        steps                 = steps,\n",
    "        levels                = levels,\n",
    "        metric                = metric,\n",
    "        initial_train_size    = initial_train_size,\n",
    "        fixed_train_size      = fixed_train_size,\n",
    "        gap                   = gap,\n",
    "        allow_incomplete_fold = allow_incomplete_fold,\n",
    "        refit                 = refit,\n",
    "        n_jobs                = n_jobs,\n",
    "        verbose               = verbose\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(search_space(trial))\n",
    "        \n",
    "        metrics_levels = backtesting_forecaster_multiseries(\n",
    "                             forecaster            = forecaster,\n",
    "                             series                = series,\n",
    "                             exog                  = exog,\n",
    "                             steps                 = steps,\n",
    "                             levels                = levels,\n",
    "                             metric                = metric,\n",
    "                             initial_train_size    = initial_train_size,\n",
    "                             fixed_train_size      = fixed_train_size,\n",
    "                             gap                   = gap,\n",
    "                             allow_incomplete_fold = allow_incomplete_fold,\n",
    "                             refit                 = refit,\n",
    "                             n_jobs                = n_jobs,\n",
    "                             verbose               = verbose,\n",
    "                             show_progress         = False\n",
    "                         )[0]\n",
    "        # Store metrics in the variable metric_values defined outside _objective.\n",
    "        nonlocal metric_values\n",
    "        metric_values.append(metrics_levels)\n",
    "\n",
    "        return metrics_levels.iloc[:, 1].mean()\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)},\n",
    "         {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    if show_progress:\n",
    "        lags_grid = tqdm(lags_grid, desc='lags grid', position=0)\n",
    "\n",
    "    for lags in lags_grid:\n",
    "        metric_values = [] # This variable will be modified inside _objective function. \n",
    "        # It is a trick to extract multiple values from _objective function since\n",
    "        # only the optimized value can be returned.\n",
    "\n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)\n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise ValueError(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "        \n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "\n",
    "            m_values = metric_values[i]\n",
    "            for m in metric:\n",
    "                m_name = m if isinstance(m, str) else m.__name__\n",
    "                metric_dict[m_name].append(m_values[m_name].mean())\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "                  'levels': [levels]*len(lags_list),\n",
    "                  'lags'  : lags_list,\n",
    "                  'params': params_list,\n",
    "                  **metric_dict\n",
    "              })\n",
    "\n",
    "    results = results.sort_values(by=list(metric_dict.keys())[0], ascending=True)\n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results[list(metric_dict.keys())[0]].iloc[0]\n",
    "        \n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(best_params)\n",
    "        forecaster.fit(series=series, exog=exog, store_in_sample_residuals=True)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, \"\n",
    "            f\"and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "            f\"  Levels: {results['levels'].iloc[0]}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.120629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286139</td>\n",
       "      <td>0.826341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.603060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1        l2\n",
       "0  0.696469  0.120629\n",
       "1  0.286139  0.826341\n",
       "2  0.226851  0.603060"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries.tests.fixtures_model_selection_multiseries import series\n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _bayesian_search_optuna_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "def create_predictors(y): # pragma: no cover\n",
    "    \"\"\"\n",
    "    Create first 4 lags of a time series, used in ForecasterAutoregCustom.\n",
    "    \"\"\"\n",
    "\n",
    "    lags = y[-1:-5:-1]\n",
    "\n",
    "    return lags\n",
    "\n",
    "series.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b484258e9694037bb7623279a029f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                     regressor = Ridge(random_state=123),\n",
    "                     level     = 'l1',\n",
    "                     lags      = 2,\n",
    "                     steps     = 3\n",
    "                 )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "lags_grid = [2, {'l1': 4, 'l2': [2, 3]}]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {'alpha' : trial.suggest_float('alpha', 1e-2, 1.0)}\n",
    "\n",
    "    return search_space\n",
    "\n",
    "results = bayesian_search_forecaster_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                steps              = steps,\n",
    "                lags_grid          = lags_grid,\n",
    "                search_space       = search_space,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = False,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False,\n",
    "                engine             = 'optuna'\n",
    "            )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.193080</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.193114</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.193174</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.193192</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.193224</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.193263</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.193336</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.193342</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.193354</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2, 3, 4], 'l2': [2, 3]}</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.193492</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.201174</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.201199</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.201257</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.201281</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.201366</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.201371</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.201380</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.201487</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels                                lags                          params  \\\n",
       "12   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.2345829390285611}   \n",
       "11   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}  {'alpha': 0.29327794160087567}   \n",
       "19   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}    {'alpha': 0.398196343012209}   \n",
       "15   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}  {'alpha': 0.42887539552321635}   \n",
       "18   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}  {'alpha': 0.48612258246951734}   \n",
       "13   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.5558016213920624}   \n",
       "17   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.6879814411990146}   \n",
       "10   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.6995044937418831}   \n",
       "14   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.7222742800877074}   \n",
       "16   [l1]  {'l1': [1, 2, 3, 4], 'l2': [2, 3]}   {'alpha': 0.9809565564007693}   \n",
       "2    [l1]                              [1, 2]   {'alpha': 0.2345829390285611}   \n",
       "1    [l1]                              [1, 2]  {'alpha': 0.29327794160087567}   \n",
       "9    [l1]                              [1, 2]    {'alpha': 0.398196343012209}   \n",
       "5    [l1]                              [1, 2]  {'alpha': 0.42887539552321635}   \n",
       "8    [l1]                              [1, 2]  {'alpha': 0.48612258246951734}   \n",
       "3    [l1]                              [1, 2]   {'alpha': 0.5558016213920624}   \n",
       "7    [l1]                              [1, 2]   {'alpha': 0.6879814411990146}   \n",
       "0    [l1]                              [1, 2]   {'alpha': 0.6995044937418831}   \n",
       "4    [l1]                              [1, 2]   {'alpha': 0.7222742800877074}   \n",
       "6    [l1]                              [1, 2]   {'alpha': 0.9809565564007693}   \n",
       "\n",
       "    mean_absolute_error     alpha  \n",
       "12             0.193080  0.234583  \n",
       "11             0.193114  0.293278  \n",
       "19             0.193174  0.398196  \n",
       "15             0.193192  0.428875  \n",
       "18             0.193224  0.486123  \n",
       "13             0.193263  0.555802  \n",
       "17             0.193336  0.687981  \n",
       "10             0.193342  0.699504  \n",
       "14             0.193354  0.722274  \n",
       "16             0.193492  0.980957  \n",
       "2              0.201174  0.234583  \n",
       "1              0.201199  0.293278  \n",
       "9              0.201244  0.398196  \n",
       "5              0.201257  0.428875  \n",
       "8              0.201281  0.486123  \n",
       "3              0.201311  0.555802  \n",
       "7              0.201366  0.687981  \n",
       "0              0.201371  0.699504  \n",
       "4              0.201380  0.722274  \n",
       "6              0.201487  0.980957  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in results['lags'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693},\n",
       "       {'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['params'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19308029, 0.19311433, 0.19317444, 0.19319184, 0.1932241 ,\n",
       "       0.19326299, 0.19333567, 0.19334194, 0.1933543 , 0.19349184,\n",
       "       0.20117356, 0.20119892, 0.20124394, 0.20125703, 0.20128136,\n",
       "       0.20131081, 0.2013662 , 0.201371  , 0.20138047, 0.20148678])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mean_absolute_error'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656,\n",
       "       0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['alpha'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([12, 11, 19, 15, 18, 13, 17, 10, 14, 16, 2, 1, 9, 5, 8, 3, 7, 0, 4, 6], dtype='int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 models compared for 1 level(s). Number of iterations: 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12d4115ca5e433d8ef4d13aac04066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46330c51eedf4a7e90c3f7d2c9417d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skforecast.ForecasterAutoregMultiSeriesCustom import ForecasterAutoregMultiSeriesCustom\n",
    "from skforecast.ForecasterAutoregMultiVariate import ForecasterAutoregMultiVariate \n",
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                     regressor          = Ridge(random_state=123),\n",
    "                     level              = 'l1',\n",
    "                     lags               = 2,\n",
    "                     steps              = 3,\n",
    "                     transformer_series = None\n",
    "                 )\n",
    "\n",
    "lags_grid = [{'l1': 2, 'l2': 3}, {'l1': [1, 3], 'l2': 3}, {'l1': 2, 'l2': [1, 4]}, 3]\n",
    "# lags_grid = {\n",
    "#     'lags_1': {'l1': 2, 'l2': 3},\n",
    "#     'lags_2': {'l1': [1, 3], 'l2': 3},\n",
    "#     'lags_3': {'l1': 2, 'l2': [1, 4]},\n",
    "#     'lags_4': 3\n",
    "# }\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "param_grid = [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}]\n",
    "\n",
    "results = _evaluate_grid_hyperparameters_multiseries(\n",
    "                forecaster          = forecaster,\n",
    "                series              = series,\n",
    "                param_grid          = param_grid,\n",
    "                steps               = steps,\n",
    "                metric              = mean_absolute_error,\n",
    "                initial_train_size  = len(series) - n_validation,\n",
    "                fixed_train_size    = False,\n",
    "                levels              = None,\n",
    "                exog                = None,\n",
    "                lags_grid           = lags_grid,\n",
    "                refit               = False,\n",
    "                return_best         = False,\n",
    "                verbose             = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.205320</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.205552</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.206778</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.213537</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 3], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.216228</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 3], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.218011</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 3], 'l2': [1, 2, 3]}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.218640</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 4]}</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.224015</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 4]}</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.228302</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>{'l1': [1, 2], 'l2': [1, 4]}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.228781</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels                             lags           params  \\\n",
       "0    [l1]  {'l1': [1, 2], 'l2': [1, 2, 3]}  {'alpha': 0.01}   \n",
       "1    [l1]  {'l1': [1, 2], 'l2': [1, 2, 3]}   {'alpha': 0.1}   \n",
       "2    [l1]  {'l1': [1, 2], 'l2': [1, 2, 3]}     {'alpha': 1}   \n",
       "11   [l1]                        [1, 2, 3]     {'alpha': 1}   \n",
       "5    [l1]  {'l1': [1, 3], 'l2': [1, 2, 3]}     {'alpha': 1}   \n",
       "10   [l1]                        [1, 2, 3]   {'alpha': 0.1}   \n",
       "9    [l1]                        [1, 2, 3]  {'alpha': 0.01}   \n",
       "4    [l1]  {'l1': [1, 3], 'l2': [1, 2, 3]}   {'alpha': 0.1}   \n",
       "3    [l1]  {'l1': [1, 3], 'l2': [1, 2, 3]}  {'alpha': 0.01}   \n",
       "8    [l1]     {'l1': [1, 2], 'l2': [1, 4]}     {'alpha': 1}   \n",
       "7    [l1]     {'l1': [1, 2], 'l2': [1, 4]}   {'alpha': 0.1}   \n",
       "6    [l1]     {'l1': [1, 2], 'l2': [1, 4]}  {'alpha': 0.01}   \n",
       "\n",
       "    mean_absolute_error  alpha  \n",
       "0              0.205320   0.01  \n",
       "1              0.205552   0.10  \n",
       "2              0.206778   1.00  \n",
       "11             0.213537   1.00  \n",
       "5              0.214436   1.00  \n",
       "10             0.216228   0.10  \n",
       "9              0.216700   0.01  \n",
       "4              0.218011   0.10  \n",
       "3              0.218640   0.01  \n",
       "8              0.224015   1.00  \n",
       "7              0.228302   0.10  \n",
       "6              0.228781   0.01  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " [1, 2, 3],\n",
       " ['l1', 'l2'],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2'],\n",
       " ['l1', 'l2']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in results['lags'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 1},\n",
       "       {'alpha': 1}, {'alpha': 0.1}, {'alpha': 0.01}, {'alpha': 0.1},\n",
       "       {'alpha': 0.01}, {'alpha': 1}, {'alpha': 0.1}, {'alpha': 0.01}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['params'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2053202 , 0.20555199, 0.20677802, 0.21353688, 0.21443621,\n",
       "       0.21622784, 0.2166998 , 0.21801147, 0.21863968, 0.22401526,\n",
       "       0.22830217, 0.22878132])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mean_absolute_error'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.1 , 1.  , 1.  , 1.  , 0.1 , 0.01, 0.1 , 0.01, 1.  , 0.1 ,\n",
       "       0.01])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['alpha'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 11, 5, 10, 9, 4, 3, 8, 7, 6], dtype='int64')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3fb9befaf2432aaed9f1f2084683ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "                     regressor = RandomForestRegressor(random_state=123),\n",
    "                     lags      = 2 \n",
    "                 )\n",
    "\n",
    "    steps = 3\n",
    "    n_validation = 12\n",
    "    lags_grid = [2, 4]\n",
    "\n",
    "    def search_space(trial):\n",
    "        search_space  = {'n_estimators': trial.suggest_int('n_estimators', 100, 200),\n",
    "                         'max_depth'   : trial.suggest_int('max_depth', 20, 35, log=True),\n",
    "                         'max_features': trial.suggest_categorical('max_features', ['log2', 'sqrt'])}\n",
    "         \n",
    "        return search_space\n",
    "\n",
    "    # kwargs_study_optimize\n",
    "    timeout = 2.0\n",
    "\n",
    "    results = _bayesian_search_optuna_multiseries(\n",
    "                  forecaster            = forecaster,\n",
    "                  series                = series,\n",
    "                  steps                 = steps,\n",
    "                  lags_grid             = lags_grid,\n",
    "                  search_space          = search_space,\n",
    "                  metric                = 'mean_absolute_error',\n",
    "                  refit                 = False,\n",
    "                  initial_train_size    = len(series) - n_validation,\n",
    "                  n_trials              = 10,\n",
    "                  random_state          = 123,\n",
    "                  n_jobs                = 1,\n",
    "                  return_best           = False,\n",
    "                  verbose               = False,\n",
    "                  kwargs_study_optimize = {'timeout': timeout}\n",
    "              )[0]\n",
    "    \n",
    "    expected_results = pd.DataFrame({\n",
    "        'levels': [['l1', 'l2']]*2,\n",
    "        'lags'  : [[1, 2], [1, 2]],\n",
    "        'params':[{'n_estimators': 144, 'max_depth': 20, 'max_features': 'sqrt'},\n",
    "                  {'n_estimators': 143, 'max_depth': 33, 'max_features': 'log2'}],\n",
    "        'mean_absolute_error': np.array([0.18642719, 0.18984788]),                                                               \n",
    "        'n_estimators': np.array([144, 143]),\n",
    "        'max_depth': np.array([20, 33]),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "        },\n",
    "        index=pd.Index([3, 9], dtype=\"int64\")\n",
    "    ).sort_values(by='mean_absolute_error', ascending=True)\n",
    "\n",
    "    pd.testing.assert_frame_equal(results.head(2), expected_results, check_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                regressor = Ridge(random_state=123),\n",
    "                lags      = 4\n",
    "             )\n",
    "\n",
    "steps              = 3\n",
    "metric             = 'mean_absolute_error'\n",
    "levels             = ['l1']\n",
    "n_validation       = 12\n",
    "initial_train_size = len(series) - n_validation\n",
    "fixed_train_size   = True\n",
    "refit              = True\n",
    "verbose            = False\n",
    "show_progress      = False\n",
    "\n",
    "n_trials = 10\n",
    "random_state = 123\n",
    "\n",
    "def objective(\n",
    "    trial,\n",
    "    forecaster         = forecaster,\n",
    "    series             = series,\n",
    "    levels             = levels,\n",
    "    steps              = steps,\n",
    "    metric             = metric,\n",
    "    initial_train_size = initial_train_size,\n",
    "    fixed_train_size   = fixed_train_size,\n",
    "    refit              = refit,\n",
    "    verbose            = verbose,\n",
    "    show_progress      = show_progress\n",
    ") -> float:\n",
    "    \n",
    "    alpha = trial.suggest_float('alpha', 1e-2, 1.0)\n",
    "    \n",
    "    forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor = Ridge(random_state=random_state, \n",
    "                                        alpha=alpha),\n",
    "                    lags      = 4\n",
    "                    )\n",
    "\n",
    "    metrics_levels, _ = backtesting_forecaster_multiseries(\n",
    "                            forecaster         = forecaster,\n",
    "                            series             = series,\n",
    "                            levels             = levels,\n",
    "                            steps              = steps,\n",
    "                            metric             = metric,\n",
    "                            initial_train_size = initial_train_size,\n",
    "                            fixed_train_size   = fixed_train_size,\n",
    "                            refit              = refit,\n",
    "                            verbose            = verbose,\n",
    "                            show_progress      = show_progress     \n",
    "                        )\n",
    "\n",
    "    return abs(metrics_levels.iloc[:, 1].mean())\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", \n",
    "                            sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "lags_grid = [2, 4]\n",
    "def search_space(trial):\n",
    "    search_space  = {'alpha': trial.suggest_float('alpha', 1e-2, 1.0)}\n",
    "\n",
    "    return search_space\n",
    "\n",
    "return_best  = False\n",
    "\n",
    "_, results_opt_best = _bayesian_search_optuna_multiseries(\n",
    "                        forecaster         = forecaster,\n",
    "                        series             = series,\n",
    "                        levels             = levels, \n",
    "                        lags_grid          = lags_grid,\n",
    "                        search_space       = search_space,\n",
    "                        steps              = steps,\n",
    "                        metric             = metric,\n",
    "                        refit              = refit,\n",
    "                        initial_train_size = initial_train_size,\n",
    "                        fixed_train_size   = fixed_train_size,\n",
    "                        n_trials           = n_trials,\n",
    "                        return_best        = return_best,\n",
    "                        verbose            = verbose,\n",
    "                        show_progress      = show_progress\n",
    "                    )\n",
    "\n",
    "assert best_trial.number == results_opt_best.number\n",
    "assert best_trial.values == results_opt_best.values\n",
    "assert best_trial.params == results_opt_best.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.215850</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.215857</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.215871</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.215874</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.215890</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.215908</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.215911</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.215942</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.2345829390285611}</td>\n",
       "      <td>0.216304</td>\n",
       "      <td>0.234583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.29327794160087567}</td>\n",
       "      <td>0.216306</td>\n",
       "      <td>0.293278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.398196343012209}</td>\n",
       "      <td>0.216309</td>\n",
       "      <td>0.398196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.42887539552321635}</td>\n",
       "      <td>0.216310</td>\n",
       "      <td>0.428875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.48612258246951734}</td>\n",
       "      <td>0.216312</td>\n",
       "      <td>0.486123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.5558016213920624}</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.555802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6879814411990146}</td>\n",
       "      <td>0.216319</td>\n",
       "      <td>0.687981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.6995044937418831}</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.699504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.7222742800877074}</td>\n",
       "      <td>0.216320</td>\n",
       "      <td>0.722274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[l1]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'alpha': 0.9809565564007693}</td>\n",
       "      <td>0.216329</td>\n",
       "      <td>0.980957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels          lags                          params  mean_absolute_error  \\\n",
       "12   [l1]  [1, 2, 3, 4]   {'alpha': 0.2345829390285611}             0.215850   \n",
       "11   [l1]  [1, 2, 3, 4]  {'alpha': 0.29327794160087567}             0.215857   \n",
       "19   [l1]  [1, 2, 3, 4]    {'alpha': 0.398196343012209}             0.215871   \n",
       "15   [l1]  [1, 2, 3, 4]  {'alpha': 0.42887539552321635}             0.215874   \n",
       "18   [l1]  [1, 2, 3, 4]  {'alpha': 0.48612258246951734}             0.215882   \n",
       "13   [l1]  [1, 2, 3, 4]   {'alpha': 0.5558016213920624}             0.215890   \n",
       "17   [l1]  [1, 2, 3, 4]   {'alpha': 0.6879814411990146}             0.215907   \n",
       "10   [l1]  [1, 2, 3, 4]   {'alpha': 0.6995044937418831}             0.215908   \n",
       "14   [l1]  [1, 2, 3, 4]   {'alpha': 0.7222742800877074}             0.215911   \n",
       "16   [l1]  [1, 2, 3, 4]   {'alpha': 0.9809565564007693}             0.215942   \n",
       "2    [l1]        [1, 2]   {'alpha': 0.2345829390285611}             0.216304   \n",
       "1    [l1]        [1, 2]  {'alpha': 0.29327794160087567}             0.216306   \n",
       "9    [l1]        [1, 2]    {'alpha': 0.398196343012209}             0.216309   \n",
       "5    [l1]        [1, 2]  {'alpha': 0.42887539552321635}             0.216310   \n",
       "8    [l1]        [1, 2]  {'alpha': 0.48612258246951734}             0.216312   \n",
       "3    [l1]        [1, 2]   {'alpha': 0.5558016213920624}             0.216315   \n",
       "7    [l1]        [1, 2]   {'alpha': 0.6879814411990146}             0.216319   \n",
       "0    [l1]        [1, 2]   {'alpha': 0.6995044937418831}             0.216320   \n",
       "4    [l1]        [1, 2]   {'alpha': 0.7222742800877074}             0.216320   \n",
       "6    [l1]        [1, 2]   {'alpha': 0.9809565564007693}             0.216329   \n",
       "\n",
       "       alpha  \n",
       "12  0.234583  \n",
       "11  0.293278  \n",
       "19  0.398196  \n",
       "15  0.428875  \n",
       "18  0.486123  \n",
       "13  0.555802  \n",
       "17  0.687981  \n",
       "10  0.699504  \n",
       "14  0.722274  \n",
       "16  0.980957  \n",
       "2   0.234583  \n",
       "1   0.293278  \n",
       "9   0.398196  \n",
       "5   0.428875  \n",
       "8   0.486123  \n",
       "3   0.555802  \n",
       "7   0.687981  \n",
       "0   0.699504  \n",
       "4   0.722274  \n",
       "6   0.980957  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2, 3, 4],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1, 2]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in _['lags'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693},\n",
       "       {'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
       "       {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
       "       {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
       "       {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
       "       {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['params'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21584992, 0.21585737, 0.2158706 , 0.21587445, 0.2158816 ,\n",
       "       0.21589025, 0.21590653, 0.21590794, 0.21591073, 0.21594197,\n",
       "       0.2163035 , 0.21630557, 0.21630925, 0.21631032, 0.21631231,\n",
       "       0.21631472, 0.21631927, 0.21631967, 0.21632045, 0.21632921])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['mean_absolute_error'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656,\n",
       "       0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
       "       0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['alpha'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([12, 11, 19, 15, 18, 13, 17, 10, 14, 16, 2, 1, 9, 5, 8, 3, 7, 0, 4, 6], dtype='int64')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                     regressor = Ridge(random_state=123),\n",
    "                     lags      = 2 \n",
    "                 )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "lags_grid = [4, 2]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {'alpha' : trial.suggest_float('alpha', 1e-2, 1.0)}\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "# kwargs_create_study\n",
    "sampler = TPESampler(seed=123, prior_weight=2.0, consider_magic_clip=False)\n",
    "\n",
    "results = _bayesian_search_optuna_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                steps              = steps,\n",
    "                lags_grid          = lags_grid,\n",
    "                search_space       = search_space,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = False,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False,\n",
    "                kwargs_create_study = {'sampler':sampler}\n",
    "            )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20,\n",
      "         10 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe18aca31da249fa92221a4e790bc02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor = Ridge(random_state=123),\n",
    "                    level     = 'l1',\n",
    "                    lags      = 2,\n",
    "                    steps     = 3\n",
    "                )\n",
    "\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "lags_grid = [2, {'l1': 4, 'l2': [2, 3]}]\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {'alpha' : trial.suggest_float('alpha', 1e-2, 1.0)}\n",
    "\n",
    "    return search_space\n",
    "\n",
    "results = bayesian_search_forecaster_multiseries(\n",
    "                forecaster         = forecaster,\n",
    "                series             = series,\n",
    "                steps              = steps,\n",
    "                lags_grid          = lags_grid,\n",
    "                search_space       = search_space,\n",
    "                metric             = 'mean_absolute_error',\n",
    "                refit              = False,\n",
    "                initial_train_size = len(series) - n_validation,\n",
    "                n_trials           = 10,\n",
    "                random_state       = 123,\n",
    "                return_best        = False,\n",
    "                verbose            = False,\n",
    "                engine             = 'optuna'\n",
    "            )[0]\n",
    "\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': [['l1']]*10*2,\n",
    "    'lags'  : [{'l1': [1, 2, 3, 4], 'l2': [2, 3]}]*10 + [[1, 2]]*10,\n",
    "    'params': [{'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
    "                {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
    "                {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
    "                {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
    "                {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693},\n",
    "                {'alpha': 0.2345829390285611}, {'alpha': 0.29327794160087567},\n",
    "                {'alpha': 0.398196343012209}, {'alpha': 0.42887539552321635},\n",
    "                {'alpha': 0.48612258246951734}, {'alpha': 0.5558016213920624},\n",
    "                {'alpha': 0.6879814411990146}, {'alpha': 0.6995044937418831},\n",
    "                {'alpha': 0.7222742800877074}, {'alpha': 0.9809565564007693}],\n",
    "    'mean_absolute_error': np.array([0.19308029, 0.19311433, 0.19317444, 0.19319184, 0.1932241 ,\n",
    "                                        0.19326299, 0.19333567, 0.19334194, 0.1933543 , 0.19349184,\n",
    "                                        0.20117356, 0.20119892, 0.20124394, 0.20125703, 0.20128136,\n",
    "                                        0.20131081, 0.2013662 , 0.201371  , 0.20138047, 0.20148678]),\n",
    "    'alpha': np.array([0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
    "                        0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656,\n",
    "                        0.23458294, 0.29327794, 0.39819634, 0.4288754 , 0.48612258,\n",
    "                        0.55580162, 0.68798144, 0.69950449, 0.72227428, 0.98095656])\n",
    "    },\n",
    "    index=pd.Index([12, 11, 19, 15, 18, 13, 17, 10, 14, 16, 2, 1, 9, 5, 8, 3, 7, 0, 4, 6], dtype=\"int64\")\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(results, expected_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['l1'], ['l1'], ['l1'], ['l1'], ['l1'], ['l1']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[['l1']]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 models compared for 1 level(s). Number of iterations: 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b365d29eb4127b121978eaa71b165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1eb378095642a285e9ce6c671e39cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "DataFrame.iloc[:, 1] (column name=\"lags\") are different\n\nDataFrame.iloc[:, 1] (column name=\"lags\") values are different (100.0 %)\n[index]: [0, 1, 2, 11, 5, 10, 9, 4, 3, 8, 7, 6]\n[left]:  [lags_1, lags_1, lags_1, lags_4, lags_2, lags_4, lags_4, lags_2, lags_2, lags_3, lags_3, lags_3]\n[right]: [{'l1': [1, 2], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 2, 3]}, [1, 2, 3], {'l1': [1, 3], 'l2': [1, 2, 3]}, [1, 2, 3], [1, 2, 3], {'l1': [1, 3], 'l2': [1, 2, 3]}, {'l1': [1, 3], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 4]}, {'l1': [1, 2], 'l2': [1, 4]}, {'l1': [1, 2], 'l2': [1, 4]}]\nAt positional index 0, first diff: lags_1 != {'l1': array([1, 2]), 'l2': array([1, 2, 3])}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 62\u001b[0m\n\u001b[0;32m     21\u001b[0m results \u001b[38;5;241m=\u001b[39m _evaluate_grid_hyperparameters_multiseries(\n\u001b[0;32m     22\u001b[0m                 forecaster          \u001b[38;5;241m=\u001b[39m forecaster,\n\u001b[0;32m     23\u001b[0m                 series              \u001b[38;5;241m=\u001b[39m series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 verbose             \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m             )\n\u001b[0;32m     37\u001b[0m expected_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m'\u001b[39m: [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlags\u001b[39m\u001b[38;5;124m'\u001b[39m  : [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     index\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mIndex([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m6\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m )\n\u001b[1;32m---> 62\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_frame_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtesting.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.testing.assert_almost_equal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11\\Lib\\site-packages\\pandas\\_testing\\asserters.py:598\u001b[0m, in \u001b[0;36mraise_assert_detail\u001b[1;34m(obj, message, left, right, diff, first_diff, index_values)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfirst_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 598\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: DataFrame.iloc[:, 1] (column name=\"lags\") are different\n\nDataFrame.iloc[:, 1] (column name=\"lags\") values are different (100.0 %)\n[index]: [0, 1, 2, 11, 5, 10, 9, 4, 3, 8, 7, 6]\n[left]:  [lags_1, lags_1, lags_1, lags_4, lags_2, lags_4, lags_4, lags_2, lags_2, lags_3, lags_3, lags_3]\n[right]: [{'l1': [1, 2], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 2, 3]}, [1, 2, 3], {'l1': [1, 3], 'l2': [1, 2, 3]}, [1, 2, 3], [1, 2, 3], {'l1': [1, 3], 'l2': [1, 2, 3]}, {'l1': [1, 3], 'l2': [1, 2, 3]}, {'l1': [1, 2], 'l2': [1, 4]}, {'l1': [1, 2], 'l2': [1, 4]}, {'l1': [1, 2], 'l2': [1, 4]}]\nAt positional index 0, first diff: lags_1 != {'l1': array([1, 2]), 'l2': array([1, 2, 3])}"
     ]
    }
   ],
   "source": [
    "from skforecast.model_selection_multiseries.model_selection_multiseries import _evaluate_grid_hyperparameters_multiseries\n",
    "\n",
    "forecaster = ForecasterAutoregMultiVariate(\n",
    "                    regressor          = Ridge(random_state=123),\n",
    "                    level              = 'l1',\n",
    "                    lags               = 2,\n",
    "                    steps              = 3,\n",
    "                    transformer_series = None\n",
    "                )\n",
    "\n",
    "lags_grid = {\n",
    "    'lags_1': {'l1': 2, 'l2': 3},\n",
    "    'lags_2': {'l1': [1, 3], 'l2': 3},\n",
    "    'lags_3': {'l1': 2, 'l2': [1, 4]},\n",
    "    'lags_4': 3\n",
    "}\n",
    "steps = 3\n",
    "n_validation = 12\n",
    "param_grid = [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}]\n",
    "\n",
    "results = _evaluate_grid_hyperparameters_multiseries(\n",
    "                forecaster          = forecaster,\n",
    "                series              = series,\n",
    "                param_grid          = param_grid,\n",
    "                steps               = steps,\n",
    "                metric              = mean_absolute_error,\n",
    "                initial_train_size  = len(series) - n_validation,\n",
    "                fixed_train_size    = False,\n",
    "                levels              = None,\n",
    "                exog                = None,\n",
    "                lags_grid           = lags_grid,\n",
    "                refit               = False,\n",
    "                return_best         = False,\n",
    "                verbose             = False\n",
    "            )\n",
    "\n",
    "expected_results = pd.DataFrame({\n",
    "    'levels': [['l1']]*12,\n",
    "    'lags'  : [{'l1': np.array([1, 2]), 'l2': np.array([1, 2, 3])},\n",
    "                {'l1': np.array([1, 2]), 'l2': np.array([1, 2, 3])},\n",
    "                {'l1': np.array([1, 2]), 'l2': np.array([1, 2, 3])},\n",
    "                [1, 2, 3],\n",
    "                {'l1': np.array([1, 3]), 'l2': np.array([1, 2, 3])},\n",
    "                [1, 2, 3],\n",
    "                [1, 2, 3],\n",
    "                {'l1': np.array([1, 3]), 'l2': np.array([1, 2, 3])},\n",
    "                {'l1': np.array([1, 3]), 'l2': np.array([1, 2, 3])},\n",
    "                {'l1': np.array([1, 2]), 'l2': np.array([1, 4])},\n",
    "                {'l1': np.array([1, 2]), 'l2': np.array([1, 4])},\n",
    "                {'l1': np.array([1, 2]), 'l2': np.array([1, 4])}],\n",
    "    'params': [{'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1}, {'alpha': 1},\n",
    "                {'alpha': 1}, {'alpha': 0.1}, {'alpha': 0.01}, {'alpha': 0.1},\n",
    "                {'alpha': 0.01}, {'alpha': 1}, {'alpha': 0.1}, {'alpha': 0.01}],\n",
    "    'mean_absolute_error': np.array([0.2053202 , 0.20555199, 0.20677802, 0.21353688, \n",
    "                                        0.21443621, 0.21622784, 0.2166998 , 0.21801147, \n",
    "                                        0.21863968, 0.22401526, 0.22830217, 0.22878132]),                                                               \n",
    "    'alpha' : np.array([0.01, 0.1 , 1.  , 1.  , 1.  , 0.1 , 0.01, 0.1 , 0.01, 1.  , 0.1 , 0.01])\n",
    "    },\n",
    "    index=pd.Index([0, 1, 2, 11, 5, 10, 9, 4, 3, 8, 7, 6], dtype='int64')\n",
    ")\n",
    "\n",
    "pd.testing.assert_frame_equal(results, expected_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lags_1', 'lags_1', 'lags_1', 'lags_4', 'lags_2', 'lags_4',\n",
       "       'lags_4', 'lags_2', 'lags_2', 'lags_3', 'lags_3', 'lags_3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.lags.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
