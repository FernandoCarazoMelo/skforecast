{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "\n",
    "# Data download\n",
    "# ==============================================================================\n",
    "#data = fetch_dataset(name=\"items_sales\")\n",
    "#data.to_parquet('items_sales.parquet', index=True)\n",
    "data = pd.read_parquet('items_sales.parquet')\n",
    "data = data.asfreq('D')\n",
    "data.head()\n",
    "exog = pd.DataFrame({\n",
    "    'exog_1': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    'exog_2': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    # 'exog_3': (['A'] * int(data.shape[0] / 2) + ['B'] * int(data.shape[0] / 2 + 1)),\n",
    "}, index=data.index)\n",
    "\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "transformer_exog = ColumnTransformer(\n",
    "                        [('scale', StandardScaler(), ['exog_1', 'exog_2']),\n",
    "                        ('onehot', OneHotEncoder(), ['exog_3'])],\n",
    "                        remainder = 'passthrough',\n",
    "                        verbose_feature_names_out = False\n",
    "                    )\n",
    "\n",
    "# Create and train ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = [1, 5],\n",
    "                 encoding           = 'onehot',\n",
    "                 transformer_series = StandardScaler(),\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "# forecaster.fit(series=data_train, exog=exog.loc[data_train.index])\n",
    "forecaster.fit(series=data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_window, exog_values_dict, levels, prediction_index, residuals = (\n",
    "    forecaster._create_predict_inputs(steps=2)\n",
    "    # exog=exog.loc[data_test.index])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[99., 99.],\n",
       "        [99., 99.]]),\n",
       " 2: array([[999., 999.],\n",
       "        [999., 999.]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "n_levels = len(levels)\n",
    "lags = np.array([1, 2, 3, 4, 5])\n",
    "steps = 2\n",
    "lags_shape = len(lags)\n",
    "exog_shape = 2\n",
    "encoding = 'onehot'\n",
    "series_col_names = levels\n",
    "encoding_mapping = {'item_1': 0, 'item_2': 1, 'item_3': 2}\n",
    "# Exog es un diccionario donde las claves son el step y los son numpy arrays en los\n",
    "# que cada fila es un level y cada columna es una variable exogena.\n",
    "exog = {\n",
    "    1:np.full(shape=(steps, exog_shape), fill_value=99, dtype=float),\n",
    "    2:np.full(shape=(steps, exog_shape), fill_value=999, dtype=float),\n",
    "}\n",
    "exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fetch_dataset(name=\"items_sales\")\n",
    "# data.to_parquet('items_sales_2.parquet', index=True)\n",
    "data = pd.read_parquet(\"items_sales_2.parquet\")\n",
    "data = data.asfreq(\"D\")\n",
    "data.head()\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "        \"exog_2\": np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    },\n",
    "    index=data.index,\n",
    ")\n",
    "\n",
    "end_train = \"2014-07-15 23:59:00\"\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test = data.loc[end_train:, :].copy()\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index])\n",
    "\n",
    "(last_window_values_dict, exog_values_dict, levels, prediction_index, _) = (\n",
    "    forecaster._create_predict_inputs(\n",
    "        steps=2, levels=None, last_window=None, exog=exog.loc[data_test.index]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_old = forecaster.predict(steps=50, exog=exog.loc[data_test.index])\n",
    "predictions_new = forecaster.predict_new(steps=50, exog=exog.loc[data_test.index])\n",
    "assert predictions_old.equals(predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (365, 100)\n"
     ]
    }
   ],
   "source": [
    "n_series = 100\n",
    "n=365\n",
    "index = pd.date_range(start='2021-01-01',periods=n, freq=\"D\")\n",
    "series = [pd.Series(np.random.normal(size=n), index=index, name=f\"series_{i+1}\") for i in range(n_series)]\n",
    "data = pd.concat(series, axis=1)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1, n_estimators=20),\n",
    "                 lags               = 5,\n",
    "                 encoding           = 'onehot',\n",
    "                 transformer_series = StandardScaler(),\n",
    "                 differentiation    = 1,\n",
    "             )\n",
    "forecaster.fit(series = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old mean time: 1.086991240014322 , std: 0.0704542397830175, max: 1.1698864999925718, min: 1.0002508000470698\n",
      "New mean time: 0.10701592001132668 , std: 0.012142772389647675, max: 0.1298501999117434, min: 0.09339679998811334\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "steps = 25\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict_013(steps=steps)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"Old mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict(steps=steps)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"New mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert forecaster.predict_013(steps=steps).equals(forecaster.predict(steps=steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old mean time: 28.384666919987648 , std: 0.8756944847781502, max: 29.55362709995825, min: 26.888340799952857\n",
      "New mean time: 0.6965285999933257 , std: 0.014021070204953256, max: 0.7125798999331892, min: 0.6794215999543667\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "steps = 25\n",
    "n_boot = 25\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict_bootstrapping_013(steps=steps, n_boot=n_boot)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"Old mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict_bootstrapping(steps=steps, n_boot=n_boot)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"New mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = forecaster.predict_bootstrapping(steps=steps, n_boot=n_boot)\n",
    "old_preds = forecaster.predict_bootstrapping_013(steps=steps, n_boot=n_boot)\n",
    "\n",
    "for key in new_preds.keys():\n",
    "    print(key)\n",
    "    pd.testing.assert_frame_equal(new_preds[key], old_preds[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_boot_0</th>\n",
       "      <th>pred_boot_1</th>\n",
       "      <th>pred_boot_2</th>\n",
       "      <th>pred_boot_3</th>\n",
       "      <th>pred_boot_4</th>\n",
       "      <th>pred_boot_5</th>\n",
       "      <th>pred_boot_6</th>\n",
       "      <th>pred_boot_7</th>\n",
       "      <th>pred_boot_8</th>\n",
       "      <th>pred_boot_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_boot_15</th>\n",
       "      <th>pred_boot_16</th>\n",
       "      <th>pred_boot_17</th>\n",
       "      <th>pred_boot_18</th>\n",
       "      <th>pred_boot_19</th>\n",
       "      <th>pred_boot_20</th>\n",
       "      <th>pred_boot_21</th>\n",
       "      <th>pred_boot_22</th>\n",
       "      <th>pred_boot_23</th>\n",
       "      <th>pred_boot_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>0.895978</td>\n",
       "      <td>0.717450</td>\n",
       "      <td>-1.011986</td>\n",
       "      <td>-0.103020</td>\n",
       "      <td>-1.293953</td>\n",
       "      <td>-1.314537</td>\n",
       "      <td>1.368333</td>\n",
       "      <td>-0.986955</td>\n",
       "      <td>0.278556</td>\n",
       "      <td>0.532839</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.434767</td>\n",
       "      <td>-0.103552</td>\n",
       "      <td>1.719209</td>\n",
       "      <td>-1.330589</td>\n",
       "      <td>1.771068</td>\n",
       "      <td>-1.765523</td>\n",
       "      <td>-0.710868</td>\n",
       "      <td>0.168703</td>\n",
       "      <td>-0.127768</td>\n",
       "      <td>0.884584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>1.740609</td>\n",
       "      <td>0.680492</td>\n",
       "      <td>-1.235880</td>\n",
       "      <td>-0.616408</td>\n",
       "      <td>-1.458220</td>\n",
       "      <td>-1.673987</td>\n",
       "      <td>-0.482207</td>\n",
       "      <td>-0.131236</td>\n",
       "      <td>1.895295</td>\n",
       "      <td>1.231233</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.978750</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.609087</td>\n",
       "      <td>1.505434</td>\n",
       "      <td>1.179623</td>\n",
       "      <td>0.890148</td>\n",
       "      <td>-0.579240</td>\n",
       "      <td>-1.984793</td>\n",
       "      <td>0.847156</td>\n",
       "      <td>1.499289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_boot_0  pred_boot_1  pred_boot_2  pred_boot_3  pred_boot_4  \\\n",
       "2022-01-01     0.895978     0.717450    -1.011986    -0.103020    -1.293953   \n",
       "2022-01-02     1.740609     0.680492    -1.235880    -0.616408    -1.458220   \n",
       "\n",
       "            pred_boot_5  pred_boot_6  pred_boot_7  pred_boot_8  pred_boot_9  \\\n",
       "2022-01-01    -1.314537     1.368333    -0.986955     0.278556     0.532839   \n",
       "2022-01-02    -1.673987    -0.482207    -0.131236     1.895295     1.231233   \n",
       "\n",
       "            ...  pred_boot_15  pred_boot_16  pred_boot_17  pred_boot_18  \\\n",
       "2022-01-01  ...     -2.434767     -0.103552      1.719209     -1.330589   \n",
       "2022-01-02  ...     -1.978750      0.011628      0.609087      1.505434   \n",
       "\n",
       "            pred_boot_19  pred_boot_20  pred_boot_21  pred_boot_22  \\\n",
       "2022-01-01      1.771068     -1.765523     -0.710868      0.168703   \n",
       "2022-01-02      1.179623      0.890148     -0.579240     -1.984793   \n",
       "\n",
       "            pred_boot_23  pred_boot_24  \n",
       "2022-01-01     -0.127768      0.884584  \n",
       "2022-01-02      0.847156      1.499289  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_preds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.2 μs ± 743 ns per loop (mean ± std. dev. of 4 runs, 2,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 2000 -r 4\n",
    "\n",
    "array = np.full(\n",
    "            shape      = (25, 500 * 10),\n",
    "            fill_value = np.nan,\n",
    "            dtype      = float\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 ns ± 2.86 ns per loop (mean ± std. dev. of 4 runs, 2,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 2000 -r 4\n",
    "\n",
    "array = np.empty(\n",
    "            shape      = (25, 500 * 10),\n",
    "            dtype      = float\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "series_2 = pd.DataFrame({'1': pd.Series(np.arange(start=0, stop=50)), \n",
    "                         '2': pd.Series(np.arange(start=50, stop=100))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\ForecasterAutoregMultiSeries.py:397: UserWarning: When using a linear model, it is recommended to use a transformer_series to ensure all series are in the same scale. You can use, for example, a `StandardScaler` from sklearn.preprocessing.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterAutoregMultiSeries(LinearRegression(), lags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      9\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mfit(series\u001b[38;5;241m=\u001b[39mseries_2)\n\u001b[1;32m---> 10\u001b[0m predictions_1 \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_window\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\ForecasterAutoregMultiSeries.py:2049\u001b[0m, in \u001b[0;36mForecasterAutoregMultiSeries.predict\u001b[1;34m(self, steps, levels, last_window, exog, suppress_warnings)\u001b[0m\n\u001b[0;32m   2034\u001b[0m set_skforecast_warnings(suppress_warnings, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2036\u001b[0m (\n\u001b[0;32m   2037\u001b[0m     last_window,\n\u001b[0;32m   2038\u001b[0m     exog_values_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     exog        \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m   2047\u001b[0m )\n\u001b[1;32m-> 2049\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_predict_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2050\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexog_values_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog_values_dict\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;66;03m# predictions_tranformed = []\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(levels):\n",
      "File \u001b[1;32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\ForecasterAutoregMultiSeries.py:1779\u001b[0m, in \u001b[0;36mForecasterAutoregMultiSeries._recursive_predict_new\u001b[1;34m(self, steps, levels, last_window, exog_values_dict)\u001b[0m\n\u001b[0;32m   1776\u001b[0m     features[:, lags_shape : lags_shape \u001b[38;5;241m+\u001b[39m levels_encoded_shape] \u001b[38;5;241m=\u001b[39m levels_encoded\n\u001b[0;32m   1778\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(steps, n_levels), fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m-> 1779\u001b[0m last_window \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_window\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m   1783\u001b[0m     step \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "last_window = pd.DataFrame(\n",
    "                      {'1': [45, 46, 47, 48, 49], \n",
    "                       '2': [95, 96, 97, 98, 99], \n",
    "                       '3': [1, 2, 3, 4, 5]}, \n",
    "                      index = pd.RangeIndex(start=45, stop=50, step=1)\n",
    "                  )\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=5)\n",
    "forecaster.fit(series=series_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1\n",
       "45  45\n",
       "46  46\n",
       "47  47\n",
       "48  48\n",
       "49  49"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = forecaster._create_predict_inputs_new(steps=5, levels='1', last_window=last_window)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1   2\n",
       "45  45  95\n",
       "46  46  96\n",
       "47  47  97\n",
       "48  48  98\n",
       "49  49  99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column position in DataFrame using iloc\n",
    "columns_to_get = ['1', '2']\n",
    "df.iloc[:, df.columns.get_indexer(columns_to_get)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': array([45, 46, 47, 48, 49])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster._create_predict_inputs(steps=5, levels='1', last_window=last_window)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_1 = forecaster.predict(steps=5, levels='1', last_window=last_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog_predict\n",
    "\n",
    "series_dict = joblib.load(r'C:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\tests\\fixture_sample_multi_series.joblib')\n",
    "exog_dict = joblib.load(r'C:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\ForecasterAutoregMultiSeries\\tests\\fixture_sample_multi_series_exog.joblib')\n",
    "end_train = \"2016-07-31 23:59:00\"\n",
    "series_dict_train = {k: v.loc[:end_train,] for k, v in series_dict.items()}\n",
    "exog_dict_train = {k: v.loc[:end_train,] for k, v in exog_dict.items()}\n",
    "series_dict_test = {k: v.loc[end_train:,] for k, v in series_dict.items()}\n",
    "exog_dict_test = {k: v.loc[end_train:,] for k, v in exog_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_train = '2003-01-30 23:59:00'\n",
    "\n",
    "# Data scaled and differentiated\n",
    "series_datetime = series.copy()\n",
    "series_datetime.index = pd.date_range(start='2003-01-01', periods=len(series), freq='D')\n",
    "series_dict_datetime = {\n",
    "    \"1\": series_datetime['1'].loc[:end_train],\n",
    "    \"2\": series_datetime['2'].loc[:end_train]\n",
    "}\n",
    "\n",
    "# Simulated exogenous variable\n",
    "rng = np.random.default_rng(9876)\n",
    "exog = pd.Series(\n",
    "    rng.normal(loc=0, scale=1, size=len(series)), name='exog'\n",
    ")\n",
    "exog.index = pd.date_range(start='2003-01-01', periods=len(series), freq='D')\n",
    "exog_dict_datetime = {\n",
    "    \"1\": exog.loc[:end_train],\n",
    "    \"2\": exog.loc[:end_train]\n",
    "}\n",
    "exog_pred = {\n",
    "    '1': exog.loc[end_train:],\n",
    "    '2': exog.loc[end_train:]\n",
    "}\n",
    "\n",
    "steps = len(series_datetime.loc[end_train:])\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = LinearRegression(), \n",
    "                    lags               = 15, \n",
    "                    transformer_series = StandardScaler(),    \n",
    "                    differentiation    = 1\n",
    "                )\n",
    "forecaster.fit(series=series_dict_datetime, exog=exog_dict_datetime)\n",
    "results = forecaster._create_predict_inputs(\n",
    "    steps=steps, exog=exog_pred, predict_boot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:936: MissingExogWarning: {'air_temperature', 'wind_speed'} not present in `exog` for series 'id_1000'. All values will be NaN. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingExogWarning)\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:936: MissingExogWarning: {'cos_day_of_week'} not present in `exog` for series 'id_1003'. All values will be NaN. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingExogWarning)\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:437: MissingValuesWarning: `exog` for series 'id_1000' has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesWarning)\n",
      "  warnings.warn(\n",
      "c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py:437: MissingValuesWarning: `exog` for series 'id_1003' has missing values. Most machine learning models do not allow missing values. Fitting the forecaster may fail. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=MissingValuesWarning)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "    regressor          = LGBMRegressor(\n",
    "        n_estimators=2, random_state=123, verbose=-1, max_depth=2\n",
    "    ),\n",
    "    lags               = 5,\n",
    "    encoding           = 'ordinal',\n",
    "    dropna_from_series = False,\n",
    "    transformer_series = StandardScaler(),\n",
    "    transformer_exog   = StandardScaler(),\n",
    ")\n",
    "forecaster.fit(\n",
    "    series=series_dict_train, exog=exog_dict_train, suppress_warnings=True\n",
    ")\n",
    "results = forecaster._create_predict_inputs(steps=5, exog=exog_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_1000': timestamp\n",
       " 2016-01-01    1012.500694\n",
       " 2016-01-02    1158.500099\n",
       " 2016-01-03     983.000099\n",
       " 2016-01-04    1675.750496\n",
       " 2016-01-05    1586.250694\n",
       "                  ...     \n",
       " 2016-07-27    1344.750595\n",
       " 2016-07-28    1310.000397\n",
       " 2016-07-29    1297.000893\n",
       " 2016-07-30    1103.500397\n",
       " 2016-07-31     871.500198\n",
       " Freq: D, Name: id_1000, Length: 213, dtype: float64,\n",
       " 'id_1001': timestamp\n",
       " 2016-07-02    2802.000000\n",
       " 2016-07-03    2807.000000\n",
       " 2016-07-04    2784.000000\n",
       " 2016-07-05    2755.000000\n",
       " 2016-07-06    2550.000198\n",
       " 2016-07-07    1876.000397\n",
       " 2016-07-08    2505.000000\n",
       " 2016-07-09    2276.000793\n",
       " 2016-07-10    1804.000099\n",
       " 2016-07-11     576.000298\n",
       " 2016-07-12     799.000597\n",
       " 2016-07-13     923.001390\n",
       " 2016-07-14    1664.000997\n",
       " 2016-07-15    1882.000496\n",
       " 2016-07-16    2024.000099\n",
       " 2016-07-17    1826.000099\n",
       " 2016-07-18    2142.999802\n",
       " 2016-07-19    2765.000000\n",
       " 2016-07-20    2720.000198\n",
       " 2016-07-21    2764.000000\n",
       " 2016-07-22    2156.000099\n",
       " 2016-07-23     825.000099\n",
       " 2016-07-24     826.000298\n",
       " 2016-07-25     824.000298\n",
       " 2016-07-26    2160.000000\n",
       " 2016-07-27    2224.000198\n",
       " 2016-07-28    2334.000496\n",
       " 2016-07-29    2559.000595\n",
       " 2016-07-30    2911.000000\n",
       " 2016-07-31    2903.000000\n",
       " Freq: D, Name: id_1001, dtype: float64,\n",
       " 'id_1002': timestamp\n",
       " 2016-01-01    3114.500198\n",
       " 2016-01-02    4110.000000\n",
       " 2016-01-03    2965.000000\n",
       " 2016-01-04    1269.500000\n",
       " 2016-01-05    3360.500000\n",
       "                  ...     \n",
       " 2016-06-27    2907.000893\n",
       " 2016-06-28    3048.000793\n",
       " 2016-06-29    3072.000298\n",
       " 2016-06-30    3541.000694\n",
       " 2016-07-01    7802.001984\n",
       " Freq: D, Name: id_1002, Length: 183, dtype: float64,\n",
       " 'id_1003': timestamp\n",
       " 2016-01-01    2294.750893\n",
       " 2016-01-02    1750.000198\n",
       " 2016-01-03    1455.750492\n",
       " 2016-01-04    2141.000198\n",
       " 2016-01-05    2384.870697\n",
       "                  ...     \n",
       " 2016-07-27    1830.871780\n",
       " 2016-07-28    1776.250992\n",
       " 2016-07-29    1644.001091\n",
       " 2016-07-30    1943.500587\n",
       " 2016-07-31    3658.369995\n",
       " Freq: D, Name: id_1003, Length: 213, dtype: float64,\n",
       " 'id_1004': timestamp\n",
       " 2016-05-02    10760.002014\n",
       " 2016-05-03    10965.000000\n",
       " 2016-05-04    10315.001007\n",
       " 2016-05-05    10605.001007\n",
       " 2016-05-06    10567.002014\n",
       "                   ...     \n",
       " 2016-07-27     8622.002014\n",
       " 2016-07-28     9045.001984\n",
       " 2016-07-29     8733.002014\n",
       " 2016-07-30     6952.000000\n",
       " 2016-07-31     5964.000000\n",
       " Freq: D, Name: id_1004, Length: 91, dtype: float64}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1000</th>\n",
       "      <th>id_1001</th>\n",
       "      <th>id_1003</th>\n",
       "      <th>id_1004</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-27</th>\n",
       "      <td>-0.352586</td>\n",
       "      <td>0.218005</td>\n",
       "      <td>-0.626520</td>\n",
       "      <td>0.614958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-28</th>\n",
       "      <td>-0.457091</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>-0.746860</td>\n",
       "      <td>0.832297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-29</th>\n",
       "      <td>-0.496185</td>\n",
       "      <td>0.678968</td>\n",
       "      <td>-1.038231</td>\n",
       "      <td>0.671990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-30</th>\n",
       "      <td>-1.078102</td>\n",
       "      <td>1.163322</td>\n",
       "      <td>-0.378377</td>\n",
       "      <td>-0.243098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-31</th>\n",
       "      <td>-1.775801</td>\n",
       "      <td>1.152314</td>\n",
       "      <td>3.399801</td>\n",
       "      <td>-0.750738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id_1000   id_1001   id_1003   id_1004\n",
       "timestamp                                         \n",
       "2016-07-27 -0.352586  0.218005 -0.626520  0.614958\n",
       "2016-07-28 -0.457091  0.369366 -0.746860  0.832297\n",
       "2016-07-29 -0.496185  0.678968 -1.038231  0.671990\n",
       "2016-07-30 -1.078102  1.163322 -0.378377 -0.243098\n",
       "2016-07-31 -1.775801  1.152314  3.399801 -0.750738"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog_predict\n",
    "\n",
    "from skforecast.utils import preprocess_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1':     pred_boot_0  pred_boot_1  pred_boot_2  pred_boot_3\n",
       " 50     0.479244      0.95156     0.391981     0.350606,\n",
       " '2':     pred_boot_0  pred_boot_1  pred_boot_2  pred_boot_3\n",
       " 50     0.221191      0.33174     0.452264     0.191767}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(LinearRegression(), lags=3,\n",
    "                                              transformer_series=StandardScaler(),\n",
    "                                              differentiation=1)\n",
    "forecaster.fit(series=series, exog=exog['exog_1']\n",
    "            #    , store_last_window=['1']\n",
    "               )\n",
    "\n",
    "results = forecaster.predict_bootstrapping(\n",
    "                steps               = 1,\n",
    "                levels              = ['1', '2'],\n",
    "                n_boot              = 4, \n",
    "                exog                = exog_predict['exog_1'], \n",
    "                in_sample_residuals = True\n",
    "            )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1':     pred_boot_0  pred_boot_1\n",
       " 10          6.0          6.0\n",
       " 11          7.0          8.0\n",
       " 12          7.0          8.0,\n",
       " '2':     pred_boot_0  pred_boot_1\n",
       " 10         58.0         59.0\n",
       " 11         59.0         58.0\n",
       " 12         56.0         57.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_2 = pd.DataFrame({'1': pd.Series(np.arange(start=0, stop=10)), \n",
    "                       '2': pd.Series(np.arange(start=50, stop=60))})\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = HistGradientBoostingRegressor(\n",
    "                                                  random_state         = 123\n",
    "                                              ),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = None,\n",
    "                )\n",
    "forecaster.fit(series=series_2)\n",
    "_ = forecaster.predict_bootstrapping(steps=3, n_boot=2)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_levels = len(forecaster.series_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': array([[6., 6.],\n",
       "        [7., 8.],\n",
       "        [7., 8.]]),\n",
       " '2': array([[58., 59.],\n",
       "        [59., 58.],\n",
       "        [56., 57.]])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{level: _[:, i::n_levels] for i, level in enumerate(forecaster.series_names_in_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.23042070e-307, 4.67296746e-307, 1.69121096e-306],\n",
       "       [9.34596888e-307, 6.23037657e-307, 2.22526399e-307],\n",
       "       [6.23053614e-307, 7.56592338e-307, 5.33590898e-322]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_cols = np.empty((3, 3), dtype=float)\n",
    "exog_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = pd.DataFrame({'1': pd.Series(np.arange(start=0, stop=50)), \n",
    "#                        '2': pd.Series(np.arange(start=50, stop=100))})\n",
    "\n",
    "df_exog = pd.DataFrame(\n",
    "    {'exog_1': exog['exog_1'],\n",
    "        'exog_2': ['a', 'b'] * 25,\n",
    "        'exog_3': pd.Categorical(['F', 'G', 'H', 'I', 'J'] * 10)}\n",
    ")\n",
    "\n",
    "exog_predict = df_exog.copy()\n",
    "exog_predict.index = pd.RangeIndex(start=50, stop=100)\n",
    "\n",
    "categorical_features = df_exog.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "transformer_exog = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            categorical_features\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                    ).set_output(transform=\"pandas\")\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                    regressor          = HistGradientBoostingRegressor(\n",
    "                                                  categorical_features = categorical_features,\n",
    "                                                  random_state         = 123\n",
    "                                              ),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = None,\n",
    "                    transformer_exog   = transformer_exog\n",
    "                )\n",
    "forecaster.fit(series=series, exog=df_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01772315, 1.73981623],\n",
       "       [0.05236473, 1.76946476],\n",
       "       [0.08680601, 1.801424  ],\n",
       "       [0.12114773, 1.83453189],\n",
       "       [0.15543994, 1.86821077]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster._recursive_predict(\n",
    "                      steps            = 5,\n",
    "                      levels           = levels,\n",
    "                      last_window      = last_window,\n",
    "                      exog_values_dict = exog_values_dict\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "from skforecast.preprocessing import TimeSeriesDifferentiator\n",
    "\n",
    "# Fixtures\n",
    "series = np.array([1, 4, 8, 10, 13, 22, 40, 46, 55, 70, 71], dtype=float)\n",
    "y = np.array([1, 4, 8, 10, 13, 22, 40, 46], dtype=float)\n",
    "next_window = np.array([55, 70, 71], dtype=float)\n",
    "next_window_diff_1 = np.array([9., 15., 1.], dtype=float)\n",
    "next_window_diff_2 = np.array([3., 6., -14.], dtype=float)\n",
    "next_window_diff_3 = np.array([15., 3., -20.], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(46.0)]\n",
      "[nan  3.  4.  2.  3.  9. 18.  6.]\n",
      "[np.float64(1.0)]\n",
      "[ 1.  4.  8. 10. 13. 22. 40. 46.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([55., 70., 71.])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = 1\n",
    "next_window_diff = next_window_diff_1\n",
    "\n",
    "transformer = TimeSeriesDifferentiator(order=order)\n",
    "transformer.fit_transform(y)\n",
    "print(transformer.last_values)\n",
    "print(transformer.transform(y))\n",
    "y_transformed = transformer.transform(y)\n",
    "print(transformer.initial_values)\n",
    "print(transformer.inverse_transform(y_transformed))\n",
    "results = transformer.inverse_transform_next_window(next_window_diff)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "from skforecast.preprocessing import TimeSeriesDifferentiator\n",
    "\n",
    "# Fixtures\n",
    "series = np.array([1, 4, 8, 10, 13, 22, 40, 46, 55, 70, 71], dtype=float)\n",
    "series_2d = np.concatenate([series.reshape(-1, 1), series.reshape(-1, 1)], axis=1)\n",
    "\n",
    "y = np.array([1, 4, 8, 10, 13, 22, 40, 46], dtype=float)\n",
    "y_2d = np.concatenate([y.reshape(-1, 1), y.reshape(-1, 1)], axis=1)\n",
    "\n",
    "next_window = np.array([55, 70, 71], dtype=float)\n",
    "next_window_diff_1 = np.array([9., 15., 1.], dtype=float)\n",
    "next_window_diff_2 = np.array([3., 6., -14.], dtype=float)\n",
    "next_window_diff_3 = np.array([15., 3., -20.], dtype=float)\n",
    "\n",
    "next_window_diff_1_2d = np.concatenate([next_window_diff_1.reshape(-1, 1), next_window_diff_1.reshape(-1, 1)], axis=1)\n",
    "next_window_diff_2_2d = np.concatenate([next_window_diff_2.reshape(-1, 1), next_window_diff_2.reshape(-1, 1)], axis=1)\n",
    "next_window_diff_3_2d = np.concatenate([next_window_diff_3.reshape(-1, 1), next_window_diff_3.reshape(-1, 1)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(46.0)]\n",
      "[nan  3.  4.  2.  3.  9. 18.  6.]\n",
      "[np.float64(1.0)]\n",
      "[ 1.  4.  8. 10. 13. 22. 40. 46.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([55., 70., 71.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = 1\n",
    "next_window_diff = next_window_diff_1_2d\n",
    "\n",
    "order = 2\n",
    "next_window_diff = next_window_diff_2_2d\n",
    "\n",
    "# order = 3\n",
    "# next_window_diff = next_window_diff_3_2d\n",
    "\n",
    "order = 1\n",
    "next_window_diff = next_window_diff_1\n",
    "\n",
    "transformer = TimeSeriesDifferentiator(order=order)\n",
    "transformer.fit_transform(y)\n",
    "print(transformer.last_values)\n",
    "print(transformer.transform(y))\n",
    "y_transformed = transformer.transform(y)\n",
    "print(transformer.initial_values)\n",
    "print(transformer.inverse_transform(y_transformed))\n",
    "results = transformer.inverse_transform_next_window(next_window_diff)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import norm\n",
    "\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.exceptions import UnknownLevelWarning\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "\n",
    "# Fixtures\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import series\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog\n",
    "from skforecast.ForecasterAutoregMultiSeries.tests.fixtures_ForecasterAutoregMultiSeries import exog_predict\n",
    "\n",
    "transformer_exog = ColumnTransformer(\n",
    "                       [('scale', StandardScaler(), ['exog_1']),\n",
    "                        ('onehot', OneHotEncoder(), ['exog_2'])],\n",
    "                       remainder = 'passthrough',\n",
    "                       verbose_feature_names_out = False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                     regressor          = LinearRegression(),\n",
    "                     lags               = 3,\n",
    "                     transformer_series = StandardScaler(),\n",
    "                     transformer_exog   = transformer_exog,\n",
    "                 )\n",
    "    \n",
    "forecaster.fit(series=series, exog=exog)\n",
    "results = forecaster.predict_quantiles(\n",
    "                steps               = 2,\n",
    "                quantiles           = [0.05, 0.55, 0.95],\n",
    "                levels              = '1',\n",
    "                exog                = exog_predict,\n",
    "                n_boot              = 4,\n",
    "                in_sample_residuals = True,\n",
    "                suppress_warnings   = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.128375  , 0.33920342, 0.4715764 ],\n",
       "       [0.09385929, 0.32079042, 0.62315962]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5061193, 3.5061193, 3.5061193, 2.5061193]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.48307367, 2.48307367, 4.48307367, 4.48307367]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['3'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
