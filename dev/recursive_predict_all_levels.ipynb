{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Joaqu√≠n Amat\\\\Documents\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for series: StandardScaler() \n",
       "Transformer for exog: StandardScaler() \n",
       "Series encoding: onehot \n",
       "Window size: 5 \n",
       "Series levels (names): ['item_1', 'item_2', 'item_3'] \n",
       "Series weights: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['exog_1', 'exog_2'] \n",
       "Training range: [\"'item_1': ['2012-01-01', '2014-07-15']\", \"'item_2': ['2012-01-01', '2014-07-15']\", \"'item_3': ['2012-01-01', '2014-07-15']\"] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: boosting_type: gbdt, class_weight: None, colsample_bytree: 1.0, importance_type: split, learning_rate: 0.1, ... \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-21 22:18:47 \n",
       "Last fit date: 2024-08-21 22:18:47 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "\n",
    "# Data download\n",
    "# ==============================================================================\n",
    "#data = fetch_dataset(name=\"items_sales\")\n",
    "#data.to_parquet('items_sales.parquet', index=True)\n",
    "data = pd.read_parquet('items_sales.parquet')\n",
    "data = data.asfreq('D')\n",
    "data.head()\n",
    "exog = pd.DataFrame({\n",
    "    'exog_1': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    'exog_2': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "}, index=data.index)\n",
    "\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "\n",
    "# Create and train ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 5,\n",
    "                 encoding           = 'onehot',\n",
    "                 transformer_series = StandardScaler(),\n",
    "                 transformer_exog   = StandardScaler(),\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[99., 99.],\n",
       "        [99., 99.]]),\n",
       " 2: array([[999., 999.],\n",
       "        [999., 999.]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "n_levels = len(levels)\n",
    "lags = np.array([1, 2, 3, 4, 5])\n",
    "steps = 2\n",
    "lags_shape = len(lags)\n",
    "exog_shape = 2\n",
    "encoding = 'onehot'\n",
    "series_col_names = levels\n",
    "encoding_mapping = {'item_1': 0, 'item_2': 1, 'item_3': 2}\n",
    "# Exog es un diccionario donde las claves son el step y los son numpy arrays en los\n",
    "# que cada fila es un level y cada columna es una variable exogena.\n",
    "exog = {\n",
    "    1:np.full(shape=(steps, exog_shape), fill_value=99, dtype=float),\n",
    "    2:np.full(shape=(steps, exog_shape), fill_value=999, dtype=float),\n",
    "}\n",
    "exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if encoding is not None:\n",
    "    if encoding == 'onehot':\n",
    "        levels_encoded = np.zeros((n_levels, len(series_col_names)), dtype=float)\n",
    "        for idx, level in enumerate(levels):\n",
    "            if level in series_col_names:\n",
    "                levels_encoded[idx, series_col_names.index(level)] = 1.\n",
    "    else:\n",
    "        levels_encoded = np.array([encoding_mapping.get(level, None) for level in levels], dtype='float64').reshape(-1, 1)\n",
    "    levels_encoded_shape = levels_encoded.shape[1]\n",
    "else:\n",
    "    levels_encoded_shape = 0\n",
    "levels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window =  np.full(shape=(lags_shape, n_levels), fill_value=5, dtype=float)\n",
    "predictions =  np.full(shape=(steps, n_levels), fill_value=np.nan, dtype=float)\n",
    "print(last_window)\n",
    "print(predictions)\n",
    "last_window = np.concatenate((last_window, predictions), axis=0)\n",
    "last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shape = lags_shape + levels_encoded_shape + exog_shape\n",
    "features = np.full(shape=(n_levels, features_shape), fill_value=np.nan, dtype=float)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan,  1.,  0.,  0., nan, nan],\n",
       "       [nan, nan, nan, nan, nan,  0.,  1.,  0., nan, nan],\n",
       "       [nan, nan, nan, nan, nan,  0.,  0.,  1., nan, nan]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if encoding is not None:\n",
    "    features[:, lags_shape:lags_shape + levels_encoded_shape] = levels_encoded\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.,  5.,  5.,  1.,  0.,  0., nan, nan],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  1.,  0., nan, nan],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  0.,  1., nan, nan]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 1\n",
    "i = 0\n",
    "features[:, :lags_shape] = last_window[-lags - (steps - i), :].transpose()\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.,  5.,  5.,  1.,  0.,  0., 99., 99.],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  1.,  0., 99., 99.],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  0.,  1., 99., 99.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if exog is not None:\n",
    "    features[:, -exog_shape:] = exog[step][i, ].transpose()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16235447, 1.32205227, 1.15616982])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = forecaster.regressor.predict(features)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16235447, 1.32205227, 1.15616982],\n",
       "       [       nan,        nan,        nan]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[i, :] = pred\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.        , 5.        , 5.        ],\n",
       "       [5.        , 5.        , 5.        ],\n",
       "       [5.        , 5.        , 5.        ],\n",
       "       [5.        , 5.        , 5.        ],\n",
       "       [5.        , 5.        , 5.        ],\n",
       "       [1.16235447, 1.32205227, 1.15616982],\n",
       "       [       nan,        nan,        nan]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window[-(steps - i), :] = pred\n",
    "last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fetch_dataset(name=\"items_sales\")\n",
    "# data.to_parquet('items_sales_2.parquet', index=True)\n",
    "data = pd.read_parquet(\"items_sales_2.parquet\")\n",
    "data = data.asfreq(\"D\")\n",
    "data.head()\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "        \"exog_2\": np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    },\n",
    "    index=data.index,\n",
    ")\n",
    "\n",
    "end_train = \"2014-07-15 23:59:00\"\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test = data.loc[end_train:, :].copy()\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index])\n",
    "\n",
    "(last_window_values_dict, exog_values_dict, levels, prediction_index, _) = (\n",
    "    forecaster._create_predict_inputs(\n",
    "        steps=2, levels=None, last_window=None, exog=exog.loc[data_test.index]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_1': array([[-0.16900541, -0.15968014],\n",
       "        [-0.13210193, -0.09496689]]),\n",
       " 'item_2': array([[-0.16900541, -0.15968014],\n",
       "        [-0.13210193, -0.09496689]]),\n",
       " 'item_3': array([[-0.16900541, -0.15968014],\n",
       "        [-0.13210193, -0.09496689]])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16900541, -0.15968014],\n",
       "       [-0.13210193, -0.09496689],\n",
       "       [-0.16900541, -0.15968014],\n",
       "       [-0.13210193, -0.09496689],\n",
       "       [-0.16900541, -0.15968014],\n",
       "       [-0.13210193, -0.09496689]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_values = np.concat(list(exog_values_dict.values()))\n",
    "exog_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[-0.16900541, -0.15968014],\n",
       "        [-0.16900541, -0.15968014],\n",
       "        [-0.16900541, -0.15968014]]),\n",
       " 2: array([[-0.13210193, -0.09496689],\n",
       "        [-0.13210193, -0.09496689],\n",
       "        [-0.13210193, -0.09496689]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog_values_dict_2 = {}\n",
    "for i in range(steps):\n",
    "    exog_values_dict_2[i+1] = exog_values[i::steps, :]\n",
    "exog_values_dict_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_old = forecaster.predict(steps=50, exog=exog.loc[data_test.index])\n",
    "predictions_new = forecaster.predict_new(steps=50, exog=exog.loc[data_test.index])\n",
    "assert predictions_old.equals(predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (365, 1000)\n"
     ]
    }
   ],
   "source": [
    "n_series = 1000\n",
    "n=365\n",
    "index = pd.date_range(start='2021-01-01',periods=n, freq=\"D\")\n",
    "series = [pd.Series(np.random.normal(size=n), index=index, name=f\"series_{i+1}\") for i in range(n_series)]\n",
    "data = pd.concat(series, axis=1)\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1, n_estimators=20),\n",
    "                 lags               = 5,\n",
    "                 encoding           = 'onehot',\n",
    "                 transformer_series = StandardScaler(),\n",
    "             )\n",
    "forecaster.fit(series = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time: 5.589584360003937 , std: 0.5060823248948181, max: 6.178835600032471, min: 4.852042399987113\n",
      "Mean time: 1.8232917400076984 , std: 0.13196965044550993, max: 2.0850156000233255, min: 1.7260719999903813\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict(steps=5)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"Mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")\n",
    "\n",
    "def benchmark_function():\n",
    "    forecaster.predict_new(steps=5)\n",
    "times = timeit.repeat(benchmark_function, repeat=5, number=1)\n",
    "times = np.array(times)\n",
    "print(f\"Mean time: {times.mean()} , std: {times.std()}, max: {times.max()}, min: {times.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert forecaster.predict(steps=5).equals(forecaster.predict_new(steps=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
