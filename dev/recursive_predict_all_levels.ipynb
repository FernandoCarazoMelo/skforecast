{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/varios/skforecast'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_sales\n",
      "-----------\n",
      "Simulated time series for the sales of 3 different items.\n",
      "Simulated data.\n",
      "Shape of the dataset: (1097, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================ \n",
       "ForecasterAutoregMultiSeries \n",
       "============================ \n",
       "Regressor: LGBMRegressor(random_state=123, verbose=-1) \n",
       "Lags: [1 2 3 4 5] \n",
       "Transformer for series: None \n",
       "Transformer for exog: None \n",
       "Series encoding: onehot \n",
       "Window size: 5 \n",
       "Series levels (names): ['item_1', 'item_2', 'item_3'] \n",
       "Series weights: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Exogenous included: True \n",
       "Type of exogenous variable: <class 'pandas.core.frame.DataFrame'> \n",
       "Exogenous variables names: ['exog_1', 'exog_2'] \n",
       "Training range: [\"'item_1': ['2012-01-01', '2014-07-15']\", \"'item_2': ['2012-01-01', '2014-07-15']\", \"'item_3': ['2012-01-01', '2014-07-15']\"] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: D \n",
       "Regressor parameters: boosting_type: gbdt, class_weight: None, colsample_bytree: 1.0, importance_type: split, learning_rate: 0.1, ... \n",
       "fit_kwargs: {} \n",
       "Creation date: 2024-08-16 12:30:58 \n",
       "Last fit date: 2024-08-16 12:30:58 \n",
       "Skforecast version: 0.13.0 \n",
       "Python version: 3.12.4 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import bayesian_search_forecaster_multiseries\n",
    "\n",
    "\n",
    "# Data download\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(name=\"items_sales\")\n",
    "data.head()\n",
    "exog = pd.DataFrame({\n",
    "    'exog_1': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "    'exog_2': np.random.normal(loc=0, scale=1, size=data.shape[0]),\n",
    "}, index=data.index)\n",
    "\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "\n",
    "# Create and train ForecasterAutoregMultiSeries\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags               = 5,\n",
    "                 encoding           = 'onehot',\n",
    "                 transformer_series = None,\n",
    "                 transformer_exog   = None,\n",
    "                 weight_func        = None,\n",
    "                 series_weights     = None,\n",
    "                 differentiation    = None,\n",
    "                 dropna_from_series = False,\n",
    "                 fit_kwargs         = None,\n",
    "                 forecaster_id      = None\n",
    "             )\n",
    "\n",
    "forecaster.fit(series=data_train, exog=exog.loc[data_train.index])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recursive_predict_all_levels\u001b[39m(\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      3\u001b[0m         steps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      4\u001b[0m         levels: \u001b[38;5;28mlist\u001b[39m,\n\u001b[1;32m      5\u001b[0m         last_window: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m----> 6\u001b[0m         exog: \u001b[43mOptional\u001b[49m[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        Predict n steps for one or multiple levels. It is an iterative process\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        in which, each prediction, is used as a predictor for the next step.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         n_levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(levels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Optional' is not defined"
     ]
    }
   ],
   "source": [
    "def _recursive_predict_all_levels(\n",
    "    self,\n",
    "    steps: int,\n",
    "    levels: list,\n",
    "    last_window: np.ndarray,\n",
    "    exog: Optional[np.ndarray] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict n steps for one or multiple levels. It is an iterative process\n",
    "    in which, each prediction, is used as a predictor for the next step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    steps : int\n",
    "        Number of future steps predicted.\n",
    "    levels : list\n",
    "        Time series to be predicted.\n",
    "    last_window : numpy ndarray\n",
    "        Series values used to create the features (lags) needed in the\n",
    "        first iteration of the prediction (t + 1).\n",
    "    exog : numpy ndarray, default `None`\n",
    "        Exogenous variable/s included as predictor/s.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : numpy ndarray\n",
    "        Predicted values.\n",
    "\n",
    "    \"\"\"\n",
    "    n_levels = len(levels)\n",
    "\n",
    "    if self.encoding is not None:\n",
    "        if self.encoding == \"onehot\":\n",
    "            levels_encoded = np.zeros(\n",
    "                (n_levels, len(self.series_col_names)), dtype=float\n",
    "            )\n",
    "            for idx, level in enumerate(levels):\n",
    "                if level in self.series_col_names:\n",
    "                    levels_encoded[idx, self.series_col_names.index(level)] = 1.0\n",
    "        else:\n",
    "            levels_encoded = np.array(\n",
    "                [self.encoding_mapping.get(level, None) for level in levels],\n",
    "                dtype=\"float64\",\n",
    "            ).reshape(-1, 1)\n",
    "        levels_encoded_shape = levels_encoded.shape[1]\n",
    "    else:\n",
    "        levels_encoded_shape = 0\n",
    "\n",
    "    lags_shape = len(self.lags)\n",
    "    exog_shape = exog.shape[1] if exog is not None else 0\n",
    "\n",
    "    features_shape = lags_shape + levels_encoded_shape + exog_shape\n",
    "    features = np.full(shape=(n_levels, features_shape), fill_value=np.nan, dtype=float)\n",
    "    if self.encoding is not None:\n",
    "        features[lags_shape : lags_shape + levels_encoded_shape] = levels_encoded\n",
    "\n",
    "    predictions = np.full(shape=(steps, n_levels), fill_value=np.nan, dtype=float)\n",
    "    last_window = np.concatenate((last_window, predictions), axis=0)\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        features[:, :lags_shape] = last_window[-self.lags - (steps - i), :]\n",
    "        if exog is not None:\n",
    "            features[:, -exog_shape:] = exog[i,].transpose()\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # Suppress scikit-learn warning: \"X does not have valid feature names,\n",
    "            # but NoOpTransformer was fitted with feature names\".\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            pred = self.regressor.predict(features.reshape(1, -1)).ravel()[0]\n",
    "            predictions[1, :] = pred\n",
    "\n",
    "        # Update `last_window` values. The first position is discarded and\n",
    "        # the new prediction is added at the end.\n",
    "        last_window[-(steps - i), :] = pred\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "n_levels = len(levels)\n",
    "lags = np.array([1, 2, 3, 4, 5])\n",
    "steps = 2\n",
    "lags_shape = len(lags)\n",
    "exog_shape = 2\n",
    "encoding = 'onehot'\n",
    "series_col_names = levels\n",
    "encoding_mapping = {'item_1': 0, 'item_2': 1, 'item_3': 2}\n",
    "exog = np.full(shape=(steps, exog_shape), fill_value=99, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if encoding is not None:\n",
    "    if encoding == 'onehot':\n",
    "        levels_encoded = np.zeros((n_levels, len(series_col_names)), dtype=float)\n",
    "        for idx, level in enumerate(levels):\n",
    "            if level in series_col_names:\n",
    "                levels_encoded[idx, series_col_names.index(level)] = 1.\n",
    "    else:\n",
    "        levels_encoded = np.array([encoding_mapping.get(level, None) for level in levels], dtype='float64').reshape(-1, 1)\n",
    "    levels_encoded_shape = levels_encoded.shape[1]\n",
    "else:\n",
    "    levels_encoded_shape = 0\n",
    "levels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]\n",
      " [5. 5. 5.]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window =  np.full(shape=(lags_shape, n_levels), fill_value=5, dtype=float)\n",
    "predictions =  np.full(shape=(steps, n_levels), fill_value=np.nan, dtype=float)\n",
    "print(last_window)\n",
    "print(predictions)\n",
    "last_window = np.concatenate((last_window, predictions), axis=0)\n",
    "last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shape = lags_shape + levels_encoded_shape + exog_shape\n",
    "features = np.full(shape=(n_levels, features_shape), fill_value=np.nan, dtype=float)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, nan,  1.,  0.,  0., nan, nan],\n",
       "       [nan, nan, nan, nan, nan,  0.,  1.,  0., nan, nan],\n",
       "       [nan, nan, nan, nan, nan,  0.,  0.,  1., nan, nan]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if encoding is not None:\n",
    "    features[:, lags_shape:lags_shape + levels_encoded_shape] = levels_encoded\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.,  5.,  5.,  1.,  0.,  0., nan, nan],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  1.,  0., nan, nan],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  0.,  1., nan, nan]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "features[:, :lags_shape] = last_window[-lags - (steps - i), :].transpose()\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.,  5.,  5.,  1.,  0.,  0., 99., 99.],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  1.,  0., 99., 99.],\n",
       "       [ 5.,  5.,  5.,  5.,  5.,  0.,  0.,  1., 99., 99.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if exog is not None:\n",
    "    features[:, -exog_shape:] = exog[i, ].transpose()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.40817988, 11.38620842, 11.40817988])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = forecaster.regressor.predict(features)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.40817988, 11.38620842, 11.40817988],\n",
       "       [        nan,         nan,         nan]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[i, :] = pred\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [ 5.,  5.,  5.],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  5.        ,  5.        ],\n",
       "       [ 5.        ,  5.        ,  5.        ],\n",
       "       [ 5.        ,  5.        ,  5.        ],\n",
       "       [ 5.        ,  5.        ,  5.        ],\n",
       "       [ 5.        ,  5.        ,  5.        ],\n",
       "       [11.40817988, 11.38620842, 11.40817988],\n",
       "       [        nan,         nan,         nan]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window[-(steps - i), :] = pred\n",
    "last_window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
