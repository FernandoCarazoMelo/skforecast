{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from skforecast.ForecasterAutoregMultiSeries import ForecasterAutoregMultiSeries\n",
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "from skforecast.model_selection_multiseries import grid_search_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Optional, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm.auto import tqdm\n",
    "import sklearn.pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_log_error,\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler, RandomSampler\n",
    "\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "from skforecast.exceptions import IgnoredArgumentWarning\n",
    "from skforecast.utils import check_backtesting_input\n",
    "from skforecast.utils import select_n_jobs_backtesting\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # disable optuna logs\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(name)-10s %(levelname)-5s %(message)s', \n",
    "    level  = logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Data download\n",
    "# ==============================================================================\n",
    "url = (\n",
    "       'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/'\n",
    "       'data/simulated_items_sales.csv'\n",
    ")\n",
    "data = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Data preparation\n",
    "# ==============================================================================\n",
    "data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "data = data.set_index('date')\n",
    "data = data.asfreq('D')\n",
    "data = data.sort_index()\n",
    "data.head()\n",
    "\n",
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2012-01-01 00:00:00 --- 2014-07-15 00:00:00   (n=927)\n",
      "Test dates  : 2014-07-16 00:00:00 --- 2015-01-01 00:00:00   (n=170)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-val-test\n",
    "# ==============================================================================\n",
    "end_train = '2014-07-15 23:59:00'\n",
    "data_train = data.loc[:end_train, :].copy()\n",
    "data_test  = data.loc[end_train:, :].copy()\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}   \"\n",
    "    f\"(n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}   \"\n",
    "    f\"(n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection_multiseries import backtesting_forecaster_multiseries\n",
    "\n",
    "def _bayesian_search_optuna_multiseries(\n",
    "    forecaster,\n",
    "    series: pd.DataFrame,\n",
    "    search_space: Callable,\n",
    "    steps: int,\n",
    "    metric: Union[str, Callable, list],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=True,\n",
    "    gap: int=0,\n",
    "    allow_incomplete_fold: bool=True,\n",
    "    levels: Optional[Union[str, list]]=None,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    lags_grid: Optional[list]=None,\n",
    "    refit: Optional[Union[bool, int]]=False,\n",
    "    n_trials: int=10,\n",
    "    random_state: int=123,\n",
    "    return_best: bool=True,\n",
    "    n_jobs: Optional[Union[int, str]]='auto',\n",
    "    verbose: bool=True,\n",
    "    show_progress: bool=True,\n",
    "    kwargs_create_study: dict={},\n",
    "    kwargs_study_optimize: dict={}\n",
    ") -> Tuple[pd.DataFrame, object]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    if return_best and exog is not None and (len(exog) != len(series)):\n",
    "        raise ValueError(\n",
    "            (f\"`exog` must have same number of samples as `series`. \"\n",
    "             f\"length `exog`: ({len(exog)}), length `series`: ({len(series)})\")\n",
    "        )\n",
    "\n",
    "    if type(forecaster).__name__ in ['ForecasterAutoregMultiSeries', \n",
    "                                     'ForecasterAutoregMultiSeriesCustom']  \\\n",
    "        and levels is not None and not isinstance(levels, (str, list)):\n",
    "        raise TypeError(\n",
    "            (\"`levels` must be a `list` of column names, a `str` of a column \"\n",
    "             \"name or `None`.\")\n",
    "        )\n",
    "\n",
    "    if type(forecaster).__name__ == 'ForecasterAutoregMultiVariate':\n",
    "        if levels and levels != forecaster.level and levels != [forecaster.level]:\n",
    "            warnings.warn(\n",
    "                (f\"`levels` argument have no use when the forecaster is of type \"\n",
    "                 f\"ForecasterAutoregMultiVariate. The level of this forecaster \"\n",
    "                 f\"is {forecaster.level}, to predict another level, change \"\n",
    "                 f\"the `level` argument when initializing the forecaster. \\n\"),\n",
    "                 IgnoredArgumentWarning\n",
    "            )\n",
    "        levels = [forecaster.level]\n",
    "    else:\n",
    "        if levels is None:\n",
    "            # Forecaster can be not fitted, so cannot use self.series_col_names\n",
    "            levels = list(series.columns) \n",
    "        elif isinstance(levels, str):\n",
    "            levels = [levels]\n",
    "\n",
    "    if type(forecaster).__name__ == 'ForecasterAutoregMultiSeriesCustom':\n",
    "        if lags_grid is not None:\n",
    "            warnings.warn(\n",
    "                \"`lags_grid` ignored if forecaster is an instance of `ForecasterAutoregMultiSeriesCustom`.\",\n",
    "                IgnoredArgumentWarning\n",
    "            )\n",
    "        lags_grid = ['custom predictors']\n",
    "        \n",
    "    elif lags_grid is None:\n",
    "        lags_grid = [forecaster.lags]\n",
    "   \n",
    "    lags_list = []\n",
    "    params_list = []\n",
    "    results_opt_best = None\n",
    "    if not isinstance(metric, list):\n",
    "        metric = [metric] \n",
    "    metric_dict = {(m if isinstance(m, str) else m.__name__): [] \n",
    "                   for m in metric}\n",
    "    \n",
    "    if len(metric_dict) != len(metric):\n",
    "        raise ValueError(\n",
    "            \"When `metric` is a `list`, each metric name must be unique.\"\n",
    "        )\n",
    "\n",
    "    # Objective function using backtesting_forecaster\n",
    "    def _objective(\n",
    "        trial,\n",
    "        search_space          = search_space,\n",
    "        forecaster            = forecaster,\n",
    "        series                = series,\n",
    "        exog                  = exog,\n",
    "        steps                 = steps,\n",
    "        levels                = levels,\n",
    "        metric                = metric,\n",
    "        initial_train_size    = initial_train_size,\n",
    "        fixed_train_size      = fixed_train_size,\n",
    "        gap                   = gap,\n",
    "        allow_incomplete_fold = allow_incomplete_fold,\n",
    "        refit                 = refit,\n",
    "        n_jobs                = n_jobs,\n",
    "        verbose               = verbose\n",
    "    ) -> float:\n",
    "        \n",
    "        forecaster.set_params(search_space(trial))\n",
    "        \n",
    "        metrics_levels = backtesting_forecaster_multiseries(\n",
    "                             forecaster            = forecaster,\n",
    "                             series                = series,\n",
    "                             exog                  = exog,\n",
    "                             steps                 = steps,\n",
    "                             levels                = levels,\n",
    "                             metric                = metric,\n",
    "                             initial_train_size    = initial_train_size,\n",
    "                             fixed_train_size      = fixed_train_size,\n",
    "                             gap                   = gap,\n",
    "                             allow_incomplete_fold = allow_incomplete_fold,\n",
    "                             refit                 = refit,\n",
    "                             n_jobs                = n_jobs,\n",
    "                             verbose               = verbose,\n",
    "                             show_progress         = False\n",
    "                         )[0]\n",
    "        # Store metrics in the variable metric_values defined outside _objective.\n",
    "        nonlocal metric_values\n",
    "        metric_values.append(metrics_levels)\n",
    "\n",
    "        return abs(metrics_levels.iloc[:, 1].mean())\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Number of models compared: {n_trials*len(lags_grid)},\n",
    "         {n_trials} bayesian search in each lag configuration.\"\"\"\n",
    "    )\n",
    "\n",
    "    if show_progress:\n",
    "        lags_grid = tqdm(lags_grid, desc='lags grid', position=0)\n",
    "\n",
    "    for lags in lags_grid:\n",
    "        metric_values = [] # This variable will be modified inside _objective function. \n",
    "        # It is a trick to extract multiple values from _objective function since\n",
    "        # only the optimized value can be returned.\n",
    "\n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(lags)\n",
    "            lags = forecaster.lags.copy()\n",
    "        \n",
    "        if 'sampler' in kwargs_create_study.keys():\n",
    "            kwargs_create_study['sampler']._rng = np.random.RandomState(random_state)\n",
    "            kwargs_create_study['sampler']._random_sampler = RandomSampler(seed=random_state)\n",
    "\n",
    "        study = optuna.create_study(**kwargs_create_study)\n",
    "\n",
    "        if 'sampler' not in kwargs_create_study.keys():\n",
    "            study.sampler = TPESampler(seed=random_state)\n",
    "\n",
    "        study.optimize(_objective, n_trials=n_trials, **kwargs_study_optimize)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        if search_space(best_trial).keys() != best_trial.params.keys():\n",
    "            raise ValueError(\n",
    "                f\"\"\"Some of the key values do not match the search_space key names.\n",
    "                Dict keys     : {list(search_space(best_trial).keys())}\n",
    "                Trial objects : {list(best_trial.params.keys())}.\"\"\"\n",
    "            )\n",
    "        \n",
    "        for i, trial in enumerate(study.get_trials()):\n",
    "            params_list.append(trial.params)\n",
    "            lags_list.append(lags)\n",
    "\n",
    "            m_values = metric_values[i]\n",
    "            for m in metric:\n",
    "                m_name = m if isinstance(m, str) else m.__name__\n",
    "                metric_dict[m_name].append(m_values[m_name].mean())\n",
    "        \n",
    "        if results_opt_best is None:\n",
    "            results_opt_best = best_trial\n",
    "        else:\n",
    "            if best_trial.value < results_opt_best.value:\n",
    "                results_opt_best = best_trial\n",
    "        \n",
    "        print(metric_dict)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "                  'levels': [levels]*len(lags_list),\n",
    "                  'lags'  : lags_list,\n",
    "                  'params': params_list,\n",
    "                  **metric_dict\n",
    "              })\n",
    "\n",
    "    results = results.sort_values(by=list(metric_dict.keys())[0], ascending=True)\n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    if return_best:\n",
    "        \n",
    "        best_lags = results['lags'].iloc[0]\n",
    "        best_params = results['params'].iloc[0]\n",
    "        best_metric = results[list(metric_dict.keys())[0]].iloc[0]\n",
    "        \n",
    "        if type(forecaster).__name__ != 'ForecasterAutoregMultiSeriesCustom':\n",
    "            forecaster.set_lags(best_lags)\n",
    "        forecaster.set_params(best_params)\n",
    "        forecaster.fit(series=series, exog=exog, store_in_sample_residuals=True)\n",
    "        \n",
    "        print(\n",
    "            f\"`Forecaster` refitted using the best-found lags and parameters, \"\n",
    "            f\"and the whole data set: \\n\"\n",
    "            f\"  Lags: {best_lags} \\n\"\n",
    "            f\"  Parameters: {best_params}\\n\"\n",
    "            f\"  Backtesting metric: {best_metric}\\n\"\n",
    "            f\"  Levels: {results['levels'].iloc[0]}\\n\"\n",
    "        )\n",
    "            \n",
    "    return results, results_opt_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Forecaster multi series\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoregMultiSeries(\n",
    "                 regressor          = RandomForestRegressor(random_state=123),\n",
    "                 lags               = 2,\n",
    "                 transformer_series = StandardScaler(),\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 6,\n",
      "         3 bayesian search in each lag configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d1f28fdd7c46cc92fb4d6537ad0441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_absolute_error': [3.22344942620262, 3.6977824960678594, 3.467055410479105], 'mean_squared_error': [17.84917034121136, 23.649984681614825, 20.528829838529116]}\n",
      "{'mean_absolute_error': [3.22344942620262, 3.6977824960678594, 3.467055410479105, 3.001566882551417, 2.8922785933104365, 3.2342470300487243], 'mean_squared_error': [17.84917034121136, 23.649984681614825, 20.528829838529116, 18.234133437451117, 15.190501124742214, 18.321157453862853]}\n"
     ]
    }
   ],
   "source": [
    "# Grid search Multi Series\n",
    "# ==============================================================================\n",
    "lags_grid = [2, 4]\n",
    "\n",
    "# Regressor hyperparameters search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'     : trial.suggest_int('n_estimators', 10, 15),\n",
    "        'min_samples_leaf' : trial.suggest_int('min_samples_leaf', 1., 3),\n",
    "        'max_features'     : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "levels = ['item_1', 'item_2', 'item_3']\n",
    "\n",
    "results, _ = _bayesian_search_optuna_multiseries(\n",
    "              forecaster         = forecaster,\n",
    "              series             = data,\n",
    "              exog               = None,\n",
    "              levels             = levels, \n",
    "              lags_grid          = lags_grid,\n",
    "              search_space       = search_space,\n",
    "              steps              = 24,\n",
    "              metric             = ['mean_absolute_error', 'mean_squared_error'],\n",
    "              initial_train_size = len(data_train),\n",
    "              n_trials           = 3,\n",
    "              refit              = True,\n",
    "              fixed_train_size   = True,\n",
    "              return_best        = False,\n",
    "              n_jobs             = 'auto',\n",
    "              verbose            = False,\n",
    "              show_progress      = True,\n",
    "              kwargs_create_study   = {},\n",
    "              kwargs_study_optimize = {}\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>2.892279</td>\n",
       "      <td>15.190501</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>3.001567</td>\n",
       "      <td>18.234133</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>3.223449</td>\n",
       "      <td>17.849170</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>3.234247</td>\n",
       "      <td>18.321157</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 12, 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>3.467055</td>\n",
       "      <td>20.528830</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[item_1, item_2, item_3]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>3.697782</td>\n",
       "      <td>23.649985</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     levels          lags  \\\n",
       "4  [item_1, item_2, item_3]  [1, 2, 3, 4]   \n",
       "3  [item_1, item_2, item_3]  [1, 2, 3, 4]   \n",
       "0  [item_1, item_2, item_3]        [1, 2]   \n",
       "5  [item_1, item_2, item_3]  [1, 2, 3, 4]   \n",
       "2  [item_1, item_2, item_3]        [1, 2]   \n",
       "1  [item_1, item_2, item_3]        [1, 2]   \n",
       "\n",
       "                                              params  mean_absolute_error  \\\n",
       "4  {'n_estimators': 14, 'min_samples_leaf': 2, 'm...             2.892279   \n",
       "3  {'n_estimators': 14, 'min_samples_leaf': 1, 'm...             3.001567   \n",
       "0  {'n_estimators': 14, 'min_samples_leaf': 1, 'm...             3.223449   \n",
       "5  {'n_estimators': 12, 'min_samples_leaf': 2, 'm...             3.234247   \n",
       "2  {'n_estimators': 12, 'min_samples_leaf': 2, 'm...             3.467055   \n",
       "1  {'n_estimators': 14, 'min_samples_leaf': 2, 'm...             3.697782   \n",
       "\n",
       "   mean_squared_error  n_estimators  min_samples_leaf max_features  \n",
       "4           15.190501            14                 2         log2  \n",
       "3           18.234133            14                 1         sqrt  \n",
       "0           17.849170            14                 1         sqrt  \n",
       "5           18.321157            12                 2         sqrt  \n",
       "2           20.528830            12                 2         sqrt  \n",
       "1           23.649985            14                 2         log2  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_absolute_error']\n",
      "[   levels  mean_absolute_error\n",
      "0  item_1                    1\n",
      "1  item_2                    2\n",
      "2  item_3                    3]\n"
     ]
    }
   ],
   "source": [
    "print(metric)\n",
    "print(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   levels  mean_absolute_error\n",
      "0  item_1                    1\n",
      "1  item_2                    2\n",
      "2  item_3                    3\n"
     ]
    }
   ],
   "source": [
    "for m_values in metric_values:\n",
    "    print(m_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ['mean_absolute_error', 'mean_squared_error']\n",
    "metric_values = [pd.DataFrame({'levels': ['item_1', 'item_2', 'item_3'],\n",
    "                                'mean_absolute_error': [1, 2, 3], \n",
    "                               'mean_squared_error': [4, 5, 6]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_error  mean_squared_error\n",
       "0  item_1                    1                   4\n",
       "1  item_2                    2                   5\n",
       "2  item_3                    3                   6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   levels  mean_absolute_error  mean_squared_error\n",
       "0  item_1                    1                   4\n",
       "1  item_2                    2                   5\n",
       "2  item_3                    3                   6"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error\n",
      "levels\n",
      "mean_squared_error\n",
      "mean_absolute_error\n"
     ]
    }
   ],
   "source": [
    "for m, m_values in zip(metric, metric_values[0]):\n",
    "    m_name = m if isinstance(m, str) else m.__name__\n",
    "    \n",
    "    print(m_name)\n",
    "    print(m_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78d62c1713fdacd99ef7c429003c7324b36fbb551fb8b6860a7ea73e9338235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
